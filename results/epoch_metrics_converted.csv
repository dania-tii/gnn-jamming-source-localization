trial,combination,epochs,actuals,predictions,mae,mse,rmse
trial_1,cartesian_knn_minmax_noact,"['Epoch: 0, Train Loss: 0.390852187361036, Val Loss: 0.396319037359772', 'Epoch: 1, Train Loss: 0.391431567924363, Val Loss: 0.396906487643719', 'Epoch: 2, Train Loss: 0.386727038238730, Val Loss: 0.399139005239263', 'Epoch: 3, Train Loss: 0.385333506124360, Val Loss: 0.397812154708487', 'Epoch: 4, Train Loss: 0.382229089736938, Val Loss: 0.395312050075242', 'Epoch: 5, Train Loss: 0.392450419919831, Val Loss: 0.394685679087133', 'Epoch: 6, Train Loss: 0.379941274012838, Val Loss: 0.391580683489641', 'Epoch: 7, Train Loss: 0.377614364027977, Val Loss: 0.378313195299019', 'Epoch: 8, Train Loss: 0.349643947822707, Val Loss: 0.441613365303386', 'Epoch: 9, Train Loss: 0.309500801776137, Val Loss: 0.390451467398441', 'Epoch: 10, Train Loss: 0.249958459820066, Val Loss: 0.236725754132777', 'Epoch: 11, Train Loss: 0.157011434435844, Val Loss: 0.181139833999403', 'Epoch: 12, Train Loss: 0.145455360412598, Val Loss: 0.131048393746217', 'Epoch: 13, Train Loss: 0.118990520813635, Val Loss: 0.150645969492016', 'Epoch: 14, Train Loss: 0.124245067792279, Val Loss: 0.144730725297422', 'Epoch: 15, Train Loss: 0.111782774329185, Val Loss: 0.119043389956156', 'Epoch: 16, Train Loss: 0.103310430688517, Val Loss: 0.106320096236287', 'Epoch: 17, Train Loss: 0.081995758627142, Val Loss: 0.090175289773580', 'Epoch: 18, Train Loss: 0.074618944632156, Val Loss: 0.073561604162960', 'Epoch: 19, Train Loss: 0.064698129094073, Val Loss: 0.073321581902829', 'Epoch: 20, Train Loss: 0.062609852690782, Val Loss: 0.066848748561108', 'Epoch: 21, Train Loss: 0.057154312197651, Val Loss: 0.077086048370058', 'Epoch: 22, Train Loss: 0.055655497259327, Val Loss: 0.063946001457446', 'Epoch: 23, Train Loss: 0.056206833704242, Val Loss: 0.069879543741770', 'Epoch: 24, Train Loss: 0.060847380863769, Val Loss: 0.068054869771004', 'Epoch: 25, Train Loss: 0.058903623372316, Val Loss: 0.064156263728033', 'Epoch: 26, Train Loss: 0.052370377683214, Val Loss: 0.062239812009714', 'Epoch: 27, Train Loss: 0.046993644109794, Val Loss: 0.064238156897552', 'Epoch: 28, Train Loss: 0.059149373854910, Val Loss: 0.076059671062412', 'Epoch: 29, Train Loss: 0.055748893746308, Val Loss: 0.070214921326348', 'Epoch: 30, Train Loss: 0.058449099904725, Val Loss: 0.062394804801002', 'Epoch: 31, Train Loss: 0.057769523135253, Val Loss: 0.066652982749722', 'Epoch: 32, Train Loss: 0.061328003449099, Val Loss: 0.060055839067156', 'Epoch: 33, Train Loss: 0.051096096634865, Val Loss: 0.062153769261909', 'Epoch: 34, Train Loss: 0.053806426402714, Val Loss: 0.047779078284899', 'Epoch: 35, Train Loss: 0.047126051570688, Val Loss: 0.052488749903260', 'Epoch: 36, Train Loss: 0.047291922249964, Val Loss: 0.065893960270015', 'Epoch: 37, Train Loss: 0.054849303859685, Val Loss: 0.064017537191059', 'Epoch: 38, Train Loss: 0.047837113695485, Val Loss: 0.069944780432817', 'Epoch: 39, Train Loss: 0.055289513697582, Val Loss: 0.074607745828954', 'Epoch: 40, Train Loss: 0.050402322118836, Val Loss: 0.054636785139640', 'Epoch: 41, Train Loss: 0.053302174167974, Val Loss: 0.056569661606442', 'Epoch: 42, Train Loss: 0.048524819713618, Val Loss: 0.067363996848916', 'Epoch: 43, Train Loss: 0.051417414631162, Val Loss: 0.054014109752395', 'Epoch: 44, Train Loss: 0.054605951798814, Val Loss: 0.051426044016173', 'Epoch: 45, Train Loss: 0.045923909970692, Val Loss: 0.058174650213032', 'Epoch: 46, Train Loss: 0.039934168968882, Val Loss: 0.051962893286889', 'Epoch: 47, Train Loss: 0.049410037430269, Val Loss: 0.062982665092656', 'Epoch: 48, Train Loss: 0.052937695490462, Val Loss: 0.060212583027103', 'Epoch: 49, Train Loss: 0.058488233281033, Val Loss: 0.076421269638972', 'Epoch: 50, Train Loss: 0.064720158332161, Val Loss: 0.073444798588753', 'Epoch: 51, Train Loss: 0.056887753573912, Val Loss: 0.072765558943943', 'Epoch: 52, Train Loss: 0.048546059589301, Val Loss: 0.050945237278938', 'Epoch: 53, Train Loss: 0.037586672763739, Val Loss: 0.054214433964455', 'Epoch: 54, Train Loss: 0.036751686063196, Val Loss: 0.060428361295525', 'Epoch: 55, Train Loss: 0.043882974689560, Val Loss: 0.053207460226435', 'Epoch: 56, Train Loss: 0.035122398686196, Val Loss: 0.054149569435553', 'Epoch: 57, Train Loss: 0.042255997790822, Val Loss: 0.058437830119422', 'Epoch: 58, Train Loss: 0.041075736816440, Val Loss: 0.053814575527654', 'Epoch: 59, Train Loss: 0.045536346999662, Val Loss: 0.054826002568007', 'Epoch: 60, Train Loss: 0.036316647859556, Val Loss: 0.051554645327005', 'Epoch: 61, Train Loss: 0.037536777555943, Val Loss: 0.078581043914186', 'Epoch: 62, Train Loss: 0.044420571465577, Val Loss: 0.068340121119311', 'Epoch: 63, Train Loss: 0.040453832330448, Val Loss: 0.063637337844932', 'Epoch: 64, Train Loss: 0.044046760004546, Val Loss: 0.053139075298201', 'Epoch: 65, Train Loss: 0.041079762258700, Val Loss: 0.058057797790477', 'Epoch: 66, Train Loss: 0.034329066851309, Val Loss: 0.062025011714661', 'Epoch: 67, Train Loss: 0.040803714788386, Val Loss: 0.062534083584041', 'Epoch: 68, Train Loss: 0.033471368120185, Val Loss: 0.058070490475405', 'Epoch: 69, Train Loss: 0.037407167521971, Val Loss: 0.045359841124578', 'Epoch: 70, Train Loss: 0.034773290822549, Val Loss: 0.064600068878270', 'Epoch: 71, Train Loss: 0.033268351773066, Val Loss: 0.044070811039119', 'Epoch: 72, Train Loss: 0.029767877422273, Val Loss: 0.057992212361459', 'Epoch: 73, Train Loss: 0.032225566117891, Val Loss: 0.067719315658465', 'Epoch: 74, Train Loss: 0.039641698423241, Val Loss: 0.063410827494932', 'Epoch: 75, Train Loss: 0.032164708045977, Val Loss: 0.050383836313179', 'Epoch: 76, Train Loss: 0.032942376498665, Val Loss: 0.052847040817142', 'Epoch: 77, Train Loss: 0.035615112100329, Val Loss: 0.057944318251402', 'Epoch: 78, Train Loss: 0.036122006763305, Val Loss: 0.052908959262299', 'Epoch: 79, Train Loss: 0.038217128254473, Val Loss: 0.059761943464929', 'Epoch: 80, Train Loss: 0.039027561367090, Val Loss: 0.056645267360815', 'Epoch: 81, Train Loss: 0.034043880578663, Val Loss: 0.040041968565096', 'Epoch: 82, Train Loss: 0.034698800050787, Val Loss: 0.058454558874170', 'Epoch: 83, Train Loss: 0.032254182467503, Val Loss: 0.055847260988120', 'Epoch: 84, Train Loss: 0.027740096806415, Val Loss: 0.044653429903767', 'Epoch: 85, Train Loss: 0.031035518672849, Val Loss: 0.052725680228887', 'Epoch: 86, Train Loss: 0.025139158059444, Val Loss: 0.068565447673653', 'Epoch: 87, Train Loss: 0.033494725424264, Val Loss: 0.059523052648839', 'Epoch: 88, Train Loss: 0.032155212014914, Val Loss: 0.047428010610130', 'Epoch: 89, Train Loss: 0.032015561658357, Val Loss: 0.065384508470412', 'Epoch: 90, Train Loss: 0.032557666035635, Val Loss: 0.067264807735090', 'Epoch: 91, Train Loss: 0.037037647728409, Val Loss: 0.069233835195050', 'Epoch: 92, Train Loss: 0.037813903763890, Val Loss: 0.056031475549169', 'Epoch: 93, Train Loss: 0.032330208591052, Val Loss: 0.051356784830039', 'Epoch: 94, Train Loss: 0.033315386357052, Val Loss: 0.065762630692034', 'Epoch: 95, Train Loss: 0.039197963928538, Val Loss: 0.053854975736502', 'Epoch: 96, Train Loss: 0.033478772932930, Val Loss: 0.063882479839253', 'Epoch: 97, Train Loss: 0.033949470679675, Val Loss: 0.066763450702031', 'Epoch: 98, Train Loss: 0.042877157085708, Val Loss: 0.045110294426029', 'Epoch: 99, Train Loss: 0.028481216968170, Val Loss: 0.046501222094803', 'Epoch: 100, Train Loss: 0.037282420987529, Val Loss: 0.065443688989476', 'Epoch: 101, Train Loss: 0.031771065135087, Val Loss: 0.059384153309194', 'Epoch: 102, Train Loss: 0.028647075673299, Val Loss: 0.065384747883813', 'Epoch: 103, Train Loss: 0.031256703792938, Val Loss: 0.060165511895761', 'Epoch: 104, Train Loss: 0.027345865432705, Val Loss: 0.054857238224058', 'Epoch: 105, Train Loss: 0.025141065008938, Val Loss: 0.063280078441356', 'Epoch: 106, Train Loss: 0.029513228551618, Val Loss: 0.069018630593112', 'Epoch: 107, Train Loss: 0.030352934795831, Val Loss: 0.064521284548171', 'Epoch: 108, Train Loss: 0.030973703334374, Val Loss: 0.054544858803803', 'Epoch: 109, Train Loss: 0.025928374912058, Val Loss: 0.056839501442896', 'Epoch: 110, Train Loss: 0.025066448508629, Val Loss: 0.047992378247507', 'Epoch: 111, Train Loss: 0.025308199559471, Val Loss: 0.055975380494739', 'Epoch: 112, Train Loss: 0.029648321015494, Val Loss: 0.066377177270073', 'Epoch: 113, Train Loss: 0.027641722001135, Val Loss: 0.054609922974399', 'Epoch: 114, Train Loss: 0.029999770224094, Val Loss: 0.056312526999549', 'Epoch: 115, Train Loss: 0.030827559663781, Val Loss: 0.069474897770719', 'Epoch: 116, Train Loss: 0.024178061235164, Val Loss: 0.054033581788341', 'Epoch: 117, Train Loss: 0.022452233226172, Val Loss: 0.050024537934047', 'Epoch: 118, Train Loss: 0.030107120916780, Val Loss: 0.063103113125897', 'Epoch: 119, Train Loss: 0.028410652319768, Val Loss: 0.051911339333112', 'Epoch: 120, Train Loss: 0.025305850963507, Val Loss: 0.055239751737452', 'Epoch: 121, Train Loss: 0.029006403471742, Val Loss: 0.058587535213905', 'Epoch: 122, Train Loss: 0.027955585026315, Val Loss: 0.058769296501961', 'Epoch: 123, Train Loss: 0.029421509376594, Val Loss: 0.055050084141619', 'Epoch: 124, Train Loss: 0.022519447707704, Val Loss: 0.053200242363594', 'Epoch: 125, Train Loss: 0.025844200780349, Val Loss: 0.055632372175089', 'Epoch: 126, Train Loss: 0.027627809771470, Val Loss: 0.052094544763818', 'Epoch: 127, Train Loss: 0.026646407587188, Val Loss: 0.056381651905902', 'Epoch: 128, Train Loss: 0.030021405778825, Val Loss: 0.066596566106785', 'Epoch: 129, Train Loss: 0.025002360210887, Val Loss: 0.058209687189171', 'Epoch: 130, Train Loss: 0.023854019452951, Val Loss: 0.047299183453574', 'Epoch: 131, Train Loss: 0.026451567453997, Val Loss: 0.053493871156013', 'Epoch: 132, Train Loss: 0.027078265856419, Val Loss: 0.048165918468977', 'Epoch: 133, Train Loss: 0.024446676485240, Val Loss: 0.053858254655180', 'Epoch: 134, Train Loss: 0.025258946099452, Val Loss: 0.073979339703466', 'Epoch: 135, Train Loss: 0.024265418693955, Val Loss: 0.055406855137059', 'Epoch: 136, Train Loss: 0.023511921587799, Val Loss: 0.055479053182132', 'Epoch: 137, Train Loss: 0.024259831224169, Val Loss: 0.058085866385337', 'Epoch: 138, Train Loss: 0.024999346983220, Val Loss: 0.051004942901658', 'Epoch: 139, Train Loss: 0.023579218092241, Val Loss: 0.059209484832756', 'Epoch: 140, Train Loss: 0.025144867865103, Val Loss: 0.063630192074925', 'Epoch: 141, Train Loss: 0.022510023521526, Val Loss: 0.053332898342474', 'Epoch: 142, Train Loss: 0.023796475026757, Val Loss: 0.055377019230615', 'Epoch: 143, Train Loss: 0.024374849961272, Val Loss: 0.054683450440114', 'Epoch: 144, Train Loss: 0.023147226909974, Val Loss: 0.059109888462858', 'Epoch: 145, Train Loss: 0.023165974566447, Val Loss: 0.056356197194845', 'Epoch: 146, Train Loss: 0.024777976263847, Val Loss: 0.055884034655085', 'Epoch: 147, Train Loss: 0.019917114504746, Val Loss: 0.052741712241462', 'Epoch: 148, Train Loss: 0.021747742779553, Val Loss: 0.048429821646123', 'Epoch: 149, Train Loss: 0.020023428502360, Val Loss: 0.060681794339678', 'Epoch: 150, Train Loss: 0.022170921920666, Val Loss: 0.049483199406302', 'Epoch: 151, Train Loss: 0.022134597147150, Val Loss: 0.054737970994955', 'Epoch: 152, Train Loss: 0.022087957909597, Val Loss: 0.053677442681157', 'Epoch: 153, Train Loss: 0.021764037798026, Val Loss: 0.058321062390777', 'Epoch: 154, Train Loss: 0.021407063518252, Val Loss: 0.048753704254826', 'Epoch: 155, Train Loss: 0.027866037429443, Val Loss: 0.051410452801396', 'Epoch: 156, Train Loss: 0.021738500334322, Val Loss: 0.055181822104549', 'Epoch: 157, Train Loss: 0.023785646539181, Val Loss: 0.054358708813335', 'Epoch: 158, Train Loss: 0.023010057397187, Val Loss: 0.058640896878911', 'Epoch: 159, Train Loss: 0.024373698513955, Val Loss: 0.053499070983945', 'Epoch: 160, Train Loss: 0.027564524207264, Val Loss: 0.045241339301521', 'Epoch: 161, Train Loss: 0.020695159078709, Val Loss: 0.049862611813076', 'Epoch: 162, Train Loss: 0.022079593102847, Val Loss: 0.049431356093423', 'Epoch: 163, Train Loss: 0.021166455931962, Val Loss: 0.052887582699909', 'Epoch: 164, Train Loss: 0.020995864777693, Val Loss: 0.050076216572162', 'Epoch: 165, Train Loss: 0.019060046545097, Val Loss: 0.051141402712374', 'Epoch: 166, Train Loss: 0.021987649612129, Val Loss: 0.049770478243855', 'Epoch: 167, Train Loss: 0.023038341796824, Val Loss: 0.055622346050134', 'Epoch: 168, Train Loss: 0.022528267199440, Val Loss: 0.049140687862580', 'Epoch: 169, Train Loss: 0.019211744024817, Val Loss: 0.053116877041193', 'Epoch: 170, Train Loss: 0.020516927753176, Val Loss: 0.054307749424355', 'Epoch: 171, Train Loss: 0.019649280567787, Val Loss: 0.050129018836852', 'Epoch: 172, Train Loss: 0.023732080656503, Val Loss: 0.057956771247766', 'Epoch: 173, Train Loss: 0.019122053669500, Val Loss: 0.052352235878282', 'Epoch: 174, Train Loss: 0.019527886661568, Val Loss: 0.060869973279874', 'Epoch: 175, Train Loss: 0.017634956897902, Val Loss: 0.058377994365539', 'Epoch: 176, Train Loss: 0.017665688813265, Val Loss: 0.059825433883816', 'Epoch: 177, Train Loss: 0.020459802621709, Val Loss: 0.052383176192190', 'Epoch: 178, Train Loss: 0.020626384964479, Val Loss: 0.049964749367174', 'Epoch: 179, Train Loss: 0.020458695877876, Val Loss: 0.053299103609540', 'Epoch: 180, Train Loss: 0.021241049880960, Val Loss: 0.056802220938897', 'Epoch: 181, Train Loss: 0.020332477986813, Val Loss: 0.051797254321476', 'Epoch: 182, Train Loss: 0.019052862721894, Val Loss: 0.049955581653525', 'Epoch: 183, Train Loss: 0.021478646368320, Val Loss: 0.050839071754705', 'Epoch: 184, Train Loss: 0.021021162691925, Val Loss: 0.051638223343726', 'Epoch: 185, Train Loss: 0.018499904644809, Val Loss: 0.050364791500297', 'Epoch: 186, Train Loss: 0.017090332361736, Val Loss: 0.049737332614534', 'Epoch: 187, Train Loss: 0.019589635610048, Val Loss: 0.047716376343460', 'Epoch: 188, Train Loss: 0.018759250574346, Val Loss: 0.051023190107309', 'Epoch: 189, Train Loss: 0.022514918353409, Val Loss: 0.055551888858617', 'Epoch: 190, Train Loss: 0.020405138709715, Val Loss: 0.055705182381313', 'Epoch: 191, Train Loss: 0.019902858750096, Val Loss: 0.053150676811735', 'Epoch: 192, Train Loss: 0.022257834972282, Val Loss: 0.053587428661007', 'Epoch: 193, Train Loss: 0.016080522909760, Val Loss: 0.054010479922660', 'Epoch: 194, Train Loss: 0.017752376784171, Val Loss: 0.053535890285716', 'Epoch: 195, Train Loss: 0.019711271127952, Val Loss: 0.053470160134814', 'Epoch: 196, Train Loss: 0.017364571868841, Val Loss: 0.053289552444987', 'Epoch: 197, Train Loss: 0.018281623721123, Val Loss: 0.052910323536983', 'Epoch: 198, Train Loss: 0.020254021809836, Val Loss: 0.052579644277240', 'Epoch: 199, Train Loss: 0.020925086124667, Val Loss: 0.052533215419813']","[ 471.1403     153.8793     290.7542     598.37305    325.16803
  740.4659     400.95618   1032.688      483.66537    626.5006
  337.39804     63.19983      5.4628296  531.7776     572.98
  562.8819     383.73654   1327.7366     418.3215     418.18646
 1111.6362    1044.3005     410.69217    632.6117     770.8096
  243.9403       2.0499268  617.8216     138.60297     10.239746
  259.98862    840.6533     672.4115     828.5887     491.27667
  849.557       13.723694   780.819      260.51508   1192.4822
  241.62308    334.45892     54.5943     694.4518    1219.9059
  730.69086    384.54898     48.199646   568.3642     649.0148
  279.37943     20.586472   401.69052    477.40497    838.6971
  471.95917    125.53729    384.86105    922.0249     541.7541
  564.26196     80.541504   307.5845     738.6224     417.87872
  303.49234   1132.605      649.5345     997.83997   1077.1912
  326.62158    315.92706    721.78955    895.2418     202.45238
  351.98355    608.1203     670.70856   1119.0164     517.8821
  265.24066     53.80777    915.9963    1082.7795     600.7388
  284.34714    122.99805     85.57712    284.28488    907.08356
    6.329773   485.5377      25.92746    624.78357     49.893707
 1062.8188     797.8456     404.75803    512.49774    457.61334
  277.92847    321.62332    192.59299    274.24643    893.3407
  649.3793     319.4779     479.95258    773.51013    982.65375
  559.5322     229.95102   1298.9675     991.0653     867.60095
  439.27567     41.41095    455.4604     296.6674     116.64441
  580.84143    540.8015    1137.2391     888.42957    232.84521
  578.2854    1317.5714     792.812      307.88156    220.76721
  290.97983    540.59924    909.3096     671.03394    644.0965
  604.7989     869.3708     904.1972   ]","[ 373.79236    62.970306  363.03952   551.96606   312.30524   814.85443
  379.89542  1089.2495    446.90012   543.1403    321.47827   208.07657
  118.44144   565.4077    504.33615   628.1731    343.36545  1391.8806
  431.9993    481.4048    937.37964  1039.352     464.9194    659.21533
  727.86255   255.88885    99.617584  487.96344    80.66266    88.61749
  318.12985   820.36707   595.40796   816.96344   401.767     656.864
  109.19028   863.51843   215.30212  1238.9141    189.77614   321.26105
  134.89015   760.87134  1173.1719    781.54285   354.37265   157.04617
  445.1754    736.31836   262.53107    55.35312   358.9279    433.27142
  850.9583    460.6693     16.59674   429.0421    995.04926   733.1991
  623.9487    218.14233   361.7968    738.9781    400.98993   323.98514
 1167.7356    602.0947    975.6946    995.4687    320.41202   307.47638
  726.8551    829.0038    241.27956   536.56885   675.7732    595.8503
 1172.5443    434.87643   313.1493    189.078     879.4569   1094.5614
  510.40286   352.68185   232.556     158.34222   270.65073   842.1417
  369.03375   348.66995    68.71167   576.6279    159.7143    992.6965
  748.81506   326.31973   597.46924   519.2367    268.35825   300.13477
  159.1198    238.56277   655.94727   537.7954    310.58704   424.46274
  690.745     936.81683   544.9731    269.21747  1270.4788   1034.0492
  793.536     431.5099     69.97058   383.08124   291.20227   191.49445
  359.9068    348.11288  1148.2698    936.55975   219.65045   477.28915
 1006.2707    795.52826   240.92252   122.91455   344.8339    549.3152
  914.0627    636.536     700.3383    643.6336    874.60144  1090.6702  ]",65.9102,7699.8306,87.7486784311094
trial_2,cartesian_knn_minmax_noact,"['Epoch: 0, Train Loss: 0.376529804297856, Val Loss: 0.411497010426088', 'Epoch: 1, Train Loss: 0.382229922073228, Val Loss: 0.420647007949425', 'Epoch: 2, Train Loss: 0.384058094450406, Val Loss: 0.413632622270873', 'Epoch: 3, Train Loss: 0.385024319802012, Val Loss: 0.399869303811680', 'Epoch: 4, Train Loss: 0.384245421205248, Val Loss: 0.426984486254779', 'Epoch: 5, Train Loss: 0.386371533785548, Val Loss: 0.400798129312920', 'Epoch: 6, Train Loss: 0.379207949553217, Val Loss: 0.413576776331121', 'Epoch: 7, Train Loss: 0.368963543857847, Val Loss: 0.386220316092173', 'Epoch: 8, Train Loss: 0.323416774826390, Val Loss: 0.307068609830105', 'Epoch: 9, Train Loss: 0.238338088350637, Val Loss: 0.161971321611693', 'Epoch: 10, Train Loss: 0.155957190053804, Val Loss: 0.194460437153325', 'Epoch: 11, Train Loss: 0.166096471782242, Val Loss: 0.114742632616650', 'Epoch: 12, Train Loss: 0.117610217737300, Val Loss: 0.099554346027699', 'Epoch: 13, Train Loss: 0.115860007171120, Val Loss: 0.105889297570243', 'Epoch: 14, Train Loss: 0.110490579158068, Val Loss: 0.087465922376423', 'Epoch: 15, Train Loss: 0.103710053754704, Val Loss: 0.083791344003244', 'Epoch: 16, Train Loss: 0.093280808467950, Val Loss: 0.105511767959053', 'Epoch: 17, Train Loss: 0.081671448690551, Val Loss: 0.067988209094796', 'Epoch: 18, Train Loss: 0.079090302810073, Val Loss: 0.063830641267652', 'Epoch: 19, Train Loss: 0.065906990053398, Val Loss: 0.053076308000141', 'Epoch: 20, Train Loss: 0.058976156104888, Val Loss: 0.064134474427467', 'Epoch: 21, Train Loss: 0.058494501747191, Val Loss: 0.054387299555608', 'Epoch: 22, Train Loss: 0.063455029257706, Val Loss: 0.066503653810783', 'Epoch: 23, Train Loss: 0.052557820188148, Val Loss: 0.053417527780050', 'Epoch: 24, Train Loss: 0.054221084474453, Val Loss: 0.041881057645448', 'Epoch: 25, Train Loss: 0.061459050646850, Val Loss: 0.066863203647010', 'Epoch: 26, Train Loss: 0.056632856306221, Val Loss: 0.101634676483544', 'Epoch: 27, Train Loss: 0.071760053081172, Val Loss: 0.070517201569270', 'Epoch: 28, Train Loss: 0.058733982433166, Val Loss: 0.046466199956326', 'Epoch: 29, Train Loss: 0.061857400728124, Val Loss: 0.085746310199752', 'Epoch: 30, Train Loss: 0.055005085255419, Val Loss: 0.036958808537968', 'Epoch: 31, Train Loss: 0.054326427834375, Val Loss: 0.047884984802680', 'Epoch: 32, Train Loss: 0.050087809828775, Val Loss: 0.050076997218033', 'Epoch: 33, Train Loss: 0.054912398702332, Val Loss: 0.031902832000262', 'Epoch: 34, Train Loss: 0.047490412901555, Val Loss: 0.040173294954002', 'Epoch: 35, Train Loss: 0.048644753039948, Val Loss: 0.040046310334495', 'Epoch: 36, Train Loss: 0.052002409340015, Val Loss: 0.033523342191157', 'Epoch: 37, Train Loss: 0.062178155407310, Val Loss: 0.049465310167183', 'Epoch: 38, Train Loss: 0.058841482337032, Val Loss: 0.067958617300698', 'Epoch: 39, Train Loss: 0.062373667157122, Val Loss: 0.048247239467773', 'Epoch: 40, Train Loss: 0.053472663275898, Val Loss: 0.036218352171338', 'Epoch: 41, Train Loss: 0.053463041516287, Val Loss: 0.042090733084037', 'Epoch: 42, Train Loss: 0.048890408660684, Val Loss: 0.046771224588156', 'Epoch: 43, Train Loss: 0.044758853635618, Val Loss: 0.036852359545953', 'Epoch: 44, Train Loss: 0.053737804692771, Val Loss: 0.071696093136614', 'Epoch: 45, Train Loss: 0.056633857611035, Val Loss: 0.040157911903930', 'Epoch: 46, Train Loss: 0.050139754079282, Val Loss: 0.038487393155017', 'Epoch: 47, Train Loss: 0.046605125069618, Val Loss: 0.035796309905973', 'Epoch: 48, Train Loss: 0.043410094720977, Val Loss: 0.048438856942636', 'Epoch: 49, Train Loss: 0.041052600634950, Val Loss: 0.053245403098338', 'Epoch: 50, Train Loss: 0.039289453599070, Val Loss: 0.045237475836819', 'Epoch: 51, Train Loss: 0.043329544099314, Val Loss: 0.052482846334125', 'Epoch: 52, Train Loss: 0.049995508444096, Val Loss: 0.052565896996494', 'Epoch: 53, Train Loss: 0.047456450494272, Val Loss: 0.048562097137867', 'Epoch: 54, Train Loss: 0.036319588843201, Val Loss: 0.042112264330640', 'Epoch: 55, Train Loss: 0.041850255003997, Val Loss: 0.050513144582510', 'Epoch: 56, Train Loss: 0.041401722734528, Val Loss: 0.033032728341465', 'Epoch: 57, Train Loss: 0.040259513870946, Val Loss: 0.040524902612422', 'Epoch: 58, Train Loss: 0.043556510337761, Val Loss: 0.052661467908007', 'Epoch: 59, Train Loss: 0.039664192923478, Val Loss: 0.033878208497878', 'Epoch: 60, Train Loss: 0.045121312540557, Val Loss: 0.034159341220264', 'Epoch: 61, Train Loss: 0.039682642423681, Val Loss: 0.032896475809993', 'Epoch: 62, Train Loss: 0.033517626513328, Val Loss: 0.039764366253759', 'Epoch: 63, Train Loss: 0.035034236232085, Val Loss: 0.034246891482987', 'Epoch: 64, Train Loss: 0.034309557372970, Val Loss: 0.039466879020135', 'Epoch: 65, Train Loss: 0.033903454363878, Val Loss: 0.031754029703073', 'Epoch: 66, Train Loss: 0.037053389607796, Val Loss: 0.036189026961272', 'Epoch: 67, Train Loss: 0.041718379195247, Val Loss: 0.040483115410263', 'Epoch: 68, Train Loss: 0.033856709354690, Val Loss: 0.036487269963166', 'Epoch: 69, Train Loss: 0.038419485624347, Val Loss: 0.040459270617276', 'Epoch: 70, Train Loss: 0.034429317872439, Val Loss: 0.039349757988627', 'Epoch: 71, Train Loss: 0.035803275448935, Val Loss: 0.058309605175799', 'Epoch: 72, Train Loss: 0.037650772237352, Val Loss: 0.035996857071013', 'Epoch: 73, Train Loss: 0.037911134106772, Val Loss: 0.044797016138380', 'Epoch: 74, Train Loss: 0.033833141970847, Val Loss: 0.034287391230464', 'Epoch: 75, Train Loss: 0.032120396782245, Val Loss: 0.048471523053718', 'Epoch: 76, Train Loss: 0.039171416578548, Val Loss: 0.057164302490877', 'Epoch: 77, Train Loss: 0.033592015504837, Val Loss: 0.039916431506616', 'Epoch: 78, Train Loss: 0.032296631618270, Val Loss: 0.069102707347184', 'Epoch: 79, Train Loss: 0.040109851530620, Val Loss: 0.038841505083397', 'Epoch: 80, Train Loss: 0.029383591642337, Val Loss: 0.039757208503557', 'Epoch: 81, Train Loss: 0.030903994371848, Val Loss: 0.036340991655986', 'Epoch: 82, Train Loss: 0.033410260719912, Val Loss: 0.036593327192928', 'Epoch: 83, Train Loss: 0.033259474273239, Val Loss: 0.035322029256459', 'Epoch: 84, Train Loss: 0.035276979341039, Val Loss: 0.044747395440936', 'Epoch: 85, Train Loss: 0.035094609084938, Val Loss: 0.038610399108041', 'Epoch: 86, Train Loss: 0.029475883447698, Val Loss: 0.034896091416930', 'Epoch: 87, Train Loss: 0.035333350034697, Val Loss: 0.034209302203222', 'Epoch: 88, Train Loss: 0.031795412967248, Val Loss: 0.038806904812880', 'Epoch: 89, Train Loss: 0.028806127075638, Val Loss: 0.034488171677698', 'Epoch: 90, Train Loss: 0.032817556389741, Val Loss: 0.039471644795302', 'Epoch: 91, Train Loss: 0.029190835676023, Val Loss: 0.037923786182408', 'Epoch: 92, Train Loss: 0.033511580101081, Val Loss: 0.042856101736878', 'Epoch: 93, Train Loss: 0.031113434849041, Val Loss: 0.036609155041250', 'Epoch: 94, Train Loss: 0.031893027414169, Val Loss: 0.038354374002665', 'Epoch: 95, Train Loss: 0.029647600437914, Val Loss: 0.041049979965795', 'Epoch: 96, Train Loss: 0.028531032215272, Val Loss: 0.033619072683381', 'Epoch: 97, Train Loss: 0.028201497891652, Val Loss: 0.041048979668906', 'Epoch: 98, Train Loss: 0.026694373227656, Val Loss: 0.036601431385586', 'Epoch: 99, Train Loss: 0.030817186193807, Val Loss: 0.038001943358474', 'Epoch: 100, Train Loss: 0.034667846480651, Val Loss: 0.034250086455634', 'Epoch: 101, Train Loss: 0.028876873065851, Val Loss: 0.038633448269331', 'Epoch: 102, Train Loss: 0.027219924144447, Val Loss: 0.044318633774916', 'Epoch: 103, Train Loss: 0.031305560975202, Val Loss: 0.040561597681407', 'Epoch: 104, Train Loss: 0.034015034192375, Val Loss: 0.045209298601769', 'Epoch: 105, Train Loss: 0.025091184436211, Val Loss: 0.054891875860366', 'Epoch: 106, Train Loss: 0.029397875070572, Val Loss: 0.043247107698610', 'Epoch: 107, Train Loss: 0.025731640734843, Val Loss: 0.043401632232196', 'Epoch: 108, Train Loss: 0.026819805348558, Val Loss: 0.037215785377405', 'Epoch: 109, Train Loss: 0.026391460493739, Val Loss: 0.035928295304378', 'Epoch: 110, Train Loss: 0.025436022185854, Val Loss: 0.033204672717010', 'Epoch: 111, Train Loss: 0.031544000575585, Val Loss: 0.035885565773104', 'Epoch: 112, Train Loss: 0.024569154583982, Val Loss: 0.037730503827333', 'Epoch: 113, Train Loss: 0.031524348205754, Val Loss: 0.046973481887218', 'Epoch: 114, Train Loss: 0.026188055585538, Val Loss: 0.042556537145918', 'Epoch: 115, Train Loss: 0.022977863039289, Val Loss: 0.043025369671258', 'Epoch: 116, Train Loss: 0.028999329012419, Val Loss: 0.033442684336368', 'Epoch: 117, Train Loss: 0.032067415637097, Val Loss: 0.035881640989277', 'Epoch: 118, Train Loss: 0.035794440656900, Val Loss: 0.034217111540563', 'Epoch: 119, Train Loss: 0.029591457652194, Val Loss: 0.038565877542803', 'Epoch: 120, Train Loss: 0.031024468929640, Val Loss: 0.035037903538482', 'Epoch: 121, Train Loss: 0.029748467728496, Val Loss: 0.036716831678694', 'Epoch: 122, Train Loss: 0.032201349070030, Val Loss: 0.040056726246169', 'Epoch: 123, Train Loss: 0.027020897649761, Val Loss: 0.045035290136708', 'Epoch: 124, Train Loss: 0.029834607749113, Val Loss: 0.042598381412752', 'Epoch: 125, Train Loss: 0.022484578524849, Val Loss: 0.039720666002144', 'Epoch: 126, Train Loss: 0.024792956853552, Val Loss: 0.038162792214390', 'Epoch: 127, Train Loss: 0.023508999496698, Val Loss: 0.041508521715348', 'Epoch: 128, Train Loss: 0.022611144131848, Val Loss: 0.047569669783115', 'Epoch: 129, Train Loss: 0.021326076638486, Val Loss: 0.039337172088298', 'Epoch: 130, Train Loss: 0.025846756396017, Val Loss: 0.038091373770978', 'Epoch: 131, Train Loss: 0.024392784506615, Val Loss: 0.039951467265685', 'Epoch: 132, Train Loss: 0.025515815642263, Val Loss: 0.041082787750797', 'Epoch: 133, Train Loss: 0.027692598157695, Val Loss: 0.042748910120942', 'Epoch: 134, Train Loss: 0.029872223202671, Val Loss: 0.050320522521030', 'Epoch: 135, Train Loss: 0.027011432818004, Val Loss: 0.040917335191008', 'Epoch: 136, Train Loss: 0.026274068547147, Val Loss: 0.040247793817385', 'Epoch: 137, Train Loss: 0.025950703437307, Val Loss: 0.035765945403413', 'Epoch: 138, Train Loss: 0.024856169708073, Val Loss: 0.034649995832958', 'Epoch: 139, Train Loss: 0.023970882142229, Val Loss: 0.036640756763518', 'Epoch: 140, Train Loss: 0.022271917999855, Val Loss: 0.036135871048001', 'Epoch: 141, Train Loss: 0.023578916609819, Val Loss: 0.032443292565982', 'Epoch: 142, Train Loss: 0.023250619315409, Val Loss: 0.039241395100500', 'Epoch: 143, Train Loss: 0.021967596906636, Val Loss: 0.037870793349364', 'Epoch: 144, Train Loss: 0.026099056404616, Val Loss: 0.038311283075900', 'Epoch: 145, Train Loss: 0.026328299460667, Val Loss: 0.040733402425593', 'Epoch: 146, Train Loss: 0.022922042491181, Val Loss: 0.035319658899398', 'Epoch: 147, Train Loss: 0.023038828812007, Val Loss: 0.037316123588067', 'Epoch: 148, Train Loss: 0.024846902782364, Val Loss: 0.037593394179236', 'Epoch: 149, Train Loss: 0.023145205141710, Val Loss: 0.041716902008788', 'Epoch: 150, Train Loss: 0.026359255226063, Val Loss: 0.040163093444073', 'Epoch: 151, Train Loss: 0.023710798139551, Val Loss: 0.033273484473201', 'Epoch: 152, Train Loss: 0.022125240415335, Val Loss: 0.036639882308064', 'Epoch: 153, Train Loss: 0.026578442526183, Val Loss: 0.036358901497090', 'Epoch: 154, Train Loss: 0.023165212944150, Val Loss: 0.039011633475170', 'Epoch: 155, Train Loss: 0.022775802162609, Val Loss: 0.036011217867560', 'Epoch: 156, Train Loss: 0.020966543217323, Val Loss: 0.034429783340205', 'Epoch: 157, Train Loss: 0.020896455871740, Val Loss: 0.039352523445180', 'Epoch: 158, Train Loss: 0.023526341521314, Val Loss: 0.036452778488059', 'Epoch: 159, Train Loss: 0.020287620369345, Val Loss: 0.038821233267134', 'Epoch: 160, Train Loss: 0.017989480136228, Val Loss: 0.035925490767554', 'Epoch: 161, Train Loss: 0.024597891473344, Val Loss: 0.036094073234408', 'Epoch: 162, Train Loss: 0.021095270889678, Val Loss: 0.038044713042451', 'Epoch: 163, Train Loss: 0.023405722475478, Val Loss: 0.040449478099066', 'Epoch: 164, Train Loss: 0.023555044517187, Val Loss: 0.039410770898967', 'Epoch: 165, Train Loss: 0.024011371590729, Val Loss: 0.040830545522498', 'Epoch: 166, Train Loss: 0.021499692728477, Val Loss: 0.035981865599751', 'Epoch: 167, Train Loss: 0.021664258890918, Val Loss: 0.039086905449177', 'Epoch: 168, Train Loss: 0.022576159398471, Val Loss: 0.036660818326654', 'Epoch: 169, Train Loss: 0.018281258642673, Val Loss: 0.037603916205240', 'Epoch: 170, Train Loss: 0.021770034384515, Val Loss: 0.038760605719731', 'Epoch: 171, Train Loss: 0.023203815267022, Val Loss: 0.036241700929223', 'Epoch: 172, Train Loss: 0.022297546666648, Val Loss: 0.036520182663067', 'Epoch: 173, Train Loss: 0.019533823377320, Val Loss: 0.037073280605854', 'Epoch: 174, Train Loss: 0.017857115981834, Val Loss: 0.039355927683187', 'Epoch: 175, Train Loss: 0.023264767735132, Val Loss: 0.038873571394519', 'Epoch: 176, Train Loss: 0.020361149949687, Val Loss: 0.039950166970040', 'Epoch: 177, Train Loss: 0.018597936257720, Val Loss: 0.037556491086655', 'Epoch: 178, Train Loss: 0.021549975299942, Val Loss: 0.043583711835020', 'Epoch: 179, Train Loss: 0.021600060963205, Val Loss: 0.036183535050827', 'Epoch: 180, Train Loss: 0.021228768530169, Val Loss: 0.036805298630938', 'Epoch: 181, Train Loss: 0.020785496902785, Val Loss: 0.035340858566942', 'Epoch: 182, Train Loss: 0.019757137833429, Val Loss: 0.034220763820816', 'Epoch: 183, Train Loss: 0.020843185417886, Val Loss: 0.034825272463036', 'Epoch: 184, Train Loss: 0.022186882993472, Val Loss: 0.036746182253189', 'Epoch: 185, Train Loss: 0.017617440649441, Val Loss: 0.036668350242756', 'Epoch: 186, Train Loss: 0.020211971165346, Val Loss: 0.035811870528216', 'Epoch: 187, Train Loss: 0.021187007294169, Val Loss: 0.037674128896359', 'Epoch: 188, Train Loss: 0.020166697180165, Val Loss: 0.038392035516374', 'Epoch: 189, Train Loss: 0.022842520182686, Val Loss: 0.036892480132255', 'Epoch: 190, Train Loss: 0.020174017708216, Val Loss: 0.037120987463630', 'Epoch: 191, Train Loss: 0.021385950568531, Val Loss: 0.039568605522315', 'Epoch: 192, Train Loss: 0.018292583325612, Val Loss: 0.037266363869562', 'Epoch: 193, Train Loss: 0.018319916977946, Val Loss: 0.037342387618441', 'Epoch: 194, Train Loss: 0.017362206109932, Val Loss: 0.036970442668958', 'Epoch: 195, Train Loss: 0.019858424851139, Val Loss: 0.038322808700755', 'Epoch: 196, Train Loss: 0.018184317475451, Val Loss: 0.038323559459638', 'Epoch: 197, Train Loss: 0.018794081306883, Val Loss: 0.037863515035221', 'Epoch: 198, Train Loss: 0.018463019281626, Val Loss: 0.037751091869943', 'Epoch: 199, Train Loss: 0.020461955772979, Val Loss: 0.037778180487680']","[ 687.8954     587.7664     806.48376   1192.2505     249.45024
   62.58194    426.27896   1012.64764    407.37656    373.86713
  264.60712     69.31613    244.11351    106.83893    290.97983
  540.59924    400.95618   1032.688      691.2141     439.6826
  937.9889      71.58554    125.02261    446.80353    166.28964
  211.36594   1139.9081     641.5614     289.0574     254.19006
  335.5677     550.8332     713.01166    101.37781   1090.6873
  140.76965   1041.1692     291.88788     55.43544    436.99503
  594.27295    523.7677     380.06744    549.14624    193.66635
  706.7205     548.6123     562.0951     737.4956     127.90927
  328.93167    348.92972     29.124512   631.9739     363.94058
  803.88574    337.39804     63.19983   1035.3289     289.96573
  322.44098    384.01755    694.1144     419.9962     245.8705
  604.0323     267.63318    818.9285     915.9963    1082.7795
  537.7522     771.3589     556.70044    855.26227    580.84143
  540.8015     269.5341     346.46228    296.6674     116.64441
  198.0301     564.53436    397.72205     76.32414    238.36115
  859.18506   1174.3181     599.6746     440.00293     99.90213
  349.61304    200.36572    383.73654   1327.7366     543.912
   84.83186    549.78577    392.8176     125.53729    384.86105
  211.00024     23.32251    212.51854    586.0235      12.562317
  312.81177   1056.3058     793.31714    392.04727    389.85242
  159.53868     58.082092   242.34076    349.28815    796.14014
  888.3277     384.54898     48.199646   600.7388     284.34714
    5.618469   295.53036    483.34933    854.8072       2.0499268
  617.8216     848.72437    541.6864     290.7542     598.37305
   28.69104    512.4936     963.3551     343.87537    285.84372
  894.3473     466.41046   1307.9707   ]","[ 658.7905     463.40854    800.69867   1169.6978     223.50627
   45.525726   469.07657   1003.93915    506.6265     552.41125
  318.3841     158.40952    264.14       149.21802    376.21826
  513.94745    441.3667    1015.89777    672.45544    481.37137
  831.8035       2.8825073  125.80054    457.12747    252.04735
   17.46045   1145.4773     647.59357    264.7849     269.94278
  261.0961     542.28864    653.08655    135.7732    1123.699
  172.32092   1004.6117     315.29913    152.19794    464.4703
  552.2761     427.7191     365.62354    529.72       247.07866
  621.152      366.25787    427.07416    673.3026      74.8757
  316.43842    413.049       -6.061981   609.41736    355.82663
  870.7749     366.82553    223.23718   1073.0641     287.1036
  317.02435    328.06348    631.46106    466.43335    251.84615
  612.27734    326.39227    776.60333    903.8491    1169.8219
  702.5943     826.09125    564.08105    688.70624    365.59406
  335.2301     311.25607    366.14392    289.58594    155.6842
  225.45546    575.539      329.58044     24.620468   229.0758
  894.3045    1174.2668     595.0717     470.7896     205.46577
  338.95242    177.28973    461.63672   1349.9563     380.14432
   57.481216   546.07837    453.6418     -51.69983    434.23563
  393.5496     216.98798     20.644257   600.1713     172.06519
  476.24844    940.11194    836.43176    370.23682    477.0265
  161.43832     -8.665283   275.08282    292.71545    954.2777
  876.4063     370.7674     125.97528    537.7875     284.4023
   40.9682     326.2954     544.425      928.7904     107.39758
  558.8452     748.60474    573.3474     326.8165     577.7628
   11.564026   473.9204    1042.2826     431.50537    334.0756
 1062.9628     618.25836   1284.3346   ]",59.48136,6480.9897,80.5045945651163
trial_3,cartesian_knn_minmax_noact,"['Epoch: 0, Train Loss: 0.384020424314908, Val Loss: 0.406710213784016', 'Epoch: 1, Train Loss: 0.378088744623320, Val Loss: 0.405511514707045', 'Epoch: 2, Train Loss: 0.376671205673899, Val Loss: 0.403015123172240', 'Epoch: 3, Train Loss: 0.380584145230906, Val Loss: 0.403933577465289', 'Epoch: 4, Train Loss: 0.384899458714894, Val Loss: 0.401159238634687', 'Epoch: 5, Train Loss: 0.372954909290586, Val Loss: 0.399742436228376', 'Epoch: 6, Train Loss: 0.379122031586511, Val Loss: 0.393554874441840', 'Epoch: 7, Train Loss: 0.374061012906688, Val Loss: 0.376558146693490', 'Epoch: 8, Train Loss: 0.322614690022809, Val Loss: 0.242698961586663', 'Epoch: 9, Train Loss: 0.278213413698333, Val Loss: 0.263104537219712', 'Epoch: 10, Train Loss: 0.248347719865186, Val Loss: 0.169653693834941', 'Epoch: 11, Train Loss: 0.190533308578389, Val Loss: 0.118916796012358', 'Epoch: 12, Train Loss: 0.132729313735451, Val Loss: 0.109023984973178', 'Epoch: 13, Train Loss: 0.094813925613250, Val Loss: 0.100266446895672', 'Epoch: 14, Train Loss: 0.107104595750570, Val Loss: 0.113961033071532', 'Epoch: 15, Train Loss: 0.110186804085970, Val Loss: 0.086903695637981', 'Epoch: 16, Train Loss: 0.116072286452566, Val Loss: 0.116112662084175', 'Epoch: 17, Train Loss: 0.091286524065903, Val Loss: 0.093149950558489', 'Epoch: 18, Train Loss: 0.075718795614583, Val Loss: 0.080703158227896', 'Epoch: 19, Train Loss: 0.083578541874886, Val Loss: 0.074741411897721', 'Epoch: 20, Train Loss: 0.066073874011636, Val Loss: 0.080497825151366', 'Epoch: 21, Train Loss: 0.064419408727969, Val Loss: 0.075693782644741', 'Epoch: 22, Train Loss: 0.059681230091623, Val Loss: 0.081040734509853', 'Epoch: 23, Train Loss: 0.064719066289919, Val Loss: 0.091436398018039', 'Epoch: 24, Train Loss: 0.062212310465319, Val Loss: 0.079294067073726', 'Epoch: 25, Train Loss: 0.057526963629893, Val Loss: 0.089354767605211', 'Epoch: 26, Train Loss: 0.053883297901068, Val Loss: 0.069622722143928', 'Epoch: 27, Train Loss: 0.063504022413066, Val Loss: 0.071821099471752', 'Epoch: 28, Train Loss: 0.057362101706011, Val Loss: 0.086651406328504', 'Epoch: 29, Train Loss: 0.055048794884767, Val Loss: 0.075105444387053', 'Epoch: 30, Train Loss: 0.051412432055388, Val Loss: 0.078239452206727', 'Epoch: 31, Train Loss: 0.053528204826372, Val Loss: 0.072208495782406', 'Epoch: 32, Train Loss: 0.054844706585365, Val Loss: 0.076822056787822', 'Epoch: 33, Train Loss: 0.059974946081638, Val Loss: 0.090468297345620', 'Epoch: 34, Train Loss: 0.065216296219400, Val Loss: 0.063895813612775', 'Epoch: 35, Train Loss: 0.061423538784896, Val Loss: 0.077813139255864', 'Epoch: 36, Train Loss: 0.058373854628631, Val Loss: 0.111567091535438', 'Epoch: 37, Train Loss: 0.062493089054312, Val Loss: 0.064172161686601', 'Epoch: 38, Train Loss: 0.060440746002964, Val Loss: 0.066203799409171', 'Epoch: 39, Train Loss: 0.044135523427810, Val Loss: 0.075376055563207', 'Epoch: 40, Train Loss: 0.055101698264480, Val Loss: 0.064158033410257', 'Epoch: 41, Train Loss: 0.052042186526316, Val Loss: 0.086293573180834', 'Epoch: 42, Train Loss: 0.044902074549879, Val Loss: 0.075980178278052', 'Epoch: 43, Train Loss: 0.043257812836340, Val Loss: 0.079952063659827', 'Epoch: 44, Train Loss: 0.048094947157162, Val Loss: 0.065429658149228', 'Epoch: 45, Train Loss: 0.052195832665477, Val Loss: 0.096266729587858', 'Epoch: 46, Train Loss: 0.047911936683314, Val Loss: 0.065314856103875', 'Epoch: 47, Train Loss: 0.055064303534372, Val Loss: 0.063623629566846', 'Epoch: 48, Train Loss: 0.051928605485175, Val Loss: 0.055163961425988', 'Epoch: 49, Train Loss: 0.041352740621993, Val Loss: 0.065502022816376', 'Epoch: 50, Train Loss: 0.044551213937146, Val Loss: 0.060782138879100', 'Epoch: 51, Train Loss: 0.044000822252461, Val Loss: 0.059363718793699', 'Epoch: 52, Train Loss: 0.040814713841038, Val Loss: 0.066620897981479', 'Epoch: 53, Train Loss: 0.035853549705020, Val Loss: 0.060420981185003', 'Epoch: 54, Train Loss: 0.045641961906637, Val Loss: 0.066903938567548', 'Epoch: 55, Train Loss: 0.041771824604699, Val Loss: 0.079590546362328', 'Epoch: 56, Train Loss: 0.040048644744924, Val Loss: 0.057198730748937', 'Epoch: 57, Train Loss: 0.042481041247291, Val Loss: 0.060864692977206', 'Epoch: 58, Train Loss: 0.038015062388565, Val Loss: 0.075311927407077', 'Epoch: 59, Train Loss: 0.039648911250489, Val Loss: 0.064280124381185', 'Epoch: 60, Train Loss: 0.043307946595762, Val Loss: 0.067322379711902', 'Epoch: 61, Train Loss: 0.043224221760673, Val Loss: 0.072633559505145', 'Epoch: 62, Train Loss: 0.043575155415705, Val Loss: 0.076232877193075', 'Epoch: 63, Train Loss: 0.040197465169643, Val Loss: 0.065515089328542', 'Epoch: 64, Train Loss: 0.039233055098781, Val Loss: 0.062988939666838', 'Epoch: 65, Train Loss: 0.039104621790882, Val Loss: 0.074220415938533', 'Epoch: 66, Train Loss: 0.037268451814141, Val Loss: 0.071508450320724', 'Epoch: 67, Train Loss: 0.038232937455177, Val Loss: 0.058973846251540', 'Epoch: 68, Train Loss: 0.037579907902649, Val Loss: 0.056449555537917', 'Epoch: 69, Train Loss: 0.042115573106068, Val Loss: 0.066585960268805', 'Epoch: 70, Train Loss: 0.040178706337299, Val Loss: 0.067089814015410', 'Epoch: 71, Train Loss: 0.041368078041290, Val Loss: 0.060701664593635', 'Epoch: 72, Train Loss: 0.038779976245548, Val Loss: 0.061054525276025', 'Epoch: 73, Train Loss: 0.038627211403634, Val Loss: 0.070413271134550', 'Epoch: 74, Train Loss: 0.036508061523948, Val Loss: 0.063659914741010', 'Epoch: 75, Train Loss: 0.043998237832316, Val Loss: 0.078958881172267', 'Epoch: 76, Train Loss: 0.040955511853099, Val Loss: 0.069282844098228', 'Epoch: 77, Train Loss: 0.038327228144876, Val Loss: 0.062053404663774', 'Epoch: 78, Train Loss: 0.029313621111214, Val Loss: 0.053471921463356', 'Epoch: 79, Train Loss: 0.030944257309394, Val Loss: 0.065591631626541', 'Epoch: 80, Train Loss: 0.034335519320198, Val Loss: 0.065926588168650', 'Epoch: 81, Train Loss: 0.039287249291582, Val Loss: 0.065312343564900', 'Epoch: 82, Train Loss: 0.036372261521007, Val Loss: 0.059609783644026', 'Epoch: 83, Train Loss: 0.029235163437469, Val Loss: 0.068798974833705', 'Epoch: 84, Train Loss: 0.037444911897182, Val Loss: 0.077194048204657', 'Epoch: 85, Train Loss: 0.036653781043632, Val Loss: 0.060470494977904', 'Epoch: 86, Train Loss: 0.030248797764736, Val Loss: 0.060033008738449', 'Epoch: 87, Train Loss: 0.034243165249271, Val Loss: 0.055188063193451', 'Epoch: 88, Train Loss: 0.030950622766146, Val Loss: 0.059591553427956', 'Epoch: 89, Train Loss: 0.032935730580773, Val Loss: 0.061194317020250', 'Epoch: 90, Train Loss: 0.031413884766932, Val Loss: 0.063521905717525', 'Epoch: 91, Train Loss: 0.030550394074193, Val Loss: 0.060174720756935', 'Epoch: 92, Train Loss: 0.029899604485503, Val Loss: 0.062429277734323', 'Epoch: 93, Train Loss: 0.025833356726382, Val Loss: 0.061901187354868', 'Epoch: 94, Train Loss: 0.030656661572201, Val Loss: 0.070347854472471', 'Epoch: 95, Train Loss: 0.027515276202134, Val Loss: 0.057011527545524', 'Epoch: 96, Train Loss: 0.030300256929227, Val Loss: 0.056232253936204', 'Epoch: 97, Train Loss: 0.031469941671406, Val Loss: 0.063468131942279', 'Epoch: 98, Train Loss: 0.030122460132199, Val Loss: 0.059130243392605', 'Epoch: 99, Train Loss: 0.033634741923639, Val Loss: 0.074434252963825', 'Epoch: 100, Train Loss: 0.030683861513223, Val Loss: 0.066385333623850', 'Epoch: 101, Train Loss: 0.027684325884495, Val Loss: 0.074708487725619', 'Epoch: 102, Train Loss: 0.029222099243530, Val Loss: 0.067912843868588', 'Epoch: 103, Train Loss: 0.034221745761377, Val Loss: 0.059009792057402', 'Epoch: 104, Train Loss: 0.031241905077228, Val Loss: 0.064194431584893', 'Epoch: 105, Train Loss: 0.031768292188644, Val Loss: 0.068346715560465', 'Epoch: 106, Train Loss: 0.027498088377927, Val Loss: 0.075335857430191', 'Epoch: 107, Train Loss: 0.030674148617046, Val Loss: 0.064819601787762', 'Epoch: 108, Train Loss: 0.026905273087323, Val Loss: 0.061919330195947', 'Epoch: 109, Train Loss: 0.028333043812641, Val Loss: 0.060032630226377', 'Epoch: 110, Train Loss: 0.023708702131574, Val Loss: 0.065065794370391', 'Epoch: 111, Train Loss: 0.025032152754388, Val Loss: 0.065104915167798', 'Epoch: 112, Train Loss: 0.025971631852112, Val Loss: 0.063589165495201', 'Epoch: 113, Train Loss: 0.028881181231035, Val Loss: 0.065083702631069', 'Epoch: 114, Train Loss: 0.026597873307765, Val Loss: 0.068467780947685', 'Epoch: 115, Train Loss: 0.026149383746088, Val Loss: 0.060068515157609', 'Epoch: 116, Train Loss: 0.024341198083545, Val Loss: 0.066195699527408', 'Epoch: 117, Train Loss: 0.026282377873680, Val Loss: 0.068269817610130', 'Epoch: 118, Train Loss: 0.026931487556015, Val Loss: 0.062658739925334', 'Epoch: 119, Train Loss: 0.025868642476520, Val Loss: 0.064787617235473', 'Epoch: 120, Train Loss: 0.026696959111307, Val Loss: 0.062475785838835', 'Epoch: 121, Train Loss: 0.027937100668039, Val Loss: 0.080631610006094', 'Epoch: 122, Train Loss: 0.028499134417091, Val Loss: 0.066500238509792', 'Epoch: 123, Train Loss: 0.026443385519087, Val Loss: 0.072777618287188', 'Epoch: 124, Train Loss: 0.026039562986365, Val Loss: 0.066345537250692', 'Epoch: 125, Train Loss: 0.023816227247672, Val Loss: 0.066348654754234', 'Epoch: 126, Train Loss: 0.021852162267481, Val Loss: 0.062987895851785', 'Epoch: 127, Train Loss: 0.024089282777693, Val Loss: 0.057704390901508', 'Epoch: 128, Train Loss: 0.024288731427597, Val Loss: 0.067219469131845', 'Epoch: 129, Train Loss: 0.020712132366108, Val Loss: 0.060862343645457', 'Epoch: 130, Train Loss: 0.022829430909561, Val Loss: 0.061057653052337', 'Epoch: 131, Train Loss: 0.025495735196663, Val Loss: 0.068104989149354', 'Epoch: 132, Train Loss: 0.026008836925030, Val Loss: 0.065291140680060', 'Epoch: 133, Train Loss: 0.023904378858528, Val Loss: 0.069848750492163', 'Epoch: 134, Train Loss: 0.027090049481818, Val Loss: 0.072470082816753', 'Epoch: 135, Train Loss: 0.023615210117506, Val Loss: 0.065052476401130', 'Epoch: 136, Train Loss: 0.019524842367641, Val Loss: 0.055905731564218', 'Epoch: 137, Train Loss: 0.026223485025444, Val Loss: 0.064203198434729', 'Epoch: 138, Train Loss: 0.023468831421009, Val Loss: 0.055903512420076', 'Epoch: 139, Train Loss: 0.022942242678255, Val Loss: 0.063076581354394', 'Epoch: 140, Train Loss: 0.021951247339270, Val Loss: 0.063493656728304', 'Epoch: 141, Train Loss: 0.022191815344351, Val Loss: 0.061574935009985', 'Epoch: 142, Train Loss: 0.027389938543950, Val Loss: 0.071322405202822', 'Epoch: 143, Train Loss: 0.022605316979545, Val Loss: 0.066225429488854', 'Epoch: 144, Train Loss: 0.023510516953788, Val Loss: 0.060128183414539', 'Epoch: 145, Train Loss: 0.024761274057840, Val Loss: 0.058752473330859', 'Epoch: 146, Train Loss: 0.021567162991102, Val Loss: 0.065429972089601', 'Epoch: 147, Train Loss: 0.020550763301019, Val Loss: 0.071158618750897', 'Epoch: 148, Train Loss: 0.021871715384935, Val Loss: 0.065446433921655', 'Epoch: 149, Train Loss: 0.021582684612700, Val Loss: 0.060038569072882', 'Epoch: 150, Train Loss: 0.025443734068956, Val Loss: 0.071312501010570', 'Epoch: 151, Train Loss: 0.023825377159353, Val Loss: 0.063700786142638', 'Epoch: 152, Train Loss: 0.021999634403203, Val Loss: 0.064757031078140', 'Epoch: 153, Train Loss: 0.023347892199776, Val Loss: 0.061403346219749', 'Epoch: 154, Train Loss: 0.026041510914053, Val Loss: 0.065992384923227', 'Epoch: 155, Train Loss: 0.022811948122191, Val Loss: 0.060740397960851', 'Epoch: 156, Train Loss: 0.021647862491331, Val Loss: 0.070460594287424', 'Epoch: 157, Train Loss: 0.023945243763072, Val Loss: 0.064472265090003', 'Epoch: 158, Train Loss: 0.021618506139410, Val Loss: 0.063194850854801', 'Epoch: 159, Train Loss: 0.021516717271879, Val Loss: 0.065300534394654', 'Epoch: 160, Train Loss: 0.019654582786773, Val Loss: 0.069955704451510', 'Epoch: 161, Train Loss: 0.021301185180034, Val Loss: 0.058621102097360', 'Epoch: 162, Train Loss: 0.020553800077843, Val Loss: 0.060350667007945', 'Epoch: 163, Train Loss: 0.021585564993854, Val Loss: 0.059072018685666', 'Epoch: 164, Train Loss: 0.019206626872931, Val Loss: 0.065199378087665', 'Epoch: 165, Train Loss: 0.022388505483312, Val Loss: 0.059771934467735', 'Epoch: 166, Train Loss: 0.021346400558416, Val Loss: 0.058698850712090', 'Epoch: 167, Train Loss: 0.020321991959853, Val Loss: 0.059144787716143', 'Epoch: 168, Train Loss: 0.019369129224547, Val Loss: 0.064147854506066', 'Epoch: 169, Train Loss: 0.020988141652197, Val Loss: 0.061367378203255', 'Epoch: 170, Train Loss: 0.022002355993858, Val Loss: 0.061714398815776', 'Epoch: 171, Train Loss: 0.018606057124478, Val Loss: 0.061192067396460', 'Epoch: 172, Train Loss: 0.020755468202489, Val Loss: 0.062286244648876', 'Epoch: 173, Train Loss: 0.017688248439559, Val Loss: 0.061726244448712', 'Epoch: 174, Train Loss: 0.021012128530336, Val Loss: 0.062142017212781', 'Epoch: 175, Train Loss: 0.021699238235929, Val Loss: 0.064579321579500', 'Epoch: 176, Train Loss: 0.022032184060663, Val Loss: 0.063044006400036', 'Epoch: 177, Train Loss: 0.018331425996231, Val Loss: 0.060568822604237', 'Epoch: 178, Train Loss: 0.021075648388692, Val Loss: 0.062786117083195', 'Epoch: 179, Train Loss: 0.019587003027222, Val Loss: 0.062564536251805', 'Epoch: 180, Train Loss: 0.016977393534034, Val Loss: 0.059779471520222', 'Epoch: 181, Train Loss: 0.020587151936655, Val Loss: 0.062742246935765', 'Epoch: 182, Train Loss: 0.017068739647844, Val Loss: 0.063731467577093', 'Epoch: 183, Train Loss: 0.018449007932629, Val Loss: 0.060728434811939', 'Epoch: 184, Train Loss: 0.017432083974459, Val Loss: 0.059679326573105', 'Epoch: 185, Train Loss: 0.020499390084296, Val Loss: 0.063425232176528', 'Epoch: 186, Train Loss: 0.020241139988814, Val Loss: 0.062835868448019', 'Epoch: 187, Train Loss: 0.017841964893575, Val Loss: 0.062723816682895', 'Epoch: 188, Train Loss: 0.017438656517438, Val Loss: 0.060575641578797', 'Epoch: 189, Train Loss: 0.019831944523113, Val Loss: 0.062511964616450', 'Epoch: 190, Train Loss: 0.019486791321209, Val Loss: 0.062348580382990', 'Epoch: 191, Train Loss: 0.018976772869272, Val Loss: 0.062638686687657', 'Epoch: 192, Train Loss: 0.019652598670551, Val Loss: 0.062296910832326', 'Epoch: 193, Train Loss: 0.016811310779303, Val Loss: 0.062130211542050', 'Epoch: 194, Train Loss: 0.017141693404743, Val Loss: 0.062257003942222', 'Epoch: 195, Train Loss: 0.020284640004060, Val Loss: 0.061094475289186', 'Epoch: 196, Train Loss: 0.021512052776026, Val Loss: 0.061413281343200', 'Epoch: 197, Train Loss: 0.017587583245976, Val Loss: 0.061356051514546', 'Epoch: 198, Train Loss: 0.014872920632895, Val Loss: 0.061263956806876', 'Epoch: 199, Train Loss: 0.021770842639463, Val Loss: 0.061222474570527']","[ 134.52554   797.6494    691.2141    439.6826     79.64363   615.89215
  490.2004     95.74954   628.44556   214.72958    43.14807   271.00787
  584.4683    423.94983   253.36862   461.46448   477.43213   116.37985
  687.8954    587.7664   1041.1692    291.88788   952.84454   109.81055
  842.1108    181.13446   694.1144    419.9962    806.48376  1192.2505
  292.5141   1150.3883    169.21231   268.91907  1429.8969    547.19257
 1175.6475    121.2063    563.5581    641.4297   1132.605     649.5345
  410.69217   632.6117    394.43427   609.6168    909.3096    671.03394
 1185.6675   1094.6262   1137.2391    888.42957  1177.7285    855.7604
  104.14691   608.6197    526.00854   405.86972   404.01263    47.2493
   20.507141  685.9015    753.615     318.85965   543.912      84.83186
  122.99805    85.57712   261.02615   283.8731    401.69052   477.40497
  721.78955   895.2418    329.59433   638.37024   279.57117   675.881
  477.07156   572.8349    691.6881    864.5598    284.28488   907.08356
  312.65588    75.50653   620.43097   823.2302    192.59299   274.24643
  267.63318   818.9285     41.233185  206.63477   332.17014   231.96283
  644.0965    604.7989    737.4956    127.90927   694.00336   165.98267
  426.52148   186.2782    806.92255   904.63446   349.7179    449.12518
  243.94936   593.6415    640.0748    102.15756   632.99805   187.88531
  146.80591   137.8653    383.73654  1327.7366     13.723694  780.819
   95.59955   489.06366   935.7298    265.4128    548.6123    562.0951
  350.84784    12.088623  417.87872   303.49234   730.1066    402.3608
  620.43274   166.78876   823.0254    925.10425  1219.9059    730.69086 ]","[ 131.61868   825.1598    673.88586   532.64685    66.02118   472.37378
  529.22626    84.49788   681.15796   175.34216    28.986023  202.95891
  631.66284   311.68604   174.25562   509.48215   515.44464   149.15724
  587.78235   520.1826   1015.06274   257.87207   918.6329    117.08893
  832.4003     82.48706   625.50464   481.79523   809.7325   1174.1814
  321.08658  1062.584     129.66861   303.85553  1275.0056    503.1858
 1222.6597    226.58838   632.33545   617.75354  1105.6138    658.8779
  411.39285   629.20624   368.31866   604.17163   949.99713   617.00006
 1233.8792   1080.1624   1207.8138    875.17303  1194.1007    824.81964
  106.21185   616.4429    366.0112    376.87366   400.2034    178.68552
  114.3273    679.81995   720.0355    289.76678   419.83255   120.48985
  182.36996   130.07114   199.56548   296.23837   392.00552   448.4159
  712.01306   933.03503   207.6912    693.5916    281.22815   629.90735
  477.9212    696.04865   579.2804    990.9429    311.8674    809.09937
  316.34988    72.09723   624.4737    837.2898    236.67906   270.5749
  317.4794    771.0358    129.0391    193.66081   293.2234    181.80083
  633.6492    674.3677    728.8622    194.29135   632.59143   211.35681
  467.35043   106.04913   786.07916  1185.4017    339.32904   500.4865
  223.43726   598.69104   543.7606    167.38805   601.91156   102.271454
   83.782425  176.48354   458.21112  1306.4666     67.155914  777.7704
  205.61722   504.03784   928.3095    259.3484    316.197     419.64816
  402.54688    73.423615  426.31543   327.50552   688.26337   403.06464
  577.18616    65.54172   903.8044    998.2927   1138.0983    683.15753 ]",49.5042,4501.1387,67.090525947223
trial_3,polar_knn_minmax_noact,"['Epoch: 0, Train Loss: 0.388400082077299, Val Loss: 0.407447452798034', 'Epoch: 1, Train Loss: 0.378943754093988, Val Loss: 0.402812151294766', 'Epoch: 2, Train Loss: 0.370512119361332, Val Loss: 0.405092317046541', 'Epoch: 3, Train Loss: 0.371929198503494, Val Loss: 0.407215933005015', 'Epoch: 4, Train Loss: 0.370863412107740, Val Loss: 0.403656266855471', 'Epoch: 5, Train Loss: 0.379092508128711, Val Loss: 0.400306203148582', 'Epoch: 6, Train Loss: 0.374772012233734, Val Loss: 0.387184912508184', 'Epoch: 7, Train Loss: 0.345670525516783, Val Loss: 0.342681724916805', 'Epoch: 8, Train Loss: 0.256939566561154, Val Loss: 0.246667748147791', 'Epoch: 9, Train Loss: 0.234711528888771, Val Loss: 0.151637987036145', 'Epoch: 10, Train Loss: 0.161636667592185, Val Loss: 0.101743561751915', 'Epoch: 11, Train Loss: 0.107163825737579, Val Loss: 0.102808631053477', 'Epoch: 12, Train Loss: 0.099544604441949, Val Loss: 0.128279201460607', 'Epoch: 13, Train Loss: 0.095741802028247, Val Loss: 0.083999023631667', 'Epoch: 14, Train Loss: 0.086178476789168, Val Loss: 0.083799465136095', 'Epoch: 15, Train Loss: 0.101822536970888, Val Loss: 0.092023730955341', 'Epoch: 16, Train Loss: 0.086310442803161, Val Loss: 0.083506783752730', 'Epoch: 17, Train Loss: 0.078192361763545, Val Loss: 0.074441319613746', 'Epoch: 18, Train Loss: 0.075587579182216, Val Loss: 0.065507864523115', 'Epoch: 19, Train Loss: 0.068033846095204, Val Loss: 0.072672000211297', 'Epoch: 20, Train Loss: 0.064176128112844, Val Loss: 0.088255832592646', 'Epoch: 21, Train Loss: 0.070595641221319, Val Loss: 0.073292839764194', 'Epoch: 22, Train Loss: 0.068666332002197, Val Loss: 0.067556803199378', 'Epoch: 23, Train Loss: 0.068753396027855, Val Loss: 0.067419501134392', 'Epoch: 24, Train Loss: 0.063178188300559, Val Loss: 0.111688127120336', 'Epoch: 25, Train Loss: 0.089991234509008, Val Loss: 0.077994132019354', 'Epoch: 26, Train Loss: 0.067034207284451, Val Loss: 0.089249517994397', 'Epoch: 27, Train Loss: 0.064757566100785, Val Loss: 0.073244264067122', 'Epoch: 28, Train Loss: 0.068426526018551, Val Loss: 0.075417416339571', 'Epoch: 29, Train Loss: 0.059006449367319, Val Loss: 0.061789489887429', 'Epoch: 30, Train Loss: 0.054942822349923, Val Loss: 0.071054515192483', 'Epoch: 31, Train Loss: 0.067826059513858, Val Loss: 0.065031733307423', 'Epoch: 32, Train Loss: 0.062247110530734, Val Loss: 0.055573007797427', 'Epoch: 33, Train Loss: 0.052690842854125, Val Loss: 0.067554925878843', 'Epoch: 34, Train Loss: 0.054823048944984, Val Loss: 0.057552867315032', 'Epoch: 35, Train Loss: 0.055212150460907, Val Loss: 0.055687000918569', 'Epoch: 36, Train Loss: 0.055398399542485, Val Loss: 0.059946329135335', 'Epoch: 37, Train Loss: 0.054720182503973, Val Loss: 0.090019007944096', 'Epoch: 38, Train Loss: 0.058094527572393, Val Loss: 0.073428911241618', 'Epoch: 39, Train Loss: 0.058793216810695, Val Loss: 0.057097256352956', 'Epoch: 40, Train Loss: 0.051436616906098, Val Loss: 0.053694077795654', 'Epoch: 41, Train Loss: 0.053497881495527, Val Loss: 0.050471299158579', 'Epoch: 42, Train Loss: 0.056655657743769, Val Loss: 0.058798614607164', 'Epoch: 43, Train Loss: 0.047658990270325, Val Loss: 0.064851737623526', 'Epoch: 44, Train Loss: 0.053295196699245, Val Loss: 0.078907353408409', 'Epoch: 45, Train Loss: 0.057440119662455, Val Loss: 0.054195454457041', 'Epoch: 46, Train Loss: 0.052927715969937, Val Loss: 0.050604126867697', 'Epoch: 47, Train Loss: 0.055097691448671, Val Loss: 0.061243461840080', 'Epoch: 48, Train Loss: 0.049699276020484, Val Loss: 0.064774871521601', 'Epoch: 49, Train Loss: 0.049100515698748, Val Loss: 0.067303841651389', 'Epoch: 50, Train Loss: 0.049543949110167, Val Loss: 0.075539921777266', 'Epoch: 51, Train Loss: 0.043464899728341, Val Loss: 0.066689439738790', 'Epoch: 52, Train Loss: 0.054259143769741, Val Loss: 0.061034711360028', 'Epoch: 53, Train Loss: 0.046694596697177, Val Loss: 0.059404468220292', 'Epoch: 54, Train Loss: 0.048594560740249, Val Loss: 0.070592837806819', 'Epoch: 55, Train Loss: 0.045634960223522, Val Loss: 0.060260094363581', 'Epoch: 56, Train Loss: 0.046486937973116, Val Loss: 0.057781701611186', 'Epoch: 57, Train Loss: 0.046649058748569, Val Loss: 0.052515135682894', 'Epoch: 58, Train Loss: 0.037886335780578, Val Loss: 0.067703261096595', 'Epoch: 59, Train Loss: 0.039793571324221, Val Loss: 0.054265326114767', 'Epoch: 60, Train Loss: 0.039940404971795, Val Loss: 0.064481178397369', 'Epoch: 61, Train Loss: 0.055514693260193, Val Loss: 0.052950192807299', 'Epoch: 62, Train Loss: 0.048904695681163, Val Loss: 0.070739226923747', 'Epoch: 63, Train Loss: 0.043594660769616, Val Loss: 0.065611611960004', 'Epoch: 64, Train Loss: 0.038521180328514, Val Loss: 0.062004610444560', 'Epoch: 65, Train Loss: 0.036493055123304, Val Loss: 0.067661347661421', 'Epoch: 66, Train Loss: 0.047178198184286, Val Loss: 0.078335798260841', 'Epoch: 67, Train Loss: 0.046114088967443, Val Loss: 0.054579646241936', 'Epoch: 68, Train Loss: 0.043608663470617, Val Loss: 0.063718870148119', 'Epoch: 69, Train Loss: 0.049211045727134, Val Loss: 0.054109002773960', 'Epoch: 70, Train Loss: 0.050730079279414, Val Loss: 0.069281171471106', 'Epoch: 71, Train Loss: 0.040532268317682, Val Loss: 0.065708334127328', 'Epoch: 72, Train Loss: 0.045093904515462, Val Loss: 0.054283161393621', 'Epoch: 73, Train Loss: 0.041752779191094, Val Loss: 0.077253985021150', 'Epoch: 74, Train Loss: 0.042699493068670, Val Loss: 0.057326416005239', 'Epoch: 75, Train Loss: 0.032659184187651, Val Loss: 0.055602297250351', 'Epoch: 76, Train Loss: 0.032644563620644, Val Loss: 0.058296815517127', 'Epoch: 77, Train Loss: 0.040503199079207, Val Loss: 0.058617547244825', 'Epoch: 78, Train Loss: 0.035353441988783, Val Loss: 0.060329733783323', 'Epoch: 79, Train Loss: 0.035361109700586, Val Loss: 0.053589128381149', 'Epoch: 80, Train Loss: 0.033986390435270, Val Loss: 0.054095542707452', 'Epoch: 81, Train Loss: 0.036152545761849, Val Loss: 0.062528917481276', 'Epoch: 82, Train Loss: 0.030511779045420, Val Loss: 0.053828922410806', 'Epoch: 83, Train Loss: 0.038040942246360, Val Loss: 0.070873894079617', 'Epoch: 84, Train Loss: 0.039438767225615, Val Loss: 0.079537204946532', 'Epoch: 85, Train Loss: 0.041744733495372, Val Loss: 0.053549889884325', 'Epoch: 86, Train Loss: 0.035658366579030, Val Loss: 0.057235989042304', 'Epoch: 87, Train Loss: 0.028778371001993, Val Loss: 0.059775932945988', 'Epoch: 88, Train Loss: 0.028474854837571, Val Loss: 0.053513322604086', 'Epoch: 89, Train Loss: 0.036610286283706, Val Loss: 0.069784599977235', 'Epoch: 90, Train Loss: 0.035925424258624, Val Loss: 0.057192763715813', 'Epoch: 91, Train Loss: 0.032602356879839, Val Loss: 0.059286620580789', 'Epoch: 92, Train Loss: 0.033397243358195, Val Loss: 0.053979232004195', 'Epoch: 93, Train Loss: 0.031014806857066, Val Loss: 0.059554338949083', 'Epoch: 94, Train Loss: 0.028705270694835, Val Loss: 0.056592341963992', 'Epoch: 95, Train Loss: 0.029478008060583, Val Loss: 0.055883094103950', 'Epoch: 96, Train Loss: 0.029393738667880, Val Loss: 0.066277922667337', 'Epoch: 97, Train Loss: 0.033240933902562, Val Loss: 0.063538246124870', 'Epoch: 98, Train Loss: 0.029340719005891, Val Loss: 0.055489349207192', 'Epoch: 99, Train Loss: 0.034107419928270, Val Loss: 0.065627946934635', 'Epoch: 100, Train Loss: 0.032407067583076, Val Loss: 0.052278788647417', 'Epoch: 101, Train Loss: 0.029738934444530, Val Loss: 0.052534639355585', 'Epoch: 102, Train Loss: 0.031514303891787, Val Loss: 0.057943572854680', 'Epoch: 103, Train Loss: 0.030521961195128, Val Loss: 0.064744842944272', 'Epoch: 104, Train Loss: 0.032943852511900, Val Loss: 0.059526766939653', 'Epoch: 105, Train Loss: 0.034502510247486, Val Loss: 0.057889435228638', 'Epoch: 106, Train Loss: 0.031743492398943, Val Loss: 0.059834404199412', 'Epoch: 107, Train Loss: 0.027955989719235, Val Loss: 0.046865887911708', 'Epoch: 108, Train Loss: 0.037876545318535, Val Loss: 0.057746442853276', 'Epoch: 109, Train Loss: 0.035777824930847, Val Loss: 0.055238230266806', 'Epoch: 110, Train Loss: 0.030029675058488, Val Loss: 0.060517509736008', 'Epoch: 111, Train Loss: 0.036622439245028, Val Loss: 0.055384640215021', 'Epoch: 112, Train Loss: 0.038767451553472, Val Loss: 0.058415490908153', 'Epoch: 113, Train Loss: 0.034853223977344, Val Loss: 0.059611398444483', 'Epoch: 114, Train Loss: 0.033667785780770, Val Loss: 0.050464373825393', 'Epoch: 115, Train Loss: 0.025455922553582, Val Loss: 0.058906072969407', 'Epoch: 116, Train Loss: 0.026678298001311, Val Loss: 0.055345428148002', 'Epoch: 117, Train Loss: 0.026325745308506, Val Loss: 0.068316186270253', 'Epoch: 118, Train Loss: 0.027028894717140, Val Loss: 0.058501308876492', 'Epoch: 119, Train Loss: 0.028816741891205, Val Loss: 0.064769277010452', 'Epoch: 120, Train Loss: 0.023787816254688, Val Loss: 0.052674177300298', 'Epoch: 121, Train Loss: 0.030002902927143, Val Loss: 0.053929220687485', 'Epoch: 122, Train Loss: 0.028675071495984, Val Loss: 0.056158107056311', 'Epoch: 123, Train Loss: 0.024351498112082, Val Loss: 0.056863230568441', 'Epoch: 124, Train Loss: 0.025679890199431, Val Loss: 0.064599716781893', 'Epoch: 125, Train Loss: 0.026391524422382, Val Loss: 0.058051450121583', 'Epoch: 126, Train Loss: 0.026485750717776, Val Loss: 0.063994684087282', 'Epoch: 127, Train Loss: 0.026177261556898, Val Loss: 0.053588821602082', 'Epoch: 128, Train Loss: 0.024982996883669, Val Loss: 0.052544004978810', 'Epoch: 129, Train Loss: 0.023317619359919, Val Loss: 0.062598567794670', 'Epoch: 130, Train Loss: 0.026571664027870, Val Loss: 0.053828791291876', 'Epoch: 131, Train Loss: 0.023843169877572, Val Loss: 0.050855218856172', 'Epoch: 132, Train Loss: 0.021279570713107, Val Loss: 0.066951720763675', 'Epoch: 133, Train Loss: 0.022350653606866, Val Loss: 0.055708769299654', 'Epoch: 134, Train Loss: 0.025755557630743, Val Loss: 0.047954532797589', 'Epoch: 135, Train Loss: 0.022324141247996, Val Loss: 0.058218665766727', 'Epoch: 136, Train Loss: 0.024508167856506, Val Loss: 0.061102780231246', 'Epoch: 137, Train Loss: 0.019469852293176, Val Loss: 0.056362801033891', 'Epoch: 138, Train Loss: 0.022662453020790, Val Loss: 0.058212426321750', 'Epoch: 139, Train Loss: 0.024353183805943, Val Loss: 0.061111770090506', 'Epoch: 140, Train Loss: 0.024995848802584, Val Loss: 0.057053695630395', 'Epoch: 141, Train Loss: 0.024978228046426, Val Loss: 0.056191544274263', 'Epoch: 142, Train Loss: 0.028671385055142, Val Loss: 0.057326575353121', 'Epoch: 143, Train Loss: 0.028224566419210, Val Loss: 0.061625514602797', 'Epoch: 144, Train Loss: 0.022965370743935, Val Loss: 0.060389372096820', 'Epoch: 145, Train Loss: 0.022615528465914, Val Loss: 0.051534428684549', 'Epoch: 146, Train Loss: 0.021675707705851, Val Loss: 0.059748753284415', 'Epoch: 147, Train Loss: 0.018888823754553, Val Loss: 0.062342067905278', 'Epoch: 148, Train Loss: 0.023567486687430, Val Loss: 0.053947036747228', 'Epoch: 149, Train Loss: 0.021314329866852, Val Loss: 0.051289225730932', 'Epoch: 150, Train Loss: 0.018424747977406, Val Loss: 0.054036645896055', 'Epoch: 151, Train Loss: 0.018591549912734, Val Loss: 0.058361773068706', 'Epoch: 152, Train Loss: 0.021237665255155, Val Loss: 0.058237421834333', 'Epoch: 153, Train Loss: 0.022655817613538, Val Loss: 0.056751617569138', 'Epoch: 154, Train Loss: 0.024245313634830, Val Loss: 0.063717567047923', 'Epoch: 155, Train Loss: 0.020558500396354, Val Loss: 0.056806881291171', 'Epoch: 156, Train Loss: 0.022134481596627, Val Loss: 0.055872444698418', 'Epoch: 157, Train Loss: 0.022595076156514, Val Loss: 0.058813674354248', 'Epoch: 158, Train Loss: 0.021646733395755, Val Loss: 0.054406935349107', 'Epoch: 159, Train Loss: 0.019102716020175, Val Loss: 0.057535161490016', 'Epoch: 160, Train Loss: 0.017903117462993, Val Loss: 0.061364828312600', 'Epoch: 161, Train Loss: 0.019558006298861, Val Loss: 0.058429235846482', 'Epoch: 162, Train Loss: 0.020175974749561, Val Loss: 0.053830688875733', 'Epoch: 163, Train Loss: 0.020279029450778, Val Loss: 0.055834975460488', 'Epoch: 164, Train Loss: 0.020770516579172, Val Loss: 0.058307777412913', 'Epoch: 165, Train Loss: 0.016439094274704, Val Loss: 0.056860907341946', 'Epoch: 166, Train Loss: 0.018433751937534, Val Loss: 0.061823851838143', 'Epoch: 167, Train Loss: 0.021635651788009, Val Loss: 0.060045130494418', 'Epoch: 168, Train Loss: 0.018907340775643, Val Loss: 0.057557426534142', 'Epoch: 169, Train Loss: 0.019581478222140, Val Loss: 0.055392103834134', 'Epoch: 170, Train Loss: 0.020121262807931, Val Loss: 0.055371839390842', 'Epoch: 171, Train Loss: 0.020100859326444, Val Loss: 0.053385548011372', 'Epoch: 172, Train Loss: 0.016579358372837, Val Loss: 0.056971170177514', 'Epoch: 173, Train Loss: 0.018615126942417, Val Loss: 0.058047863231464', 'Epoch: 174, Train Loss: 0.019198169000447, Val Loss: 0.052011834401073', 'Epoch: 175, Train Loss: 0.019314241429259, Val Loss: 0.054965419553672', 'Epoch: 176, Train Loss: 0.015361766962867, Val Loss: 0.050695416715109', 'Epoch: 177, Train Loss: 0.017628705794258, Val Loss: 0.056520679626953', 'Epoch: 178, Train Loss: 0.021098902715104, Val Loss: 0.052959163870775', 'Epoch: 179, Train Loss: 0.018448520917445, Val Loss: 0.057502881736692', 'Epoch: 180, Train Loss: 0.019081864838621, Val Loss: 0.057868505658751', 'Epoch: 181, Train Loss: 0.020498910719263, Val Loss: 0.060249812901020', 'Epoch: 182, Train Loss: 0.022186776223992, Val Loss: 0.057108902739304', 'Epoch: 183, Train Loss: 0.017824020436300, Val Loss: 0.058928402027849', 'Epoch: 184, Train Loss: 0.019828326002296, Val Loss: 0.058768278608720', 'Epoch: 185, Train Loss: 0.023537577928177, Val Loss: 0.057677457109094', 'Epoch: 186, Train Loss: 0.020508052914270, Val Loss: 0.056787567692950', 'Epoch: 187, Train Loss: 0.019120687286236, Val Loss: 0.058678727653442', 'Epoch: 188, Train Loss: 0.017286991101823, Val Loss: 0.055418693404080', 'Epoch: 189, Train Loss: 0.022185732943139, Val Loss: 0.056886540104946', 'Epoch: 190, Train Loss: 0.017073574010283, Val Loss: 0.058010072024031', 'Epoch: 191, Train Loss: 0.018079395538994, Val Loss: 0.057970899834552', 'Epoch: 192, Train Loss: 0.017618867635195, Val Loss: 0.057774004131330', 'Epoch: 193, Train Loss: 0.018644261439996, Val Loss: 0.055820489528053', 'Epoch: 194, Train Loss: 0.013243450616886, Val Loss: 0.054947265762497', 'Epoch: 195, Train Loss: 0.019541954488627, Val Loss: 0.055280538840276', 'Epoch: 196, Train Loss: 0.015974012669176, Val Loss: 0.056481779129668', 'Epoch: 197, Train Loss: 0.015986318334139, Val Loss: 0.056763546625999', 'Epoch: 198, Train Loss: 0.013494077537741, Val Loss: 0.056621780731913', 'Epoch: 199, Train Loss: 0.017286383380581, Val Loss: 0.056512938558378']","[ 134.52554   797.6494    691.2141    439.6826     79.64363   615.89215
  490.2004     95.74954   628.44556   214.72958    43.14807   271.00787
  584.4683    423.94983   253.36862   461.46448   477.43213   116.37985
  687.8954    587.7664   1041.1692    291.88788   952.84454   109.81055
  842.1108    181.13446   694.1144    419.9962    806.48376  1192.2505
  292.5141   1150.3883    169.21231   268.91907  1429.8969    547.19257
 1175.6475    121.2063    563.5581    641.4297   1132.605     649.5345
  410.69217   632.6117    394.43427   609.6168    909.3096    671.03394
 1185.6675   1094.6262   1137.2391    888.42957  1177.7285    855.7604
  104.14691   608.6197    526.00854   405.86972   404.01263    47.2493
   20.507141  685.9015    753.615     318.85965   543.912      84.83186
  122.99805    85.57712   261.02615   283.8731    401.69052   477.40497
  721.78955   895.2418    329.59433   638.37024   279.57117   675.881
  477.07156   572.8349    691.6881    864.5598    284.28488   907.08356
  312.65588    75.50653   620.43097   823.2302    192.59299   274.24643
  267.63318   818.9285     41.233185  206.63477   332.17014   231.96283
  644.0965    604.7989    737.4956    127.90927   694.00336   165.98267
  426.52148   186.2782    806.92255   904.63446   349.7179    449.12518
  243.94936   593.6415    640.0748    102.15756   632.99805   187.88531
  146.80591   137.8653    383.73654  1327.7366     13.723694  780.819
   95.59955   489.06366   935.7298    265.4128    548.6123    562.0951
  350.84784    12.088623  417.87872   303.49234   730.1066    402.3608
  620.43274   166.78876   823.0254    925.10425  1219.9059    730.69086 ]","[ 150.73846   723.4448    698.8606    605.20935    58.402374  511.7575
  515.04956   115.35634   669.466     214.63586    22.078491  230.88423
  590.02277   305.40814   185.13614   385.96515   482.84448   102.67662
  565.698     514.4332   1036.9293    300.60538   899.17346   169.00772
  840.1199     82.17407   581.6122    529.0709    842.28143  1104.9468
  241.73859  1125.9108     83.52402   343.74872  1176.3304    575.5427
 1233.7222    271.93094   605.94336   609.8821   1051.937     615.93036
  344.22348   643.0315    360.22653   548.50525   970.6883    684.77893
 1263.7109   1095.2764   1195.444     953.50354  1226.6754    821.80035
   99.43225   596.7924    401.51126   309.317     381.6852    134.51157
   70.9599    580.2074    708.8865    288.38013   469.09262   143.58653
  188.31235   118.1405    207.7763    266.02908   364.40067   409.77725
  771.42114   864.89404   181.646     587.18317   273.99622   600.30615
  503.78162   642.05927   565.1832    958.6245    307.7688    791.0038
  340.59735   139.41547   605.2761    792.089     135.85165   183.36229
  322.26007   732.1056    123.18788   139.51787   307.81982   174.26273
  666.6379    597.9576    710.68726   128.03183   611.77997   197.62628
  440.0354    156.84634   865.2985   1126.4471    357.41507   486.3947
  168.09023   631.6217    548.47815   100.72041   576.83746   171.08313
  163.14386   149.17332   411.01474  1361.5457     39.032288  839.823
  386.02432   502.2322    944.1783    246.0025    359.99915   430.3616
  378.67276   -21.426208  399.1245    289.0389    641.8901    409.16354
  627.28345    90.96655   915.5238    907.11145  1111.6294    815.9819  ]",55.916656,5494.5127,74.124980238193
trial_1,polar_knn_minmax_noact,"['Epoch: 0, Train Loss: 0.386820171560560, Val Loss: 0.396983562996893', 'Epoch: 1, Train Loss: 0.381194608552115, Val Loss: 0.402512972779346', 'Epoch: 2, Train Loss: 0.387914055160114, Val Loss: 0.394724725548065', 'Epoch: 3, Train Loss: 0.383311656968934, Val Loss: 0.396002546178572', 'Epoch: 4, Train Loss: 0.386110310043607, Val Loss: 0.392686820843003', 'Epoch: 5, Train Loss: 0.378760950905936, Val Loss: 0.389893888298309', 'Epoch: 6, Train Loss: 0.384956779224532, Val Loss: 0.380134101844195', 'Epoch: 7, Train Loss: 0.367203569837979, Val Loss: 0.392023872245442', 'Epoch: 8, Train Loss: 0.322366512247494, Val Loss: 0.275401352029858', 'Epoch: 9, Train Loss: 0.230663186737469, Val Loss: 0.209379145028916', 'Epoch: 10, Train Loss: 0.200956677751882, Val Loss: 0.185151663467740', 'Epoch: 11, Train Loss: 0.158273962459394, Val Loss: 0.135335457483024', 'Epoch: 12, Train Loss: 0.127188492034163, Val Loss: 0.202125657462712', 'Epoch: 13, Train Loss: 0.114536881979023, Val Loss: 0.098075394659783', 'Epoch: 14, Train Loss: 0.094688484445214, Val Loss: 0.119799250398170', 'Epoch: 15, Train Loss: 0.084058297531945, Val Loss: 0.095931002136433', 'Epoch: 16, Train Loss: 0.080809445785625, Val Loss: 0.098458798602223', 'Epoch: 17, Train Loss: 0.076757799567921, Val Loss: 0.094073925110878', 'Epoch: 18, Train Loss: 0.079802933548178, Val Loss: 0.087265463037924', 'Epoch: 19, Train Loss: 0.072193205888782, Val Loss: 0.089450189787330', 'Epoch: 20, Train Loss: 0.070828893088869, Val Loss: 0.097448143430732', 'Epoch: 21, Train Loss: 0.063798452195312, Val Loss: 0.079626812345602', 'Epoch: 22, Train Loss: 0.056088085685457, Val Loss: 0.078565967805458', 'Epoch: 23, Train Loss: 0.047230901196599, Val Loss: 0.061915627257390', 'Epoch: 24, Train Loss: 0.046989068122847, Val Loss: 0.072241486925067', 'Epoch: 25, Train Loss: 0.058572998802577, Val Loss: 0.057210322695248', 'Epoch: 26, Train Loss: 0.051451769524387, Val Loss: 0.056028447593703', 'Epoch: 27, Train Loss: 0.048788193081106, Val Loss: 0.070388127457012', 'Epoch: 28, Train Loss: 0.054560608097485, Val Loss: 0.055652446931962', 'Epoch: 29, Train Loss: 0.050345317061458, Val Loss: 0.062859409573403', 'Epoch: 30, Train Loss: 0.042088821663388, Val Loss: 0.059554639187726', 'Epoch: 31, Train Loss: 0.052322598307260, Val Loss: 0.060360961904128', 'Epoch: 32, Train Loss: 0.047276460432581, Val Loss: 0.073088071111477', 'Epoch: 33, Train Loss: 0.049689556205911, Val Loss: 0.064938111738725', 'Epoch: 34, Train Loss: 0.048593682103923, Val Loss: 0.071484698377775', 'Epoch: 35, Train Loss: 0.046544390198375, Val Loss: 0.067459871315143', 'Epoch: 36, Train Loss: 0.049071046390704, Val Loss: 0.077104131606492', 'Epoch: 37, Train Loss: 0.054630709146815, Val Loss: 0.075962988038858', 'Epoch: 38, Train Loss: 0.059316377820713, Val Loss: 0.083317753943530', 'Epoch: 39, Train Loss: 0.059595161782844, Val Loss: 0.067250860967871', 'Epoch: 40, Train Loss: 0.050111833959818, Val Loss: 0.061037557707591', 'Epoch: 41, Train Loss: 0.048767513994660, Val Loss: 0.058975489019896', 'Epoch: 42, Train Loss: 0.042807806682374, Val Loss: 0.075783577211427', 'Epoch: 43, Train Loss: 0.056303215612258, Val Loss: 0.086130937025177', 'Epoch: 44, Train Loss: 0.063164212607912, Val Loss: 0.082096866416660', 'Epoch: 45, Train Loss: 0.074197670710938, Val Loss: 0.069298855395931', 'Epoch: 46, Train Loss: 0.052976338591959, Val Loss: 0.069933867815769', 'Epoch: 47, Train Loss: 0.055119459384254, Val Loss: 0.058283918396090', 'Epoch: 48, Train Loss: 0.039663158889328, Val Loss: 0.058530851747050', 'Epoch: 49, Train Loss: 0.046162982870425, Val Loss: 0.066913342159806', 'Epoch: 50, Train Loss: 0.047705934249929, Val Loss: 0.059353507377885', 'Epoch: 51, Train Loss: 0.045133397249239, Val Loss: 0.058271246651808', 'Epoch: 52, Train Loss: 0.045707469806075, Val Loss: 0.060578230824886', 'Epoch: 53, Train Loss: 0.041863991479789, Val Loss: 0.064963926758730', 'Epoch: 54, Train Loss: 0.041657811962068, Val Loss: 0.056279049904057', 'Epoch: 55, Train Loss: 0.041453843803278, Val Loss: 0.066558365230307', 'Epoch: 56, Train Loss: 0.040583376373563, Val Loss: 0.061397197571668', 'Epoch: 57, Train Loss: 0.034415011028094, Val Loss: 0.061796750986215', 'Epoch: 58, Train Loss: 0.032459988258779, Val Loss: 0.066121045612928', 'Epoch: 59, Train Loss: 0.043581012370331, Val Loss: 0.059727542638553', 'Epoch: 60, Train Loss: 0.041480968573264, Val Loss: 0.058963246191993', 'Epoch: 61, Train Loss: 0.038082308535065, Val Loss: 0.063047151673924', 'Epoch: 62, Train Loss: 0.037687714743827, Val Loss: 0.058311286297711', 'Epoch: 63, Train Loss: 0.038050742686859, Val Loss: 0.052567788823084', 'Epoch: 64, Train Loss: 0.042815529209163, Val Loss: 0.052404755444238', 'Epoch: 65, Train Loss: 0.037464019044169, Val Loss: 0.064983973448927', 'Epoch: 66, Train Loss: 0.035242346913687, Val Loss: 0.065464692359621', 'Epoch: 67, Train Loss: 0.041914868301579, Val Loss: 0.075594358400188', 'Epoch: 68, Train Loss: 0.043615274264344, Val Loss: 0.068333160245057', 'Epoch: 69, Train Loss: 0.041351835243404, Val Loss: 0.061102688086755', 'Epoch: 70, Train Loss: 0.032534764680479, Val Loss: 0.059244869333325', 'Epoch: 71, Train Loss: 0.035182738610144, Val Loss: 0.052964998239821', 'Epoch: 72, Train Loss: 0.029579474191580, Val Loss: 0.051134675289645', 'Epoch: 73, Train Loss: 0.034854941402695, Val Loss: 0.060947457046220', 'Epoch: 74, Train Loss: 0.035248273584460, Val Loss: 0.060901495317618', 'Epoch: 75, Train Loss: 0.031420912527080, Val Loss: 0.058653071748488', 'Epoch: 76, Train Loss: 0.037273926527372, Val Loss: 0.075120142915032', 'Epoch: 77, Train Loss: 0.036379532356347, Val Loss: 0.056018185209144', 'Epoch: 78, Train Loss: 0.033442697088633, Val Loss: 0.058167821417252', 'Epoch: 79, Train Loss: 0.053104382407452, Val Loss: 0.054484819824045', 'Epoch: 80, Train Loss: 0.040872270108334, Val Loss: 0.069088501234849', 'Epoch: 81, Train Loss: 0.036968137669776, Val Loss: 0.063735720334631', 'Epoch: 82, Train Loss: 0.033273910438376, Val Loss: 0.060012453433239', 'Epoch: 83, Train Loss: 0.038593548216990, Val Loss: 0.056744133432706', 'Epoch: 84, Train Loss: 0.030643350710826, Val Loss: 0.057725420503905', 'Epoch: 85, Train Loss: 0.034263649356685, Val Loss: 0.051799338423845', 'Epoch: 86, Train Loss: 0.027441573794931, Val Loss: 0.053126493186662', 'Epoch: 87, Train Loss: 0.032057022941964, Val Loss: 0.055503829862132', 'Epoch: 88, Train Loss: 0.030869158450514, Val Loss: 0.053318780931559', 'Epoch: 89, Train Loss: 0.030159474749650, Val Loss: 0.057283492476651', 'Epoch: 90, Train Loss: 0.029655162245035, Val Loss: 0.060938695614988', 'Epoch: 91, Train Loss: 0.028291416753616, Val Loss: 0.056877902285619', 'Epoch: 92, Train Loss: 0.030763466310288, Val Loss: 0.049997534715768', 'Epoch: 93, Train Loss: 0.028977223073265, Val Loss: 0.052880145609379', 'Epoch: 94, Train Loss: 0.029558993742934, Val Loss: 0.052084688435901', 'Epoch: 95, Train Loss: 0.029101549514702, Val Loss: 0.051726038257281', 'Epoch: 96, Train Loss: 0.029251702795071, Val Loss: 0.050580927594142', 'Epoch: 97, Train Loss: 0.030003173942012, Val Loss: 0.056463801048019', 'Epoch: 98, Train Loss: 0.034813069339309, Val Loss: 0.061678505079313', 'Epoch: 99, Train Loss: 0.027388736006937, Val Loss: 0.054598087840008', 'Epoch: 100, Train Loss: 0.036787312211735, Val Loss: 0.051281118821917', 'Epoch: 101, Train Loss: 0.031260226720146, Val Loss: 0.056212352419441', 'Epoch: 102, Train Loss: 0.024761196957635, Val Loss: 0.060604814101349', 'Epoch: 103, Train Loss: 0.029782365608428, Val Loss: 0.052178868515925', 'Epoch: 104, Train Loss: 0.025583500109081, Val Loss: 0.048651093786413', 'Epoch: 105, Train Loss: 0.024845608510077, Val Loss: 0.059895303439010', 'Epoch: 106, Train Loss: 0.028025607046272, Val Loss: 0.055008951687452', 'Epoch: 107, Train Loss: 0.025297950154969, Val Loss: 0.059049187961853', 'Epoch: 108, Train Loss: 0.025544908695987, Val Loss: 0.053227789812919', 'Epoch: 109, Train Loss: 0.024978033200439, Val Loss: 0.061767107835322', 'Epoch: 110, Train Loss: 0.026665600482374, Val Loss: 0.060576658583049', 'Epoch: 111, Train Loss: 0.026588961082910, Val Loss: 0.056255269682769', 'Epoch: 112, Train Loss: 0.026302593361054, Val Loss: 0.052983028193315', 'Epoch: 113, Train Loss: 0.028187675401568, Val Loss: 0.060689811115012', 'Epoch: 114, Train Loss: 0.023496803228876, Val Loss: 0.055886255520763', 'Epoch: 115, Train Loss: 0.023625313703503, Val Loss: 0.057882243033611', 'Epoch: 116, Train Loss: 0.025558140328420, Val Loss: 0.059126138687134', 'Epoch: 117, Train Loss: 0.025554489943066, Val Loss: 0.056735311719504', 'Epoch: 118, Train Loss: 0.027175887753921, Val Loss: 0.060830449741898', 'Epoch: 119, Train Loss: 0.025243977749986, Val Loss: 0.053316886000561', 'Epoch: 120, Train Loss: 0.019111670021500, Val Loss: 0.064206652343273', 'Epoch: 121, Train Loss: 0.029828887964998, Val Loss: 0.060504050643155', 'Epoch: 122, Train Loss: 0.026444001588970, Val Loss: 0.061261162952040', 'Epoch: 123, Train Loss: 0.026605288365058, Val Loss: 0.064945233139125', 'Epoch: 124, Train Loss: 0.026103063686086, Val Loss: 0.060236832183419', 'Epoch: 125, Train Loss: 0.022557983574058, Val Loss: 0.056300527895942', 'Epoch: 126, Train Loss: 0.026064434155290, Val Loss: 0.066295043311336', 'Epoch: 127, Train Loss: 0.025285704992712, Val Loss: 0.052106552051775', 'Epoch: 128, Train Loss: 0.026278891334576, Val Loss: 0.056254294108261', 'Epoch: 129, Train Loss: 0.025584707568799, Val Loss: 0.058998963033611', 'Epoch: 130, Train Loss: 0.023098560981452, Val Loss: 0.062249221246351', 'Epoch: 131, Train Loss: 0.023720980289259, Val Loss: 0.049354182499828', 'Epoch: 132, Train Loss: 0.020931868680886, Val Loss: 0.055589768696915', 'Epoch: 133, Train Loss: 0.021554526407272, Val Loss: 0.059874434475646', 'Epoch: 134, Train Loss: 0.021378621592053, Val Loss: 0.060286032656829', 'Epoch: 135, Train Loss: 0.025603749789298, Val Loss: 0.063512509462960', 'Epoch: 136, Train Loss: 0.023387261333742, Val Loss: 0.062441154185570', 'Epoch: 137, Train Loss: 0.022025929364775, Val Loss: 0.057802425189452', 'Epoch: 138, Train Loss: 0.021426085449223, Val Loss: 0.055126627737826', 'Epoch: 139, Train Loss: 0.023355559512441, Val Loss: 0.057341720908880', 'Epoch: 140, Train Loss: 0.023272133166237, Val Loss: 0.062817491139426', 'Epoch: 141, Train Loss: 0.023855617802058, Val Loss: 0.057193527167494', 'Epoch: 142, Train Loss: 0.024670948407480, Val Loss: 0.054849697446281', 'Epoch: 143, Train Loss: 0.025381276117904, Val Loss: 0.058943304600138', 'Epoch: 144, Train Loss: 0.021832382306457, Val Loss: 0.059842887249860', 'Epoch: 145, Train Loss: 0.022663056783910, Val Loss: 0.056746270281799', 'Epoch: 146, Train Loss: 0.020325621989157, Val Loss: 0.057978088431286', 'Epoch: 147, Train Loss: 0.022792233420270, Val Loss: 0.057778469540856', 'Epoch: 148, Train Loss: 0.021883041531380, Val Loss: 0.061178133343205', 'Epoch: 149, Train Loss: 0.020427478610405, Val Loss: 0.065539154478095', 'Epoch: 150, Train Loss: 0.027047983769860, Val Loss: 0.061139396420031', 'Epoch: 151, Train Loss: 0.022715141331511, Val Loss: 0.055532484343558', 'Epoch: 152, Train Loss: 0.022971464054925, Val Loss: 0.058089002515330', 'Epoch: 153, Train Loss: 0.024248233065009, Val Loss: 0.058492188878132', 'Epoch: 154, Train Loss: 0.020675209217838, Val Loss: 0.057054285072919', 'Epoch: 155, Train Loss: 0.026755535709006, Val Loss: 0.059988498913519', 'Epoch: 156, Train Loss: 0.023907896663461, Val Loss: 0.060943358775341', 'Epoch: 157, Train Loss: 0.022575707707022, Val Loss: 0.061268293270559', 'Epoch: 158, Train Loss: 0.019887498446873, Val Loss: 0.053893736253182', 'Epoch: 159, Train Loss: 0.019060465374163, Val Loss: 0.053671313054634', 'Epoch: 160, Train Loss: 0.021232433683638, Val Loss: 0.058695626529780', 'Epoch: 161, Train Loss: 0.019045585899481, Val Loss: 0.056389565833590', 'Epoch: 162, Train Loss: 0.020473957660475, Val Loss: 0.051470769399946', 'Epoch: 163, Train Loss: 0.020845499288823, Val Loss: 0.054667989300056', 'Epoch: 164, Train Loss: 0.020148784321334, Val Loss: 0.055434945632111', 'Epoch: 165, Train Loss: 0.020889828912914, Val Loss: 0.055411025204442', 'Epoch: 166, Train Loss: 0.021413687583325, Val Loss: 0.052668339826844', 'Epoch: 167, Train Loss: 0.021514115988144, Val Loss: 0.054590856487101', 'Epoch: 168, Train Loss: 0.019015498658908, Val Loss: 0.057425610269561', 'Epoch: 169, Train Loss: 0.020413392156895, Val Loss: 0.056058872604009', 'Epoch: 170, Train Loss: 0.020963413441288, Val Loss: 0.055561819537119', 'Epoch: 171, Train Loss: 0.020897285613630, Val Loss: 0.055861084072879', 'Epoch: 172, Train Loss: 0.023193341945963, Val Loss: 0.058425904223413', 'Epoch: 173, Train Loss: 0.019919753606830, Val Loss: 0.058500970742016', 'Epoch: 174, Train Loss: 0.018427660821804, Val Loss: 0.057946258196325', 'Epoch: 175, Train Loss: 0.019182689554457, Val Loss: 0.057551833829193', 'Epoch: 176, Train Loss: 0.017542691103050, Val Loss: 0.057584338793249', 'Epoch: 177, Train Loss: 0.019072615408472, Val Loss: 0.055643021383069', 'Epoch: 178, Train Loss: 0.019815159562443, Val Loss: 0.053072854650743', 'Epoch: 179, Train Loss: 0.019097121232854, Val Loss: 0.056246134593631', 'Epoch: 180, Train Loss: 0.022669765366507, Val Loss: 0.057190399052519', 'Epoch: 181, Train Loss: 0.018615107783782, Val Loss: 0.057985422173233', 'Epoch: 182, Train Loss: 0.019779232995851, Val Loss: 0.056869716806845', 'Epoch: 183, Train Loss: 0.021053747273982, Val Loss: 0.054102321578698', 'Epoch: 184, Train Loss: 0.018627797519522, Val Loss: 0.054939812331489', 'Epoch: 185, Train Loss: 0.018845046537795, Val Loss: 0.054941574055137', 'Epoch: 186, Train Loss: 0.017915849307818, Val Loss: 0.055637468442772', 'Epoch: 187, Train Loss: 0.020500580580639, Val Loss: 0.056223984920617', 'Epoch: 188, Train Loss: 0.020286755037627, Val Loss: 0.055783358712991', 'Epoch: 189, Train Loss: 0.019974692924214, Val Loss: 0.055764993934920', 'Epoch: 190, Train Loss: 0.019723456286426, Val Loss: 0.054747799919410', 'Epoch: 191, Train Loss: 0.018704713255699, Val Loss: 0.054946980467348', 'Epoch: 192, Train Loss: 0.017301819287241, Val Loss: 0.054739120557453', 'Epoch: 193, Train Loss: 0.020731946386929, Val Loss: 0.055163784460588', 'Epoch: 194, Train Loss: 0.016204306988844, Val Loss: 0.055954907879685', 'Epoch: 195, Train Loss: 0.019056444721563, Val Loss: 0.056122291155837', 'Epoch: 196, Train Loss: 0.019582314150674, Val Loss: 0.055774059936856', 'Epoch: 197, Train Loss: 0.019143736588636, Val Loss: 0.055407811182015', 'Epoch: 198, Train Loss: 0.018281334146325, Val Loss: 0.055153789055167', 'Epoch: 199, Train Loss: 0.019643022811839, Val Loss: 0.055099706983928']","[ 471.1403     153.8793     290.7542     598.37305    325.16803
  740.4659     400.95618   1032.688      483.66537    626.5006
  337.39804     63.19983      5.4628296  531.7776     572.98
  562.8819     383.73654   1327.7366     418.3215     418.18646
 1111.6362    1044.3005     410.69217    632.6117     770.8096
  243.9403       2.0499268  617.8216     138.60297     10.239746
  259.98862    840.6533     672.4115     828.5887     491.27667
  849.557       13.723694   780.819      260.51508   1192.4822
  241.62308    334.45892     54.5943     694.4518    1219.9059
  730.69086    384.54898     48.199646   568.3642     649.0148
  279.37943     20.586472   401.69052    477.40497    838.6971
  471.95917    125.53729    384.86105    922.0249     541.7541
  564.26196     80.541504   307.5845     738.6224     417.87872
  303.49234   1132.605      649.5345     997.83997   1077.1912
  326.62158    315.92706    721.78955    895.2418     202.45238
  351.98355    608.1203     670.70856   1119.0164     517.8821
  265.24066     53.80777    915.9963    1082.7795     600.7388
  284.34714    122.99805     85.57712    284.28488    907.08356
    6.329773   485.5377      25.92746    624.78357     49.893707
 1062.8188     797.8456     404.75803    512.49774    457.61334
  277.92847    321.62332    192.59299    274.24643    893.3407
  649.3793     319.4779     479.95258    773.51013    982.65375
  559.5322     229.95102   1298.9675     991.0653     867.60095
  439.27567     41.41095    455.4604     296.6674     116.64441
  580.84143    540.8015    1137.2391     888.42957    232.84521
  578.2854    1317.5714     792.812      307.88156    220.76721
  290.97983    540.59924    909.3096     671.03394    644.0965
  604.7989     869.3708     904.1972   ]","[ 406.69992    189.20593    406.85516    564.2423     332.24084
  684.54895    408.72482    994.0992     441.12045    552.20667
  404.417      309.2306       1.6669312  475.4189     503.13495
  623.6587     347.77353   1381.8679     465.6367     441.36148
  959.5581    1051.3958     359.9104     665.21265    795.2964
  177.51178     -9.899719   431.389       68.641174    72.153366
  232.1265     797.7261     645.5239     809.7361     429.5546
  659.8436      86.16141    827.45886    238.71997   1192.2095
  162.1595     345.67096    122.36737    705.98315   1109.4396
  841.7783     398.85403    137.82245    497.70724    738.6747
  264.65912     46.590866   355.44852    433.8846     886.31934
  468.8077     -30.860626   438.38995    930.3117     786.85693
  532.65924    217.10275    335.6018     737.56854    442.635
  274.5684    1119.3469     606.04004   1000.8086     957.65393
  340.82138    302.01385    764.7161     841.52       224.53339
  492.09845    619.77496    478.1663    1209.889      464.94418
  288.41925    148.99481    900.97736   1129.319      491.14767
  385.64154    195.86032    158.65866    301.70474    820.0725
  337.3022     266.5671      91.948975   555.3992     226.43552
  882.19574    738.05493    371.53598    615.6128     509.39447
  205.51492    308.26093    259.58923    245.49214    679.7128
  613.63544    334.55573    488.03558    666.08704    986.1335
  532.56335    303.7839    1331.391     1060.154      864.1692
  414.15228     50.492096   437.649      256.20386    139.47223
  377.00208    284.95877   1139.4618     897.262      126.31091
  450.6317    1021.7452     728.46277    263.15826    188.83386
  256.73193    592.65857    969.7979     675.787      589.0389
  750.5226     883.2161    1058.8358   ]",66.37045,8532.103,92.3693809606977
trial_2,polar_knn_minmax_noact,"['Epoch: 0, Train Loss: 0.385197931102344, Val Loss: 0.435088845816526', 'Epoch: 1, Train Loss: 0.389257341623306, Val Loss: 0.400355059089083', 'Epoch: 2, Train Loss: 0.394948576177870, Val Loss: 0.394581094835744', 'Epoch: 3, Train Loss: 0.384731648223741, Val Loss: 0.403556986288591', 'Epoch: 4, Train Loss: 0.378889537283352, Val Loss: 0.412532386454669', 'Epoch: 5, Train Loss: 0.382213309407234, Val Loss: 0.394889076550802', 'Epoch: 6, Train Loss: 0.378028501357351, Val Loss: 0.409182898926012', 'Epoch: 7, Train Loss: 0.370842075773648, Val Loss: 0.409604007547552', 'Epoch: 8, Train Loss: 0.345106742211751, Val Loss: 0.303112082409136', 'Epoch: 9, Train Loss: 0.272863805294037, Val Loss: 0.208853356765978', 'Epoch: 10, Train Loss: 0.205269572990281, Val Loss: 0.118558808512083', 'Epoch: 11, Train Loss: 0.150112650224141, Val Loss: 0.109964670500521', 'Epoch: 12, Train Loss: 0.128051749031459, Val Loss: 0.091157597122770', 'Epoch: 13, Train Loss: 0.104013772681355, Val Loss: 0.089344604674614', 'Epoch: 14, Train Loss: 0.092175817915371, Val Loss: 0.091538280700192', 'Epoch: 15, Train Loss: 0.085807702903237, Val Loss: 0.105955566364256', 'Epoch: 16, Train Loss: 0.086089488384979, Val Loss: 0.081345612691207', 'Epoch: 17, Train Loss: 0.077586936897465, Val Loss: 0.055737905204296', 'Epoch: 18, Train Loss: 0.064733924078090, Val Loss: 0.069675374663237', 'Epoch: 19, Train Loss: 0.066342072029199, Val Loss: 0.050820607127565', 'Epoch: 20, Train Loss: 0.064233625307679, Val Loss: 0.046805392075894', 'Epoch: 21, Train Loss: 0.059007457856621, Val Loss: 0.050232829695398', 'Epoch: 22, Train Loss: 0.058472794081484, Val Loss: 0.089298787893671', 'Epoch: 23, Train Loss: 0.058037913803543, Val Loss: 0.053253320694873', 'Epoch: 24, Train Loss: 0.053308107757143, Val Loss: 0.047893031867165', 'Epoch: 25, Train Loss: 0.059697510807642, Val Loss: 0.081304156644778', 'Epoch: 26, Train Loss: 0.062173252925277, Val Loss: 0.039654005262436', 'Epoch: 27, Train Loss: 0.054958038032055, Val Loss: 0.064309631333207', 'Epoch: 28, Train Loss: 0.055448766797781, Val Loss: 0.039513408629732', 'Epoch: 29, Train Loss: 0.055758788516479, Val Loss: 0.058524822985584', 'Epoch: 30, Train Loss: 0.057843768170902, Val Loss: 0.068340869563999', 'Epoch: 31, Train Loss: 0.051640455478004, Val Loss: 0.056619866666469', 'Epoch: 32, Train Loss: 0.050785138670887, Val Loss: 0.044337485775803', 'Epoch: 33, Train Loss: 0.055405144446662, Val Loss: 0.049575081193876', 'Epoch: 34, Train Loss: 0.055660052224994, Val Loss: 0.052219845735553', 'Epoch: 35, Train Loss: 0.053211448980229, Val Loss: 0.060511901523128', 'Epoch: 36, Train Loss: 0.052598849737218, Val Loss: 0.054819337685000', 'Epoch: 37, Train Loss: 0.049969588539430, Val Loss: 0.060254898148053', 'Epoch: 38, Train Loss: 0.049183499733252, Val Loss: 0.074534567693869', 'Epoch: 39, Train Loss: 0.065996620271887, Val Loss: 0.067703928346887', 'Epoch: 40, Train Loss: 0.055437725037336, Val Loss: 0.046551957049153', 'Epoch: 41, Train Loss: 0.054216787219048, Val Loss: 0.046900305332560', 'Epoch: 42, Train Loss: 0.065521621544446, Val Loss: 0.095927765423601', 'Epoch: 43, Train Loss: 0.060017273362194, Val Loss: 0.038117874244397', 'Epoch: 44, Train Loss: 0.050059708367501, Val Loss: 0.042545407008605', 'Epoch: 45, Train Loss: 0.050661057233810, Val Loss: 0.055021737278862', 'Epoch: 46, Train Loss: 0.048028445137399, Val Loss: 0.038000336510198', 'Epoch: 47, Train Loss: 0.056029101966747, Val Loss: 0.051985944141493', 'Epoch: 48, Train Loss: 0.041926043374198, Val Loss: 0.042275126794156', 'Epoch: 49, Train Loss: 0.046104024297425, Val Loss: 0.055546508819768', 'Epoch: 50, Train Loss: 0.041104391749416, Val Loss: 0.047244769013063', 'Epoch: 51, Train Loss: 0.038441787606903, Val Loss: 0.044194014065645', 'Epoch: 52, Train Loss: 0.039885379240981, Val Loss: 0.045923307573310', 'Epoch: 53, Train Loss: 0.039635619281658, Val Loss: 0.047291382286472', 'Epoch: 54, Train Loss: 0.039355806474175, Val Loss: 0.055333650805000', 'Epoch: 55, Train Loss: 0.042380360753409, Val Loss: 0.042418591367702', 'Epoch: 56, Train Loss: 0.037594129065318, Val Loss: 0.050745226894364', 'Epoch: 57, Train Loss: 0.039300964480000, Val Loss: 0.043159548193216', 'Epoch: 58, Train Loss: 0.035209427720734, Val Loss: 0.049254815235282', 'Epoch: 59, Train Loss: 0.058995220277991, Val Loss: 0.050837268640118', 'Epoch: 60, Train Loss: 0.047390672378242, Val Loss: 0.039796015318257', 'Epoch: 61, Train Loss: 0.044405677222780, Val Loss: 0.043304454817465', 'Epoch: 62, Train Loss: 0.039078951680235, Val Loss: 0.053142930973660', 'Epoch: 63, Train Loss: 0.040322026636984, Val Loss: 0.046992278968294', 'Epoch: 64, Train Loss: 0.036669214788292, Val Loss: 0.050127279747165', 'Epoch: 65, Train Loss: 0.042801761733634, Val Loss: 0.053431548291084', 'Epoch: 66, Train Loss: 0.039840860957546, Val Loss: 0.047960575557116', 'Epoch: 67, Train Loss: 0.038535917709981, Val Loss: 0.041125406412351', 'Epoch: 68, Train Loss: 0.041648354514369, Val Loss: 0.057943842740673', 'Epoch: 69, Train Loss: 0.042944431437978, Val Loss: 0.044340361784579', 'Epoch: 70, Train Loss: 0.038879998427417, Val Loss: 0.047493438292859', 'Epoch: 71, Train Loss: 0.037533512472042, Val Loss: 0.040924178633952', 'Epoch: 72, Train Loss: 0.040481698699296, Val Loss: 0.040772596248919', 'Epoch: 73, Train Loss: 0.037714062125555, Val Loss: 0.048341564834118', 'Epoch: 74, Train Loss: 0.033256117786680, Val Loss: 0.052608295216818', 'Epoch: 75, Train Loss: 0.040269370856030, Val Loss: 0.056764686508386', 'Epoch: 76, Train Loss: 0.037615092870380, Val Loss: 0.040927447632632', 'Epoch: 77, Train Loss: 0.032239554849054, Val Loss: 0.041722596651225', 'Epoch: 78, Train Loss: 0.033272492034095, Val Loss: 0.044940426691689', 'Epoch: 79, Train Loss: 0.038082975095936, Val Loss: 0.052224108243756', 'Epoch: 80, Train Loss: 0.035566090739199, Val Loss: 0.040982876022375', 'Epoch: 81, Train Loss: 0.036370813181358, Val Loss: 0.046710804951462', 'Epoch: 82, Train Loss: 0.033868258419846, Val Loss: 0.044970741241493', 'Epoch: 83, Train Loss: 0.031875044107437, Val Loss: 0.043318525572073', 'Epoch: 84, Train Loss: 0.029841427026050, Val Loss: 0.040001497646286', 'Epoch: 85, Train Loss: 0.034559406207076, Val Loss: 0.040869144835707', 'Epoch: 86, Train Loss: 0.031884382944554, Val Loss: 0.044778687032786', 'Epoch: 87, Train Loss: 0.035542097474848, Val Loss: 0.060062055334900', 'Epoch: 88, Train Loss: 0.034910498053900, Val Loss: 0.045792741260040', 'Epoch: 89, Train Loss: 0.037400012436722, Val Loss: 0.044718311831468', 'Epoch: 90, Train Loss: 0.033565000497869, Val Loss: 0.042431566342147', 'Epoch: 91, Train Loss: 0.031352943208601, Val Loss: 0.046249640364708', 'Epoch: 92, Train Loss: 0.040515870388065, Val Loss: 0.054340566931800', 'Epoch: 93, Train Loss: 0.035594925683524, Val Loss: 0.043595460441076', 'Epoch: 94, Train Loss: 0.036490894721023, Val Loss: 0.044156556949019', 'Epoch: 95, Train Loss: 0.029562411696783, Val Loss: 0.041249331735978', 'Epoch: 96, Train Loss: 0.033917571684080, Val Loss: 0.040737345821760', 'Epoch: 97, Train Loss: 0.027833592811865, Val Loss: 0.045798101857530', 'Epoch: 98, Train Loss: 0.026665857061744, Val Loss: 0.049077925681503', 'Epoch: 99, Train Loss: 0.031059065700642, Val Loss: 0.048487379018104', 'Epoch: 100, Train Loss: 0.032118009270302, Val Loss: 0.041007005680127', 'Epoch: 101, Train Loss: 0.029870205292744, Val Loss: 0.044335475050364', 'Epoch: 102, Train Loss: 0.023746676476938, Val Loss: 0.043477944013747', 'Epoch: 103, Train Loss: 0.026961869892797, Val Loss: 0.046263698262699', 'Epoch: 104, Train Loss: 0.027767730344619, Val Loss: 0.052097654301730', 'Epoch: 105, Train Loss: 0.027564369275102, Val Loss: 0.048405339094726', 'Epoch: 106, Train Loss: 0.029435082338750, Val Loss: 0.041335023883166', 'Epoch: 107, Train Loss: 0.027498403963234, Val Loss: 0.041752162417679', 'Epoch: 108, Train Loss: 0.024019004644028, Val Loss: 0.044937286723518', 'Epoch: 109, Train Loss: 0.027070389860975, Val Loss: 0.049509277320326', 'Epoch: 110, Train Loss: 0.027989713807723, Val Loss: 0.048395935050917', 'Epoch: 111, Train Loss: 0.026237360534391, Val Loss: 0.046029828998585', 'Epoch: 112, Train Loss: 0.026489677306797, Val Loss: 0.050834434614940', 'Epoch: 113, Train Loss: 0.033413528863873, Val Loss: 0.061147383216656', 'Epoch: 114, Train Loss: 0.027330561208406, Val Loss: 0.050120190745502', 'Epoch: 115, Train Loss: 0.025841771624982, Val Loss: 0.044995337894017', 'Epoch: 116, Train Loss: 0.026981364669544, Val Loss: 0.045926384402044', 'Epoch: 117, Train Loss: 0.028492922761611, Val Loss: 0.036881348118186', 'Epoch: 118, Train Loss: 0.027433902890022, Val Loss: 0.048887229552775', 'Epoch: 119, Train Loss: 0.028235353995115, Val Loss: 0.046927982941270', 'Epoch: 120, Train Loss: 0.028783894543137, Val Loss: 0.044821838396742', 'Epoch: 121, Train Loss: 0.022923843669040, Val Loss: 0.051529479128393', 'Epoch: 122, Train Loss: 0.024436469056777, Val Loss: 0.042765555381210', 'Epoch: 123, Train Loss: 0.024618693228279, Val Loss: 0.043823845374087', 'Epoch: 124, Train Loss: 0.022585882672242, Val Loss: 0.046403388182322', 'Epoch: 125, Train Loss: 0.023251229098865, Val Loss: 0.057641799251239', 'Epoch: 126, Train Loss: 0.022949172716056, Val Loss: 0.054400699664698', 'Epoch: 127, Train Loss: 0.024434292822012, Val Loss: 0.050424966961145', 'Epoch: 128, Train Loss: 0.026441755837628, Val Loss: 0.044093834518483', 'Epoch: 129, Train Loss: 0.022025537677109, Val Loss: 0.054066077213396', 'Epoch: 130, Train Loss: 0.024022848744478, Val Loss: 0.045459547559872', 'Epoch: 131, Train Loss: 0.022062868478575, Val Loss: 0.048203440270189', 'Epoch: 132, Train Loss: 0.025264983730657, Val Loss: 0.049406052764618', 'Epoch: 133, Train Loss: 0.028025458034660, Val Loss: 0.048555126357259', 'Epoch: 134, Train Loss: 0.025521773445819, Val Loss: 0.049829643558372', 'Epoch: 135, Train Loss: 0.024899685954941, Val Loss: 0.045862946320664', 'Epoch: 136, Train Loss: 0.021787851150813, Val Loss: 0.043113243441577', 'Epoch: 137, Train Loss: 0.025314572998988, Val Loss: 0.046729409897869', 'Epoch: 138, Train Loss: 0.026050117066396, Val Loss: 0.047788919147217', 'Epoch: 139, Train Loss: 0.021199652792088, Val Loss: 0.044916385431972', 'Epoch: 140, Train Loss: 0.022728989566011, Val Loss: 0.043520166030662', 'Epoch: 141, Train Loss: 0.022603385416525, Val Loss: 0.046684822744944', 'Epoch: 142, Train Loss: 0.023402385546693, Val Loss: 0.046209140144514', 'Epoch: 143, Train Loss: 0.024245271858360, Val Loss: 0.041654888258287', 'Epoch: 144, Train Loss: 0.021718527190387, Val Loss: 0.042993764534141', 'Epoch: 145, Train Loss: 0.022825460614903, Val Loss: 0.046383770747167', 'Epoch: 146, Train Loss: 0.026376187934407, Val Loss: 0.043501920998096', 'Epoch: 147, Train Loss: 0.020064596286310, Val Loss: 0.040702897942427', 'Epoch: 148, Train Loss: 0.023894811847380, Val Loss: 0.050312085810936', 'Epoch: 149, Train Loss: 0.022832188489182, Val Loss: 0.042119059570585', 'Epoch: 150, Train Loss: 0.021846680569329, Val Loss: 0.043651979303721', 'Epoch: 151, Train Loss: 0.022561231361968, Val Loss: 0.044336577482296', 'Epoch: 152, Train Loss: 0.020008196389037, Val Loss: 0.043302856653816', 'Epoch: 153, Train Loss: 0.021257055524204, Val Loss: 0.042581758603002', 'Epoch: 154, Train Loss: 0.018659686736230, Val Loss: 0.043710526530490', 'Epoch: 155, Train Loss: 0.021905269407268, Val Loss: 0.049591537847212', 'Epoch: 156, Train Loss: 0.019674416831029, Val Loss: 0.046096739669641', 'Epoch: 157, Train Loss: 0.020614005758294, Val Loss: 0.051371313236428', 'Epoch: 158, Train Loss: 0.021527842552002, Val Loss: 0.044547588931340', 'Epoch: 159, Train Loss: 0.021289087233267, Val Loss: 0.044479703192006', 'Epoch: 160, Train Loss: 0.022316954098642, Val Loss: 0.044755273131710', 'Epoch: 161, Train Loss: 0.023718190246395, Val Loss: 0.043730363701329', 'Epoch: 162, Train Loss: 0.021071510855108, Val Loss: 0.040394671204867', 'Epoch: 163, Train Loss: 0.022930904557662, Val Loss: 0.040954825468361', 'Epoch: 164, Train Loss: 0.020735452816422, Val Loss: 0.040729939429597', 'Epoch: 165, Train Loss: 0.020613701282335, Val Loss: 0.039723948660222', 'Epoch: 166, Train Loss: 0.020875192646469, Val Loss: 0.042471317461494', 'Epoch: 167, Train Loss: 0.021038835136486, Val Loss: 0.043394682533813', 'Epoch: 168, Train Loss: 0.023011536670050, Val Loss: 0.046840539597201', 'Epoch: 169, Train Loss: 0.022096530201712, Val Loss: 0.045354106096607', 'Epoch: 170, Train Loss: 0.018984983276044, Val Loss: 0.051621029887236', 'Epoch: 171, Train Loss: 0.024209103613560, Val Loss: 0.046838774035374', 'Epoch: 172, Train Loss: 0.019137955536800, Val Loss: 0.046046115514455', 'Epoch: 173, Train Loss: 0.017843826341310, Val Loss: 0.043940952950806', 'Epoch: 174, Train Loss: 0.017864140681922, Val Loss: 0.050665228825175', 'Epoch: 175, Train Loss: 0.022909501634006, Val Loss: 0.045694716387626', 'Epoch: 176, Train Loss: 0.017487421764859, Val Loss: 0.047160102731802', 'Epoch: 177, Train Loss: 0.020716178829649, Val Loss: 0.046214663677595', 'Epoch: 178, Train Loss: 0.021541233972779, Val Loss: 0.047721886386474', 'Epoch: 179, Train Loss: 0.019131454040429, Val Loss: 0.042765103054769', 'Epoch: 180, Train Loss: 0.018901460205338, Val Loss: 0.045257272593903', 'Epoch: 181, Train Loss: 0.020633015315980, Val Loss: 0.046913557431915', 'Epoch: 182, Train Loss: 0.022338020349188, Val Loss: 0.043378053007252', 'Epoch: 183, Train Loss: 0.019727435362126, Val Loss: 0.047514161603017', 'Epoch: 184, Train Loss: 0.021160918886640, Val Loss: 0.044441183295214', 'Epoch: 185, Train Loss: 0.017884640289204, Val Loss: 0.045507276092063', 'Epoch: 186, Train Loss: 0.021325002690511, Val Loss: 0.044745574338418', 'Epoch: 187, Train Loss: 0.018218006206942, Val Loss: 0.048012200404297', 'Epoch: 188, Train Loss: 0.020453141137425, Val Loss: 0.045122973395116', 'Epoch: 189, Train Loss: 0.020849917882255, Val Loss: 0.044636070276752', 'Epoch: 190, Train Loss: 0.020715461378651, Val Loss: 0.044863716050079', 'Epoch: 191, Train Loss: 0.019467155049954, Val Loss: 0.044646240037048', 'Epoch: 192, Train Loss: 0.020925183647445, Val Loss: 0.044404022085170', 'Epoch: 193, Train Loss: 0.021002385765314, Val Loss: 0.044743635268374', 'Epoch: 194, Train Loss: 0.018045055679977, Val Loss: 0.044258385219357', 'Epoch: 195, Train Loss: 0.018464548513293, Val Loss: 0.045198035341772', 'Epoch: 196, Train Loss: 0.018771993994181, Val Loss: 0.046029086196513', 'Epoch: 197, Train Loss: 0.014421092545880, Val Loss: 0.046353046923424', 'Epoch: 198, Train Loss: 0.021537200215140, Val Loss: 0.046257997552554', 'Epoch: 199, Train Loss: 0.018407125092511, Val Loss: 0.046176431982806']","[ 687.8954     587.7664     806.48376   1192.2505     249.45024
   62.58194    426.27896   1012.64764    407.37656    373.86713
  264.60712     69.31613    244.11351    106.83893    290.97983
  540.59924    400.95618   1032.688      691.2141     439.6826
  937.9889      71.58554    125.02261    446.80353    166.28964
  211.36594   1139.9081     641.5614     289.0574     254.19006
  335.5677     550.8332     713.01166    101.37781   1090.6873
  140.76965   1041.1692     291.88788     55.43544    436.99503
  594.27295    523.7677     380.06744    549.14624    193.66635
  706.7205     548.6123     562.0951     737.4956     127.90927
  328.93167    348.92972     29.124512   631.9739     363.94058
  803.88574    337.39804     63.19983   1035.3289     289.96573
  322.44098    384.01755    694.1144     419.9962     245.8705
  604.0323     267.63318    818.9285     915.9963    1082.7795
  537.7522     771.3589     556.70044    855.26227    580.84143
  540.8015     269.5341     346.46228    296.6674     116.64441
  198.0301     564.53436    397.72205     76.32414    238.36115
  859.18506   1174.3181     599.6746     440.00293     99.90213
  349.61304    200.36572    383.73654   1327.7366     543.912
   84.83186    549.78577    392.8176     125.53729    384.86105
  211.00024     23.32251    212.51854    586.0235      12.562317
  312.81177   1056.3058     793.31714    392.04727    389.85242
  159.53868     58.082092   242.34076    349.28815    796.14014
  888.3277     384.54898     48.199646   600.7388     284.34714
    5.618469   295.53036    483.34933    854.8072       2.0499268
  617.8216     848.72437    541.6864     290.7542     598.37305
   28.69104    512.4936     963.3551     343.87537    285.84372
  894.3473     466.41046   1307.9707   ]","[ 710.4049    507.0453    868.66345  1072.8059    241.27965    29.552856
  457.7751   1100.5596    526.28796   450.68063   279.46127   130.7709
  310.98166   190.34006   343.15695   478.7273    478.47992   984.7991
  643.0139    564.3063    832.36884   -26.626953   90.892456  499.9478
  303.1182     90.746155 1152.6261    651.17114   289.19806   216.70609
  294.57202   558.26855   673.9276     48.273438 1076.2903    179.34619
 1051.5593    322.00516    97.28366   458.58655   642.4448    433.9141
  399.16058   546.0947    264.3489    636.67236   378.5058    466.38177
  709.36304    84.68649   267.3286    462.43906    18.5625    645.948
  320.09528   862.8938    404.93185   283.40604   991.0139    221.63657
  374.79205   351.24384   626.76843   533.03986   272.71478   615.9681
  297.44308   769.70245  1034.8584   1136.3434    668.505     841.34326
  492.13284   716.2224    401.9933    269.84503   318.21204   318.80286
  291.78705   178.06189   256.27277   554.22577   354.34015    29.211166
  205.00806   878.89417  1202.9397    612.3822    454.99536   175.45802
  354.50085   152.87128   455.69025  1306.3577    394.77145   102.29137
  445.58392   417.9366    -27.087982  454.16348   463.64978   294.9083
  233.65364   569.2204    271.0488    439.37024   963.1969    959.2834
  392.65683   446.30865   197.55643    41.649017  278.95404   342.2105
  930.65283   881.1107    398.43695   115.313324  471.23685   358.9474
   48.06404   330.1888    575.197     791.7265    121.65631   456.5126
  905.04645   621.6994    388.7549    551.9745     11.907196  477.51666
 1018.7789    419.54987   321.75775   873.5585    727.5292   1285.3146  ]",66.61308,7755.714,88.0665309137785
trial_1,cartesian_knn_minmax_act,"['Epoch: 0, Train Loss: 0.390845937388284, Val Loss: 0.396327248802691', 'Epoch: 1, Train Loss: 0.391412662608283, Val Loss: 0.396915760229934', 'Epoch: 2, Train Loss: 0.386685345854078, Val Loss: 0.399173655180317', 'Epoch: 3, Train Loss: 0.385312271969659, Val Loss: 0.397849091977784', 'Epoch: 4, Train Loss: 0.382242630634989, Val Loss: 0.395286589860916', 'Epoch: 5, Train Loss: 0.392605368580137, Val Loss: 0.394752794368701', 'Epoch: 6, Train Loss: 0.379579454660416, Val Loss: 0.391809219212243', 'Epoch: 7, Train Loss: 0.377372790660177, Val Loss: 0.376546872158845', 'Epoch: 8, Train Loss: 0.341355144977570, Val Loss: 0.364680171915979', 'Epoch: 9, Train Loss: 0.261183191623007, Val Loss: 0.332539211619984', 'Epoch: 10, Train Loss: 0.188499246324812, Val Loss: 0.209074609207385', 'Epoch: 11, Train Loss: 0.154653817947422, Val Loss: 0.169248342175375', 'Epoch: 12, Train Loss: 0.130424503237009, Val Loss: 0.144567732558106', 'Epoch: 13, Train Loss: 0.116095117160252, Val Loss: 0.155237306248058', 'Epoch: 14, Train Loss: 0.111262077199561, Val Loss: 0.146027353676883', 'Epoch: 15, Train Loss: 0.105859881533044, Val Loss: 0.157131897680687', 'Epoch: 16, Train Loss: 0.098661706117647, Val Loss: 0.095672344619578', 'Epoch: 17, Train Loss: 0.080333419144154, Val Loss: 0.087941958145662', 'Epoch: 18, Train Loss: 0.066530511847564, Val Loss: 0.078429039229046', 'Epoch: 19, Train Loss: 0.065101863284196, Val Loss: 0.081787155658910', 'Epoch: 20, Train Loss: 0.057036966085434, Val Loss: 0.066689491271973', 'Epoch: 21, Train Loss: 0.052918827959469, Val Loss: 0.071246050975539', 'Epoch: 22, Train Loss: 0.045872265473008, Val Loss: 0.073183296756311', 'Epoch: 23, Train Loss: 0.045077117692147, Val Loss: 0.059812824044264', 'Epoch: 24, Train Loss: 0.043261216953397, Val Loss: 0.059719363396818', 'Epoch: 25, Train Loss: 0.044543979423387, Val Loss: 0.055534481437820', 'Epoch: 26, Train Loss: 0.037437235271292, Val Loss: 0.054717003170288', 'Epoch: 27, Train Loss: 0.036526581937713, Val Loss: 0.061969911961844', 'Epoch: 28, Train Loss: 0.041526244687183, Val Loss: 0.066715861360232', 'Epoch: 29, Train Loss: 0.036610420261111, Val Loss: 0.057828556407582', 'Epoch: 30, Train Loss: 0.033976201766304, Val Loss: 0.056903821952415', 'Epoch: 31, Train Loss: 0.038390926750643, Val Loss: 0.054690911237038', 'Epoch: 32, Train Loss: 0.038559778194342, Val Loss: 0.067788775897387', 'Epoch: 33, Train Loss: 0.034163452551833, Val Loss: 0.061329125454932', 'Epoch: 34, Train Loss: 0.041160056367517, Val Loss: 0.058338130965377', 'Epoch: 35, Train Loss: 0.034685809298285, Val Loss: 0.054506910231077', 'Epoch: 36, Train Loss: 0.033851681144110, Val Loss: 0.051157470453869', 'Epoch: 37, Train Loss: 0.036685530096292, Val Loss: 0.066484159789979', 'Epoch: 38, Train Loss: 0.037505163944193, Val Loss: 0.075611734480569', 'Epoch: 39, Train Loss: 0.039925627942596, Val Loss: 0.057033698780067', 'Epoch: 40, Train Loss: 0.030059621070645, Val Loss: 0.048851878354044', 'Epoch: 41, Train Loss: 0.027041446617139, Val Loss: 0.052949311042374', 'Epoch: 42, Train Loss: 0.030780331896884, Val Loss: 0.046463579390988', 'Epoch: 43, Train Loss: 0.031727264369173, Val Loss: 0.051769118756056', 'Epoch: 44, Train Loss: 0.028509260022214, Val Loss: 0.041122566344160', 'Epoch: 45, Train Loss: 0.026663334707596, Val Loss: 0.042912865001144', 'Epoch: 46, Train Loss: 0.027049672789872, Val Loss: 0.048896415102662', 'Epoch: 47, Train Loss: 0.031081692448684, Val Loss: 0.058377417199539', 'Epoch: 48, Train Loss: 0.032691638118454, Val Loss: 0.055733160764882', 'Epoch: 49, Train Loss: 0.027987158258579, Val Loss: 0.051175760387471', 'Epoch: 50, Train Loss: 0.025090208277106, Val Loss: 0.051243621404424', 'Epoch: 51, Train Loss: 0.023220721898334, Val Loss: 0.056577854874459', 'Epoch: 52, Train Loss: 0.023806361415024, Val Loss: 0.058945590573730', 'Epoch: 53, Train Loss: 0.026539954024234, Val Loss: 0.053784303141363', 'Epoch: 54, Train Loss: 0.026533869228193, Val Loss: 0.056858986446803', 'Epoch: 55, Train Loss: 0.024064502080104, Val Loss: 0.061766169175054', 'Epoch: 56, Train Loss: 0.023772037987198, Val Loss: 0.050218323414976', 'Epoch: 57, Train Loss: 0.022242994114224, Val Loss: 0.054359004691695', 'Epoch: 58, Train Loss: 0.024124275759927, Val Loss: 0.060539051382379', 'Epoch: 59, Train Loss: 0.027264591838632, Val Loss: 0.045106231037414', 'Epoch: 60, Train Loss: 0.019960161165467, Val Loss: 0.047718435413007', 'Epoch: 61, Train Loss: 0.017478895240596, Val Loss: 0.048513914373788', 'Epoch: 62, Train Loss: 0.023380312336875, Val Loss: 0.047793972221288', 'Epoch: 63, Train Loss: 0.020156448307846, Val Loss: 0.047250941621535', 'Epoch: 64, Train Loss: 0.021285516742085, Val Loss: 0.041944859436516', 'Epoch: 65, Train Loss: 0.020469387727124, Val Loss: 0.050782086609891', 'Epoch: 66, Train Loss: 0.018519364829574, Val Loss: 0.051722426531893', 'Epoch: 67, Train Loss: 0.021598479577473, Val Loss: 0.050672046162865', 'Epoch: 68, Train Loss: 0.019244504161179, Val Loss: 0.050172545806025', 'Epoch: 69, Train Loss: 0.019400694806661, Val Loss: 0.052746358186458', 'Epoch: 70, Train Loss: 0.017410128310855, Val Loss: 0.047196449091037', 'Epoch: 71, Train Loss: 0.018134098766106, Val Loss: 0.047396931797266', 'Epoch: 72, Train Loss: 0.015755137761257, Val Loss: 0.052516993417433', 'Epoch: 73, Train Loss: 0.017147497407028, Val Loss: 0.054400370597388', 'Epoch: 74, Train Loss: 0.016018870552736, Val Loss: 0.055347613877419', 'Epoch: 75, Train Loss: 0.013561859061675, Val Loss: 0.048270340896014', 'Epoch: 76, Train Loss: 0.014417014151279, Val Loss: 0.056503280178841', 'Epoch: 77, Train Loss: 0.016205540991255, Val Loss: 0.053344334165255', 'Epoch: 78, Train Loss: 0.013298982554781, Val Loss: 0.045173361615250', 'Epoch: 79, Train Loss: 0.014929673368377, Val Loss: 0.046916203855565', 'Epoch: 80, Train Loss: 0.014245583742325, Val Loss: 0.050653343060703', 'Epoch: 81, Train Loss: 0.012691229648356, Val Loss: 0.045748102845568', 'Epoch: 82, Train Loss: 0.017014619827803, Val Loss: 0.054490021232403', 'Epoch: 83, Train Loss: 0.014558474533260, Val Loss: 0.053822190472574', 'Epoch: 84, Train Loss: 0.012748374337597, Val Loss: 0.053608271039345', 'Epoch: 85, Train Loss: 0.011523078095966, Val Loss: 0.051721575444169', 'Epoch: 86, Train Loss: 0.012367893509301, Val Loss: 0.048913934239835', 'Epoch: 87, Train Loss: 0.013209855982235, Val Loss: 0.041401710812793', 'Epoch: 88, Train Loss: 0.013670519393470, Val Loss: 0.055676011650851', 'Epoch: 89, Train Loss: 0.014100908833955, Val Loss: 0.051945068139696', 'Epoch: 90, Train Loss: 0.015111168646919, Val Loss: 0.045850679955699', 'Epoch: 91, Train Loss: 0.013494168541261, Val Loss: 0.045912051686283', 'Epoch: 92, Train Loss: 0.012824769065316, Val Loss: 0.048164372642835', 'Epoch: 93, Train Loss: 0.012099109523531, Val Loss: 0.050563884673245', 'Epoch: 94, Train Loss: 0.011743488788073, Val Loss: 0.050618735000943', 'Epoch: 95, Train Loss: 0.011645918545712, Val Loss: 0.051978503551447', 'Epoch: 96, Train Loss: 0.012935362357114, Val Loss: 0.047599976487232', 'Epoch: 97, Train Loss: 0.013472546889846, Val Loss: 0.056344825830875', 'Epoch: 98, Train Loss: 0.015875600943608, Val Loss: 0.064425185096986', 'Epoch: 99, Train Loss: 0.013947302076433, Val Loss: 0.048878592735326', 'Epoch: 100, Train Loss: 0.014869749778882, Val Loss: 0.047938751000347', 'Epoch: 101, Train Loss: 0.013758750698928, Val Loss: 0.045953196558085', 'Epoch: 102, Train Loss: 0.011958651144856, Val Loss: 0.045971975972255', 'Epoch: 103, Train Loss: 0.011028766133157, Val Loss: 0.047413581925811', 'Epoch: 104, Train Loss: 0.011864135574017, Val Loss: 0.045600433467012', 'Epoch: 105, Train Loss: 0.009281323557453, Val Loss: 0.054169985945478', 'Epoch: 106, Train Loss: 0.010745306033641, Val Loss: 0.046693936921656', 'Epoch: 107, Train Loss: 0.010561435483396, Val Loss: 0.054028522731228', 'Epoch: 108, Train Loss: 0.012856182575758, Val Loss: 0.050867064094002', 'Epoch: 109, Train Loss: 0.011124426499009, Val Loss: 0.049864068006476', 'Epoch: 110, Train Loss: 0.010667101945728, Val Loss: 0.047531225464561', 'Epoch: 111, Train Loss: 0.011806353494259, Val Loss: 0.058247388876749', 'Epoch: 112, Train Loss: 0.009964994154871, Val Loss: 0.049789529575995', 'Epoch: 113, Train Loss: 0.010661797830835, Val Loss: 0.049433825763338', 'Epoch: 114, Train Loss: 0.011124348035082, Val Loss: 0.049338760305986', 'Epoch: 115, Train Loss: 0.010686914702611, Val Loss: 0.058230558974725', 'Epoch: 116, Train Loss: 0.010713662353477, Val Loss: 0.046999428167262', 'Epoch: 117, Train Loss: 0.009929695665570, Val Loss: 0.050987815145742', 'Epoch: 118, Train Loss: 0.008282646170950, Val Loss: 0.055392637284416', 'Epoch: 119, Train Loss: 0.010200299123036, Val Loss: 0.053697974731525', 'Epoch: 120, Train Loss: 0.009357275940212, Val Loss: 0.051156425763938', 'Epoch: 121, Train Loss: 0.010355042260406, Val Loss: 0.049354363656179', 'Epoch: 122, Train Loss: 0.010205078404397, Val Loss: 0.048681171159401', 'Epoch: 123, Train Loss: 0.011529316726540, Val Loss: 0.052656585463520', 'Epoch: 124, Train Loss: 0.011678831585284, Val Loss: 0.054178488073927', 'Epoch: 125, Train Loss: 0.010378561614613, Val Loss: 0.051659426454342', 'Epoch: 126, Train Loss: 0.009963226305055, Val Loss: 0.051714596761899', 'Epoch: 127, Train Loss: 0.010253484693489, Val Loss: 0.049403289474095', 'Epoch: 128, Train Loss: 0.009810006112925, Val Loss: 0.055373295605408', 'Epoch: 129, Train Loss: 0.009013721153938, Val Loss: 0.053472256400820', 'Epoch: 130, Train Loss: 0.009774094347709, Val Loss: 0.049923227874167', 'Epoch: 131, Train Loss: 0.008782891390313, Val Loss: 0.050014180554585', 'Epoch: 132, Train Loss: 0.010873051127419, Val Loss: 0.046261485101599', 'Epoch: 133, Train Loss: 0.009005972150979, Val Loss: 0.049757599096858', 'Epoch: 134, Train Loss: 0.008542642928660, Val Loss: 0.051959333264015', 'Epoch: 135, Train Loss: 0.008576391730458, Val Loss: 0.049511816183274', 'Epoch: 136, Train Loss: 0.008909032414002, Val Loss: 0.051628970287063', 'Epoch: 137, Train Loss: 0.007644841015073, Val Loss: 0.051362318353671', 'Epoch: 138, Train Loss: 0.008769360736811, Val Loss: 0.047806776495594', 'Epoch: 139, Train Loss: 0.009760649176314, Val Loss: 0.056638124032003', 'Epoch: 140, Train Loss: 0.009461568901315, Val Loss: 0.051847510322025', 'Epoch: 141, Train Loss: 0.007972741566066, Val Loss: 0.051411165093834', 'Epoch: 142, Train Loss: 0.007795048062690, Val Loss: 0.059462966058742', 'Epoch: 143, Train Loss: 0.010040287277661, Val Loss: 0.055411477883657', 'Epoch: 144, Train Loss: 0.010963268212176, Val Loss: 0.054070851116469', 'Epoch: 145, Train Loss: 0.008295746586685, Val Loss: 0.049604560220332', 'Epoch: 146, Train Loss: 0.008063848529543, Val Loss: 0.047237136034351', 'Epoch: 147, Train Loss: 0.008569819287264, Val Loss: 0.052037248162158', 'Epoch: 148, Train Loss: 0.007840398150230, Val Loss: 0.053137895876937', 'Epoch: 149, Train Loss: 0.008026628023280, Val Loss: 0.052556502209468', 'Epoch: 150, Train Loss: 0.008403356187046, Val Loss: 0.055143830451098', 'Epoch: 151, Train Loss: 0.007301684535508, Val Loss: 0.054192709143866', 'Epoch: 152, Train Loss: 0.007959533981713, Val Loss: 0.063496023642294', 'Epoch: 153, Train Loss: 0.008835152855941, Val Loss: 0.054013681061792', 'Epoch: 154, Train Loss: 0.007439147398275, Val Loss: 0.047480832503149', 'Epoch: 155, Train Loss: 0.009681767318398, Val Loss: 0.049838727904540', 'Epoch: 156, Train Loss: 0.007634803054056, Val Loss: 0.054613746194677', 'Epoch: 157, Train Loss: 0.008196651669485, Val Loss: 0.052312719099449', 'Epoch: 158, Train Loss: 0.007105991344101, Val Loss: 0.052084231579846', 'Epoch: 159, Train Loss: 0.006897646118887, Val Loss: 0.051971438764171', 'Epoch: 160, Train Loss: 0.008211639393786, Val Loss: 0.052388111157625', 'Epoch: 161, Train Loss: 0.007198399365214, Val Loss: 0.054665716223870', 'Epoch: 162, Train Loss: 0.007920315688742, Val Loss: 0.052570227872242', 'Epoch: 163, Train Loss: 0.007803972012230, Val Loss: 0.050436362624168', 'Epoch: 164, Train Loss: 0.007312012570245, Val Loss: 0.056098999060465', 'Epoch: 165, Train Loss: 0.007305524910667, Val Loss: 0.052339276468212', 'Epoch: 166, Train Loss: 0.007633769768290, Val Loss: 0.050726933997463', 'Epoch: 167, Train Loss: 0.007447342920516, Val Loss: 0.052331965360226', 'Epoch: 168, Train Loss: 0.008058713250128, Val Loss: 0.054495740907662', 'Epoch: 169, Train Loss: 0.006674833279768, Val Loss: 0.054596816683470', 'Epoch: 170, Train Loss: 0.007789425718199, Val Loss: 0.051983644113396', 'Epoch: 171, Train Loss: 0.006579189261954, Val Loss: 0.057478217549171', 'Epoch: 172, Train Loss: 0.007951155970139, Val Loss: 0.054004084318876', 'Epoch: 173, Train Loss: 0.007310415950737, Val Loss: 0.053777929508325', 'Epoch: 174, Train Loss: 0.006429966738714, Val Loss: 0.052786922703187', 'Epoch: 175, Train Loss: 0.005596428527497, Val Loss: 0.054789202428903', 'Epoch: 176, Train Loss: 0.006137919562337, Val Loss: 0.056296180312832', 'Epoch: 177, Train Loss: 0.006954895897901, Val Loss: 0.053519448350099', 'Epoch: 178, Train Loss: 0.007011583673635, Val Loss: 0.055194367061962', 'Epoch: 179, Train Loss: 0.006596223684028, Val Loss: 0.053057353492036', 'Epoch: 180, Train Loss: 0.007512493824054, Val Loss: 0.051970847063895', 'Epoch: 181, Train Loss: 0.006437718186394, Val Loss: 0.052815583957867', 'Epoch: 182, Train Loss: 0.006090722662131, Val Loss: 0.051859875915177', 'Epoch: 183, Train Loss: 0.005585713045938, Val Loss: 0.054686968243032', 'Epoch: 184, Train Loss: 0.006912127303492, Val Loss: 0.052845647050576', 'Epoch: 185, Train Loss: 0.006561754138342, Val Loss: 0.052592324967863', 'Epoch: 186, Train Loss: 0.006537157776100, Val Loss: 0.052118917136933', 'Epoch: 187, Train Loss: 0.005977783202460, Val Loss: 0.051307484394673', 'Epoch: 188, Train Loss: 0.006466839529042, Val Loss: 0.052257602244164', 'Epoch: 189, Train Loss: 0.007025935371140, Val Loss: 0.052811090919104', 'Epoch: 190, Train Loss: 0.006396266498736, Val Loss: 0.052747659441648', 'Epoch: 191, Train Loss: 0.006264912845966, Val Loss: 0.052715839056129', 'Epoch: 192, Train Loss: 0.006821572747348, Val Loss: 0.053317470758250', 'Epoch: 193, Train Loss: 0.005648211742352, Val Loss: 0.054308638371753', 'Epoch: 194, Train Loss: 0.006031690631062, Val Loss: 0.054062316984390', 'Epoch: 195, Train Loss: 0.007594144869862, Val Loss: 0.053537072077619', 'Epoch: 196, Train Loss: 0.006098659542788, Val Loss: 0.053704672436597', 'Epoch: 197, Train Loss: 0.006366912308814, Val Loss: 0.053679954542807', 'Epoch: 198, Train Loss: 0.006381505401805, Val Loss: 0.053508113223043', 'Epoch: 199, Train Loss: 0.006145740892472, Val Loss: 0.053429676643149']","[ 471.1403     153.8793     290.7542     598.37305    325.16803
  740.4659     400.95618   1032.688      483.66537    626.5006
  337.39804     63.19983      5.4628296  531.7776     572.98
  562.8819     383.73654   1327.7366     418.3215     418.18646
 1111.6362    1044.3005     410.69217    632.6117     770.8096
  243.9403       2.0499268  617.8216     138.60297     10.239746
  259.98862    840.6533     672.4115     828.5887     491.27667
  849.557       13.723694   780.819      260.51508   1192.4822
  241.62308    334.45892     54.5943     694.4518    1219.9059
  730.69086    384.54898     48.199646   568.3642     649.0148
  279.37943     20.586472   401.69052    477.40497    838.6971
  471.95917    125.53729    384.86105    922.0249     541.7541
  564.26196     80.541504   307.5845     738.6224     417.87872
  303.49234   1132.605      649.5345     997.83997   1077.1912
  326.62158    315.92706    721.78955    895.2418     202.45238
  351.98355    608.1203     670.70856   1119.0164     517.8821
  265.24066     53.80777    915.9963    1082.7795     600.7388
  284.34714    122.99805     85.57712    284.28488    907.08356
    6.329773   485.5377      25.92746    624.78357     49.893707
 1062.8188     797.8456     404.75803    512.49774    457.61334
  277.92847    321.62332    192.59299    274.24643    893.3407
  649.3793     319.4779     479.95258    773.51013    982.65375
  559.5322     229.95102   1298.9675     991.0653     867.60095
  439.27567     41.41095    455.4604     296.6674     116.64441
  580.84143    540.8015    1137.2391     888.42957    232.84521
  578.2854    1317.5714     792.812      307.88156    220.76721
  290.97983    540.59924    909.3096     671.03394    644.0965
  604.7989     869.3708     904.1972   ]","[ 429.48096   100.74567   385.34537   499.2467    260.00592   747.48474
  368.8979   1096.5334    478.47025   552.5971    361.09116   147.3533
   61.626892  515.1634    488.21866   631.3558    281.83502  1319.1423
  445.4266    506.76456  1072.4312   1121.791     436.91327   649.10144
  748.66394   213.53659    61.371033  427.63126    52.164505   67.56329
  330.5407    880.86597   624.7091    887.92426   465.9195    652.723
   57.802795  873.4335    193.4436   1270.364     195.07002   331.83984
  148.51985   711.0458   1176.6187    740.0688    408.12933   141.83823
  473.90778   751.36035   284.39203    50.984253  352.66776   414.16632
  902.3643    514.8506     25.122406  437.02356  1015.312     761.3703
  609.60754   195.32196   355.91736   758.1198    441.18024   300.76974
 1109.4707    634.42365  1004.97626  1049.9347    335.76178   299.11343
  700.62524   875.3109    186.10623   548.9364    637.2733    642.67554
 1186.0826    461.6073    275.78702   142.3457    831.2177   1117.0178
  562.1383    360.65482   124.17401    41.60376   413.68375   892.8993
  313.84702   337.98083    76.9707    579.14136   117.82144  1014.6186
  789.84595   301.53308   619.16907   516.78595   244.61705   232.99277
  215.37552   269.88452   669.5178    575.04584   332.6266    345.79984
  661.0737    988.38354   540.0084    281.19455  1342.1296   1098.5076
  785.87646   491.4642     42.602448  408.60898   285.2473    129.11987
  280.95294   339.5623   1171.2843   1032.135     200.70679   458.27142
 1062.2434    797.73846   258.20502    57.32727   324.37653   527.91406
  831.0179    691.33264   705.8521    649.69824   967.99225  1083.0188  ]",64.463684,7577.94,87.0513638112939
trial_2,cartesian_knn_minmax_act,"['Epoch: 0, Train Loss: 0.376529221023832, Val Loss: 0.411519456993450', 'Epoch: 1, Train Loss: 0.382226571440697, Val Loss: 0.420678281422817', 'Epoch: 2, Train Loss: 0.384037562779018, Val Loss: 0.413633323077000', 'Epoch: 3, Train Loss: 0.385055373821940, Val Loss: 0.399732773954218', 'Epoch: 4, Train Loss: 0.384193607739040, Val Loss: 0.426159160606789', 'Epoch: 5, Train Loss: 0.386521043522017, Val Loss: 0.400818021911563', 'Epoch: 6, Train Loss: 0.379529054675783, Val Loss: 0.410699915705305', 'Epoch: 7, Train Loss: 0.370988645723888, Val Loss: 0.395105802651608', 'Epoch: 8, Train Loss: 0.326543954866273, Val Loss: 0.296250630057219', 'Epoch: 9, Train Loss: 0.219228872231075, Val Loss: 0.130468438407688', 'Epoch: 10, Train Loss: 0.149009359734399, Val Loss: 0.188536631790074', 'Epoch: 11, Train Loss: 0.145628433674574, Val Loss: 0.099108529136036', 'Epoch: 12, Train Loss: 0.103648872247764, Val Loss: 0.103123575110327', 'Epoch: 13, Train Loss: 0.097930754401854, Val Loss: 0.088178051579179', 'Epoch: 14, Train Loss: 0.089293665119580, Val Loss: 0.086690131123319', 'Epoch: 15, Train Loss: 0.089274871562208, Val Loss: 0.078582813342412', 'Epoch: 16, Train Loss: 0.083171156368085, Val Loss: 0.092415333612624', 'Epoch: 17, Train Loss: 0.074693446446742, Val Loss: 0.092785518305997', 'Epoch: 18, Train Loss: 0.072858566950474, Val Loss: 0.053701939569278', 'Epoch: 19, Train Loss: 0.059634552204183, Val Loss: 0.058104786485659', 'Epoch: 20, Train Loss: 0.053422863196049, Val Loss: 0.064802817181882', 'Epoch: 21, Train Loss: 0.055951533306922, Val Loss: 0.056677426634864', 'Epoch: 22, Train Loss: 0.064295120670327, Val Loss: 0.065485157241875', 'Epoch: 23, Train Loss: 0.046852170090590, Val Loss: 0.055367398668419', 'Epoch: 24, Train Loss: 0.049384254163929, Val Loss: 0.051779890926837', 'Epoch: 25, Train Loss: 0.046507334602731, Val Loss: 0.048704600921183', 'Epoch: 26, Train Loss: 0.041092949653310, Val Loss: 0.089077324578256', 'Epoch: 27, Train Loss: 0.054963782562741, Val Loss: 0.054269614319007', 'Epoch: 28, Train Loss: 0.046569606555360, Val Loss: 0.054143869572065', 'Epoch: 29, Train Loss: 0.059756010371659, Val Loss: 0.050608854458639', 'Epoch: 30, Train Loss: 0.050809883113418, Val Loss: 0.067206763813815', 'Epoch: 31, Train Loss: 0.040061365413879, Val Loss: 0.053674799474803', 'Epoch: 32, Train Loss: 0.038725390764219, Val Loss: 0.044670023274552', 'Epoch: 33, Train Loss: 0.035710947055902, Val Loss: 0.029999609916668', 'Epoch: 34, Train Loss: 0.032726496724146, Val Loss: 0.032545342476982', 'Epoch: 35, Train Loss: 0.034799217246473, Val Loss: 0.046667397688990', 'Epoch: 36, Train Loss: 0.036585050368948, Val Loss: 0.028622922600445', 'Epoch: 37, Train Loss: 0.034751426694649, Val Loss: 0.050077818997317', 'Epoch: 38, Train Loss: 0.036671301216951, Val Loss: 0.045394282943259', 'Epoch: 39, Train Loss: 0.035552017124636, Val Loss: 0.035950505979020', 'Epoch: 40, Train Loss: 0.039580387994647, Val Loss: 0.052739639851180', 'Epoch: 41, Train Loss: 0.040291069474603, Val Loss: 0.038962260650640', 'Epoch: 42, Train Loss: 0.048451676964760, Val Loss: 0.040877620409116', 'Epoch: 43, Train Loss: 0.037880328217787, Val Loss: 0.034216701081305', 'Epoch: 44, Train Loss: 0.033404578587839, Val Loss: 0.034782310778444', 'Epoch: 45, Train Loss: 0.027626824033047, Val Loss: 0.043455221323353', 'Epoch: 46, Train Loss: 0.032690908227648, Val Loss: 0.031675948846069', 'Epoch: 47, Train Loss: 0.035435290874115, Val Loss: 0.039681301311110', 'Epoch: 48, Train Loss: 0.039766940820430, Val Loss: 0.043207339208686', 'Epoch: 49, Train Loss: 0.031483289652637, Val Loss: 0.040799173441800', 'Epoch: 50, Train Loss: 0.030808465555310, Val Loss: 0.055783751787561', 'Epoch: 51, Train Loss: 0.032589453006429, Val Loss: 0.029642867928046', 'Epoch: 52, Train Loss: 0.030520077927836, Val Loss: 0.031806265681305', 'Epoch: 53, Train Loss: 0.029607189420078, Val Loss: 0.048368397041817', 'Epoch: 54, Train Loss: 0.024278600301061, Val Loss: 0.032383847643029', 'Epoch: 55, Train Loss: 0.025806640274823, Val Loss: 0.036546721772263', 'Epoch: 56, Train Loss: 0.023774329240301, Val Loss: 0.028632246070739', 'Epoch: 57, Train Loss: 0.027504224729325, Val Loss: 0.040394351845889', 'Epoch: 58, Train Loss: 0.025764531655503, Val Loss: 0.031345133472121', 'Epoch: 59, Train Loss: 0.028315233598862, Val Loss: 0.036539963813442', 'Epoch: 60, Train Loss: 0.028238756582141, Val Loss: 0.035156023660392', 'Epoch: 61, Train Loss: 0.021121348853090, Val Loss: 0.028961491629933', 'Epoch: 62, Train Loss: 0.021889790293894, Val Loss: 0.036010303506345', 'Epoch: 63, Train Loss: 0.023361883126199, Val Loss: 0.032889817615576', 'Epoch: 64, Train Loss: 0.023648865520954, Val Loss: 0.033289051438315', 'Epoch: 65, Train Loss: 0.019932220623429, Val Loss: 0.027951333558921', 'Epoch: 66, Train Loss: 0.019744655316962, Val Loss: 0.028646910675999', 'Epoch: 67, Train Loss: 0.023938211080219, Val Loss: 0.031366538722068', 'Epoch: 68, Train Loss: 0.021807639127863, Val Loss: 0.024605191228065', 'Epoch: 69, Train Loss: 0.015806602580207, Val Loss: 0.024659611905615', 'Epoch: 70, Train Loss: 0.016908309156341, Val Loss: 0.032879557770987', 'Epoch: 71, Train Loss: 0.020098757331393, Val Loss: 0.029846814997268', 'Epoch: 72, Train Loss: 0.022193927051766, Val Loss: 0.031736500730569', 'Epoch: 73, Train Loss: 0.016811335060213, Val Loss: 0.033792345699939', 'Epoch: 74, Train Loss: 0.018755660059729, Val Loss: 0.029843194219707', 'Epoch: 75, Train Loss: 0.015887325762638, Val Loss: 0.024758136407896', 'Epoch: 76, Train Loss: 0.017583898002548, Val Loss: 0.028587796287893', 'Epoch: 77, Train Loss: 0.015950863582215, Val Loss: 0.028177590871399', 'Epoch: 78, Train Loss: 0.016075183238302, Val Loss: 0.028610535953758', 'Epoch: 79, Train Loss: 0.018361161196870, Val Loss: 0.030804925231319', 'Epoch: 80, Train Loss: 0.016361901935722, Val Loss: 0.036525228117226', 'Epoch: 81, Train Loss: 0.017491527101291, Val Loss: 0.032141011716290', 'Epoch: 82, Train Loss: 0.019432858630483, Val Loss: 0.027555899073680', 'Epoch: 83, Train Loss: 0.015784023529185, Val Loss: 0.032031599488674', 'Epoch: 84, Train Loss: 0.017668592344437, Val Loss: 0.031342065780226', 'Epoch: 85, Train Loss: 0.017717438883015, Val Loss: 0.033062147879691', 'Epoch: 86, Train Loss: 0.016212463079553, Val Loss: 0.026652121577751', 'Epoch: 87, Train Loss: 0.017216889919447, Val Loss: 0.026621078564362', 'Epoch: 88, Train Loss: 0.015661181150270, Val Loss: 0.037408438257196', 'Epoch: 89, Train Loss: 0.014581883060081, Val Loss: 0.031539587811990', 'Epoch: 90, Train Loss: 0.013292837621910, Val Loss: 0.033585707911036', 'Epoch: 91, Train Loss: 0.017717529354351, Val Loss: 0.033369045591716', 'Epoch: 92, Train Loss: 0.016936493305756, Val Loss: 0.035665443449309', 'Epoch: 93, Train Loss: 0.016239654472364, Val Loss: 0.031468175803170', 'Epoch: 94, Train Loss: 0.014092237821647, Val Loss: 0.031586352439428', 'Epoch: 95, Train Loss: 0.014415254151183, Val Loss: 0.027633416025448', 'Epoch: 96, Train Loss: 0.013907798898539, Val Loss: 0.033388264604251', 'Epoch: 97, Train Loss: 0.013100427309317, Val Loss: 0.026948775700999', 'Epoch: 98, Train Loss: 0.012217167033149, Val Loss: 0.028701212609921', 'Epoch: 99, Train Loss: 0.014975357867245, Val Loss: 0.037494547954394', 'Epoch: 100, Train Loss: 0.015573375392705, Val Loss: 0.025646721633772', 'Epoch: 101, Train Loss: 0.013417190007333, Val Loss: 0.031745188784870', 'Epoch: 102, Train Loss: 0.015039296488145, Val Loss: 0.030549583561493', 'Epoch: 103, Train Loss: 0.014129864318030, Val Loss: 0.026163290000775', 'Epoch: 104, Train Loss: 0.016649314335414, Val Loss: 0.024939018922548', 'Epoch: 105, Train Loss: 0.013801088090986, Val Loss: 0.032823557937236', 'Epoch: 106, Train Loss: 0.014231166270162, Val Loss: 0.027476529449676', 'Epoch: 107, Train Loss: 0.013194966063436, Val Loss: 0.031362305367083', 'Epoch: 108, Train Loss: 0.012593148874917, Val Loss: 0.032289027970171', 'Epoch: 109, Train Loss: 0.011842919314014, Val Loss: 0.030576078644530', 'Epoch: 110, Train Loss: 0.011964053447757, Val Loss: 0.025521451438015', 'Epoch: 111, Train Loss: 0.013307648178722, Val Loss: 0.031282281615969', 'Epoch: 112, Train Loss: 0.011646447403889, Val Loss: 0.027307878389503', 'Epoch: 113, Train Loss: 0.011820765212178, Val Loss: 0.027408003863512', 'Epoch: 114, Train Loss: 0.011230106265949, Val Loss: 0.030028432946314', 'Epoch: 115, Train Loss: 0.011314694536850, Val Loss: 0.027934677814218', 'Epoch: 116, Train Loss: 0.012806396731841, Val Loss: 0.026187567068546', 'Epoch: 117, Train Loss: 0.010836014357795, Val Loss: 0.030467769977721', 'Epoch: 118, Train Loss: 0.011989312579057, Val Loss: 0.024955043174101', 'Epoch: 119, Train Loss: 0.011254357573177, Val Loss: 0.025408073384879', 'Epoch: 120, Train Loss: 0.012417780335194, Val Loss: 0.028239521818856', 'Epoch: 121, Train Loss: 0.011221759087805, Val Loss: 0.026578186813629', 'Epoch: 122, Train Loss: 0.012398605002090, Val Loss: 0.028351446006899', 'Epoch: 123, Train Loss: 0.010828033289207, Val Loss: 0.030849779306939', 'Epoch: 124, Train Loss: 0.011777496397761, Val Loss: 0.032365702861694', 'Epoch: 125, Train Loss: 0.011258087253996, Val Loss: 0.031106101969878', 'Epoch: 126, Train Loss: 0.011364862721946, Val Loss: 0.031601518561894', 'Epoch: 127, Train Loss: 0.011045534030667, Val Loss: 0.029083664641913', 'Epoch: 128, Train Loss: 0.011394441393869, Val Loss: 0.028910749521332', 'Epoch: 129, Train Loss: 0.010451150791986, Val Loss: 0.028347273907540', 'Epoch: 130, Train Loss: 0.011190185755757, Val Loss: 0.028355656361038', 'Epoch: 131, Train Loss: 0.009703871361645, Val Loss: 0.029891241087832', 'Epoch: 132, Train Loss: 0.009749013864036, Val Loss: 0.034746784039519', 'Epoch: 133, Train Loss: 0.011221557356683, Val Loss: 0.032666328504230', 'Epoch: 134, Train Loss: 0.010865792765149, Val Loss: 0.026688280035601', 'Epoch: 135, Train Loss: 0.010252223283585, Val Loss: 0.030503169464117', 'Epoch: 136, Train Loss: 0.009882000607571, Val Loss: 0.029980624151049', 'Epoch: 137, Train Loss: 0.010519294068217, Val Loss: 0.028562920407928', 'Epoch: 138, Train Loss: 0.010702244471759, Val Loss: 0.034020718525756', 'Epoch: 139, Train Loss: 0.010679108755929, Val Loss: 0.026603589864504', 'Epoch: 140, Train Loss: 0.010343228533332, Val Loss: 0.027993268530929', 'Epoch: 141, Train Loss: 0.008839387114027, Val Loss: 0.025674747359572', 'Epoch: 142, Train Loss: 0.008838367166131, Val Loss: 0.028012581536490', 'Epoch: 143, Train Loss: 0.009449692642582, Val Loss: 0.032317235289762', 'Epoch: 144, Train Loss: 0.009047532088256, Val Loss: 0.025715371311614', 'Epoch: 145, Train Loss: 0.008167103132499, Val Loss: 0.025536801680132', 'Epoch: 146, Train Loss: 0.008493974272694, Val Loss: 0.027961786808164', 'Epoch: 147, Train Loss: 0.009281018116911, Val Loss: 0.031546193033908', 'Epoch: 148, Train Loss: 0.008297693782619, Val Loss: 0.028613048464511', 'Epoch: 149, Train Loss: 0.009392541334299, Val Loss: 0.031607213514772', 'Epoch: 150, Train Loss: 0.009574347475011, Val Loss: 0.026761814937786', 'Epoch: 151, Train Loss: 0.009033417828115, Val Loss: 0.025852746132648', 'Epoch: 152, Train Loss: 0.009019425604492, Val Loss: 0.031551958993077', 'Epoch: 153, Train Loss: 0.009211443131790, Val Loss: 0.028550076891075', 'Epoch: 154, Train Loss: 0.009139069888209, Val Loss: 0.030580367243877', 'Epoch: 155, Train Loss: 0.008501187033419, Val Loss: 0.029966733503071', 'Epoch: 156, Train Loss: 0.007457036957411, Val Loss: 0.027544705874541', 'Epoch: 157, Train Loss: 0.007295310896422, Val Loss: 0.030035996414495', 'Epoch: 158, Train Loss: 0.007569568547686, Val Loss: 0.027377565984022', 'Epoch: 159, Train Loss: 0.007279180156599, Val Loss: 0.029581249804434', 'Epoch: 160, Train Loss: 0.006926296711234, Val Loss: 0.028650144072758', 'Epoch: 161, Train Loss: 0.008363289525732, Val Loss: 0.027750583111563', 'Epoch: 162, Train Loss: 0.007834992754007, Val Loss: 0.030282220577426', 'Epoch: 163, Train Loss: 0.007558436798198, Val Loss: 0.030353275043043', 'Epoch: 164, Train Loss: 0.008172058483719, Val Loss: 0.031860254196958', 'Epoch: 165, Train Loss: 0.009320818187137, Val Loss: 0.028647618198937', 'Epoch: 166, Train Loss: 0.007914145310809, Val Loss: 0.028672882355750', 'Epoch: 167, Train Loss: 0.007481679353597, Val Loss: 0.034936217421835', 'Epoch: 168, Train Loss: 0.008248404533203, Val Loss: 0.030756102987763', 'Epoch: 169, Train Loss: 0.007321973863457, Val Loss: 0.031335264613683', 'Epoch: 170, Train Loss: 0.007514391094446, Val Loss: 0.029559988345048', 'Epoch: 171, Train Loss: 0.008605117743303, Val Loss: 0.031139972845488', 'Epoch: 172, Train Loss: 0.007825512505536, Val Loss: 0.028947749711347', 'Epoch: 173, Train Loss: 0.006930079045040, Val Loss: 0.032403100507729', 'Epoch: 174, Train Loss: 0.008367997028732, Val Loss: 0.027499459175901', 'Epoch: 175, Train Loss: 0.008031473594851, Val Loss: 0.034359517196814', 'Epoch: 176, Train Loss: 0.008723889211459, Val Loss: 0.029147337952798', 'Epoch: 177, Train Loss: 0.008435801070716, Val Loss: 0.029612602553133', 'Epoch: 178, Train Loss: 0.008071906631812, Val Loss: 0.029872864428343', 'Epoch: 179, Train Loss: 0.007240610513171, Val Loss: 0.030013504776765', 'Epoch: 180, Train Loss: 0.006961076420599, Val Loss: 0.032261909352559', 'Epoch: 181, Train Loss: 0.007746486558712, Val Loss: 0.029391672913775', 'Epoch: 182, Train Loss: 0.008081469851147, Val Loss: 0.032207987638134', 'Epoch: 183, Train Loss: 0.006499215777564, Val Loss: 0.030410652641546', 'Epoch: 184, Train Loss: 0.008081189556313, Val Loss: 0.029578934818732', 'Epoch: 185, Train Loss: 0.006160758069849, Val Loss: 0.029809835846677', 'Epoch: 186, Train Loss: 0.007526594047834, Val Loss: 0.029253068323614', 'Epoch: 187, Train Loss: 0.006778673967347, Val Loss: 0.030470623719421', 'Epoch: 188, Train Loss: 0.007941957995562, Val Loss: 0.031282270270767', 'Epoch: 189, Train Loss: 0.007438357886193, Val Loss: 0.029490092374159', 'Epoch: 190, Train Loss: 0.007055985874363, Val Loss: 0.029682878348412', 'Epoch: 191, Train Loss: 0.007546583090776, Val Loss: 0.030012199147181', 'Epoch: 192, Train Loss: 0.007033312726500, Val Loss: 0.029648183421655', 'Epoch: 193, Train Loss: 0.007570489542559, Val Loss: 0.030399172256390', 'Epoch: 194, Train Loss: 0.007222647778690, Val Loss: 0.029468385672027', 'Epoch: 195, Train Loss: 0.006708038272336, Val Loss: 0.028755232155549', 'Epoch: 196, Train Loss: 0.007490503518576, Val Loss: 0.028809796821213', 'Epoch: 197, Train Loss: 0.006369335842984, Val Loss: 0.029161881034573', 'Epoch: 198, Train Loss: 0.006947552020262, Val Loss: 0.029418109831485', 'Epoch: 199, Train Loss: 0.007761604036205, Val Loss: 0.029486512059741']","[ 687.8954     587.7664     806.48376   1192.2505     249.45024
   62.58194    426.27896   1012.64764    407.37656    373.86713
  264.60712     69.31613    244.11351    106.83893    290.97983
  540.59924    400.95618   1032.688      691.2141     439.6826
  937.9889      71.58554    125.02261    446.80353    166.28964
  211.36594   1139.9081     641.5614     289.0574     254.19006
  335.5677     550.8332     713.01166    101.37781   1090.6873
  140.76965   1041.1692     291.88788     55.43544    436.99503
  594.27295    523.7677     380.06744    549.14624    193.66635
  706.7205     548.6123     562.0951     737.4956     127.90927
  328.93167    348.92972     29.124512   631.9739     363.94058
  803.88574    337.39804     63.19983   1035.3289     289.96573
  322.44098    384.01755    694.1144     419.9962     245.8705
  604.0323     267.63318    818.9285     915.9963    1082.7795
  537.7522     771.3589     556.70044    855.26227    580.84143
  540.8015     269.5341     346.46228    296.6674     116.64441
  198.0301     564.53436    397.72205     76.32414    238.36115
  859.18506   1174.3181     599.6746     440.00293     99.90213
  349.61304    200.36572    383.73654   1327.7366     543.912
   84.83186    549.78577    392.8176     125.53729    384.86105
  211.00024     23.32251    212.51854    586.0235      12.562317
  312.81177   1056.3058     793.31714    392.04727    389.85242
  159.53868     58.082092   242.34076    349.28815    796.14014
  888.3277     384.54898     48.199646   600.7388     284.34714
    5.618469   295.53036    483.34933    854.8072       2.0499268
  617.8216     848.72437    541.6864     290.7542     598.37305
   28.69104    512.4936     963.3551     343.87537    285.84372
  894.3473     466.41046   1307.9707   ]","[ 683.54565    583.33014    879.07025   1185.4238     205.98265
   33.585663   442.57834   1077.676      520.2014     517.7278
  256.81424    135.47351    276.67358    113.60953    380.66953
  543.1472     442.67346    979.3906     679.9292     450.58917
  826.31433     39.66339    102.315796   471.85623    276.8897
   65.68875   1242.8151     662.9123     268.0453     230.83595
  321.19702    558.1853     604.4487      93.71356   1272.596
   88.34216   1100.7056     319.34787     59.854553   464.1802
  613.35974    392.3991     411.65964    572.0112     212.12492
  631.5848     335.11005    426.5889     735.52014    167.53555
  316.05884    406.02695     16.684326   657.60657    311.45383
  884.094      379.867      165.04642   1085.6565     231.9729
  351.7578     312.9165     687.3616     441.5245     254.68494
  611.5015     277.7212     789.9806     941.022     1193.6373
  700.23285    848.0854     466.7558     694.4841     271.12152
  311.01794    339.91577    378.5282     288.221      178.53955
  213.60106    572.95026    336.801       45.506424   112.0585
  914.47253   1233.062      592.83356    522.49194    205.29697
  337.0173     200.31967    529.73334   1318.0972     383.07864
   67.25462    520.5613     454.73184      7.9340515  512.11743
  417.93298    159.4682      39.966522   555.5682     155.63873
  470.64014    954.03894    848.9193     359.427      468.68982
  185.82968     27.190948   286.11768    301.13098    948.2628
  885.1494     380.8096     143.44388    546.0756     253.76274
   34.69467    374.16132    539.2199     978.7063      66.30072
  499.92334    850.32404    546.31226    366.53198    587.5322
   11.912323   456.37775   1079.8368     396.53363    203.36685
  975.5143     741.07416   1296.8038   ]",63.22882,7472.7734,86.4452048265258
trial_3,cartesian_knn_minmax_act,"['Epoch: 0, Train Loss: 0.383985928126744, Val Loss: 0.406662825382117', 'Epoch: 1, Train Loss: 0.378062852791377, Val Loss: 0.405736133907781', 'Epoch: 2, Train Loss: 0.376653788345201, Val Loss: 0.403015321854389', 'Epoch: 3, Train Loss: 0.380561163382871, Val Loss: 0.403909090793494', 'Epoch: 4, Train Loss: 0.384920382073947, Val Loss: 0.401058355967204', 'Epoch: 5, Train Loss: 0.372958434479577, Val Loss: 0.400100842569814', 'Epoch: 6, Train Loss: 0.379104843097074, Val Loss: 0.393680123668728', 'Epoch: 7, Train Loss: 0.373751025114741, Val Loss: 0.376291670582511', 'Epoch: 8, Train Loss: 0.323269715266568, Val Loss: 0.249424095406677', 'Epoch: 9, Train Loss: 0.265166848897934, Val Loss: 0.239999698418559', 'Epoch: 10, Train Loss: 0.225705393190895, Val Loss: 0.198656279480819', 'Epoch: 11, Train Loss: 0.179760989333902, Val Loss: 0.087829506081162', 'Epoch: 12, Train Loss: 0.126898683075394, Val Loss: 0.104137738827955', 'Epoch: 13, Train Loss: 0.090188974514604, Val Loss: 0.113615333751747', 'Epoch: 14, Train Loss: 0.101267213267939, Val Loss: 0.110967332892346', 'Epoch: 15, Train Loss: 0.096884258623634, Val Loss: 0.078760570761832', 'Epoch: 16, Train Loss: 0.075091277648296, Val Loss: 0.101405098526315', 'Epoch: 17, Train Loss: 0.067213552338736, Val Loss: 0.083214531765517', 'Epoch: 18, Train Loss: 0.055898357448833, Val Loss: 0.084435927392350', 'Epoch: 19, Train Loss: 0.063935557380319, Val Loss: 0.076661594070946', 'Epoch: 20, Train Loss: 0.059023137071303, Val Loss: 0.094392317488338', 'Epoch: 21, Train Loss: 0.058410043695143, Val Loss: 0.072521806488195', 'Epoch: 22, Train Loss: 0.054669118619391, Val Loss: 0.079570427513152', 'Epoch: 23, Train Loss: 0.048413332551718, Val Loss: 0.086837677736626', 'Epoch: 24, Train Loss: 0.046941205992230, Val Loss: 0.096427282487804', 'Epoch: 25, Train Loss: 0.049348491377064, Val Loss: 0.073945466090332', 'Epoch: 26, Train Loss: 0.038770869241229, Val Loss: 0.071757155188331', 'Epoch: 27, Train Loss: 0.039391493158681, Val Loss: 0.064469133023963', 'Epoch: 28, Train Loss: 0.042783389001020, Val Loss: 0.086402859849234', 'Epoch: 29, Train Loss: 0.039029135102672, Val Loss: 0.070978211013205', 'Epoch: 30, Train Loss: 0.034529225900769, Val Loss: 0.066375040533868', 'Epoch: 31, Train Loss: 0.039885938965849, Val Loss: 0.067522628853718', 'Epoch: 32, Train Loss: 0.039494931298707, Val Loss: 0.092958517022480', 'Epoch: 33, Train Loss: 0.040451173404498, Val Loss: 0.089665350913437', 'Epoch: 34, Train Loss: 0.056785945647529, Val Loss: 0.058819408669616', 'Epoch: 35, Train Loss: 0.047281451789396, Val Loss: 0.084128323434429', 'Epoch: 36, Train Loss: 0.038115621145282, Val Loss: 0.086395352457960', 'Epoch: 37, Train Loss: 0.040628188954932, Val Loss: 0.061295386516687', 'Epoch: 38, Train Loss: 0.047559830360115, Val Loss: 0.074802188823620', 'Epoch: 39, Train Loss: 0.034438262826630, Val Loss: 0.065544852440133', 'Epoch: 40, Train Loss: 0.037253590965910, Val Loss: 0.062603125828459', 'Epoch: 41, Train Loss: 0.035213502789182, Val Loss: 0.069340339438482', 'Epoch: 42, Train Loss: 0.036080358549953, Val Loss: 0.064848355102268', 'Epoch: 43, Train Loss: 0.038580206355878, Val Loss: 0.081360725036850', 'Epoch: 44, Train Loss: 0.036222936585546, Val Loss: 0.067707507419541', 'Epoch: 45, Train Loss: 0.035178512401347, Val Loss: 0.076819480022867', 'Epoch: 46, Train Loss: 0.034630001389555, Val Loss: 0.059112916785208', 'Epoch: 47, Train Loss: 0.042116900639875, Val Loss: 0.091578259048137', 'Epoch: 48, Train Loss: 0.030521501787007, Val Loss: 0.057318142241319', 'Epoch: 49, Train Loss: 0.028502002092344, Val Loss: 0.058319263724667', 'Epoch: 50, Train Loss: 0.029008607845753, Val Loss: 0.068015851419080', 'Epoch: 51, Train Loss: 0.028064555887665, Val Loss: 0.057746001886147', 'Epoch: 52, Train Loss: 0.027915287363742, Val Loss: 0.061421458157852', 'Epoch: 53, Train Loss: 0.023912263901106, Val Loss: 0.079191998945493', 'Epoch: 54, Train Loss: 0.026181804548417, Val Loss: 0.066870851639771', 'Epoch: 55, Train Loss: 0.025071642361581, Val Loss: 0.071918539025567', 'Epoch: 56, Train Loss: 0.021865930275193, Val Loss: 0.070877163473404', 'Epoch: 57, Train Loss: 0.029150650969573, Val Loss: 0.064375711322734', 'Epoch: 58, Train Loss: 0.025708564889750, Val Loss: 0.071043593301014', 'Epoch: 59, Train Loss: 0.023557774057346, Val Loss: 0.061162697207747', 'Epoch: 60, Train Loss: 0.020764673727431, Val Loss: 0.070308580204393', 'Epoch: 61, Train Loss: 0.021574683620461, Val Loss: 0.064266522612536', 'Epoch: 62, Train Loss: 0.024193017211344, Val Loss: 0.068469663630381', 'Epoch: 63, Train Loss: 0.024629513466997, Val Loss: 0.059053807321823', 'Epoch: 64, Train Loss: 0.018827626415129, Val Loss: 0.057823688444456', 'Epoch: 65, Train Loss: 0.023286027567727, Val Loss: 0.064411989892974', 'Epoch: 66, Train Loss: 0.021122279244342, Val Loss: 0.063315299180844', 'Epoch: 67, Train Loss: 0.021378457014050, Val Loss: 0.057092641056939', 'Epoch: 68, Train Loss: 0.019107410617705, Val Loss: 0.061052679789789', 'Epoch: 69, Train Loss: 0.019077493210456, Val Loss: 0.063441844798173', 'Epoch: 70, Train Loss: 0.021920135444296, Val Loss: 0.065833606729002', 'Epoch: 71, Train Loss: 0.019171116607530, Val Loss: 0.064759722586270', 'Epoch: 72, Train Loss: 0.018213125012283, Val Loss: 0.060722291243799', 'Epoch: 73, Train Loss: 0.017129452899098, Val Loss: 0.060561054753083', 'Epoch: 74, Train Loss: 0.018084208081876, Val Loss: 0.060942421639056', 'Epoch: 75, Train Loss: 0.022821623299803, Val Loss: 0.071830703538250', 'Epoch: 76, Train Loss: 0.019042221164065, Val Loss: 0.066891166974198', 'Epoch: 77, Train Loss: 0.016314781137875, Val Loss: 0.065954617139968', 'Epoch: 78, Train Loss: 0.015668318008206, Val Loss: 0.059809116251541', 'Epoch: 79, Train Loss: 0.014553022903523, Val Loss: 0.062049926681952', 'Epoch: 80, Train Loss: 0.015401524491608, Val Loss: 0.068464710405379', 'Epoch: 81, Train Loss: 0.016739111659782, Val Loss: 0.067393873225559', 'Epoch: 82, Train Loss: 0.022349730200533, Val Loss: 0.073842524212192', 'Epoch: 83, Train Loss: 0.015118009743414, Val Loss: 0.071911330419508', 'Epoch: 84, Train Loss: 0.015858605903174, Val Loss: 0.071789070836861', 'Epoch: 85, Train Loss: 0.017964870070240, Val Loss: 0.060777616546010', 'Epoch: 86, Train Loss: 0.016818712798080, Val Loss: 0.066411304993160', 'Epoch: 87, Train Loss: 0.013139754866383, Val Loss: 0.063430309860092', 'Epoch: 88, Train Loss: 0.013937004243157, Val Loss: 0.061638024607391', 'Epoch: 89, Train Loss: 0.013552617048845, Val Loss: 0.072235677391291', 'Epoch: 90, Train Loss: 0.013903636086200, Val Loss: 0.065647024999965', 'Epoch: 91, Train Loss: 0.012707423950945, Val Loss: 0.066478036682714', 'Epoch: 92, Train Loss: 0.012293614879517, Val Loss: 0.071503819841327', 'Epoch: 93, Train Loss: 0.012752027117780, Val Loss: 0.066716491893837', 'Epoch: 94, Train Loss: 0.012199900279354, Val Loss: 0.066776776742755', 'Epoch: 95, Train Loss: 0.012551781654890, Val Loss: 0.061750327265172', 'Epoch: 96, Train Loss: 0.011942908034793, Val Loss: 0.058032757743742', 'Epoch: 97, Train Loss: 0.012165022747857, Val Loss: 0.067090043290095', 'Epoch: 98, Train Loss: 0.012067367389266, Val Loss: 0.063731714575128', 'Epoch: 99, Train Loss: 0.012058347995792, Val Loss: 0.068820666183125', 'Epoch: 100, Train Loss: 0.011348430133824, Val Loss: 0.069340737621215', 'Epoch: 101, Train Loss: 0.012744711312865, Val Loss: 0.074891309169206', 'Epoch: 102, Train Loss: 0.011725120146626, Val Loss: 0.070361185141585', 'Epoch: 103, Train Loss: 0.013163270761392, Val Loss: 0.064601300171379', 'Epoch: 104, Train Loss: 0.011511144860248, Val Loss: 0.071080855573669', 'Epoch: 105, Train Loss: 0.012162272086633, Val Loss: 0.072738374555201', 'Epoch: 106, Train Loss: 0.012617731666459, Val Loss: 0.066558800186172', 'Epoch: 107, Train Loss: 0.010286096749561, Val Loss: 0.058408804915168', 'Epoch: 108, Train Loss: 0.011935302455510, Val Loss: 0.060444814124794', 'Epoch: 109, Train Loss: 0.010779650316441, Val Loss: 0.067045702401436', 'Epoch: 110, Train Loss: 0.010063580869298, Val Loss: 0.062860452033805', 'Epoch: 111, Train Loss: 0.010425402649811, Val Loss: 0.063055517434171', 'Epoch: 112, Train Loss: 0.010651580224346, Val Loss: 0.065313225160494', 'Epoch: 113, Train Loss: 0.010282489936799, Val Loss: 0.071387276392091', 'Epoch: 114, Train Loss: 0.011194541917316, Val Loss: 0.086481362919916', 'Epoch: 115, Train Loss: 0.011555082896458, Val Loss: 0.075797205169996', 'Epoch: 116, Train Loss: 0.013193762062916, Val Loss: 0.075388493806575', 'Epoch: 117, Train Loss: 0.011111103962841, Val Loss: 0.068891415485378', 'Epoch: 118, Train Loss: 0.010923057861094, Val Loss: 0.076647349492167', 'Epoch: 119, Train Loss: 0.010465748242236, Val Loss: 0.072286406136823', 'Epoch: 120, Train Loss: 0.010013819572383, Val Loss: 0.066083603961901', 'Epoch: 121, Train Loss: 0.010964702748294, Val Loss: 0.063243298791349', 'Epoch: 122, Train Loss: 0.011945427794542, Val Loss: 0.070135806320292', 'Epoch: 123, Train Loss: 0.009689361522240, Val Loss: 0.069887713444504', 'Epoch: 124, Train Loss: 0.009200546125482, Val Loss: 0.062874697826125', 'Epoch: 125, Train Loss: 0.010301261341998, Val Loss: 0.064895547474876', 'Epoch: 126, Train Loss: 0.009717911581642, Val Loss: 0.065819570738258', 'Epoch: 127, Train Loss: 0.010411471860217, Val Loss: 0.070071656990683', 'Epoch: 128, Train Loss: 0.009432453362803, Val Loss: 0.064869581693501', 'Epoch: 129, Train Loss: 0.008250275660040, Val Loss: 0.068413057336302', 'Epoch: 130, Train Loss: 0.008546756713518, Val Loss: 0.067278083978277', 'Epoch: 131, Train Loss: 0.009357909339347, Val Loss: 0.071192981618823', 'Epoch: 132, Train Loss: 0.009226889948228, Val Loss: 0.072158589507594', 'Epoch: 133, Train Loss: 0.007761381666309, Val Loss: 0.067729080716769', 'Epoch: 134, Train Loss: 0.008056499762461, Val Loss: 0.068330141518152', 'Epoch: 135, Train Loss: 0.007203643991878, Val Loss: 0.068086080478899', 'Epoch: 136, Train Loss: 0.007875599765352, Val Loss: 0.064916658356334', 'Epoch: 137, Train Loss: 0.008603758544528, Val Loss: 0.067997566113869', 'Epoch: 138, Train Loss: 0.008592182337972, Val Loss: 0.066915128831611', 'Epoch: 139, Train Loss: 0.008081413605916, Val Loss: 0.071534205792528', 'Epoch: 140, Train Loss: 0.007632119381534, Val Loss: 0.068621649209297', 'Epoch: 141, Train Loss: 0.007669901408787, Val Loss: 0.068726187910546', 'Epoch: 142, Train Loss: 0.009936214092055, Val Loss: 0.061906352752086', 'Epoch: 143, Train Loss: 0.007305490817609, Val Loss: 0.070074365671837', 'Epoch: 144, Train Loss: 0.007663884998432, Val Loss: 0.071591382112467', 'Epoch: 145, Train Loss: 0.008423697003829, Val Loss: 0.080454173864740', 'Epoch: 146, Train Loss: 0.009556200421814, Val Loss: 0.072462495529290', 'Epoch: 147, Train Loss: 0.008429437775963, Val Loss: 0.065968291608222', 'Epoch: 148, Train Loss: 0.008029759562175, Val Loss: 0.078032869958516', 'Epoch: 149, Train Loss: 0.008002486312762, Val Loss: 0.069335243467129', 'Epoch: 150, Train Loss: 0.009389862418175, Val Loss: 0.071216918076530', 'Epoch: 151, Train Loss: 0.008796041698328, Val Loss: 0.069045448619308', 'Epoch: 152, Train Loss: 0.007409518883963, Val Loss: 0.071766508291617', 'Epoch: 153, Train Loss: 0.007082014993232, Val Loss: 0.068870924187429', 'Epoch: 154, Train Loss: 0.008382256608456, Val Loss: 0.070238033196691', 'Epoch: 155, Train Loss: 0.007520640202399, Val Loss: 0.075112325562672', 'Epoch: 156, Train Loss: 0.007537747633510, Val Loss: 0.067928505045446', 'Epoch: 157, Train Loss: 0.008697525764416, Val Loss: 0.073860714155616', 'Epoch: 158, Train Loss: 0.008016077236139, Val Loss: 0.070002193873127', 'Epoch: 159, Train Loss: 0.006947285096560, Val Loss: 0.070942077898618', 'Epoch: 160, Train Loss: 0.007189671708537, Val Loss: 0.067008539131193', 'Epoch: 161, Train Loss: 0.006983538457592, Val Loss: 0.074190602835381', 'Epoch: 162, Train Loss: 0.006524654704013, Val Loss: 0.074553497248527', 'Epoch: 163, Train Loss: 0.007719213342560, Val Loss: 0.070684464253259', 'Epoch: 164, Train Loss: 0.006893516551437, Val Loss: 0.071050460817236', 'Epoch: 165, Train Loss: 0.006776696403644, Val Loss: 0.068404176977999', 'Epoch: 166, Train Loss: 0.007051733289180, Val Loss: 0.067153162351160', 'Epoch: 167, Train Loss: 0.006457846112815, Val Loss: 0.073118364269083', 'Epoch: 168, Train Loss: 0.007059926433223, Val Loss: 0.068960551398270', 'Epoch: 169, Train Loss: 0.006768744122902, Val Loss: 0.072894786343430', 'Epoch: 170, Train Loss: 0.007749913726002, Val Loss: 0.069110043403326', 'Epoch: 171, Train Loss: 0.007777452552026, Val Loss: 0.069681461561810', 'Epoch: 172, Train Loss: 0.006619379190462, Val Loss: 0.069571810689839', 'Epoch: 173, Train Loss: 0.006068107788451, Val Loss: 0.069521600888534', 'Epoch: 174, Train Loss: 0.006564170155408, Val Loss: 0.068564464309902', 'Epoch: 175, Train Loss: 0.006347738439217, Val Loss: 0.071899233442364', 'Epoch: 176, Train Loss: 0.006566308987593, Val Loss: 0.068522169734492', 'Epoch: 177, Train Loss: 0.006710611250518, Val Loss: 0.067897376801932', 'Epoch: 178, Train Loss: 0.007728971740497, Val Loss: 0.068571353839202', 'Epoch: 179, Train Loss: 0.006568909024021, Val Loss: 0.070618589154699', 'Epoch: 180, Train Loss: 0.006630363142384, Val Loss: 0.067552727054466', 'Epoch: 181, Train Loss: 0.006744207581505, Val Loss: 0.071720636365089', 'Epoch: 182, Train Loss: 0.005857771079588, Val Loss: 0.068884174480583', 'Epoch: 183, Train Loss: 0.006526339865689, Val Loss: 0.071440560460994', 'Epoch: 184, Train Loss: 0.006291633488477, Val Loss: 0.069398877295581', 'Epoch: 185, Train Loss: 0.005947770683893, Val Loss: 0.072331563880046', 'Epoch: 186, Train Loss: 0.006320640478017, Val Loss: 0.070527149646571', 'Epoch: 187, Train Loss: 0.005584857376691, Val Loss: 0.070554431753628', 'Epoch: 188, Train Loss: 0.005782490263560, Val Loss: 0.070299913147182', 'Epoch: 189, Train Loss: 0.005306614097208, Val Loss: 0.070421336049383', 'Epoch: 190, Train Loss: 0.005342497107839, Val Loss: 0.070065338729006', 'Epoch: 191, Train Loss: 0.005818274903244, Val Loss: 0.070036202782031', 'Epoch: 192, Train Loss: 0.006104462647012, Val Loss: 0.069037968687939', 'Epoch: 193, Train Loss: 0.006287819140458, Val Loss: 0.069517747470827', 'Epoch: 194, Train Loss: 0.005800940911286, Val Loss: 0.071091082059976', 'Epoch: 195, Train Loss: 0.005402634918158, Val Loss: 0.069443885914304', 'Epoch: 196, Train Loss: 0.006167349987663, Val Loss: 0.068606344926538', 'Epoch: 197, Train Loss: 0.006683460104146, Val Loss: 0.068921242586591', 'Epoch: 198, Train Loss: 0.005076406756416, Val Loss: 0.069265241762905', 'Epoch: 199, Train Loss: 0.006623532772729, Val Loss: 0.069285192159992']","[ 134.52554   797.6494    691.2141    439.6826     79.64363   615.89215
  490.2004     95.74954   628.44556   214.72958    43.14807   271.00787
  584.4683    423.94983   253.36862   461.46448   477.43213   116.37985
  687.8954    587.7664   1041.1692    291.88788   952.84454   109.81055
  842.1108    181.13446   694.1144    419.9962    806.48376  1192.2505
  292.5141   1150.3883    169.21231   268.91907  1429.8969    547.19257
 1175.6475    121.2063    563.5581    641.4297   1132.605     649.5345
  410.69217   632.6117    394.43427   609.6168    909.3096    671.03394
 1185.6675   1094.6262   1137.2391    888.42957  1177.7285    855.7604
  104.14691   608.6197    526.00854   405.86972   404.01263    47.2493
   20.507141  685.9015    753.615     318.85965   543.912      84.83186
  122.99805    85.57712   261.02615   283.8731    401.69052   477.40497
  721.78955   895.2418    329.59433   638.37024   279.57117   675.881
  477.07156   572.8349    691.6881    864.5598    284.28488   907.08356
  312.65588    75.50653   620.43097   823.2302    192.59299   274.24643
  267.63318   818.9285     41.233185  206.63477   332.17014   231.96283
  644.0965    604.7989    737.4956    127.90927   694.00336   165.98267
  426.52148   186.2782    806.92255   904.63446   349.7179    449.12518
  243.94936   593.6415    640.0748    102.15756   632.99805   187.88531
  146.80591   137.8653    383.73654  1327.7366     13.723694  780.819
   95.59955   489.06366   935.7298    265.4128    548.6123    562.0951
  350.84784    12.088623  417.87872   303.49234   730.1066    402.3608
  620.43274   166.78876   823.0254    925.10425  1219.9059    730.69086 ]","[  35.522583   841.7042     686.0276     520.70575     40.23056
  439.03793    560.8255     125.236694   685.3178      96.13995
    6.3332825  154.762      640.99774    352.54486    144.22937
  543.95276    515.2277     169.05122    573.569      523.0821
 1087.8684     297.75336    986.2272      84.85089    852.19385
   71.00415    669.9336     468.39523    801.9965    1197.1174
  245.27914   1202.3511     130.37152    332.4935    1398.7506
  529.3777    1374.3503     133.30005    679.313      682.02783
 1134.6514     660.81696    413.77533    652.36993    391.6096
  598.0807     850.43567    653.21277   1284.2429    1145.4697
 1173.986      923.32776   1265.6265     838.79596     57.726105
  561.7897     379.9097     353.9715     409.05304    152.28522
  108.77219    603.35486    729.98413    338.68695    433.68045
  152.74597    178.56818     46.910522   201.5682     283.7436
  355.44632    460.54102    683.1092     945.7919     254.68799
  568.6488     296.1168     622.9592     553.1377     649.2217
  684.87756    959.6577     372.76605    840.9488     295.28873
   30.097168   634.224      832.8545     255.40057    279.933
  348.48254    784.5886      90.798874   161.86774    282.1059
   87.30908    638.13885    633.24347    811.1566      82.97189
  679.8322     142.13739    489.6174      54.80542    986.2827
 1088.0808     371.80518    491.66174    235.05905    548.74194
  567.4774     149.88554    591.9321      50.247803    76.67407
  161.25998    397.89575   1318.2375      51.647003   774.9072
  291.4053     443.71753   1017.1909     244.03192    278.9257
  412.0698     352.73715     37.735626   427.57446    289.97763
  685.30176    391.1839     550.587       64.843414   997.05365
 1022.26636   1208.1488     708.66614  ]",56.544167,5529.072,74.3577284304984
trial_1,polar_knn_minmax_act,"['Epoch: 0, Train Loss: 0.386822994266238, Val Loss: 0.396984668843674', 'Epoch: 1, Train Loss: 0.381134835737092, Val Loss: 0.402644518198389', 'Epoch: 2, Train Loss: 0.387842627508300, Val Loss: 0.394717629660260', 'Epoch: 3, Train Loss: 0.383336742009435, Val Loss: 0.395917673679915', 'Epoch: 4, Train Loss: 0.386461881654603, Val Loss: 0.392781165738900', 'Epoch: 5, Train Loss: 0.378874397703580, Val Loss: 0.389960368925875', 'Epoch: 6, Train Loss: 0.385071375540325, Val Loss: 0.380865580882087', 'Epoch: 7, Train Loss: 0.367795160838536, Val Loss: 0.382707742127505', 'Epoch: 8, Train Loss: 0.317286172083446, Val Loss: 0.268340374258432', 'Epoch: 9, Train Loss: 0.226702386247260, Val Loss: 0.247845970319979', 'Epoch: 10, Train Loss: 0.162078584943499, Val Loss: 0.114499461136857', 'Epoch: 11, Train Loss: 0.150866483471223, Val Loss: 0.107140642111049', 'Epoch: 12, Train Loss: 0.113137339907033, Val Loss: 0.104909011699034', 'Epoch: 13, Train Loss: 0.095721373334527, Val Loss: 0.105154507087939', 'Epoch: 14, Train Loss: 0.074305823604975, Val Loss: 0.100703492760658', 'Epoch: 15, Train Loss: 0.071630611483540, Val Loss: 0.089439447856311', 'Epoch: 16, Train Loss: 0.069760938574161, Val Loss: 0.100545366605123', 'Epoch: 17, Train Loss: 0.063729227653572, Val Loss: 0.112519254089531', 'Epoch: 18, Train Loss: 0.059798425063491, Val Loss: 0.077350471733194', 'Epoch: 19, Train Loss: 0.061216468523656, Val Loss: 0.072703431953083', 'Epoch: 20, Train Loss: 0.059652988266732, Val Loss: 0.082569714071173', 'Epoch: 21, Train Loss: 0.045211716954197, Val Loss: 0.065328684720126', 'Epoch: 22, Train Loss: 0.042469984452639, Val Loss: 0.065582455107660', 'Epoch: 23, Train Loss: 0.040887125634721, Val Loss: 0.064967822057731', 'Epoch: 24, Train Loss: 0.044198244011828, Val Loss: 0.061279375218984', 'Epoch: 25, Train Loss: 0.039285235106945, Val Loss: 0.054252520090703', 'Epoch: 26, Train Loss: 0.041649252841515, Val Loss: 0.052308033135804', 'Epoch: 27, Train Loss: 0.034725071995386, Val Loss: 0.057706980994253', 'Epoch: 28, Train Loss: 0.039208190914776, Val Loss: 0.053572918881070', 'Epoch: 29, Train Loss: 0.038519777357578, Val Loss: 0.059412105855617', 'Epoch: 30, Train Loss: 0.032523105852306, Val Loss: 0.051668517517321', 'Epoch: 31, Train Loss: 0.038700123849724, Val Loss: 0.056139032949101', 'Epoch: 32, Train Loss: 0.035003747258868, Val Loss: 0.068928962404078', 'Epoch: 33, Train Loss: 0.038146564870008, Val Loss: 0.053839436534679', 'Epoch: 34, Train Loss: 0.035960219135242, Val Loss: 0.067192758461743', 'Epoch: 35, Train Loss: 0.034503731078335, Val Loss: 0.059218879563339', 'Epoch: 36, Train Loss: 0.032822385430336, Val Loss: 0.048885918476365', 'Epoch: 37, Train Loss: 0.030821079188692, Val Loss: 0.057930670904391', 'Epoch: 38, Train Loss: 0.047898873021560, Val Loss: 0.062207031204845', 'Epoch: 39, Train Loss: 0.039629914930889, Val Loss: 0.058187190894828', 'Epoch: 40, Train Loss: 0.037669720527317, Val Loss: 0.063943541411198', 'Epoch: 41, Train Loss: 0.037073917021709, Val Loss: 0.054474116218361', 'Epoch: 42, Train Loss: 0.036569681284683, Val Loss: 0.053949467499148', 'Epoch: 43, Train Loss: 0.035566841252148, Val Loss: 0.059384306271871', 'Epoch: 44, Train Loss: 0.038100158662668, Val Loss: 0.051910704961329', 'Epoch: 45, Train Loss: 0.031748559059841, Val Loss: 0.073798412174890', 'Epoch: 46, Train Loss: 0.037666998537523, Val Loss: 0.050863804239215', 'Epoch: 47, Train Loss: 0.031758573970624, Val Loss: 0.055185672234405', 'Epoch: 48, Train Loss: 0.026607218664140, Val Loss: 0.050399876227885', 'Epoch: 49, Train Loss: 0.025812891578036, Val Loss: 0.052005614069375', 'Epoch: 50, Train Loss: 0.029216613886612, Val Loss: 0.060119673045296', 'Epoch: 51, Train Loss: 0.033023985768003, Val Loss: 0.063031269068068', 'Epoch: 52, Train Loss: 0.031283446188484, Val Loss: 0.057955015761157', 'Epoch: 53, Train Loss: 0.030235419448997, Val Loss: 0.058913993677407', 'Epoch: 54, Train Loss: 0.026170796182539, Val Loss: 0.048240890331341', 'Epoch: 55, Train Loss: 0.025568326136896, Val Loss: 0.056623895737258', 'Epoch: 56, Train Loss: 0.027237718791834, Val Loss: 0.051410167619134', 'Epoch: 57, Train Loss: 0.024545682061996, Val Loss: 0.066746016343435', 'Epoch: 58, Train Loss: 0.025996302986251, Val Loss: 0.057700940351369', 'Epoch: 59, Train Loss: 0.026653973917876, Val Loss: 0.053690287877213', 'Epoch: 60, Train Loss: 0.021282171897058, Val Loss: 0.046226344607545', 'Epoch: 61, Train Loss: 0.021712263779981, Val Loss: 0.061305213776050', 'Epoch: 62, Train Loss: 0.021304319679205, Val Loss: 0.059254594372981', 'Epoch: 63, Train Loss: 0.023506881469595, Val Loss: 0.048786355351860', 'Epoch: 64, Train Loss: 0.022508967667818, Val Loss: 0.057216219039577', 'Epoch: 65, Train Loss: 0.020951642787882, Val Loss: 0.052025891388908', 'Epoch: 66, Train Loss: 0.019044669012406, Val Loss: 0.062673886334806', 'Epoch: 67, Train Loss: 0.021230457084520, Val Loss: 0.062418362746636', 'Epoch: 68, Train Loss: 0.017958419330950, Val Loss: 0.054004526838209', 'Epoch: 69, Train Loss: 0.020629064911710, Val Loss: 0.059316799947710', 'Epoch: 70, Train Loss: 0.017796050890216, Val Loss: 0.050951933431806', 'Epoch: 71, Train Loss: 0.018414162698069, Val Loss: 0.053519507136309', 'Epoch: 72, Train Loss: 0.016866925704692, Val Loss: 0.061163577335802', 'Epoch: 73, Train Loss: 0.017068758673434, Val Loss: 0.056322866260554', 'Epoch: 74, Train Loss: 0.019759376599853, Val Loss: 0.057700462639332', 'Epoch: 75, Train Loss: 0.019284284141447, Val Loss: 0.066855261497425', 'Epoch: 76, Train Loss: 0.019554762369288, Val Loss: 0.063658973653660', 'Epoch: 77, Train Loss: 0.019970561776842, Val Loss: 0.052943552872448', 'Epoch: 78, Train Loss: 0.015731985215098, Val Loss: 0.052066981679562', 'Epoch: 79, Train Loss: 0.019709533146982, Val Loss: 0.056832756000486', 'Epoch: 80, Train Loss: 0.018981721584818, Val Loss: 0.057913877267503', 'Epoch: 81, Train Loss: 0.016073988551008, Val Loss: 0.056241811112021', 'Epoch: 82, Train Loss: 0.015420573896595, Val Loss: 0.059253174811602', 'Epoch: 83, Train Loss: 0.013929780971791, Val Loss: 0.054009940701001', 'Epoch: 84, Train Loss: 0.012568629346788, Val Loss: 0.058012555494453', 'Epoch: 85, Train Loss: 0.013107598360096, Val Loss: 0.057437246270252', 'Epoch: 86, Train Loss: 0.014179445204458, Val Loss: 0.057025018966559', 'Epoch: 87, Train Loss: 0.015606004279107, Val Loss: 0.056989946261500', 'Epoch: 88, Train Loss: 0.013425856895213, Val Loss: 0.064104793819063', 'Epoch: 89, Train Loss: 0.014163537217038, Val Loss: 0.059580944873618', 'Epoch: 90, Train Loss: 0.015281350152301, Val Loss: 0.059279774174546', 'Epoch: 91, Train Loss: 0.013227275373148, Val Loss: 0.054684753473284', 'Epoch: 92, Train Loss: 0.013342435870852, Val Loss: 0.059311541926229', 'Epoch: 93, Train Loss: 0.010934832372836, Val Loss: 0.061387272890319', 'Epoch: 94, Train Loss: 0.013212367260296, Val Loss: 0.061456422998824', 'Epoch: 95, Train Loss: 0.012900411683534, Val Loss: 0.050930504884684', 'Epoch: 96, Train Loss: 0.013874226382801, Val Loss: 0.058045730897875', 'Epoch: 97, Train Loss: 0.014491926379768, Val Loss: 0.059050981858463', 'Epoch: 98, Train Loss: 0.016861112522227, Val Loss: 0.054123325047619', 'Epoch: 99, Train Loss: 0.016696847043931, Val Loss: 0.056390082124959', 'Epoch: 100, Train Loss: 0.015673193681453, Val Loss: 0.055892275420554', 'Epoch: 101, Train Loss: 0.013760659311499, Val Loss: 0.057933727448637', 'Epoch: 102, Train Loss: 0.014792835073812, Val Loss: 0.063555716903824', 'Epoch: 103, Train Loss: 0.012413634120354, Val Loss: 0.061786179797667', 'Epoch: 104, Train Loss: 0.014194095041603, Val Loss: 0.062941365056869', 'Epoch: 105, Train Loss: 0.011600066774658, Val Loss: 0.058073031123389', 'Epoch: 106, Train Loss: 0.012306751483785, Val Loss: 0.059122595597397', 'Epoch: 107, Train Loss: 0.011964292365259, Val Loss: 0.058432425428746', 'Epoch: 108, Train Loss: 0.012882100019072, Val Loss: 0.055610917325160', 'Epoch: 109, Train Loss: 0.011494487191417, Val Loss: 0.062179130868930', 'Epoch: 110, Train Loss: 0.012098879220762, Val Loss: 0.066344861618497', 'Epoch: 111, Train Loss: 0.011579275463841, Val Loss: 0.055781252682209', 'Epoch: 112, Train Loss: 0.010611103847623, Val Loss: 0.062486652228417', 'Epoch: 113, Train Loss: 0.011033035748239, Val Loss: 0.060725203009717', 'Epoch: 114, Train Loss: 0.010556547170771, Val Loss: 0.055480123695099', 'Epoch: 115, Train Loss: 0.010348592385916, Val Loss: 0.059672648651582', 'Epoch: 116, Train Loss: 0.010192383014198, Val Loss: 0.057346868469860', 'Epoch: 117, Train Loss: 0.010858981171623, Val Loss: 0.058932667654572', 'Epoch: 118, Train Loss: 0.010567904815876, Val Loss: 0.059182483561789', 'Epoch: 119, Train Loss: 0.010837950045243, Val Loss: 0.062659010742650', 'Epoch: 120, Train Loss: 0.012472906815154, Val Loss: 0.062476858835329', 'Epoch: 121, Train Loss: 0.011617448114391, Val Loss: 0.065232115261482', 'Epoch: 122, Train Loss: 0.009495241367923, Val Loss: 0.070601408059398', 'Epoch: 123, Train Loss: 0.010860667963113, Val Loss: 0.064758479312965', 'Epoch: 124, Train Loss: 0.008663203766836, Val Loss: 0.062783399258148', 'Epoch: 125, Train Loss: 0.009494275586413, Val Loss: 0.074461947336341', 'Epoch: 126, Train Loss: 0.010201793430107, Val Loss: 0.067844260991974', 'Epoch: 127, Train Loss: 0.008742776898933, Val Loss: 0.065331756391309', 'Epoch: 128, Train Loss: 0.011826683900186, Val Loss: 0.067675124571630', 'Epoch: 129, Train Loss: 0.010339538965906, Val Loss: 0.071555814734011', 'Epoch: 130, Train Loss: 0.009215032881392, Val Loss: 0.065909751775590', 'Epoch: 131, Train Loss: 0.010351924491780, Val Loss: 0.065158210864121', 'Epoch: 132, Train Loss: 0.011102157611666, Val Loss: 0.056270743635568', 'Epoch: 133, Train Loss: 0.009350761870987, Val Loss: 0.065868887147217', 'Epoch: 134, Train Loss: 0.009202796466915, Val Loss: 0.069590896029364', 'Epoch: 135, Train Loss: 0.010043878906540, Val Loss: 0.068604119884020', 'Epoch: 136, Train Loss: 0.009420614190666, Val Loss: 0.062764495046753', 'Epoch: 137, Train Loss: 0.008588101681588, Val Loss: 0.066221273983970', 'Epoch: 138, Train Loss: 0.009645640484190, Val Loss: 0.065989885930762', 'Epoch: 139, Train Loss: 0.008187925576099, Val Loss: 0.068786853642175', 'Epoch: 140, Train Loss: 0.008155589856740, Val Loss: 0.068394772087534', 'Epoch: 141, Train Loss: 0.008439866360277, Val Loss: 0.071269682975429', 'Epoch: 142, Train Loss: 0.007577963639051, Val Loss: 0.061996933242137', 'Epoch: 143, Train Loss: 0.008979971553864, Val Loss: 0.064322335927775', 'Epoch: 144, Train Loss: 0.009972444003714, Val Loss: 0.065978240447514', 'Epoch: 145, Train Loss: 0.008912669760840, Val Loss: 0.070823543648602', 'Epoch: 146, Train Loss: 0.007101283109348, Val Loss: 0.067745463527513', 'Epoch: 147, Train Loss: 0.007902609683307, Val Loss: 0.058556464980498', 'Epoch: 148, Train Loss: 0.006997866356479, Val Loss: 0.068160326925643', 'Epoch: 149, Train Loss: 0.008634338055604, Val Loss: 0.065220283062169', 'Epoch: 150, Train Loss: 0.008931287198461, Val Loss: 0.063032551640362', 'Epoch: 151, Train Loss: 0.007804317865521, Val Loss: 0.063649082499923', 'Epoch: 152, Train Loss: 0.009389423565673, Val Loss: 0.064100598408417', 'Epoch: 153, Train Loss: 0.008705209541534, Val Loss: 0.070724302733486', 'Epoch: 154, Train Loss: 0.007943379027503, Val Loss: 0.065986263989048', 'Epoch: 155, Train Loss: 0.007649453290339, Val Loss: 0.067346819817568', 'Epoch: 156, Train Loss: 0.008400331966446, Val Loss: 0.068079531870105', 'Epoch: 157, Train Loss: 0.007991298717181, Val Loss: 0.067077832465822', 'Epoch: 158, Train Loss: 0.007783683316250, Val Loss: 0.059900089082393', 'Epoch: 159, Train Loss: 0.008194114430808, Val Loss: 0.066983051795625', 'Epoch: 160, Train Loss: 0.007536205862250, Val Loss: 0.066088848323985', 'Epoch: 161, Train Loss: 0.007504345549803, Val Loss: 0.059593634736357', 'Epoch: 162, Train Loss: 0.008157765792151, Val Loss: 0.063336630831614', 'Epoch: 163, Train Loss: 0.007200305084033, Val Loss: 0.063791223547675', 'Epoch: 164, Train Loss: 0.007269555702806, Val Loss: 0.067945679198160', 'Epoch: 165, Train Loss: 0.006848028727940, Val Loss: 0.062861031429334', 'Epoch: 166, Train Loss: 0.007503763340147, Val Loss: 0.066488195775133', 'Epoch: 167, Train Loss: 0.008346451745768, Val Loss: 0.058521351523020', 'Epoch: 168, Train Loss: 0.007352488913706, Val Loss: 0.067471147260883', 'Epoch: 169, Train Loss: 0.007384523017598, Val Loss: 0.060761847448620', 'Epoch: 170, Train Loss: 0.007413397343563, Val Loss: 0.064703463012296', 'Epoch: 171, Train Loss: 0.006728680704587, Val Loss: 0.061897218453162', 'Epoch: 172, Train Loss: 0.008207882056013, Val Loss: 0.066649963797042', 'Epoch: 173, Train Loss: 0.007116640086419, Val Loss: 0.062933654552608', 'Epoch: 174, Train Loss: 0.006329399367262, Val Loss: 0.063732484807119', 'Epoch: 175, Train Loss: 0.006522571934121, Val Loss: 0.061593011247389', 'Epoch: 176, Train Loss: 0.007193547041555, Val Loss: 0.063049791324319', 'Epoch: 177, Train Loss: 0.007320738430800, Val Loss: 0.062663904193676', 'Epoch: 178, Train Loss: 0.006858236489019, Val Loss: 0.061352052584742', 'Epoch: 179, Train Loss: 0.008163985131042, Val Loss: 0.061011153753057', 'Epoch: 180, Train Loss: 0.006562568147534, Val Loss: 0.061596213642395', 'Epoch: 181, Train Loss: 0.006491961922230, Val Loss: 0.064339364794168', 'Epoch: 182, Train Loss: 0.006202894080031, Val Loss: 0.067292739044536', 'Epoch: 183, Train Loss: 0.006858365976119, Val Loss: 0.066713312527899', 'Epoch: 184, Train Loss: 0.006621256370896, Val Loss: 0.064383523933815', 'Epoch: 185, Train Loss: 0.006257506885699, Val Loss: 0.066182709891688', 'Epoch: 186, Train Loss: 0.006131625651116, Val Loss: 0.066784598497730', 'Epoch: 187, Train Loss: 0.006670970153729, Val Loss: 0.066536123779687', 'Epoch: 188, Train Loss: 0.007159018789285, Val Loss: 0.065423983403228', 'Epoch: 189, Train Loss: 0.007523910974019, Val Loss: 0.065934490638249', 'Epoch: 190, Train Loss: 0.005864790990017, Val Loss: 0.064538115691958', 'Epoch: 191, Train Loss: 0.006620960310102, Val Loss: 0.065065490815676', 'Epoch: 192, Train Loss: 0.007131026791675, Val Loss: 0.064459062886961', 'Epoch: 193, Train Loss: 0.006160896787021, Val Loss: 0.065961957598726', 'Epoch: 194, Train Loss: 0.006106699317960, Val Loss: 0.068318487794110', 'Epoch: 195, Train Loss: 0.006289094353893, Val Loss: 0.067761922988928', 'Epoch: 196, Train Loss: 0.005851623901565, Val Loss: 0.066503595504345', 'Epoch: 197, Train Loss: 0.006147475281198, Val Loss: 0.065876911535408', 'Epoch: 198, Train Loss: 0.005815351265483, Val Loss: 0.065702167537176', 'Epoch: 199, Train Loss: 0.005710497930912, Val Loss: 0.065769070533640']","[ 471.1403     153.8793     290.7542     598.37305    325.16803
  740.4659     400.95618   1032.688      483.66537    626.5006
  337.39804     63.19983      5.4628296  531.7776     572.98
  562.8819     383.73654   1327.7366     418.3215     418.18646
 1111.6362    1044.3005     410.69217    632.6117     770.8096
  243.9403       2.0499268  617.8216     138.60297     10.239746
  259.98862    840.6533     672.4115     828.5887     491.27667
  849.557       13.723694   780.819      260.51508   1192.4822
  241.62308    334.45892     54.5943     694.4518    1219.9059
  730.69086    384.54898     48.199646   568.3642     649.0148
  279.37943     20.586472   401.69052    477.40497    838.6971
  471.95917    125.53729    384.86105    922.0249     541.7541
  564.26196     80.541504   307.5845     738.6224     417.87872
  303.49234   1132.605      649.5345     997.83997   1077.1912
  326.62158    315.92706    721.78955    895.2418     202.45238
  351.98355    608.1203     670.70856   1119.0164     517.8821
  265.24066     53.80777    915.9963    1082.7795     600.7388
  284.34714    122.99805     85.57712    284.28488    907.08356
    6.329773   485.5377      25.92746    624.78357     49.893707
 1062.8188     797.8456     404.75803    512.49774    457.61334
  277.92847    321.62332    192.59299    274.24643    893.3407
  649.3793     319.4779     479.95258    773.51013    982.65375
  559.5322     229.95102   1298.9675     991.0653     867.60095
  439.27567     41.41095    455.4604     296.6674     116.64441
  580.84143    540.8015    1137.2391     888.42957    232.84521
  578.2854    1317.5714     792.812      307.88156    220.76721
  290.97983    540.59924    909.3096     671.03394    644.0965
  604.7989     869.3708     904.1972   ]","[ 420.55664    39.38971   310.2712    583.70764   400.2155    741.8368
  414.11395   997.75867   441.21848   589.3877    467.15686   270.09766
   41.867615  517.2908    464.0488    637.23157   314.0561   1318.1931
  475.4256    455.89478   936.13226  1070.9438    315.65588   709.48724
  732.25757   193.61996    58.217712  489.71332    44.226715   81.53174
  299.9974    906.20044   705.2169    863.0657    431.69504   688.62195
   61.680145  923.31226   208.44034  1280.9968    175.84161   353.93182
  157.63573   700.13794  1139.6631    872.12445   352.8876    114.67618
  525.26764   744.9754    263.24808    34.48758   329.73123   470.4129
  917.4648    511.88324    10.747009  458.92395   975.8753    787.89734
  574.3645    229.58508   336.96707   765.69086   480.33112   284.2335
 1119.0076    629.02264  1059.8295   1054.3108    325.6572    243.1144
  754.22144   935.2866    255.53548   525.7574    609.5847    534.78107
 1204.0581    475.18768   255.31801   158.86305   870.7117   1124.7749
  519.2366    383.11896   128.06479   169.46448   269.86853   922.30585
  390.8116    222.82928    87.35689   579.76135   234.99286   956.7132
  778.704     348.35297   691.37683   493.8299    182.65709   279.77896
  213.11888   229.27718   696.05334   637.23004   338.68655   503.5977
  689.7505    985.7771    514.6899    305.51022  1357.924    1166.5583
  867.9868    442.9188     32.727295  382.19656   247.62779   104.39841
  350.75293   318.09308  1162.7914    846.2307    114.86859   417.29706
 1126.8981    753.36163   206.01846   105.34082   362.79236   484.69824
  875.2598    734.912     576.3987    564.88965   897.4991   1066.952   ]",70.73136,8931.922,94.5088454854888
trial_2,polar_knn_minmax_act,"['Epoch: 0, Train Loss: 0.385137281247548, Val Loss: 0.435115395170270', 'Epoch: 1, Train Loss: 0.389249948518617, Val Loss: 0.400509589549267', 'Epoch: 2, Train Loss: 0.394977443984577, Val Loss: 0.394509303750414', 'Epoch: 3, Train Loss: 0.384805413229125, Val Loss: 0.403432168743827', 'Epoch: 4, Train Loss: 0.379040498818670, Val Loss: 0.412796850457336', 'Epoch: 5, Train Loss: 0.382105731538364, Val Loss: 0.395343016494404', 'Epoch: 6, Train Loss: 0.377998592598098, Val Loss: 0.407941220384656', 'Epoch: 7, Train Loss: 0.370386034250259, Val Loss: 0.406200685284354', 'Epoch: 8, Train Loss: 0.344265050121716, Val Loss: 0.301981719154300', 'Epoch: 9, Train Loss: 0.269939475825855, Val Loss: 0.237730098493171', 'Epoch: 10, Train Loss: 0.191318627979074, Val Loss: 0.098748165888317', 'Epoch: 11, Train Loss: 0.112188206187316, Val Loss: 0.082826967943798', 'Epoch: 12, Train Loss: 0.105789644111480, Val Loss: 0.073464527443954', 'Epoch: 13, Train Loss: 0.089998279831239, Val Loss: 0.103108315538107', 'Epoch: 14, Train Loss: 0.079690868567143, Val Loss: 0.070497745422251', 'Epoch: 15, Train Loss: 0.071343435772828, Val Loss: 0.080844711060777', 'Epoch: 16, Train Loss: 0.061621748709253, Val Loss: 0.065082123559533', 'Epoch: 17, Train Loss: 0.063052650008883, Val Loss: 0.061188019191225', 'Epoch: 18, Train Loss: 0.052560501332794, Val Loss: 0.066109071965470', 'Epoch: 19, Train Loss: 0.050626972158040, Val Loss: 0.054509846324270', 'Epoch: 20, Train Loss: 0.048165844088154, Val Loss: 0.051412731987622', 'Epoch: 21, Train Loss: 0.045134837872216, Val Loss: 0.045962907486793', 'Epoch: 22, Train Loss: 0.050965127535164, Val Loss: 0.061677181698156', 'Epoch: 23, Train Loss: 0.049301483801433, Val Loss: 0.056734218741908', 'Epoch: 24, Train Loss: 0.039797381364873, Val Loss: 0.047441294755448', 'Epoch: 25, Train Loss: 0.041435976778822, Val Loss: 0.060030074507901', 'Epoch: 26, Train Loss: 0.041064398097140, Val Loss: 0.042062566361644', 'Epoch: 27, Train Loss: 0.039459950357143, Val Loss: 0.053025936764298', 'Epoch: 28, Train Loss: 0.044592770614794, Val Loss: 0.045032545529080', 'Epoch: 29, Train Loss: 0.043026909232140, Val Loss: 0.051215265905767', 'Epoch: 30, Train Loss: 0.037496768337275, Val Loss: 0.058886491834666', 'Epoch: 31, Train Loss: 0.038737159222364, Val Loss: 0.055687862617726', 'Epoch: 32, Train Loss: 0.041196990625135, Val Loss: 0.063096206296574', 'Epoch: 33, Train Loss: 0.037638688060854, Val Loss: 0.038508477324451', 'Epoch: 34, Train Loss: 0.041152992951018, Val Loss: 0.052898247020714', 'Epoch: 35, Train Loss: 0.042147591577045, Val Loss: 0.045918673841339', 'Epoch: 36, Train Loss: 0.038323196050312, Val Loss: 0.049512389059545', 'Epoch: 37, Train Loss: 0.034781924715000, Val Loss: 0.038334609609041', 'Epoch: 38, Train Loss: 0.034529155519392, Val Loss: 0.047711168726285', 'Epoch: 39, Train Loss: 0.035865582924868, Val Loss: 0.048222901483038', 'Epoch: 40, Train Loss: 0.038952920851963, Val Loss: 0.051229218190367', 'Epoch: 41, Train Loss: 0.035098161016192, Val Loss: 0.045742287159418', 'Epoch: 42, Train Loss: 0.037685282395354, Val Loss: 0.078108005620765', 'Epoch: 43, Train Loss: 0.048805576350008, Val Loss: 0.037762464729674', 'Epoch: 44, Train Loss: 0.037637228944472, Val Loss: 0.042089410598926', 'Epoch: 45, Train Loss: 0.040460379395102, Val Loss: 0.062833904345153', 'Epoch: 46, Train Loss: 0.036652096946325, Val Loss: 0.045744191303101', 'Epoch: 47, Train Loss: 0.043929256232721, Val Loss: 0.045710403020635', 'Epoch: 48, Train Loss: 0.032970312184521, Val Loss: 0.040751788539417', 'Epoch: 49, Train Loss: 0.028412946499884, Val Loss: 0.053766791059664', 'Epoch: 50, Train Loss: 0.028286174205797, Val Loss: 0.042935435631962', 'Epoch: 51, Train Loss: 0.028421557441886, Val Loss: 0.039465091106567', 'Epoch: 52, Train Loss: 0.029749815086169, Val Loss: 0.049938367566828', 'Epoch: 53, Train Loss: 0.025489115688418, Val Loss: 0.042808858959964', 'Epoch: 54, Train Loss: 0.023825621964144, Val Loss: 0.047377820634706', 'Epoch: 55, Train Loss: 0.028158375793802, Val Loss: 0.046058741257046', 'Epoch: 56, Train Loss: 0.032005509494671, Val Loss: 0.042324551014286', 'Epoch: 57, Train Loss: 0.023359060553568, Val Loss: 0.045349668203430', 'Epoch: 58, Train Loss: 0.025079639495483, Val Loss: 0.042946425125454', 'Epoch: 59, Train Loss: 0.026041153818369, Val Loss: 0.042541860461687', 'Epoch: 60, Train Loss: 0.023413816866066, Val Loss: 0.048367552459240', 'Epoch: 61, Train Loss: 0.021673629858664, Val Loss: 0.044935210974831', 'Epoch: 62, Train Loss: 0.022480348191623, Val Loss: 0.041392801527047', 'Epoch: 63, Train Loss: 0.025920195571546, Val Loss: 0.040468076032332', 'Epoch: 64, Train Loss: 0.023425091324108, Val Loss: 0.046843008110017', 'Epoch: 65, Train Loss: 0.023931428657046, Val Loss: 0.051389779669769', 'Epoch: 66, Train Loss: 0.023288703922715, Val Loss: 0.044095235961405', 'Epoch: 67, Train Loss: 0.021118891891092, Val Loss: 0.037538553785646', 'Epoch: 68, Train Loss: 0.021513473375567, Val Loss: 0.044743474347122', 'Epoch: 69, Train Loss: 0.021750384276467, Val Loss: 0.037795681788614', 'Epoch: 70, Train Loss: 0.019843647189971, Val Loss: 0.048185676900726', 'Epoch: 71, Train Loss: 0.023156920580992, Val Loss: 0.044266440990296', 'Epoch: 72, Train Loss: 0.022546017143343, Val Loss: 0.040575533653751', 'Epoch: 73, Train Loss: 0.021501333253192, Val Loss: 0.054349641950632', 'Epoch: 74, Train Loss: 0.019629204645753, Val Loss: 0.036208429740685', 'Epoch: 75, Train Loss: 0.018977485530611, Val Loss: 0.037590906094534', 'Epoch: 76, Train Loss: 0.018183828930237, Val Loss: 0.042600885372270', 'Epoch: 77, Train Loss: 0.017468006749238, Val Loss: 0.040685357046172', 'Epoch: 78, Train Loss: 0.018064481339284, Val Loss: 0.052584237517845', 'Epoch: 79, Train Loss: 0.023542581658278, Val Loss: 0.043577200084022', 'Epoch: 80, Train Loss: 0.018491316653256, Val Loss: 0.045366830333616', 'Epoch: 81, Train Loss: 0.018115685254868, Val Loss: 0.047499492425810', 'Epoch: 82, Train Loss: 0.015182309584426, Val Loss: 0.041054461546468', 'Epoch: 83, Train Loss: 0.016082031452762, Val Loss: 0.043722707778215', 'Epoch: 84, Train Loss: 0.015292081582759, Val Loss: 0.044031244321642', 'Epoch: 85, Train Loss: 0.015451034863612, Val Loss: 0.040789110586047', 'Epoch: 86, Train Loss: 0.014588820016278, Val Loss: 0.050166273658926', 'Epoch: 87, Train Loss: 0.015517652666728, Val Loss: 0.038725285423976', 'Epoch: 88, Train Loss: 0.013070325433676, Val Loss: 0.042088539988706', 'Epoch: 89, Train Loss: 0.016849535850010, Val Loss: 0.039665670359902', 'Epoch: 90, Train Loss: 0.015166217328182, Val Loss: 0.043153801350854', 'Epoch: 91, Train Loss: 0.015560546424240, Val Loss: 0.038313186304136', 'Epoch: 92, Train Loss: 0.014813377322363, Val Loss: 0.050313596246821', 'Epoch: 93, Train Loss: 0.015533550309816, Val Loss: 0.042339513529882', 'Epoch: 94, Train Loss: 0.015613948194576, Val Loss: 0.037875968624245', 'Epoch: 95, Train Loss: 0.013231156526932, Val Loss: 0.040718963143952', 'Epoch: 96, Train Loss: 0.011636757424900, Val Loss: 0.040245198390701', 'Epoch: 97, Train Loss: 0.011771810573659, Val Loss: 0.038052789246043', 'Epoch: 98, Train Loss: 0.011088638666219, Val Loss: 0.041416330996788', 'Epoch: 99, Train Loss: 0.013653828962041, Val Loss: 0.040140613066879', 'Epoch: 100, Train Loss: 0.013495182019791, Val Loss: 0.041054541103993', 'Epoch: 101, Train Loss: 0.012616230474253, Val Loss: 0.041628947425069', 'Epoch: 102, Train Loss: 0.013415120874665, Val Loss: 0.040107384324074', 'Epoch: 103, Train Loss: 0.010914990611907, Val Loss: 0.045154524797743', 'Epoch: 104, Train Loss: 0.013619781372004, Val Loss: 0.039700882960901', 'Epoch: 105, Train Loss: 0.011773052292743, Val Loss: 0.036957909719962', 'Epoch: 106, Train Loss: 0.011547669236149, Val Loss: 0.038837712935426', 'Epoch: 107, Train Loss: 0.011499141076846, Val Loss: 0.042541074820540', 'Epoch: 108, Train Loss: 0.011666411766782, Val Loss: 0.043085415650046', 'Epoch: 109, Train Loss: 0.011700328439474, Val Loss: 0.037228501500618', 'Epoch: 110, Train Loss: 0.011872268481446, Val Loss: 0.043699283491481', 'Epoch: 111, Train Loss: 0.012630941545857, Val Loss: 0.039028727816361', 'Epoch: 112, Train Loss: 0.009643242661176, Val Loss: 0.041426865158207', 'Epoch: 113, Train Loss: 0.011708051698016, Val Loss: 0.042704399900906', 'Epoch: 114, Train Loss: 0.010802892236305, Val Loss: 0.045643676185247', 'Epoch: 115, Train Loss: 0.011553918078010, Val Loss: 0.044301386471048', 'Epoch: 116, Train Loss: 0.011904670557539, Val Loss: 0.041995160620321', 'Epoch: 117, Train Loss: 0.011796702564295, Val Loss: 0.047893585580768', 'Epoch: 118, Train Loss: 0.010816237855969, Val Loss: 0.044679387952342', 'Epoch: 119, Train Loss: 0.009664786314326, Val Loss: 0.046366317705675', 'Epoch: 120, Train Loss: 0.010875934734941, Val Loss: 0.044211032264160', 'Epoch: 121, Train Loss: 0.009148577660588, Val Loss: 0.043291756036607', 'Epoch: 122, Train Loss: 0.010044594228800, Val Loss: 0.038132789685871', 'Epoch: 123, Train Loss: 0.010547897811713, Val Loss: 0.041889987490845', 'Epoch: 124, Train Loss: 0.010670764970460, Val Loss: 0.039694827388633', 'Epoch: 125, Train Loss: 0.010034538788854, Val Loss: 0.044072980286949', 'Epoch: 126, Train Loss: 0.008729879644566, Val Loss: 0.039101327515461', 'Epoch: 127, Train Loss: 0.009724178451246, Val Loss: 0.040364873087542', 'Epoch: 128, Train Loss: 0.010345791067396, Val Loss: 0.045480823200760', 'Epoch: 129, Train Loss: 0.009109368448013, Val Loss: 0.040706399856417', 'Epoch: 130, Train Loss: 0.011952960863709, Val Loss: 0.041718565746013', 'Epoch: 131, Train Loss: 0.008786897407845, Val Loss: 0.041240968431036', 'Epoch: 132, Train Loss: 0.009183619437473, Val Loss: 0.044746358963576', 'Epoch: 133, Train Loss: 0.011763412671696, Val Loss: 0.044820836921589', 'Epoch: 134, Train Loss: 0.010945150296071, Val Loss: 0.037535958090854', 'Epoch: 135, Train Loss: 0.011608018573107, Val Loss: 0.040981264051163', 'Epoch: 136, Train Loss: 0.008393062378413, Val Loss: 0.046176643844581', 'Epoch: 137, Train Loss: 0.008613452980561, Val Loss: 0.045474387931101', 'Epoch: 138, Train Loss: 0.010799364685746, Val Loss: 0.040266397324475', 'Epoch: 139, Train Loss: 0.010343597603164, Val Loss: 0.036784733109402', 'Epoch: 140, Train Loss: 0.009799945600597, Val Loss: 0.042208451947028', 'Epoch: 141, Train Loss: 0.009964272113783, Val Loss: 0.047451954222087', 'Epoch: 142, Train Loss: 0.009448247429516, Val Loss: 0.040178424876296', 'Epoch: 143, Train Loss: 0.009113898534062, Val Loss: 0.040544518241377', 'Epoch: 144, Train Loss: 0.008494638621674, Val Loss: 0.039421952357798', 'Epoch: 145, Train Loss: 0.008536885924903, Val Loss: 0.043335307953936', 'Epoch: 146, Train Loss: 0.009122396386894, Val Loss: 0.040546983480453', 'Epoch: 147, Train Loss: 0.008464478555002, Val Loss: 0.041642347294273', 'Epoch: 148, Train Loss: 0.008671838257994, Val Loss: 0.038909587783344', 'Epoch: 149, Train Loss: 0.007597689915981, Val Loss: 0.044059426495523', 'Epoch: 150, Train Loss: 0.008664513405945, Val Loss: 0.040609154229363', 'Epoch: 151, Train Loss: 0.009159323825900, Val Loss: 0.046291262193611', 'Epoch: 152, Train Loss: 0.008585943906967, Val Loss: 0.043979450439413', 'Epoch: 153, Train Loss: 0.006923988361710, Val Loss: 0.042166871442036', 'Epoch: 154, Train Loss: 0.007663057285494, Val Loss: 0.043469254266132', 'Epoch: 155, Train Loss: 0.007554298798953, Val Loss: 0.043431615964933', 'Epoch: 156, Train Loss: 0.007492488216875, Val Loss: 0.043671654452654', 'Epoch: 157, Train Loss: 0.006997020682320, Val Loss: 0.042268947331291', 'Epoch: 158, Train Loss: 0.007783076892208, Val Loss: 0.043863894333216', 'Epoch: 159, Train Loss: 0.007296477777085, Val Loss: 0.040686443786729', 'Epoch: 160, Train Loss: 0.007241662458650, Val Loss: 0.040909021810600', 'Epoch: 161, Train Loss: 0.007815140199714, Val Loss: 0.043396048417146', 'Epoch: 162, Train Loss: 0.007162837378149, Val Loss: 0.041163787104641', 'Epoch: 163, Train Loss: 0.006757930985519, Val Loss: 0.042530393340822', 'Epoch: 164, Train Loss: 0.007217859616503, Val Loss: 0.038805402025129', 'Epoch: 165, Train Loss: 0.006753759857799, Val Loss: 0.037873849498503', 'Epoch: 166, Train Loss: 0.007267683711169, Val Loss: 0.041732127354904', 'Epoch: 167, Train Loss: 0.007043616180973, Val Loss: 0.040155577727339', 'Epoch: 168, Train Loss: 0.006750253910598, Val Loss: 0.043076590465551', 'Epoch: 169, Train Loss: 0.007270396088383, Val Loss: 0.041037674146620', 'Epoch: 170, Train Loss: 0.006284555120926, Val Loss: 0.041065596269839', 'Epoch: 171, Train Loss: 0.008117172235091, Val Loss: 0.043337570108248', 'Epoch: 172, Train Loss: 0.007674569696454, Val Loss: 0.044010137405359', 'Epoch: 173, Train Loss: 0.007032276596874, Val Loss: 0.043677252237544', 'Epoch: 174, Train Loss: 0.005750080055025, Val Loss: 0.044230166145346', 'Epoch: 175, Train Loss: 0.007495568699336, Val Loss: 0.041583201085979', 'Epoch: 176, Train Loss: 0.007068411729831, Val Loss: 0.043407332377903', 'Epoch: 177, Train Loss: 0.007387404163767, Val Loss: 0.044532854674440', 'Epoch: 178, Train Loss: 0.006352616507294, Val Loss: 0.045597204148318', 'Epoch: 179, Train Loss: 0.006974828146797, Val Loss: 0.044174387147932', 'Epoch: 180, Train Loss: 0.006749378317701, Val Loss: 0.043899959687031', 'Epoch: 181, Train Loss: 0.006445561036734, Val Loss: 0.043764174210303', 'Epoch: 182, Train Loss: 0.006544734318075, Val Loss: 0.042006887495518', 'Epoch: 183, Train Loss: 0.006913212527122, Val Loss: 0.042842594172918', 'Epoch: 184, Train Loss: 0.006444518986557, Val Loss: 0.042426744983955', 'Epoch: 185, Train Loss: 0.006377527141012, Val Loss: 0.042095139622688', 'Epoch: 186, Train Loss: 0.006624920659565, Val Loss: 0.044921584878907', 'Epoch: 187, Train Loss: 0.005830601489704, Val Loss: 0.042912371569511', 'Epoch: 188, Train Loss: 0.006770234887621, Val Loss: 0.041156186637553', 'Epoch: 189, Train Loss: 0.007250058497967, Val Loss: 0.043596625779614', 'Epoch: 190, Train Loss: 0.006707190486070, Val Loss: 0.043903537546143', 'Epoch: 191, Train Loss: 0.006489081640861, Val Loss: 0.043310903464303', 'Epoch: 192, Train Loss: 0.006957493339931, Val Loss: 0.043606146944292', 'Epoch: 193, Train Loss: 0.007551068706172, Val Loss: 0.043518665387775', 'Epoch: 194, Train Loss: 0.006406806076744, Val Loss: 0.043441105408199', 'Epoch: 195, Train Loss: 0.006193342169614, Val Loss: 0.044082511667952', 'Epoch: 196, Train Loss: 0.006546896616263, Val Loss: 0.044262532822110', 'Epoch: 197, Train Loss: 0.006073412202698, Val Loss: 0.043547811833295', 'Epoch: 198, Train Loss: 0.006866661898260, Val Loss: 0.042985994255904', 'Epoch: 199, Train Loss: 0.006302959451984, Val Loss: 0.042847322525852']","[ 687.8954     587.7664     806.48376   1192.2505     249.45024
   62.58194    426.27896   1012.64764    407.37656    373.86713
  264.60712     69.31613    244.11351    106.83893    290.97983
  540.59924    400.95618   1032.688      691.2141     439.6826
  937.9889      71.58554    125.02261    446.80353    166.28964
  211.36594   1139.9081     641.5614     289.0574     254.19006
  335.5677     550.8332     713.01166    101.37781   1090.6873
  140.76965   1041.1692     291.88788     55.43544    436.99503
  594.27295    523.7677     380.06744    549.14624    193.66635
  706.7205     548.6123     562.0951     737.4956     127.90927
  328.93167    348.92972     29.124512   631.9739     363.94058
  803.88574    337.39804     63.19983   1035.3289     289.96573
  322.44098    384.01755    694.1144     419.9962     245.8705
  604.0323     267.63318    818.9285     915.9963    1082.7795
  537.7522     771.3589     556.70044    855.26227    580.84143
  540.8015     269.5341     346.46228    296.6674     116.64441
  198.0301     564.53436    397.72205     76.32414    238.36115
  859.18506   1174.3181     599.6746     440.00293     99.90213
  349.61304    200.36572    383.73654   1327.7366     543.912
   84.83186    549.78577    392.8176     125.53729    384.86105
  211.00024     23.32251    212.51854    586.0235      12.562317
  312.81177   1056.3058     793.31714    392.04727    389.85242
  159.53868     58.082092   242.34076    349.28815    796.14014
  888.3277     384.54898     48.199646   600.7388     284.34714
    5.618469   295.53036    483.34933    854.8072       2.0499268
  617.8216     848.72437    541.6864     290.7542     598.37305
   28.69104    512.4936     963.3551     343.87537    285.84372
  894.3473     466.41046   1307.9707   ]","[ 677.88245   547.8755    829.7822   1124.6709    212.87267    32.51413
  429.64633  1119.426     536.5669    455.94888   303.6874    170.42311
  289.55203   108.66156   366.20334   572.3484    537.8354    945.486
  670.9458    569.7506    895.12744    17.961365   54.810394  500.59155
  321.67828    45.255096 1268.5852    724.76404   331.7027    212.10336
  285.36545   550.64355   721.0501     65.47241  1128.3318    189.41437
 1100.76      350.55026    53.610626  471.2143    613.1146    450.24713
  398.97263   606.001     284.63098   609.3943    351.4463    375.31152
  789.7648     69.74042   289.40918   419.8221     11.747314  699.07104
  304.543     813.5848    332.8956    186.44986  1096.8115    178.02924
  313.78253   346.5072    697.8967    452.17807   250.54074   609.1849
  326.1786    739.14185  1003.7672   1081.9261    700.27057   979.7511
  403.6789    616.3398    326.58478   254.20332   333.84842   320.11877
  214.10172    92.46924   158.89265   536.0492    278.28766    49.763153
  143.05475   880.336    1323.2493    643.2977    510.30188   206.21233
  332.26752   112.76825   497.45413  1316.2104    389.97708   149.67834
  420.06952   477.84912    10.537964  485.8648    413.36383   191.66351
  158.45218   659.26135    52.68695   439.50388   927.1077    928.44025
  380.19733   470.7002    142.85057    11.697388  256.65973   306.86896
  924.85986   846.58264   415.05853   112.85983   593.6836    287.88657
   37.476227  339.13776   639.83954   861.9455     76.43646   498.7988
  903.0157    621.28467   391.83618   608.72974     3.696991  494.52863
 1035.1204    414.59106   230.13965   953.34973   684.9517   1298.8436  ]",71.084564,8397.242,91.6364675634106
trial_3,polar_knn_minmax_act,"['Epoch: 0, Train Loss: 0.388371084417616, Val Loss: 0.407510822469538', 'Epoch: 1, Train Loss: 0.378919243812561, Val Loss: 0.402821171464342', 'Epoch: 2, Train Loss: 0.370544373989105, Val Loss: 0.405057113278996', 'Epoch: 3, Train Loss: 0.371940683041300, Val Loss: 0.407228415662592', 'Epoch: 4, Train Loss: 0.370881844844137, Val Loss: 0.403693952343681', 'Epoch: 5, Train Loss: 0.379120288150651, Val Loss: 0.399984539458246', 'Epoch: 6, Train Loss: 0.374777061598642, Val Loss: 0.387604922959299', 'Epoch: 7, Train Loss: 0.348181362662997, Val Loss: 0.342661334709688', 'Epoch: 8, Train Loss: 0.271996849349567, Val Loss: 0.192487959270224', 'Epoch: 9, Train Loss: 0.201769511614527, Val Loss: 0.149148171316042', 'Epoch: 10, Train Loss: 0.124670266040734, Val Loss: 0.108165328814225', 'Epoch: 11, Train Loss: 0.100082812032529, Val Loss: 0.079536903536681', 'Epoch: 12, Train Loss: 0.088660745748452, Val Loss: 0.122082048688423', 'Epoch: 13, Train Loss: 0.085913447397096, Val Loss: 0.103841469369151', 'Epoch: 14, Train Loss: 0.082595980593136, Val Loss: 0.090417207275150', 'Epoch: 15, Train Loss: 0.085051173876439, Val Loss: 0.086392288519578', 'Epoch: 16, Train Loss: 0.070147054269910, Val Loss: 0.084435070215753', 'Epoch: 17, Train Loss: 0.067460546802197, Val Loss: 0.059741846031763', 'Epoch: 18, Train Loss: 0.068619665290628, Val Loss: 0.063610063357787', 'Epoch: 19, Train Loss: 0.056227403027671, Val Loss: 0.062498861867370', 'Epoch: 20, Train Loss: 0.053671876633806, Val Loss: 0.094335709105838', 'Epoch: 21, Train Loss: 0.053720176752125, Val Loss: 0.070674781264229', 'Epoch: 22, Train Loss: 0.048509672018034, Val Loss: 0.056522555762168', 'Epoch: 23, Train Loss: 0.050697154099388, Val Loss: 0.057541239160028', 'Epoch: 24, Train Loss: 0.046931112185121, Val Loss: 0.076123945640795', 'Epoch: 25, Train Loss: 0.063876836826759, Val Loss: 0.058174961218328', 'Epoch: 26, Train Loss: 0.055835007024663, Val Loss: 0.068972374453689', 'Epoch: 27, Train Loss: 0.045212363225541, Val Loss: 0.061572868659189', 'Epoch: 28, Train Loss: 0.043068515802068, Val Loss: 0.054692871078397', 'Epoch: 29, Train Loss: 0.044193167904658, Val Loss: 0.052304360225345', 'Epoch: 30, Train Loss: 0.045147768620934, Val Loss: 0.059641906822270', 'Epoch: 31, Train Loss: 0.049504598203514, Val Loss: 0.065144724692359', 'Epoch: 32, Train Loss: 0.044838613431369, Val Loss: 0.048149919814684', 'Epoch: 33, Train Loss: 0.047616962609547, Val Loss: 0.058102139356461', 'Epoch: 34, Train Loss: 0.043624703905412, Val Loss: 0.063442473384467', 'Epoch: 35, Train Loss: 0.039555191727621, Val Loss: 0.050217905695635', 'Epoch: 36, Train Loss: 0.045008698744433, Val Loss: 0.059031405514388', 'Epoch: 37, Train Loss: 0.043372142527785, Val Loss: 0.051165782917065', 'Epoch: 38, Train Loss: 0.036748078784772, Val Loss: 0.053434726415258', 'Epoch: 39, Train Loss: 0.035307679724480, Val Loss: 0.053108367448052', 'Epoch: 40, Train Loss: 0.035345494348024, Val Loss: 0.052173210364400', 'Epoch: 41, Train Loss: 0.040108354496104, Val Loss: 0.053392188482438', 'Epoch: 42, Train Loss: 0.038459758806442, Val Loss: 0.049486071774454', 'Epoch: 43, Train Loss: 0.038861828190940, Val Loss: 0.078924685152191', 'Epoch: 44, Train Loss: 0.038843764125236, Val Loss: 0.062828334217722', 'Epoch: 45, Train Loss: 0.041115707850882, Val Loss: 0.054145256057382', 'Epoch: 46, Train Loss: 0.035840899018305, Val Loss: 0.061760855517632', 'Epoch: 47, Train Loss: 0.031566360566233, Val Loss: 0.055503162470731', 'Epoch: 48, Train Loss: 0.036839522554406, Val Loss: 0.055022861018325', 'Epoch: 49, Train Loss: 0.034178885365171, Val Loss: 0.059929492685831', 'Epoch: 50, Train Loss: 0.030477110429534, Val Loss: 0.052788717665173', 'Epoch: 51, Train Loss: 0.025088257289359, Val Loss: 0.053986348550428', 'Epoch: 52, Train Loss: 0.027589235853936, Val Loss: 0.057462156834927', 'Epoch: 53, Train Loss: 0.026278124057821, Val Loss: 0.054866610715787', 'Epoch: 54, Train Loss: 0.027702300144093, Val Loss: 0.053185872112711', 'Epoch: 55, Train Loss: 0.029238090983459, Val Loss: 0.050078331408176', 'Epoch: 56, Train Loss: 0.024843172635883, Val Loss: 0.054353718561205', 'Epoch: 57, Train Loss: 0.026110084926976, Val Loss: 0.053238919117686', 'Epoch: 58, Train Loss: 0.023276498541236, Val Loss: 0.062888733986201', 'Epoch: 59, Train Loss: 0.028471228467034, Val Loss: 0.058611107425708', 'Epoch: 60, Train Loss: 0.029253576749137, Val Loss: 0.051051040038918', 'Epoch: 61, Train Loss: 0.030416772567800, Val Loss: 0.045216586102139', 'Epoch: 62, Train Loss: 0.031176047333117, Val Loss: 0.062374478601145', 'Epoch: 63, Train Loss: 0.023512565264744, Val Loss: 0.057215568637758', 'Epoch: 64, Train Loss: 0.026579319100295, Val Loss: 0.046347950613408', 'Epoch: 65, Train Loss: 0.024570563342422, Val Loss: 0.058344273277643', 'Epoch: 66, Train Loss: 0.023454640991986, Val Loss: 0.058053458730380', 'Epoch: 67, Train Loss: 0.020680871792138, Val Loss: 0.049087183493556', 'Epoch: 68, Train Loss: 0.018534692935646, Val Loss: 0.050987854571731', 'Epoch: 69, Train Loss: 0.019879215929125, Val Loss: 0.056492676528058', 'Epoch: 70, Train Loss: 0.025605844333768, Val Loss: 0.049947749484669', 'Epoch: 71, Train Loss: 0.021909208369574, Val Loss: 0.051088543467675', 'Epoch: 72, Train Loss: 0.022211705733623, Val Loss: 0.048651009741606', 'Epoch: 73, Train Loss: 0.020552816468158, Val Loss: 0.046813030134548', 'Epoch: 74, Train Loss: 0.018871582312776, Val Loss: 0.051947482381806', 'Epoch: 75, Train Loss: 0.018053598369339, Val Loss: 0.051616299050775', 'Epoch: 76, Train Loss: 0.019556664462600, Val Loss: 0.050989658571780', 'Epoch: 77, Train Loss: 0.020892563542085, Val Loss: 0.053752214788939', 'Epoch: 78, Train Loss: 0.017738426037665, Val Loss: 0.051557627605331', 'Epoch: 79, Train Loss: 0.018910503081445, Val Loss: 0.055605289390466', 'Epoch: 80, Train Loss: 0.017796697760267, Val Loss: 0.053598940767574', 'Epoch: 81, Train Loss: 0.018731617501804, Val Loss: 0.052975437745000', 'Epoch: 82, Train Loss: 0.015844661143741, Val Loss: 0.053884290268108', 'Epoch: 83, Train Loss: 0.016760506866766, Val Loss: 0.046661515748411', 'Epoch: 84, Train Loss: 0.015993104781955, Val Loss: 0.061418323608285', 'Epoch: 85, Train Loss: 0.015734178679330, Val Loss: 0.055051044194084', 'Epoch: 86, Train Loss: 0.012999630333590, Val Loss: 0.051477813281853', 'Epoch: 87, Train Loss: 0.014177609634187, Val Loss: 0.056030188997587', 'Epoch: 88, Train Loss: 0.013758030587009, Val Loss: 0.052160174910431', 'Epoch: 89, Train Loss: 0.018023822323552, Val Loss: 0.052558592266657', 'Epoch: 90, Train Loss: 0.017551044401314, Val Loss: 0.051364921936483', 'Epoch: 91, Train Loss: 0.016395183213587, Val Loss: 0.051395137579124', 'Epoch: 92, Train Loss: 0.014786745155496, Val Loss: 0.050142263542071', 'Epoch: 93, Train Loss: 0.013937655470467, Val Loss: 0.064549506797145', 'Epoch: 94, Train Loss: 0.012761206366122, Val Loss: 0.049409339523691', 'Epoch: 95, Train Loss: 0.013179282491495, Val Loss: 0.055225066586652', 'Epoch: 96, Train Loss: 0.015149960427412, Val Loss: 0.051933693551374', 'Epoch: 97, Train Loss: 0.015031017296548, Val Loss: 0.052128789551330', 'Epoch: 98, Train Loss: 0.012986730052424, Val Loss: 0.054156385531480', 'Epoch: 99, Train Loss: 0.012735213086541, Val Loss: 0.056967780604309', 'Epoch: 100, Train Loss: 0.014636995137802, Val Loss: 0.050358040803324', 'Epoch: 101, Train Loss: 0.011551652269970, Val Loss: 0.055944944534338', 'Epoch: 102, Train Loss: 0.012774221333010, Val Loss: 0.057108261072162', 'Epoch: 103, Train Loss: 0.012834086415491, Val Loss: 0.054477323975527', 'Epoch: 104, Train Loss: 0.012071764229664, Val Loss: 0.052440833593154', 'Epoch: 105, Train Loss: 0.010919739592022, Val Loss: 0.044321109434928', 'Epoch: 106, Train Loss: 0.012780282679679, Val Loss: 0.053319259680751', 'Epoch: 107, Train Loss: 0.011401249761028, Val Loss: 0.052295838567344', 'Epoch: 108, Train Loss: 0.012217120001359, Val Loss: 0.054558798162775', 'Epoch: 109, Train Loss: 0.011277142280181, Val Loss: 0.053969089957801', 'Epoch: 110, Train Loss: 0.012692341481202, Val Loss: 0.056277878413146', 'Epoch: 111, Train Loss: 0.013589957862028, Val Loss: 0.051875524448626', 'Epoch: 112, Train Loss: 0.011358942138031, Val Loss: 0.052397541539518', 'Epoch: 113, Train Loss: 0.011591494515804, Val Loss: 0.052845069468304', 'Epoch: 114, Train Loss: 0.010724516585469, Val Loss: 0.049419477109261', 'Epoch: 115, Train Loss: 0.008920037021328, Val Loss: 0.051305837918666', 'Epoch: 116, Train Loss: 0.010085092691172, Val Loss: 0.053618067265206', 'Epoch: 117, Train Loss: 0.010243607751493, Val Loss: 0.052780472941584', 'Epoch: 118, Train Loss: 0.008986122374024, Val Loss: 0.052746358045349', 'Epoch: 119, Train Loss: 0.010248743729400, Val Loss: 0.055023988084444', 'Epoch: 120, Train Loss: 0.009442729010646, Val Loss: 0.054382928110885', 'Epoch: 121, Train Loss: 0.014519133904417, Val Loss: 0.053123026179630', 'Epoch: 122, Train Loss: 0.011331731320492, Val Loss: 0.057312766894359', 'Epoch: 123, Train Loss: 0.011063349017474, Val Loss: 0.049156229604374', 'Epoch: 124, Train Loss: 0.009844806377909, Val Loss: 0.052462927602006', 'Epoch: 125, Train Loss: 0.011038123896079, Val Loss: 0.054393467168803', 'Epoch: 126, Train Loss: 0.009001110580617, Val Loss: 0.053169971617701', 'Epoch: 127, Train Loss: 0.008922117562698, Val Loss: 0.051571244486805', 'Epoch: 128, Train Loss: 0.010823162239311, Val Loss: 0.054026690368174', 'Epoch: 129, Train Loss: 0.010166489386133, Val Loss: 0.055922609104803', 'Epoch: 130, Train Loss: 0.010145576737289, Val Loss: 0.053277335450702', 'Epoch: 131, Train Loss: 0.011032243126205, Val Loss: 0.058559593871575', 'Epoch: 132, Train Loss: 0.009872382539990, Val Loss: 0.053955123632808', 'Epoch: 133, Train Loss: 0.007771335276110, Val Loss: 0.052089041564614', 'Epoch: 134, Train Loss: 0.009148129943891, Val Loss: 0.051180183248961', 'Epoch: 135, Train Loss: 0.010320812796376, Val Loss: 0.054594497573844', 'Epoch: 136, Train Loss: 0.009647339782012, Val Loss: 0.054805121807890', 'Epoch: 137, Train Loss: 0.009061958840383, Val Loss: 0.055313280268544', 'Epoch: 138, Train Loss: 0.007892776879349, Val Loss: 0.055838032791419', 'Epoch: 139, Train Loss: 0.009915925861735, Val Loss: 0.053403747903014', 'Epoch: 140, Train Loss: 0.010434574480834, Val Loss: 0.055666910039938', 'Epoch: 141, Train Loss: 0.009797135135159, Val Loss: 0.052166622781167', 'Epoch: 142, Train Loss: 0.010374374853979, Val Loss: 0.059050535458620', 'Epoch: 143, Train Loss: 0.009247117509533, Val Loss: 0.054227857949269', 'Epoch: 144, Train Loss: 0.008713093785835, Val Loss: 0.057514544788071', 'Epoch: 145, Train Loss: 0.007702270389668, Val Loss: 0.051718394441361', 'Epoch: 146, Train Loss: 0.008083519243103, Val Loss: 0.054295238050999', 'Epoch: 147, Train Loss: 0.007836864695751, Val Loss: 0.059232944135808', 'Epoch: 148, Train Loss: 0.009797004118030, Val Loss: 0.056125019564096', 'Epoch: 149, Train Loss: 0.008561445533165, Val Loss: 0.055781610458243', 'Epoch: 150, Train Loss: 0.008943204668217, Val Loss: 0.052441015134029', 'Epoch: 151, Train Loss: 0.007517936606226, Val Loss: 0.050687159595051', 'Epoch: 152, Train Loss: 0.007081916289670, Val Loss: 0.054660206829960', 'Epoch: 153, Train Loss: 0.007555149562125, Val Loss: 0.052322741513225', 'Epoch: 154, Train Loss: 0.008692826809628, Val Loss: 0.054381064407415', 'Epoch: 155, Train Loss: 0.007318371790461, Val Loss: 0.055698340123689', 'Epoch: 156, Train Loss: 0.008110257065190, Val Loss: 0.050563474679648', 'Epoch: 157, Train Loss: 0.007932959141077, Val Loss: 0.052082582010013', 'Epoch: 158, Train Loss: 0.007555491856432, Val Loss: 0.053143848693281', 'Epoch: 159, Train Loss: 0.006633731802659, Val Loss: 0.053993580256109', 'Epoch: 160, Train Loss: 0.006265881970259, Val Loss: 0.053309572663045', 'Epoch: 161, Train Loss: 0.007988501506458, Val Loss: 0.051578452613092', 'Epoch: 162, Train Loss: 0.007719981218023, Val Loss: 0.054286329372024', 'Epoch: 163, Train Loss: 0.006676823266649, Val Loss: 0.057240549136292', 'Epoch: 164, Train Loss: 0.007614725036547, Val Loss: 0.052023820014614', 'Epoch: 165, Train Loss: 0.006719198842932, Val Loss: 0.054109409948896', 'Epoch: 166, Train Loss: 0.007022365861173, Val Loss: 0.054169488569834', 'Epoch: 167, Train Loss: 0.008480733825958, Val Loss: 0.053171926290926', 'Epoch: 168, Train Loss: 0.006902014620469, Val Loss: 0.052248070199946', 'Epoch: 169, Train Loss: 0.007782986420872, Val Loss: 0.055862999958635', 'Epoch: 170, Train Loss: 0.008232229089897, Val Loss: 0.052191458247376', 'Epoch: 171, Train Loss: 0.006778174861600, Val Loss: 0.054991407700899', 'Epoch: 172, Train Loss: 0.006971633593951, Val Loss: 0.056812171273949', 'Epoch: 173, Train Loss: 0.007158655872835, Val Loss: 0.053164453612584', 'Epoch: 174, Train Loss: 0.007068128225261, Val Loss: 0.053861496977113', 'Epoch: 175, Train Loss: 0.006819913762489, Val Loss: 0.053874666195814', 'Epoch: 176, Train Loss: 0.006246579711192, Val Loss: 0.053745951376517', 'Epoch: 177, Train Loss: 0.006491138217305, Val Loss: 0.057241139707692', 'Epoch: 178, Train Loss: 0.007334805908613, Val Loss: 0.052870002765716', 'Epoch: 179, Train Loss: 0.007383585441858, Val Loss: 0.055594684330351', 'Epoch: 180, Train Loss: 0.007058767701632, Val Loss: 0.053613607531809', 'Epoch: 181, Train Loss: 0.007485763535702, Val Loss: 0.055241024855411', 'Epoch: 182, Train Loss: 0.006535986405132, Val Loss: 0.054507023372659', 'Epoch: 183, Train Loss: 0.006923354031252, Val Loss: 0.053276910869913', 'Epoch: 184, Train Loss: 0.006710983380409, Val Loss: 0.053204499763634', 'Epoch: 185, Train Loss: 0.006342155825613, Val Loss: 0.052869164399012', 'Epoch: 186, Train Loss: 0.006042098593233, Val Loss: 0.053524421372761', 'Epoch: 187, Train Loss: 0.006332321558148, Val Loss: 0.054230957376686', 'Epoch: 188, Train Loss: 0.006348024787647, Val Loss: 0.053209248365778', 'Epoch: 189, Train Loss: 0.006080184464476, Val Loss: 0.054258622158545', 'Epoch: 190, Train Loss: 0.006568829545618, Val Loss: 0.053993361691634', 'Epoch: 191, Train Loss: 0.006146505341998, Val Loss: 0.054142551524847', 'Epoch: 192, Train Loss: 0.006357819856411, Val Loss: 0.054311232387342', 'Epoch: 193, Train Loss: 0.006043988080429, Val Loss: 0.052919781569279', 'Epoch: 194, Train Loss: 0.005902171417672, Val Loss: 0.052586527767055', 'Epoch: 195, Train Loss: 0.006248717429116, Val Loss: 0.053153025437937', 'Epoch: 196, Train Loss: 0.005441466861937, Val Loss: 0.054053035508277', 'Epoch: 197, Train Loss: 0.005812981531822, Val Loss: 0.054302104078515', 'Epoch: 198, Train Loss: 0.005608807933251, Val Loss: 0.054208624628231', 'Epoch: 199, Train Loss: 0.006627203896642, Val Loss: 0.054112988883968']","[ 134.52554   797.6494    691.2141    439.6826     79.64363   615.89215
  490.2004     95.74954   628.44556   214.72958    43.14807   271.00787
  584.4683    423.94983   253.36862   461.46448   477.43213   116.37985
  687.8954    587.7664   1041.1692    291.88788   952.84454   109.81055
  842.1108    181.13446   694.1144    419.9962    806.48376  1192.2505
  292.5141   1150.3883    169.21231   268.91907  1429.8969    547.19257
 1175.6475    121.2063    563.5581    641.4297   1132.605     649.5345
  410.69217   632.6117    394.43427   609.6168    909.3096    671.03394
 1185.6675   1094.6262   1137.2391    888.42957  1177.7285    855.7604
  104.14691   608.6197    526.00854   405.86972   404.01263    47.2493
   20.507141  685.9015    753.615     318.85965   543.912      84.83186
  122.99805    85.57712   261.02615   283.8731    401.69052   477.40497
  721.78955   895.2418    329.59433   638.37024   279.57117   675.881
  477.07156   572.8349    691.6881    864.5598    284.28488   907.08356
  312.65588    75.50653   620.43097   823.2302    192.59299   274.24643
  267.63318   818.9285     41.233185  206.63477   332.17014   231.96283
  644.0965    604.7989    737.4956    127.90927   694.00336   165.98267
  426.52148   186.2782    806.92255   904.63446   349.7179    449.12518
  243.94936   593.6415    640.0748    102.15756   632.99805   187.88531
  146.80591   137.8653    383.73654  1327.7366     13.723694  780.819
   95.59955   489.06366   935.7298    265.4128    548.6123    562.0951
  350.84784    12.088623  417.87872   303.49234   730.1066    402.3608
  620.43274   166.78876   823.0254    925.10425  1219.9059    730.69086 ]","[  33.460724  818.69507   678.17236   548.85394    83.32703   495.20767
  543.25165   143.56265   652.8731    224.53558    20.029297  235.9228
  589.2654    313.76285    97.48932   369.809     531.7495    138.68112
  557.5215    515.9592   1094.935     351.10095   916.8115     99.13129
  819.1813     73.38153   648.36865   471.11017   872.8693   1183.061
  209.91766  1235.036      34.170746  295.63077  1346.3966    523.8811
 1329.1069    138.84601   570.73083   607.0894   1120.6318    726.8352
  315.68127   704.5763    403.3246    601.7927    899.18384   705.4961
 1304.822    1151.2659   1167.0101    981.02106  1286.1816    824.09894
  108.28729   586.74506   400.4217    381.35242   410.13153    89.242615
   98.809265  648.0305    643.82776   279.43777   432.35513   186.97343
  125.24988    57.519775  200.54137   290.7999    378.6871    408.7323
  722.86896   901.65247   262.85092   504.48553   273.99768   618.2866
  460.15643   670.4172    620.7252    957.2529    264.06552   891.54016
  301.52765    40.810547  643.81635   827.73413   159.9611    238.33443
  314.6303    730.48834    87.38223   122.35779   302.73654   173.84222
  695.7175    634.2953    686.25       84.67755   606.557     145.48187
  470.4469    124.942505  865.7077   1087.1887    355.04535   489.3462
  223.71095   611.93604   576.84094    25.098999  557.6233     65.99927
  124.868835  179.93611   495.9755   1314.689      52.381256  837.9231
  258.02478   515.71686  1013.57214   162.46509   302.78003   462.30548
  370.97623    24.20346   441.13318   294.1828    633.3436    394.04202
  608.4813     94.03998   950.571    1012.20667  1210.3918    831.23804 ]",55.620094,5050.356,71.0658564785597
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 0.395702051264899, Val Loss: 0.395932170703556', 'Epoch: 1, Train Loss: 0.381920037525041, Val Loss: 0.397102763029662', 'Epoch: 2, Train Loss: 0.377760604023933, Val Loss: 0.397178394324852', 'Epoch: 3, Train Loss: 0.380837136081287, Val Loss: 0.384779748139959', 'Epoch: 4, Train Loss: 0.359900119049208, Val Loss: 0.361487915344311', 'Epoch: 5, Train Loss: 0.301993218915803, Val Loss: 0.330997370853738', 'Epoch: 6, Train Loss: 0.258849646363940, Val Loss: 0.257566307417371', 'Epoch: 7, Train Loss: 0.207218958863190, Val Loss: 0.261093154535488', 'Epoch: 8, Train Loss: 0.173850050994328, Val Loss: 0.206547808184317', 'Epoch: 9, Train Loss: 0.145449504256248, Val Loss: 0.163875606193235', 'Epoch: 10, Train Loss: 0.118389000850064, Val Loss: 0.126832953682452', 'Epoch: 11, Train Loss: 0.114459824881383, Val Loss: 0.119294534804243', 'Epoch: 12, Train Loss: 0.093736981706960, Val Loss: 0.098373648766993', 'Epoch: 13, Train Loss: 0.093296831207616, Val Loss: 0.096233504118793', 'Epoch: 14, Train Loss: 0.082849245518446, Val Loss: 0.090604092897565', 'Epoch: 15, Train Loss: 0.079049460589886, Val Loss: 0.100602739264793', 'Epoch: 16, Train Loss: 0.079682586714625, Val Loss: 0.080311020709236', 'Epoch: 17, Train Loss: 0.078434293823583, Val Loss: 0.086403438158220', 'Epoch: 18, Train Loss: 0.071023345259683, Val Loss: 0.094985230487179', 'Epoch: 19, Train Loss: 0.071411545255354, Val Loss: 0.095140282713780', 'Epoch: 20, Train Loss: 0.065872126924140, Val Loss: 0.071148208511824', 'Epoch: 21, Train Loss: 0.060945581112589, Val Loss: 0.073434111986761', 'Epoch: 22, Train Loss: 0.070975882666452, Val Loss: 0.077682324205384', 'Epoch: 23, Train Loss: 0.064473786258272, Val Loss: 0.103524612319289', 'Epoch: 24, Train Loss: 0.070880593731999, Val Loss: 0.084820521261656', 'Epoch: 25, Train Loss: 0.065687578437584, Val Loss: 0.061313982516753', 'Epoch: 26, Train Loss: 0.053110920691064, Val Loss: 0.068396699572490', 'Epoch: 27, Train Loss: 0.054488381370902, Val Loss: 0.064952535103216', 'Epoch: 28, Train Loss: 0.060324084279793, Val Loss: 0.065612895922227', 'Epoch: 29, Train Loss: 0.049838351351874, Val Loss: 0.079855656900415', 'Epoch: 30, Train Loss: 0.050855733454227, Val Loss: 0.080395368464065', 'Epoch: 31, Train Loss: 0.065656900139792, Val Loss: 0.061443987189595', 'Epoch: 32, Train Loss: 0.050762419455818, Val Loss: 0.055276271633127', 'Epoch: 33, Train Loss: 0.054290169317807, Val Loss: 0.062850293336493', 'Epoch: 34, Train Loss: 0.044826357891517, Val Loss: 0.075470229512024', 'Epoch: 35, Train Loss: 0.046471689162510, Val Loss: 0.077770773420167', 'Epoch: 36, Train Loss: 0.048044648819736, Val Loss: 0.056963848472206', 'Epoch: 37, Train Loss: 0.049171221708613, Val Loss: 0.064807652806242', 'Epoch: 38, Train Loss: 0.042772344446608, Val Loss: 0.063759161102952', 'Epoch: 39, Train Loss: 0.062094641716353, Val Loss: 0.050173464372303', 'Epoch: 40, Train Loss: 0.054975871528898, Val Loss: 0.055012587980000', 'Epoch: 41, Train Loss: 0.046280547311263, Val Loss: 0.056736199015921', 'Epoch: 42, Train Loss: 0.046494666486979, Val Loss: 0.068717205784086', 'Epoch: 43, Train Loss: 0.042771887300270, Val Loss: 0.069974565539848', 'Epoch: 44, Train Loss: 0.048881822398731, Val Loss: 0.047409814683664', 'Epoch: 45, Train Loss: 0.049754135842834, Val Loss: 0.095494446316452', 'Epoch: 46, Train Loss: 0.046219877765647, Val Loss: 0.058048215440728', 'Epoch: 47, Train Loss: 0.041494524904660, Val Loss: 0.062714154408737', 'Epoch: 48, Train Loss: 0.036659509741834, Val Loss: 0.057361900573596', 'Epoch: 49, Train Loss: 0.039663082254784, Val Loss: 0.064746790593772', 'Epoch: 50, Train Loss: 0.039619561816965, Val Loss: 0.062523967276017', 'Epoch: 51, Train Loss: 0.039562432095408, Val Loss: 0.057991270342785', 'Epoch: 52, Train Loss: 0.047456206620804, Val Loss: 0.057941633022644', 'Epoch: 53, Train Loss: 0.039035344363323, Val Loss: 0.073908039114692', 'Epoch: 54, Train Loss: 0.040199598297477, Val Loss: 0.057602124316900', 'Epoch: 55, Train Loss: 0.034237319071378, Val Loss: 0.059794640676542', 'Epoch: 56, Train Loss: 0.038033222779632, Val Loss: 0.071808621851784', 'Epoch: 57, Train Loss: 0.040056331482317, Val Loss: 0.060928144238212', 'Epoch: 58, Train Loss: 0.037830109708011, Val Loss: 0.058062031865120', 'Epoch: 59, Train Loss: 0.032417841654803, Val Loss: 0.073383324426796', 'Epoch: 60, Train Loss: 0.034710151409464, Val Loss: 0.060670433961081', 'Epoch: 61, Train Loss: 0.039163847719984, Val Loss: 0.065201221993475', 'Epoch: 62, Train Loss: 0.030381115419524, Val Loss: 0.053223329709109', 'Epoch: 63, Train Loss: 0.037233544447060, Val Loss: 0.069312028974916', 'Epoch: 64, Train Loss: 0.036191384707178, Val Loss: 0.062897445238901', 'Epoch: 65, Train Loss: 0.043593848789377, Val Loss: 0.070289995747082', 'Epoch: 66, Train Loss: 0.036456541823489, Val Loss: 0.059495906881762', 'Epoch: 67, Train Loss: 0.033367261822735, Val Loss: 0.060363119326983', 'Epoch: 68, Train Loss: 0.036874914142702, Val Loss: 0.060913137103798', 'Epoch: 69, Train Loss: 0.030087708229465, Val Loss: 0.049433379201218', 'Epoch: 70, Train Loss: 0.029891129317028, Val Loss: 0.064253762364388', 'Epoch: 71, Train Loss: 0.031354916947229, Val Loss: 0.056896899177721', 'Epoch: 72, Train Loss: 0.030791853820639, Val Loss: 0.060840825888921', 'Epoch: 73, Train Loss: 0.027495230281992, Val Loss: 0.054851725415298', 'Epoch: 74, Train Loss: 0.025893123155194, Val Loss: 0.064636245200580', 'Epoch: 75, Train Loss: 0.030417134187051, Val Loss: 0.061151314315132', 'Epoch: 76, Train Loss: 0.028165742754936, Val Loss: 0.058730232839783', 'Epoch: 77, Train Loss: 0.028326888568699, Val Loss: 0.061402883719314', 'Epoch: 78, Train Loss: 0.035289598894971, Val Loss: 0.064616691288944', 'Epoch: 79, Train Loss: 0.036234594482396, Val Loss: 0.051394690336152', 'Epoch: 80, Train Loss: 0.030009198401655, Val Loss: 0.058882036105250', 'Epoch: 81, Train Loss: 0.028400608537985, Val Loss: 0.061509439665260', 'Epoch: 82, Train Loss: 0.027827818079719, Val Loss: 0.052221092296708', 'Epoch: 83, Train Loss: 0.027220453800900, Val Loss: 0.054059509837040', 'Epoch: 84, Train Loss: 0.028970045303660, Val Loss: 0.056909411468289', 'Epoch: 85, Train Loss: 0.027190565530743, Val Loss: 0.063171960300568', 'Epoch: 86, Train Loss: 0.031457605106490, Val Loss: 0.065006629267538', 'Epoch: 87, Train Loss: 0.028571469110570, Val Loss: 0.062075933004080', 'Epoch: 88, Train Loss: 0.031041079999081, Val Loss: 0.057026276308479', 'Epoch: 89, Train Loss: 0.027073303370603, Val Loss: 0.069702844841011', 'Epoch: 90, Train Loss: 0.034077474581344, Val Loss: 0.076414561181357', 'Epoch: 91, Train Loss: 0.033215332044555, Val Loss: 0.060783500726702', 'Epoch: 92, Train Loss: 0.033095485796886, Val Loss: 0.073237329044125', 'Epoch: 93, Train Loss: 0.028692406003496, Val Loss: 0.062422839924693', 'Epoch: 94, Train Loss: 0.026982644040670, Val Loss: 0.060596608472141', 'Epoch: 95, Train Loss: 0.027986973524094, Val Loss: 0.073829853258124', 'Epoch: 96, Train Loss: 0.027394459582865, Val Loss: 0.058481103077418', 'Epoch: 97, Train Loss: 0.026863340487970, Val Loss: 0.056654582082322', 'Epoch: 98, Train Loss: 0.024115000718406, Val Loss: 0.057092205593080', 'Epoch: 99, Train Loss: 0.023164018789040, Val Loss: 0.057912818297292', 'Epoch: 100, Train Loss: 0.026369225765978, Val Loss: 0.054814109409397', 'Epoch: 101, Train Loss: 0.028534341470471, Val Loss: 0.053767661394721', 'Epoch: 102, Train Loss: 0.026095558955733, Val Loss: 0.059275700964711', 'Epoch: 103, Train Loss: 0.025920592381486, Val Loss: 0.067356436033592', 'Epoch: 104, Train Loss: 0.034786560439638, Val Loss: 0.065924661107023', 'Epoch: 105, Train Loss: 0.029684236273170, Val Loss: 0.059081798010139', 'Epoch: 106, Train Loss: 0.026356293287660, Val Loss: 0.055662880051938', 'Epoch: 107, Train Loss: 0.024286289898945, Val Loss: 0.063254885036837', 'Epoch: 108, Train Loss: 0.027468895007457, Val Loss: 0.069987285204909', 'Epoch: 109, Train Loss: 0.029361065610179, Val Loss: 0.070932068833799', 'Epoch: 110, Train Loss: 0.027470272034407, Val Loss: 0.055238030893220', 'Epoch: 111, Train Loss: 0.022173518980188, Val Loss: 0.049614680197203', 'Epoch: 112, Train Loss: 0.026166428346187, Val Loss: 0.061512319879098', 'Epoch: 113, Train Loss: 0.029240110090801, Val Loss: 0.058396975312269', 'Epoch: 114, Train Loss: 0.026759479194880, Val Loss: 0.057387778761260', 'Epoch: 115, Train Loss: 0.026102648914925, Val Loss: 0.054112400520932', 'Epoch: 116, Train Loss: 0.026452229757394, Val Loss: 0.067427060101181', 'Epoch: 117, Train Loss: 0.029107671962785, Val Loss: 0.054204762433514', 'Epoch: 118, Train Loss: 0.023555836773344, Val Loss: 0.053916089293180', 'Epoch: 119, Train Loss: 0.026534669899515, Val Loss: 0.062768120777257', 'Epoch: 120, Train Loss: 0.022060182411224, Val Loss: 0.061178539964286', 'Epoch: 121, Train Loss: 0.020927662362478, Val Loss: 0.053693008242231', 'Epoch: 122, Train Loss: 0.023833396778043, Val Loss: 0.059681461108002', 'Epoch: 123, Train Loss: 0.021773836176310, Val Loss: 0.057605256524050', 'Epoch: 124, Train Loss: 0.024351188314280, Val Loss: 0.056352253777511', 'Epoch: 125, Train Loss: 0.022289919866515, Val Loss: 0.067092200458953', 'Epoch: 126, Train Loss: 0.027920941622662, Val Loss: 0.068842368553195', 'Epoch: 127, Train Loss: 0.026856023884778, Val Loss: 0.055867252137625', 'Epoch: 128, Train Loss: 0.024774839303323, Val Loss: 0.052775877556114', 'Epoch: 129, Train Loss: 0.023674929248435, Val Loss: 0.056025746871125', 'Epoch: 130, Train Loss: 0.020554397720844, Val Loss: 0.062472338647102', 'Epoch: 131, Train Loss: 0.024312674134438, Val Loss: 0.055991049743060', 'Epoch: 132, Train Loss: 0.025744998029300, Val Loss: 0.066766353916715', 'Epoch: 133, Train Loss: 0.023657241037914, Val Loss: 0.055173824964599', 'Epoch: 134, Train Loss: 0.024483560584486, Val Loss: 0.056329239188044', 'Epoch: 135, Train Loss: 0.023747217242739, Val Loss: 0.053301558124297', 'Epoch: 136, Train Loss: 0.023737630341202, Val Loss: 0.057160580474319', 'Epoch: 137, Train Loss: 0.020159561320075, Val Loss: 0.063503447524977', 'Epoch: 138, Train Loss: 0.021935188078455, Val Loss: 0.058843045410785', 'Epoch: 139, Train Loss: 0.022662111158882, Val Loss: 0.062002634347388', 'Epoch: 140, Train Loss: 0.019095717131027, Val Loss: 0.063669813514659', 'Epoch: 141, Train Loss: 0.024584685053144, Val Loss: 0.062141697628028', 'Epoch: 142, Train Loss: 0.020983830759568, Val Loss: 0.057090009873112', 'Epoch: 143, Train Loss: 0.024402095803193, Val Loss: 0.057947813617912', 'Epoch: 144, Train Loss: 0.022903815710119, Val Loss: 0.054316559242028', 'Epoch: 145, Train Loss: 0.022281037244414, Val Loss: 0.060076745396311', 'Epoch: 146, Train Loss: 0.018016453167158, Val Loss: 0.060464564936631', 'Epoch: 147, Train Loss: 0.021987686865032, Val Loss: 0.053737990671035', 'Epoch: 148, Train Loss: 0.021498598890113, Val Loss: 0.055480634398533', 'Epoch: 149, Train Loss: 0.026154153048992, Val Loss: 0.068252789703282', 'Epoch: 150, Train Loss: 0.024111685609179, Val Loss: 0.060888176163038', 'Epoch: 151, Train Loss: 0.021499162805932, Val Loss: 0.050001969899644', 'Epoch: 152, Train Loss: 0.021262641131346, Val Loss: 0.049495367897731', 'Epoch: 153, Train Loss: 0.022783655540219, Val Loss: 0.059215675926570', 'Epoch: 154, Train Loss: 0.022243101748505, Val Loss: 0.051158139990135', 'Epoch: 155, Train Loss: 0.024998155954693, Val Loss: 0.055624008686705', 'Epoch: 156, Train Loss: 0.023888113974993, Val Loss: 0.055571905929934', 'Epoch: 157, Train Loss: 0.021161521585392, Val Loss: 0.051872125572779', 'Epoch: 158, Train Loss: 0.023864174328212, Val Loss: 0.060407307450518', 'Epoch: 159, Train Loss: 0.019031965705965, Val Loss: 0.054692121448390', 'Epoch: 160, Train Loss: 0.022636742331088, Val Loss: 0.058239854194901', 'Epoch: 161, Train Loss: 0.022180893657995, Val Loss: 0.054206300978408', 'Epoch: 162, Train Loss: 0.023642870996680, Val Loss: 0.054673995399340', 'Epoch: 163, Train Loss: 0.023098763211497, Val Loss: 0.054498520820881', 'Epoch: 164, Train Loss: 0.019372014727976, Val Loss: 0.052473381951903', 'Epoch: 165, Train Loss: 0.017830980841869, Val Loss: 0.053080722238078', 'Epoch: 166, Train Loss: 0.021295335609466, Val Loss: 0.057573431707693', 'Epoch: 167, Train Loss: 0.019028553805713, Val Loss: 0.055287453261289', 'Epoch: 168, Train Loss: 0.022185750505222, Val Loss: 0.057558926669034', 'Epoch: 169, Train Loss: 0.021906242572836, Val Loss: 0.056827812370929', 'Epoch: 170, Train Loss: 0.019154717347452, Val Loss: 0.055877700560924', 'Epoch: 171, Train Loss: 0.019773816157665, Val Loss: 0.053418730978261', 'Epoch: 172, Train Loss: 0.023652312212757, Val Loss: 0.054291629260688', 'Epoch: 173, Train Loss: 0.020760556416852, Val Loss: 0.053174497785442', 'Epoch: 174, Train Loss: 0.020399062495146, Val Loss: 0.051742194897749', 'Epoch: 175, Train Loss: 0.018205076323024, Val Loss: 0.052899897662979', 'Epoch: 176, Train Loss: 0.018091412261128, Val Loss: 0.056010257226951', 'Epoch: 177, Train Loss: 0.018365426521216, Val Loss: 0.055292675948956', 'Epoch: 178, Train Loss: 0.019031858138208, Val Loss: 0.053239757985328', 'Epoch: 179, Train Loss: 0.019756914382534, Val Loss: 0.051684296040824', 'Epoch: 180, Train Loss: 0.021835469374699, Val Loss: 0.053119676131191', 'Epoch: 181, Train Loss: 0.017736675616886, Val Loss: 0.052365584270746', 'Epoch: 182, Train Loss: 0.019926000519523, Val Loss: 0.054329072266366', 'Epoch: 183, Train Loss: 0.020530648329960, Val Loss: 0.054023418406194', 'Epoch: 184, Train Loss: 0.019200676519956, Val Loss: 0.053726753163518', 'Epoch: 185, Train Loss: 0.019159283488989, Val Loss: 0.052848810273590', 'Epoch: 186, Train Loss: 0.019934995399256, Val Loss: 0.053845553461349', 'Epoch: 187, Train Loss: 0.020175670074033, Val Loss: 0.052849415689707', 'Epoch: 188, Train Loss: 0.023265017130013, Val Loss: 0.052301163079612', 'Epoch: 189, Train Loss: 0.019043009462101, Val Loss: 0.050860357442589', 'Epoch: 190, Train Loss: 0.019515022103276, Val Loss: 0.054173758309899', 'Epoch: 191, Train Loss: 0.019336863221335, Val Loss: 0.054478029635820', 'Epoch: 192, Train Loss: 0.018949105869979, Val Loss: 0.053056786006147', 'Epoch: 193, Train Loss: 0.017155138310045, Val Loss: 0.052872716590311', 'Epoch: 194, Train Loss: 0.017404498066753, Val Loss: 0.053512869402766', 'Epoch: 195, Train Loss: 0.018345922032105, Val Loss: 0.053366048656630', 'Epoch: 196, Train Loss: 0.019122020740594, Val Loss: 0.051877831757972', 'Epoch: 197, Train Loss: 0.020458066835999, Val Loss: 0.051765905467398', 'Epoch: 198, Train Loss: 0.020878665082689, Val Loss: 0.052106101291649', 'Epoch: 199, Train Loss: 0.016241873681013, Val Loss: 0.052193929243720']","[ 471.1403     153.8793     290.7542     598.37305    325.16803
  740.4659     400.95618   1032.688      483.66537    626.5006
  337.39804     63.19983      5.4628296  531.7776     572.98
  562.8819     383.73654   1327.7366     418.3215     418.18646
 1111.6362    1044.3005     410.69217    632.6117     770.8096
  243.9403       2.0499268  617.8216     138.60297     10.239746
  259.98862    840.6533     672.4115     828.5887     491.27667
  849.557       13.723694   780.819      260.51508   1192.4822
  241.62308    334.45892     54.5943     694.4518    1219.9059
  730.69086    384.54898     48.199646   568.3642     649.0148
  279.37943     20.586472   401.69052    477.40497    838.6971
  471.95917    125.53729    384.86105    922.0249     541.7541
  564.26196     80.541504   307.5845     738.6224     417.87872
  303.49234   1132.605      649.5345     997.83997   1077.1912
  326.62158    315.92706    721.78955    895.2418     202.45238
  351.98355    608.1203     670.70856   1119.0164     517.8821
  265.24066     53.80777    915.9963    1082.7795     600.7388
  284.34714    122.99805     85.57712    284.28488    907.08356
    6.329773   485.5377      25.92746    624.78357     49.893707
 1062.8188     797.8456     404.75803    512.49774    457.61334
  277.92847    321.62332    192.59299    274.24643    893.3407
  649.3793     319.4779     479.95258    773.51013    982.65375
  559.5322     229.95102   1298.9675     991.0653     867.60095
  439.27567     41.41095    455.4604     296.6674     116.64441
  580.84143    540.8015    1137.2391     888.42957    232.84521
  578.2854    1317.5714     792.812      307.88156    220.76721
  290.97983    540.59924    909.3096     671.03394    644.0965
  604.7989     869.3708     904.1972   ]","[ 452.07758   156.02014   368.3086    495.3702    399.80438   706.6256
  446.47687   997.24963   490.7209    538.1644    290.70837   146.02957
   87.47586   483.579     465.17404   586.7193    384.84732  1413.6091
  464.67685   495.6739   1011.11774  1021.61163   397.6902    580.95996
  765.8572    198.74997    55.34561   416.57104    43.330658   61.332794
  164.35287   923.26807   619.04016   842.71045   409.4952    724.1522
   15.93869   887.73975   275.2364   1259.9141    186.22375   359.41562
  170.2286    654.8419   1121.1129    748.26624   345.79263   153.43692
  412.54428   691.90967   257.81256    77.00542   354.871     438.56183
  857.61163   477.749      67.54953   463.87582   935.4504    784.38696
  593.2423    195.22754   343.18195   784.19543   449.74725   268.29608
 1095.8516    682.3263   1055.3759   1036.5251    342.7689    301.5685
  714.35846   833.63806   183.12216   458.99344   580.01904   580.6237
 1202.6984    473.6705    259.5246    146.5588    942.3982   1061.4965
  549.90674   308.75522   236.3989    218.44519   212.78537   823.1325
  235.86102   364.23312   129.12656   559.4304    269.85632   897.5372
  690.66675   354.4466    677.4866    562.5381    208.5928    206.32501
  194.72995   293.14417   679.29407   623.9302    285.4979    487.1009
  676.6721    953.42474   508.0392    259.86417  1217.223    1023.30646
  829.2634    421.61108    53.10742   409.59906   278.73236   175.92578
  363.61005   307.11014  1162.7286    933.62964   233.31061   466.8776
  973.6728    786.8161    406.88943   157.9679    292.55206   641.39954
  987.6867    653.7389    586.54877   610.1163    958.6321   1052.92    ]",66.50275,7782.9746,88.2211687146288
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 0.383969332490649, Val Loss: 0.395140994227294', 'Epoch: 1, Train Loss: 0.383792008672442, Val Loss: 0.398524119998469', 'Epoch: 2, Train Loss: 0.386100822261402, Val Loss: 0.391994035379453', 'Epoch: 3, Train Loss: 0.389301734311240, Val Loss: 0.380454722001697', 'Epoch: 4, Train Loss: 0.364151926977294, Val Loss: 0.352256152440201', 'Epoch: 5, Train Loss: 0.306987395243985, Val Loss: 0.258402468128638', 'Epoch: 6, Train Loss: 0.219935201108456, Val Loss: 0.167679279816873', 'Epoch: 7, Train Loss: 0.145674918113010, Val Loss: 0.118299447225802', 'Epoch: 8, Train Loss: 0.114326902266060, Val Loss: 0.130965087083027', 'Epoch: 9, Train Loss: 0.115059297531843, Val Loss: 0.128009639962605', 'Epoch: 10, Train Loss: 0.103090303816966, Val Loss: 0.111288191553092', 'Epoch: 11, Train Loss: 0.089154673208083, Val Loss: 0.083830973302776', 'Epoch: 12, Train Loss: 0.075901557558349, Val Loss: 0.091111383570189', 'Epoch: 13, Train Loss: 0.070197641317333, Val Loss: 0.078711062782642', 'Epoch: 14, Train Loss: 0.063712849414774, Val Loss: 0.086314485154369', 'Epoch: 15, Train Loss: 0.066351249281849, Val Loss: 0.062799507423981', 'Epoch: 16, Train Loss: 0.073111116353955, Val Loss: 0.061231568483918', 'Epoch: 17, Train Loss: 0.065775795706681, Val Loss: 0.062411459614382', 'Epoch: 18, Train Loss: 0.072638460035835, Val Loss: 0.094704702979829', 'Epoch: 19, Train Loss: 0.065403072163463, Val Loss: 0.095034618212870', 'Epoch: 20, Train Loss: 0.061764694750309, Val Loss: 0.076050821522420', 'Epoch: 21, Train Loss: 0.058286336383649, Val Loss: 0.067589022614288', 'Epoch: 22, Train Loss: 0.054250216377633, Val Loss: 0.075649130299236', 'Epoch: 23, Train Loss: 0.061015145454024, Val Loss: 0.084547972137278', 'Epoch: 24, Train Loss: 0.049895796392645, Val Loss: 0.065119388682598', 'Epoch: 25, Train Loss: 0.041743983381561, Val Loss: 0.049819049256092', 'Epoch: 26, Train Loss: 0.056748831112470, Val Loss: 0.054303781806745', 'Epoch: 27, Train Loss: 0.050776316651276, Val Loss: 0.057528673642964', 'Epoch: 28, Train Loss: 0.045313139978264, Val Loss: 0.060807867808211', 'Epoch: 29, Train Loss: 0.038852619273322, Val Loss: 0.059957336747285', 'Epoch: 30, Train Loss: 0.042411993922932, Val Loss: 0.063730796516845', 'Epoch: 31, Train Loss: 0.057742476995502, Val Loss: 0.061321227952386', 'Epoch: 32, Train Loss: 0.052259961143136, Val Loss: 0.064050675228690', 'Epoch: 33, Train Loss: 0.053993061450975, Val Loss: 0.045666003684429', 'Epoch: 34, Train Loss: 0.050830115697214, Val Loss: 0.058458536820994', 'Epoch: 35, Train Loss: 0.040928905430649, Val Loss: 0.057905259104728', 'Epoch: 36, Train Loss: 0.057000957695501, Val Loss: 0.048844599419019', 'Epoch: 37, Train Loss: 0.053002765136106, Val Loss: 0.056122413229649', 'Epoch: 38, Train Loss: 0.051697516281690, Val Loss: 0.064327044694713', 'Epoch: 39, Train Loss: 0.045250536607844, Val Loss: 0.081932835506670', 'Epoch: 40, Train Loss: 0.068226864029254, Val Loss: 0.050866501857385', 'Epoch: 41, Train Loss: 0.050651926813381, Val Loss: 0.035623516788650', 'Epoch: 42, Train Loss: 0.041312894650868, Val Loss: 0.041536949257451', 'Epoch: 43, Train Loss: 0.042801294741886, Val Loss: 0.071101788123611', 'Epoch: 44, Train Loss: 0.049464823412044, Val Loss: 0.073653551749885', 'Epoch: 45, Train Loss: 0.050147858049188, Val Loss: 0.078260682974801', 'Epoch: 46, Train Loss: 0.055274220981768, Val Loss: 0.073327582756368', 'Epoch: 47, Train Loss: 0.042706853976207, Val Loss: 0.057551674377244', 'Epoch: 48, Train Loss: 0.039132664778403, Val Loss: 0.059974054227386', 'Epoch: 49, Train Loss: 0.035762971666242, Val Loss: 0.055961169358907', 'Epoch: 50, Train Loss: 0.040969979683203, Val Loss: 0.046205010325083', 'Epoch: 51, Train Loss: 0.039661085765277, Val Loss: 0.046557867010547', 'Epoch: 52, Train Loss: 0.035536742236997, Val Loss: 0.058764341633033', 'Epoch: 53, Train Loss: 0.033662563722048, Val Loss: 0.048338751167510', 'Epoch: 54, Train Loss: 0.038427973831339, Val Loss: 0.074004447482752', 'Epoch: 55, Train Loss: 0.044730200432241, Val Loss: 0.064470272285469', 'Epoch: 56, Train Loss: 0.041207913774997, Val Loss: 0.057602342726155', 'Epoch: 57, Train Loss: 0.036583744787744, Val Loss: 0.058839885334513', 'Epoch: 58, Train Loss: 0.035249582092677, Val Loss: 0.065472137521614', 'Epoch: 59, Train Loss: 0.033495359388845, Val Loss: 0.057124188325057', 'Epoch: 60, Train Loss: 0.028399701163705, Val Loss: 0.052453814310755', 'Epoch: 61, Train Loss: 0.035061143072588, Val Loss: 0.068629524942177', 'Epoch: 62, Train Loss: 0.044372911298914, Val Loss: 0.058355094441636', 'Epoch: 63, Train Loss: 0.039849560574761, Val Loss: 0.058000794657732', 'Epoch: 64, Train Loss: 0.038951060601643, Val Loss: 0.064479987362795', 'Epoch: 65, Train Loss: 0.037470013834536, Val Loss: 0.059361514127390', 'Epoch: 66, Train Loss: 0.044691591656634, Val Loss: 0.064990249942198', 'Epoch: 67, Train Loss: 0.045908109151891, Val Loss: 0.062226340516865', 'Epoch: 68, Train Loss: 0.036461049291704, Val Loss: 0.054258107219181', 'Epoch: 69, Train Loss: 0.033308280764946, Val Loss: 0.055621715636472', 'Epoch: 70, Train Loss: 0.038254912543510, Val Loss: 0.048942119123019', 'Epoch: 71, Train Loss: 0.029235084807234, Val Loss: 0.057102016822407', 'Epoch: 72, Train Loss: 0.031649732696159, Val Loss: 0.052871064247676', 'Epoch: 73, Train Loss: 0.032499029035015, Val Loss: 0.050326822075118', 'Epoch: 74, Train Loss: 0.026909277641347, Val Loss: 0.051776111182390', 'Epoch: 75, Train Loss: 0.038296691008977, Val Loss: 0.061928576253580', 'Epoch: 76, Train Loss: 0.033400063402951, Val Loss: 0.051421502520415', 'Epoch: 77, Train Loss: 0.030896634794772, Val Loss: 0.050426005272929', 'Epoch: 78, Train Loss: 0.032783528656832, Val Loss: 0.057618006866312', 'Epoch: 79, Train Loss: 0.028391644292112, Val Loss: 0.044700703668323', 'Epoch: 80, Train Loss: 0.029251572676003, Val Loss: 0.048412766928474', 'Epoch: 81, Train Loss: 0.028426608869008, Val Loss: 0.051261045680748', 'Epoch: 82, Train Loss: 0.025281267772828, Val Loss: 0.047577676123403', 'Epoch: 83, Train Loss: 0.026873100548983, Val Loss: 0.051562617899794', 'Epoch: 84, Train Loss: 0.027897752887969, Val Loss: 0.053050646156242', 'Epoch: 85, Train Loss: 0.025146945246628, Val Loss: 0.057713708558092', 'Epoch: 86, Train Loss: 0.027140375625874, Val Loss: 0.047160399287488', 'Epoch: 87, Train Loss: 0.026180748561663, Val Loss: 0.046804554901566', 'Epoch: 88, Train Loss: 0.029004718376590, Val Loss: 0.052276386498389', 'Epoch: 89, Train Loss: 0.025709488961313, Val Loss: 0.049357309316595', 'Epoch: 90, Train Loss: 0.023603940249554, Val Loss: 0.056319479435457', 'Epoch: 91, Train Loss: 0.027650762615459, Val Loss: 0.047519822943617', 'Epoch: 92, Train Loss: 0.030564249094043, Val Loss: 0.056773840252197', 'Epoch: 93, Train Loss: 0.024195979615407, Val Loss: 0.053954569933315', 'Epoch: 94, Train Loss: 0.028298741472619, Val Loss: 0.047674293847663', 'Epoch: 95, Train Loss: 0.023392760261361, Val Loss: 0.047231484047546', 'Epoch: 96, Train Loss: 0.023158709518611, Val Loss: 0.048680667201001', 'Epoch: 97, Train Loss: 0.028624795776393, Val Loss: 0.047496728995942', 'Epoch: 98, Train Loss: 0.027618197458131, Val Loss: 0.060827176453489', 'Epoch: 99, Train Loss: 0.031815611158631, Val Loss: 0.047904787683916', 'Epoch: 100, Train Loss: 0.019832941304360, Val Loss: 0.051613274439605', 'Epoch: 101, Train Loss: 0.021950923638152, Val Loss: 0.047177311710336', 'Epoch: 102, Train Loss: 0.023717621341348, Val Loss: 0.051764744700808', 'Epoch: 103, Train Loss: 0.024172955259149, Val Loss: 0.049589522352273', 'Epoch: 104, Train Loss: 0.023190402891487, Val Loss: 0.046384146345328', 'Epoch: 105, Train Loss: 0.023733678539949, Val Loss: 0.050452916537214', 'Epoch: 106, Train Loss: 0.024911729352815, Val Loss: 0.050744006269132', 'Epoch: 107, Train Loss: 0.022335723574672, Val Loss: 0.046615943326756', 'Epoch: 108, Train Loss: 0.024461106796350, Val Loss: 0.053791879316453', 'Epoch: 109, Train Loss: 0.023355961910316, Val Loss: 0.053095755872853', 'Epoch: 110, Train Loss: 0.025740796766643, Val Loss: 0.052072228715670', 'Epoch: 111, Train Loss: 0.024841130178954, Val Loss: 0.049786208867745', 'Epoch: 112, Train Loss: 0.023313884357257, Val Loss: 0.050482104687641', 'Epoch: 113, Train Loss: 0.022737796085754, Val Loss: 0.049363411370326', 'Epoch: 114, Train Loss: 0.021152682070221, Val Loss: 0.051948765349208', 'Epoch: 115, Train Loss: 0.023975458993976, Val Loss: 0.050612210606535', 'Epoch: 116, Train Loss: 0.022278850499008, Val Loss: 0.045877717266029', 'Epoch: 117, Train Loss: 0.024942644805248, Val Loss: 0.049125482864452', 'Epoch: 118, Train Loss: 0.021942390727678, Val Loss: 0.055239463789445', 'Epoch: 119, Train Loss: 0.020348405465484, Val Loss: 0.045652375979857', 'Epoch: 120, Train Loss: 0.022034149683480, Val Loss: 0.049980935047973', 'Epoch: 121, Train Loss: 0.020958455545562, Val Loss: 0.054127588924585', 'Epoch: 122, Train Loss: 0.022472126409411, Val Loss: 0.053623627617278', 'Epoch: 123, Train Loss: 0.023019993544689, Val Loss: 0.047293428980717', 'Epoch: 124, Train Loss: 0.026646017562598, Val Loss: 0.047295151052601', 'Epoch: 125, Train Loss: 0.026420137113226, Val Loss: 0.043253435527511', 'Epoch: 126, Train Loss: 0.022074990905821, Val Loss: 0.045537244810751', 'Epoch: 127, Train Loss: 0.026277996599674, Val Loss: 0.053968170968195', 'Epoch: 128, Train Loss: 0.027914789372257, Val Loss: 0.046682835471901', 'Epoch: 129, Train Loss: 0.026097380689212, Val Loss: 0.053141045863881', 'Epoch: 130, Train Loss: 0.022295793584947, Val Loss: 0.047281212487371', 'Epoch: 131, Train Loss: 0.023239633534104, Val Loss: 0.043901114216582', 'Epoch: 132, Train Loss: 0.027629469454821, Val Loss: 0.051040301550970', 'Epoch: 133, Train Loss: 0.023438652046025, Val Loss: 0.059067352251573', 'Epoch: 134, Train Loss: 0.021347123530826, Val Loss: 0.054454667804142', 'Epoch: 135, Train Loss: 0.022807188864265, Val Loss: 0.049395034555346', 'Epoch: 136, Train Loss: 0.023642044181802, Val Loss: 0.052795142838449', 'Epoch: 137, Train Loss: 0.020760381261685, Val Loss: 0.053497601356922', 'Epoch: 138, Train Loss: 0.022566283088444, Val Loss: 0.054934981942290', 'Epoch: 139, Train Loss: 0.024169259970742, Val Loss: 0.053504681242912', 'Epoch: 140, Train Loss: 0.021049073631210, Val Loss: 0.050111813978715', 'Epoch: 141, Train Loss: 0.023689153205071, Val Loss: 0.048989929851483', 'Epoch: 142, Train Loss: 0.018374801679913, Val Loss: 0.048616526591958', 'Epoch: 143, Train Loss: 0.020302563440055, Val Loss: 0.051605919503014', 'Epoch: 144, Train Loss: 0.020451436351453, Val Loss: 0.048198466541979', 'Epoch: 145, Train Loss: 0.024913397617638, Val Loss: 0.048220702023669', 'Epoch: 146, Train Loss: 0.021318786744294, Val Loss: 0.043658316996174', 'Epoch: 147, Train Loss: 0.021658954144056, Val Loss: 0.046223501646609', 'Epoch: 148, Train Loss: 0.018103796855680, Val Loss: 0.049405384978110', 'Epoch: 149, Train Loss: 0.021569602257971, Val Loss: 0.056784501976588', 'Epoch: 150, Train Loss: 0.023847306779187, Val Loss: 0.049874507144771', 'Epoch: 151, Train Loss: 0.019406631322844, Val Loss: 0.049000747276075', 'Epoch: 152, Train Loss: 0.019518986809999, Val Loss: 0.042835137044842', 'Epoch: 153, Train Loss: 0.020115816633084, Val Loss: 0.050687718148710', 'Epoch: 154, Train Loss: 0.020752032686557, Val Loss: 0.046941814859482', 'Epoch: 155, Train Loss: 0.018162837518113, Val Loss: 0.051360197788612', 'Epoch: 156, Train Loss: 0.020347857515195, Val Loss: 0.053386241677358', 'Epoch: 157, Train Loss: 0.020479218302561, Val Loss: 0.051599549298937', 'Epoch: 158, Train Loss: 0.018418135254511, Val Loss: 0.048225723319885', 'Epoch: 159, Train Loss: 0.019673249883843, Val Loss: 0.046907732291429', 'Epoch: 160, Train Loss: 0.020313007557499, Val Loss: 0.050788114298925', 'Epoch: 161, Train Loss: 0.021323094277510, Val Loss: 0.048036634724474', 'Epoch: 162, Train Loss: 0.021013710880652, Val Loss: 0.050147653486805', 'Epoch: 163, Train Loss: 0.023037796707026, Val Loss: 0.048418044394842', 'Epoch: 164, Train Loss: 0.024416178265320, Val Loss: 0.049955783016754', 'Epoch: 165, Train Loss: 0.018520334469421, Val Loss: 0.050235722778421', 'Epoch: 166, Train Loss: 0.019527836769287, Val Loss: 0.044989670203491', 'Epoch: 167, Train Loss: 0.019260082460408, Val Loss: 0.044588580050252', 'Epoch: 168, Train Loss: 0.017726891940194, Val Loss: 0.052059021891292', 'Epoch: 169, Train Loss: 0.018647566969906, Val Loss: 0.045386723694250', 'Epoch: 170, Train Loss: 0.020035467842328, Val Loss: 0.048010219227184', 'Epoch: 171, Train Loss: 0.017951850513262, Val Loss: 0.050837936387821', 'Epoch: 172, Train Loss: 0.019835515280387, Val Loss: 0.056568963340286', 'Epoch: 173, Train Loss: 0.020060118287802, Val Loss: 0.044059754095294', 'Epoch: 174, Train Loss: 0.020219820950712, Val Loss: 0.047599943411170', 'Epoch: 175, Train Loss: 0.021520571650139, Val Loss: 0.049910452386195', 'Epoch: 176, Train Loss: 0.020105685639594, Val Loss: 0.048881508184202', 'Epoch: 177, Train Loss: 0.017683403100818, Val Loss: 0.043945661717744', 'Epoch: 178, Train Loss: 0.015694701179330, Val Loss: 0.048777934954022', 'Epoch: 179, Train Loss: 0.018825124816171, Val Loss: 0.050291377373717', 'Epoch: 180, Train Loss: 0.018112051799627, Val Loss: 0.045576876904251', 'Epoch: 181, Train Loss: 0.018540167449308, Val Loss: 0.046085191495491', 'Epoch: 182, Train Loss: 0.019781546999833, Val Loss: 0.046601545940520', 'Epoch: 183, Train Loss: 0.020212609320879, Val Loss: 0.044313556542902', 'Epoch: 184, Train Loss: 0.019721422144877, Val Loss: 0.048449552420414', 'Epoch: 185, Train Loss: 0.019815740109022, Val Loss: 0.047581725401070', 'Epoch: 186, Train Loss: 0.017736773073141, Val Loss: 0.045060402572607', 'Epoch: 187, Train Loss: 0.019800285010466, Val Loss: 0.046160071241585', 'Epoch: 188, Train Loss: 0.016110227310232, Val Loss: 0.048361514328104', 'Epoch: 189, Train Loss: 0.019109896450703, Val Loss: 0.047327569770542', 'Epoch: 190, Train Loss: 0.019815150581832, Val Loss: 0.045535597414004', 'Epoch: 191, Train Loss: 0.017220020892897, Val Loss: 0.045166735593794', 'Epoch: 192, Train Loss: 0.018390473177923, Val Loss: 0.045421398216576', 'Epoch: 193, Train Loss: 0.017655261526150, Val Loss: 0.045581371720993', 'Epoch: 194, Train Loss: 0.016565639592175, Val Loss: 0.045444355769591', 'Epoch: 195, Train Loss: 0.018009427003562, Val Loss: 0.045808225954798', 'Epoch: 196, Train Loss: 0.017222374444827, Val Loss: 0.046813797600793', 'Epoch: 197, Train Loss: 0.016086632319327, Val Loss: 0.046919428051986', 'Epoch: 198, Train Loss: 0.021093767402428, Val Loss: 0.046549407285497', 'Epoch: 199, Train Loss: 0.018024955743126, Val Loss: 0.046377189118754']","[ 471.1403     153.8793     290.7542     598.37305    325.16803
  740.4659     400.95618   1032.688      483.66537    626.5006
  337.39804     63.19983      5.4628296  531.7776     572.98
  562.8819     383.73654   1327.7366     418.3215     418.18646
 1111.6362    1044.3005     410.69217    632.6117     770.8096
  243.9403       2.0499268  617.8216     138.60297     10.239746
  259.98862    840.6533     672.4115     828.5887     491.27667
  849.557       13.723694   780.819      260.51508   1192.4822
  241.62308    334.45892     54.5943     694.4518    1219.9059
  730.69086    384.54898     48.199646   568.3642     649.0148
  279.37943     20.586472   401.69052    477.40497    838.6971
  471.95917    125.53729    384.86105    922.0249     541.7541
  564.26196     80.541504   307.5845     738.6224     417.87872
  303.49234   1132.605      649.5345     997.83997   1077.1912
  326.62158    315.92706    721.78955    895.2418     202.45238
  351.98355    608.1203     670.70856   1119.0164     517.8821
  265.24066     53.80777    915.9963    1082.7795     600.7388
  284.34714    122.99805     85.57712    284.28488    907.08356
    6.329773   485.5377      25.92746    624.78357     49.893707
 1062.8188     797.8456     404.75803    512.49774    457.61334
  277.92847    321.62332    192.59299    274.24643    893.3407
  649.3793     319.4779     479.95258    773.51013    982.65375
  559.5322     229.95102   1298.9675     991.0653     867.60095
  439.27567     41.41095    455.4604     296.6674     116.64441
  580.84143    540.8015    1137.2391     888.42957    232.84521
  578.2854    1317.5714     792.812      307.88156    220.76721
  290.97983    540.59924    909.3096     671.03394    644.0965
  604.7989     869.3708     904.1972   ]","[ 457.87454   145.92734   320.40137   472.74124   379.4042    728.7775
  410.3359   1085.9956    452.4746    538.83826   302.601     158.89346
   76.43274   423.11475   427.6241    589.8442    309.73853  1377.5469
  471.37665   491.51938   941.8834   1036.283     348.17065   620.721
  781.0729    228.08539    82.304016  424.35687    86.144516  179.51596
  239.29959   816.66296   640.6306    713.70795   409.8631    720.9253
   85.509735  842.98425   288.43756  1245.9036    182.07555   307.42218
  138.41412   800.94763  1043.3992    629.5       384.49707   194.41986
  540.72534   622.84      263.64642    47.36502   340.76443   446.08154
  860.97876   498.06497   -16.696106  424.13037   959.437     749.6872
  592.6986    251.66577   345.27124   697.6212    452.2202    280.44196
 1012.26166   566.0924   1018.06854   969.73505   295.84857   302.26828
  650.23376   849.30896   224.16241   412.20398   563.97485   589.24854
 1217.0527    487.7165    267.26575   127.02057   879.1067   1095.4661
  539.00037   274.97083   195.8432    166.86432   209.27039   872.22955
  320.59518   296.8988    122.778336  536.02673   321.97595   832.6632
  758.9796    363.4742    621.72546   517.0826    223.63072   245.41125
  226.67378   280.83328   677.89325   615.8344    338.67834   450.78592
  710.18335   872.6711    516.3712    281.43622  1293.0845   1067.1309
  827.1662    425.48926    57.04889   405.57187   227.84619   189.08615
  391.8026    357.03043  1269.9307    959.53925   114.42236   411.33228
 1011.19604   774.8919    330.7505    215.30554   250.20955   573.9363
  941.44165   786.1233    580.7137    691.3358    956.5228   1087.2615  ]",71.822754,8995.491,94.84456342320048
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 0.386088897074972, Val Loss: 0.398875986310569', 'Epoch: 1, Train Loss: 0.385221032159669, Val Loss: 0.394868251049157', 'Epoch: 2, Train Loss: 0.383584475943020, Val Loss: 0.390499280709209', 'Epoch: 3, Train Loss: 0.367415592074394, Val Loss: 0.380713656996236', 'Epoch: 4, Train Loss: 0.347360715270042, Val Loss: 0.350753350578474', 'Epoch: 5, Train Loss: 0.282318331301212, Val Loss: 0.264882077660524', 'Epoch: 6, Train Loss: 0.181232133081981, Val Loss: 0.150393600716735', 'Epoch: 7, Train Loss: 0.129079917711871, Val Loss: 0.170412817010374', 'Epoch: 8, Train Loss: 0.117852437176875, Val Loss: 0.136096843602982', 'Epoch: 9, Train Loss: 0.117713169327804, Val Loss: 0.133478157038829', 'Epoch: 10, Train Loss: 0.097992414342506, Val Loss: 0.115392891520804', 'Epoch: 11, Train Loss: 0.083298406962837, Val Loss: 0.100611586575255', 'Epoch: 12, Train Loss: 0.075084534606763, Val Loss: 0.086091951579984', 'Epoch: 13, Train Loss: 0.074593615052955, Val Loss: 0.086315684015669', 'Epoch: 14, Train Loss: 0.076959709237729, Val Loss: 0.077135716875394', 'Epoch: 15, Train Loss: 0.062627904117107, Val Loss: 0.082704251914313', 'Epoch: 16, Train Loss: 0.074879114116941, Val Loss: 0.061368147080595', 'Epoch: 17, Train Loss: 0.052521351192679, Val Loss: 0.072534801043344', 'Epoch: 18, Train Loss: 0.053722592070699, Val Loss: 0.071018745050286', 'Epoch: 19, Train Loss: 0.058601501264742, Val Loss: 0.077003813913148', 'Epoch: 20, Train Loss: 0.050062338422452, Val Loss: 0.070612023866764', 'Epoch: 21, Train Loss: 0.054139456844756, Val Loss: 0.064615875482559', 'Epoch: 22, Train Loss: 0.060426306511675, Val Loss: 0.094106504637184', 'Epoch: 23, Train Loss: 0.062188392238958, Val Loss: 0.049152590108640', 'Epoch: 24, Train Loss: 0.049035011923739, Val Loss: 0.054951006038622', 'Epoch: 25, Train Loss: 0.040876326550330, Val Loss: 0.052195661560153', 'Epoch: 26, Train Loss: 0.060443788234677, Val Loss: 0.100710185188236', 'Epoch: 27, Train Loss: 0.067884752260787, Val Loss: 0.081722306934270', 'Epoch: 28, Train Loss: 0.054419988234128, Val Loss: 0.079906229367197', 'Epoch: 29, Train Loss: 0.042489397206477, Val Loss: 0.067503205754540', 'Epoch: 30, Train Loss: 0.046009522729686, Val Loss: 0.065480556169694', 'Epoch: 31, Train Loss: 0.045405428856611, Val Loss: 0.057683129315123', 'Epoch: 32, Train Loss: 0.045531057353531, Val Loss: 0.074724417631373', 'Epoch: 33, Train Loss: 0.042445173354021, Val Loss: 0.075543563248533', 'Epoch: 34, Train Loss: 0.061495563813618, Val Loss: 0.065456092696298', 'Epoch: 35, Train Loss: 0.062750487721392, Val Loss: 0.115848150442947', 'Epoch: 36, Train Loss: 0.073001972532698, Val Loss: 0.088531705522628', 'Epoch: 37, Train Loss: 0.055647486022541, Val Loss: 0.074305913100640', 'Epoch: 38, Train Loss: 0.052675230827715, Val Loss: 0.067820875707901', 'Epoch: 39, Train Loss: 0.040658923664263, Val Loss: 0.057746480388398', 'Epoch: 40, Train Loss: 0.046579712469663, Val Loss: 0.053880925995834', 'Epoch: 41, Train Loss: 0.048591432028583, Val Loss: 0.070364432127187', 'Epoch: 42, Train Loss: 0.046148843131959, Val Loss: 0.059895552807685', 'Epoch: 43, Train Loss: 0.043948636922453, Val Loss: 0.051523619303198', 'Epoch: 44, Train Loss: 0.041761516859489, Val Loss: 0.053436736378706', 'Epoch: 45, Train Loss: 0.056155342741736, Val Loss: 0.090241009651711', 'Epoch: 46, Train Loss: 0.046724321453699, Val Loss: 0.062244875525886', 'Epoch: 47, Train Loss: 0.047116081363388, Val Loss: 0.074517161331394', 'Epoch: 48, Train Loss: 0.043909569670047, Val Loss: 0.060356874526902', 'Epoch: 49, Train Loss: 0.039766538888216, Val Loss: 0.062627478248694', 'Epoch: 50, Train Loss: 0.044904664424913, Val Loss: 0.052377906881950', 'Epoch: 51, Train Loss: 0.052130860675658, Val Loss: 0.093797443773259', 'Epoch: 52, Train Loss: 0.056853337479489, Val Loss: 0.052500358528712', 'Epoch: 53, Train Loss: 0.031882983965001, Val Loss: 0.060166685587981', 'Epoch: 54, Train Loss: 0.039187734414424, Val Loss: 0.082670966558384', 'Epoch: 55, Train Loss: 0.044397179569517, Val Loss: 0.088762645609677', 'Epoch: 56, Train Loss: 0.038068868752037, Val Loss: 0.056168842030633', 'Epoch: 57, Train Loss: 0.035090931425137, Val Loss: 0.074084820112947', 'Epoch: 58, Train Loss: 0.038160841912031, Val Loss: 0.051769012952167', 'Epoch: 59, Train Loss: 0.039148597578917, Val Loss: 0.052718355637890', 'Epoch: 60, Train Loss: 0.034318081236311, Val Loss: 0.054110943085768', 'Epoch: 61, Train Loss: 0.033850523111011, Val Loss: 0.070226410798954', 'Epoch: 62, Train Loss: 0.037790251762739, Val Loss: 0.056502619476029', 'Epoch: 63, Train Loss: 0.029724848190589, Val Loss: 0.054085527518482', 'Epoch: 64, Train Loss: 0.034687986730465, Val Loss: 0.045221901131850', 'Epoch: 65, Train Loss: 0.031251839761223, Val Loss: 0.047440739687194', 'Epoch: 66, Train Loss: 0.031709601171315, Val Loss: 0.064852724557347', 'Epoch: 67, Train Loss: 0.027922942702259, Val Loss: 0.052179585239201', 'Epoch: 68, Train Loss: 0.029883661972625, Val Loss: 0.052523876399253', 'Epoch: 69, Train Loss: 0.029707394806402, Val Loss: 0.058440451086922', 'Epoch: 70, Train Loss: 0.028088963524039, Val Loss: 0.060714464239550', 'Epoch: 71, Train Loss: 0.027645320232425, Val Loss: 0.043861880334038', 'Epoch: 72, Train Loss: 0.032109789683350, Val Loss: 0.046201734916505', 'Epoch: 73, Train Loss: 0.026848215942404, Val Loss: 0.051012595014816', 'Epoch: 74, Train Loss: 0.030499713694943, Val Loss: 0.072614798632761', 'Epoch: 75, Train Loss: 0.028695937113038, Val Loss: 0.048365072996327', 'Epoch: 76, Train Loss: 0.031684192961880, Val Loss: 0.058893271129240', 'Epoch: 77, Train Loss: 0.030873060359487, Val Loss: 0.048018255355683', 'Epoch: 78, Train Loss: 0.033422051662845, Val Loss: 0.051112318806576', 'Epoch: 79, Train Loss: 0.040206869265863, Val Loss: 0.046647846472986', 'Epoch: 80, Train Loss: 0.030804491003177, Val Loss: 0.045288261590582', 'Epoch: 81, Train Loss: 0.034425252782447, Val Loss: 0.069088198018797', 'Epoch: 82, Train Loss: 0.031023305441652, Val Loss: 0.072272768752141', 'Epoch: 83, Train Loss: 0.028084145858884, Val Loss: 0.055368571683313', 'Epoch: 84, Train Loss: 0.025580182205886, Val Loss: 0.053910509485639', 'Epoch: 85, Train Loss: 0.030089139539216, Val Loss: 0.055970882601810', 'Epoch: 86, Train Loss: 0.028020688465663, Val Loss: 0.060489836064252', 'Epoch: 87, Train Loss: 0.026494715096695, Val Loss: 0.055766515772451', 'Epoch: 88, Train Loss: 0.029956761614553, Val Loss: 0.053796608565432', 'Epoch: 89, Train Loss: 0.027703107268150, Val Loss: 0.068914933271255', 'Epoch: 90, Train Loss: 0.032483309041709, Val Loss: 0.077497694867127', 'Epoch: 91, Train Loss: 0.029878467986626, Val Loss: 0.047316670022679', 'Epoch: 92, Train Loss: 0.027312746936721, Val Loss: 0.053152260934990', 'Epoch: 93, Train Loss: 0.024379654920527, Val Loss: 0.053414652067603', 'Epoch: 94, Train Loss: 0.029069729615003, Val Loss: 0.057971633970737', 'Epoch: 95, Train Loss: 0.026999741792679, Val Loss: 0.052858177572489', 'Epoch: 96, Train Loss: 0.028049131988415, Val Loss: 0.051524493165992', 'Epoch: 97, Train Loss: 0.026846985332668, Val Loss: 0.068721071788759', 'Epoch: 98, Train Loss: 0.028287780936807, Val Loss: 0.050754255248290', 'Epoch: 99, Train Loss: 0.024350002408028, Val Loss: 0.058242500054114', 'Epoch: 100, Train Loss: 0.027317775346871, Val Loss: 0.057044795911872', 'Epoch: 101, Train Loss: 0.027737794443965, Val Loss: 0.046291831767920', 'Epoch: 102, Train Loss: 0.029516753607563, Val Loss: 0.051896723100182', 'Epoch: 103, Train Loss: 0.027016752000366, Val Loss: 0.059637436840796', 'Epoch: 104, Train Loss: 0.029783541935363, Val Loss: 0.049723148458835', 'Epoch: 105, Train Loss: 0.029426337485867, Val Loss: 0.046184806040291', 'Epoch: 106, Train Loss: 0.027063795631485, Val Loss: 0.056502753586480', 'Epoch: 107, Train Loss: 0.027156347342368, Val Loss: 0.068231690336357', 'Epoch: 108, Train Loss: 0.027376348684941, Val Loss: 0.061219724346742', 'Epoch: 109, Train Loss: 0.024351725487837, Val Loss: 0.056242466255119', 'Epoch: 110, Train Loss: 0.021267524654312, Val Loss: 0.053394551699360', 'Epoch: 111, Train Loss: 0.023396790293711, Val Loss: 0.042978707588080', 'Epoch: 112, Train Loss: 0.028941788444562, Val Loss: 0.059098964726383', 'Epoch: 113, Train Loss: 0.026184621267021, Val Loss: 0.054343403288812', 'Epoch: 114, Train Loss: 0.024949507920870, Val Loss: 0.051649379459294', 'Epoch: 115, Train Loss: 0.020349318627268, Val Loss: 0.045728188685396', 'Epoch: 116, Train Loss: 0.026619748079351, Val Loss: 0.052506283772263', 'Epoch: 117, Train Loss: 0.019481787657631, Val Loss: 0.050087430260398', 'Epoch: 118, Train Loss: 0.025295322893986, Val Loss: 0.057064211278251', 'Epoch: 119, Train Loss: 0.025908816339714, Val Loss: 0.043928228544466', 'Epoch: 120, Train Loss: 0.022322507176016, Val Loss: 0.051471154459498', 'Epoch: 121, Train Loss: 0.022452542691358, Val Loss: 0.052965591520523', 'Epoch: 122, Train Loss: 0.023456731079412, Val Loss: 0.057309559743964', 'Epoch: 123, Train Loss: 0.023034639656544, Val Loss: 0.059093734418804', 'Epoch: 124, Train Loss: 0.024003216131989, Val Loss: 0.054460934899522', 'Epoch: 125, Train Loss: 0.029543684662453, Val Loss: 0.057127085881251', 'Epoch: 126, Train Loss: 0.025656615383923, Val Loss: 0.060968754417969', 'Epoch: 127, Train Loss: 0.025503662414849, Val Loss: 0.055412569224383', 'Epoch: 128, Train Loss: 0.026241021031248, Val Loss: 0.051897623068230', 'Epoch: 129, Train Loss: 0.025204298884741, Val Loss: 0.050404368532878', 'Epoch: 130, Train Loss: 0.023152691977365, Val Loss: 0.053766460778813', 'Epoch: 131, Train Loss: 0.024092456924596, Val Loss: 0.059154785717979', 'Epoch: 132, Train Loss: 0.022377266082913, Val Loss: 0.053504456963503', 'Epoch: 133, Train Loss: 0.022268272470683, Val Loss: 0.048616000987364', 'Epoch: 134, Train Loss: 0.022354157109346, Val Loss: 0.053390980274840', 'Epoch: 135, Train Loss: 0.022826479614845, Val Loss: 0.055998382469018', 'Epoch: 136, Train Loss: 0.021819402995918, Val Loss: 0.059193719742876', 'Epoch: 137, Train Loss: 0.025463073181787, Val Loss: 0.068282066703294', 'Epoch: 138, Train Loss: 0.022534606313067, Val Loss: 0.052827240673430', 'Epoch: 139, Train Loss: 0.025253777658301, Val Loss: 0.055676130916585', 'Epoch: 140, Train Loss: 0.020081860013306, Val Loss: 0.057172063963883', 'Epoch: 141, Train Loss: 0.019514170076166, Val Loss: 0.052663142962212', 'Epoch: 142, Train Loss: 0.024875593305166, Val Loss: 0.056432332617767', 'Epoch: 143, Train Loss: 0.024180858861655, Val Loss: 0.047062195893942', 'Epoch: 144, Train Loss: 0.023337706258254, Val Loss: 0.067063388160684', 'Epoch: 145, Train Loss: 0.024249466934374, Val Loss: 0.050012326827555', 'Epoch: 146, Train Loss: 0.021430796810559, Val Loss: 0.052430384453725', 'Epoch: 147, Train Loss: 0.019130625030292, Val Loss: 0.054740189151330', 'Epoch: 148, Train Loss: 0.019759160865630, Val Loss: 0.049355240200054', 'Epoch: 149, Train Loss: 0.019555487270866, Val Loss: 0.050651078140645', 'Epoch: 150, Train Loss: 0.021919016460223, Val Loss: 0.053788727996024', 'Epoch: 151, Train Loss: 0.018377238086292, Val Loss: 0.049148524010723', 'Epoch: 152, Train Loss: 0.020636134913989, Val Loss: 0.050927998766190', 'Epoch: 153, Train Loss: 0.020053129111018, Val Loss: 0.051013838048234', 'Epoch: 154, Train Loss: 0.022114954822298, Val Loss: 0.051274154434037', 'Epoch: 155, Train Loss: 0.022057935861605, Val Loss: 0.047691551008911', 'Epoch: 156, Train Loss: 0.021547916345298, Val Loss: 0.059348440870191', 'Epoch: 157, Train Loss: 0.021657235853906, Val Loss: 0.051641651626789', 'Epoch: 158, Train Loss: 0.019264564383775, Val Loss: 0.055743188512596', 'Epoch: 159, Train Loss: 0.018750749528408, Val Loss: 0.054341063806505', 'Epoch: 160, Train Loss: 0.018657928066594, Val Loss: 0.052009233753338', 'Epoch: 161, Train Loss: 0.018775837329615, Val Loss: 0.050814718233817', 'Epoch: 162, Train Loss: 0.022352915589831, Val Loss: 0.048538955775174', 'Epoch: 163, Train Loss: 0.020491219158950, Val Loss: 0.060224707718148', 'Epoch: 164, Train Loss: 0.020209694081651, Val Loss: 0.048454486680302', 'Epoch: 165, Train Loss: 0.019142473083256, Val Loss: 0.049358568013166', 'Epoch: 166, Train Loss: 0.017622910573014, Val Loss: 0.055470690074744', 'Epoch: 167, Train Loss: 0.021586551663599, Val Loss: 0.049894474051667', 'Epoch: 168, Train Loss: 0.019558798854372, Val Loss: 0.053629006230921', 'Epoch: 169, Train Loss: 0.019316018292946, Val Loss: 0.053267136216164', 'Epoch: 170, Train Loss: 0.018361163990838, Val Loss: 0.050023248532053', 'Epoch: 171, Train Loss: 0.020127834752202, Val Loss: 0.051875044619947', 'Epoch: 172, Train Loss: 0.021755375633282, Val Loss: 0.049773823131214', 'Epoch: 173, Train Loss: 0.020727991658662, Val Loss: 0.052358074170170', 'Epoch: 174, Train Loss: 0.018648813811264, Val Loss: 0.050750721641111', 'Epoch: 175, Train Loss: 0.016765868923228, Val Loss: 0.054323390069785', 'Epoch: 176, Train Loss: 0.019128782408578, Val Loss: 0.050644264697577', 'Epoch: 177, Train Loss: 0.016492742313338, Val Loss: 0.052678807666807', 'Epoch: 178, Train Loss: 0.020725644725774, Val Loss: 0.049055272995523', 'Epoch: 179, Train Loss: 0.022566297557205, Val Loss: 0.048207913158518', 'Epoch: 180, Train Loss: 0.022906049952975, Val Loss: 0.051126407459378', 'Epoch: 181, Train Loss: 0.018667626327702, Val Loss: 0.050588506076372', 'Epoch: 182, Train Loss: 0.019448215940169, Val Loss: 0.050574083106987', 'Epoch: 183, Train Loss: 0.018132328787552, Val Loss: 0.049223631676851', 'Epoch: 184, Train Loss: 0.018333698689405, Val Loss: 0.048817673641624', 'Epoch: 185, Train Loss: 0.019398738430547, Val Loss: 0.051483323854027', 'Epoch: 186, Train Loss: 0.021590581463118, Val Loss: 0.054349267798843', 'Epoch: 187, Train Loss: 0.019690725819341, Val Loss: 0.051023510764494', 'Epoch: 188, Train Loss: 0.019086399315191, Val Loss: 0.051004763353955', 'Epoch: 189, Train Loss: 0.018769748375884, Val Loss: 0.050961063328114', 'Epoch: 190, Train Loss: 0.016545123221087, Val Loss: 0.051245021549138', 'Epoch: 191, Train Loss: 0.018486057674246, Val Loss: 0.050464447136178', 'Epoch: 192, Train Loss: 0.019831519440881, Val Loss: 0.049706306139177', 'Epoch: 193, Train Loss: 0.015063880876239, Val Loss: 0.049051187763160', 'Epoch: 194, Train Loss: 0.016679469429489, Val Loss: 0.049413690399943', 'Epoch: 195, Train Loss: 0.018702051402735, Val Loss: 0.049869987774979', 'Epoch: 196, Train Loss: 0.020237353297749, Val Loss: 0.050364917539286', 'Epoch: 197, Train Loss: 0.017616501876286, Val Loss: 0.049859280613336', 'Epoch: 198, Train Loss: 0.016305305462863, Val Loss: 0.049506015849836', 'Epoch: 199, Train Loss: 0.017295982688665, Val Loss: 0.049511713681347']","[ 471.1403     153.8793     290.7542     598.37305    325.16803
  740.4659     400.95618   1032.688      483.66537    626.5006
  337.39804     63.19983      5.4628296  531.7776     572.98
  562.8819     383.73654   1327.7366     418.3215     418.18646
 1111.6362    1044.3005     410.69217    632.6117     770.8096
  243.9403       2.0499268  617.8216     138.60297     10.239746
  259.98862    840.6533     672.4115     828.5887     491.27667
  849.557       13.723694   780.819      260.51508   1192.4822
  241.62308    334.45892     54.5943     694.4518    1219.9059
  730.69086    384.54898     48.199646   568.3642     649.0148
  279.37943     20.586472   401.69052    477.40497    838.6971
  471.95917    125.53729    384.86105    922.0249     541.7541
  564.26196     80.541504   307.5845     738.6224     417.87872
  303.49234   1132.605      649.5345     997.83997   1077.1912
  326.62158    315.92706    721.78955    895.2418     202.45238
  351.98355    608.1203     670.70856   1119.0164     517.8821
  265.24066     53.80777    915.9963    1082.7795     600.7388
  284.34714    122.99805     85.57712    284.28488    907.08356
    6.329773   485.5377      25.92746    624.78357     49.893707
 1062.8188     797.8456     404.75803    512.49774    457.61334
  277.92847    321.62332    192.59299    274.24643    893.3407
  649.3793     319.4779     479.95258    773.51013    982.65375
  559.5322     229.95102   1298.9675     991.0653     867.60095
  439.27567     41.41095    455.4604     296.6674     116.64441
  580.84143    540.8015    1137.2391     888.42957    232.84521
  578.2854    1317.5714     792.812      307.88156    220.76721
  290.97983    540.59924    909.3096     671.03394    644.0965
  604.7989     869.3708     904.1972   ]","[ 441.13626   128.56238   327.5311    478.09744   328.53183   716.7679
  395.2804   1060.388     469.93735   553.16376   336.89642   189.36633
   44.435364  449.5288    469.04797   535.6776    416.8726   1313.9768
  486.10126   495.64594  1084.6199   1026.4061    335.4406    614.47955
  789.2191    192.0805    111.97781   466.5432     89.30696   133.45227
  257.46198   795.74426   657.9258    744.8149    414.87527   790.80945
   76.647064  788.4592    275.22778  1218.8699    202.71541   274.99634
  160.20934   683.50574  1102.7191    668.2706    351.0062    162.02255
  583.9568    609.5103    275.53424    63.880844  339.77463   458.58685
  843.7694    481.00894    61.7894    484.50626   951.2254    776.63806
  562.13794   265.61597   377.3615    732.6247    432.52307   287.59677
 1021.7105    622.2845   1035.5367    976.9301    265.46866   317.0889
  656.6167    883.3463    191.58113   370.52304   551.5572    573.8248
 1206.8243    478.14044   264.82617   136.31934   947.0226   1105.8492
  545.4829    282.0056    306.94498   192.90222   224.79163   865.5992
  270.94083   299.73883   111.003235  505.7906    339.60696   828.31384
  762.72876   359.06506   651.08777   535.0794    203.29309   239.24167
  203.35466   277.91455   704.07166   695.51587   359.2468    474.19824
  726.2246    941.2683    550.36615   251.205    1351.7722   1062.4695
  896.20856   431.2096     87.52644   415.96915   216.63211   151.79016
  374.12152   315.18826  1203.4933    908.27423   171.23828   362.00912
  961.0467    783.2581    320.71033   187.90326   224.57187   658.0724
 1029.373     747.4441    590.8769    619.2542    995.5062   1062.099   ]",65.850914,8481.743,92.09637975546325
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 0.386088886431285, Val Loss: 0.398876056075096', 'Epoch: 1, Train Loss: 0.385221698454448, Val Loss: 0.394869325738965', 'Epoch: 2, Train Loss: 0.383586783494268, Val Loss: 0.390499606051228', 'Epoch: 3, Train Loss: 0.367420247622899, Val Loss: 0.380726912933769', 'Epoch: 4, Train Loss: 0.347387897116797, Val Loss: 0.350602915341204', 'Epoch: 5, Train Loss: 0.282375562403883, Val Loss: 0.265335602064927', 'Epoch: 6, Train Loss: 0.181896827050618, Val Loss: 0.152964446129221', 'Epoch: 7, Train Loss: 0.128098305314779, Val Loss: 0.165233042881344', 'Epoch: 8, Train Loss: 0.115584811461823, Val Loss: 0.134937981312925', 'Epoch: 9, Train Loss: 0.118677290954760, Val Loss: 0.134956783636219', 'Epoch: 10, Train Loss: 0.099381445241826, Val Loss: 0.116519266118606', 'Epoch: 11, Train Loss: 0.083765936483230, Val Loss: 0.099976209302743', 'Epoch: 12, Train Loss: 0.075476702834879, Val Loss: 0.088197357218825', 'Epoch: 13, Train Loss: 0.074352303785937, Val Loss: 0.088951029756572', 'Epoch: 14, Train Loss: 0.078015290732895, Val Loss: 0.075866906931906', 'Epoch: 15, Train Loss: 0.062896558881870, Val Loss: 0.083543541629545', 'Epoch: 16, Train Loss: 0.074249767565301, Val Loss: 0.061571133181904', 'Epoch: 17, Train Loss: 0.053791317024401, Val Loss: 0.074356038970026', 'Epoch: 18, Train Loss: 0.053896223194897, Val Loss: 0.072429892353036', 'Epoch: 19, Train Loss: 0.058363219190921, Val Loss: 0.075153296206598', 'Epoch: 20, Train Loss: 0.052068363342966, Val Loss: 0.071658109794512', 'Epoch: 21, Train Loss: 0.055964469909668, Val Loss: 0.059755174838232', 'Epoch: 22, Train Loss: 0.056706718302199, Val Loss: 0.086007197472182', 'Epoch: 23, Train Loss: 0.057318812369236, Val Loss: 0.047150261474378', 'Epoch: 24, Train Loss: 0.047841850535146, Val Loss: 0.057131114952040', 'Epoch: 25, Train Loss: 0.041601503400930, Val Loss: 0.054741739323645', 'Epoch: 26, Train Loss: 0.057463844705905, Val Loss: 0.094717417928306', 'Epoch: 27, Train Loss: 0.066219266770141, Val Loss: 0.079585127024488', 'Epoch: 28, Train Loss: 0.051696708159787, Val Loss: 0.072368152665369', 'Epoch: 29, Train Loss: 0.039995977655053, Val Loss: 0.066568813935825', 'Epoch: 30, Train Loss: 0.044588993968708, Val Loss: 0.070635439291822', 'Epoch: 31, Train Loss: 0.044451765316938, Val Loss: 0.058560140543815', 'Epoch: 32, Train Loss: 0.045927363048707, Val Loss: 0.077849898148667', 'Epoch: 33, Train Loss: 0.041145022426333, Val Loss: 0.070391136249810', 'Epoch: 34, Train Loss: 0.055839954742364, Val Loss: 0.061517068664684', 'Epoch: 35, Train Loss: 0.059114466022168, Val Loss: 0.123790435718768', 'Epoch: 36, Train Loss: 0.074955616146326, Val Loss: 0.088249888835531', 'Epoch: 37, Train Loss: 0.058920426826392, Val Loss: 0.061490560458465', 'Epoch: 38, Train Loss: 0.058476497286132, Val Loss: 0.064618545415049', 'Epoch: 39, Train Loss: 0.042493080720305, Val Loss: 0.067981219765815', 'Epoch: 40, Train Loss: 0.048716348595917, Val Loss: 0.054486188078017', 'Epoch: 41, Train Loss: 0.051604940689036, Val Loss: 0.075815680803675', 'Epoch: 42, Train Loss: 0.045856728883726, Val Loss: 0.064965861172161', 'Epoch: 43, Train Loss: 0.041185209128473, Val Loss: 0.047206820468559', 'Epoch: 44, Train Loss: 0.037754944791751, Val Loss: 0.048421476233863', 'Epoch: 45, Train Loss: 0.051122465037874, Val Loss: 0.090029423322641', 'Epoch: 46, Train Loss: 0.045179077690201, Val Loss: 0.056714122719837', 'Epoch: 47, Train Loss: 0.044458678258317, Val Loss: 0.069218410461238', 'Epoch: 48, Train Loss: 0.042377884765821, Val Loss: 0.063941782791958', 'Epoch: 49, Train Loss: 0.035887039931757, Val Loss: 0.061886062083597', 'Epoch: 50, Train Loss: 0.048343571302082, Val Loss: 0.050424675936952', 'Epoch: 51, Train Loss: 0.058787672913500, Val Loss: 0.092554398015085', 'Epoch: 52, Train Loss: 0.060766259740506, Val Loss: 0.050910716340172', 'Epoch: 53, Train Loss: 0.038118056553815, Val Loss: 0.057833631438288', 'Epoch: 54, Train Loss: 0.041766806904759, Val Loss: 0.066681564870206', 'Epoch: 55, Train Loss: 0.042045756642308, Val Loss: 0.100231197719095', 'Epoch: 56, Train Loss: 0.046353503662561, Val Loss: 0.057294729363286', 'Epoch: 57, Train Loss: 0.041419477335044, Val Loss: 0.077625126154585', 'Epoch: 58, Train Loss: 0.041136780221547, Val Loss: 0.054875072289371', 'Epoch: 59, Train Loss: 0.039409701712430, Val Loss: 0.052639242600311', 'Epoch: 60, Train Loss: 0.034177606393184, Val Loss: 0.055277218223747', 'Epoch: 61, Train Loss: 0.036051031468170, Val Loss: 0.072748371089498', 'Epoch: 62, Train Loss: 0.038617056927511, Val Loss: 0.047977582071767', 'Epoch: 63, Train Loss: 0.027812206053308, Val Loss: 0.052006731148471', 'Epoch: 64, Train Loss: 0.036015783968781, Val Loss: 0.043870058983113', 'Epoch: 65, Train Loss: 0.033502162567207, Val Loss: 0.043587425808338', 'Epoch: 66, Train Loss: 0.031989371670144, Val Loss: 0.062359998623530', 'Epoch: 67, Train Loss: 0.026577957905829, Val Loss: 0.044162804768844', 'Epoch: 68, Train Loss: 0.028224511870316, Val Loss: 0.045210514217615', 'Epoch: 69, Train Loss: 0.028382074753089, Val Loss: 0.051773071006844', 'Epoch: 70, Train Loss: 0.028495514765382, Val Loss: 0.054255502213809', 'Epoch: 71, Train Loss: 0.028718787112406, Val Loss: 0.041528224662849', 'Epoch: 72, Train Loss: 0.034038240755243, Val Loss: 0.042404979100507', 'Epoch: 73, Train Loss: 0.027804612381650, Val Loss: 0.046848023959407', 'Epoch: 74, Train Loss: 0.028451313065099, Val Loss: 0.066120918219288', 'Epoch: 75, Train Loss: 0.028734167239496, Val Loss: 0.043904839422215', 'Epoch: 76, Train Loss: 0.031756006846470, Val Loss: 0.045838632253986', 'Epoch: 77, Train Loss: 0.029390133518193, Val Loss: 0.050999293160258', 'Epoch: 78, Train Loss: 0.066552434914878, Val Loss: 0.082819354353529', 'Epoch: 79, Train Loss: 0.075389512415443, Val Loss: 0.070546016097069', 'Epoch: 80, Train Loss: 0.052437674254179, Val Loss: 0.046871307037884', 'Epoch: 81, Train Loss: 0.050795715834413, Val Loss: 0.084417481680937', 'Epoch: 82, Train Loss: 0.048220719876034, Val Loss: 0.066152376771876', 'Epoch: 83, Train Loss: 0.038128950500063, Val Loss: 0.050363195100517', 'Epoch: 84, Train Loss: 0.031120543501207, Val Loss: 0.048748647935237', 'Epoch: 85, Train Loss: 0.036130445078015, Val Loss: 0.051834703677080', 'Epoch: 86, Train Loss: 0.034137521138681, Val Loss: 0.051229234869507', 'Epoch: 87, Train Loss: 0.030994775172855, Val Loss: 0.048836496686845', 'Epoch: 88, Train Loss: 0.029899160244635, Val Loss: 0.048820266443672', 'Epoch: 89, Train Loss: 0.029359817371837, Val Loss: 0.056376243320604', 'Epoch: 90, Train Loss: 0.030602160042950, Val Loss: 0.059325398651488', 'Epoch: 91, Train Loss: 0.031453572213650, Val Loss: 0.042987882187872', 'Epoch: 92, Train Loss: 0.028135175484100, Val Loss: 0.048390185319339', 'Epoch: 93, Train Loss: 0.024701254176242, Val Loss: 0.045259313149886', 'Epoch: 94, Train Loss: 0.027301777819438, Val Loss: 0.052061362869360', 'Epoch: 95, Train Loss: 0.029191537760198, Val Loss: 0.051899192064549', 'Epoch: 96, Train Loss: 0.031656565144658, Val Loss: 0.041763956263436', 'Epoch: 97, Train Loss: 0.026680972027991, Val Loss: 0.057523257353089', 'Epoch: 98, Train Loss: 0.029299252134349, Val Loss: 0.042357096335653', 'Epoch: 99, Train Loss: 0.024361560520317, Val Loss: 0.047019628074133', 'Epoch: 100, Train Loss: 0.027206885827971, Val Loss: 0.047049087895588', 'Epoch: 101, Train Loss: 0.027981351528849, Val Loss: 0.042085800940792', 'Epoch: 102, Train Loss: 0.028925495488303, Val Loss: 0.046877779461669', 'Epoch: 103, Train Loss: 0.026158099062741, Val Loss: 0.045002694008872', 'Epoch: 104, Train Loss: 0.028388030827045, Val Loss: 0.043268529811140', 'Epoch: 105, Train Loss: 0.025998740190906, Val Loss: 0.038771432372883', 'Epoch: 106, Train Loss: 0.026360283738800, Val Loss: 0.044583511341250', 'Epoch: 107, Train Loss: 0.024678216382329, Val Loss: 0.058632039662563', 'Epoch: 108, Train Loss: 0.027946603883590, Val Loss: 0.050975559039437', 'Epoch: 109, Train Loss: 0.024108023515769, Val Loss: 0.044476961491234', 'Epoch: 110, Train Loss: 0.021276829697724, Val Loss: 0.043310001266725', 'Epoch: 111, Train Loss: 0.023495838312166, Val Loss: 0.035859885202213', 'Epoch: 112, Train Loss: 0.029375116939523, Val Loss: 0.050601133794496', 'Epoch: 113, Train Loss: 0.028098471130111, Val Loss: 0.045469003588413', 'Epoch: 114, Train Loss: 0.025812474944230, Val Loss: 0.044304858610937', 'Epoch: 115, Train Loss: 0.021826754191092, Val Loss: 0.040888810473861', 'Epoch: 116, Train Loss: 0.027502466658396, Val Loss: 0.041083860549737', 'Epoch: 117, Train Loss: 0.019518773803221, Val Loss: 0.041019487392270', 'Epoch: 118, Train Loss: 0.025362919350820, Val Loss: 0.050537710557833', 'Epoch: 119, Train Loss: 0.026200083683112, Val Loss: 0.041141951625997', 'Epoch: 120, Train Loss: 0.022139371904944, Val Loss: 0.048070277538941', 'Epoch: 121, Train Loss: 0.023002460399376, Val Loss: 0.043355378971407', 'Epoch: 122, Train Loss: 0.023583031192954, Val Loss: 0.046595438016635', 'Epoch: 123, Train Loss: 0.022922523718859, Val Loss: 0.046806033982924', 'Epoch: 124, Train Loss: 0.022034885361791, Val Loss: 0.044236323147109', 'Epoch: 125, Train Loss: 0.025216298710023, Val Loss: 0.045634990572139', 'Epoch: 126, Train Loss: 0.026179036923817, Val Loss: 0.046562172670030', 'Epoch: 127, Train Loss: 0.024611748754978, Val Loss: 0.042710346621320', 'Epoch: 128, Train Loss: 0.026412679148572, Val Loss: 0.043872116528677', 'Epoch: 129, Train Loss: 0.026573929669602, Val Loss: 0.043882373988516', 'Epoch: 130, Train Loss: 0.024622574781201, Val Loss: 0.048251252564968', 'Epoch: 131, Train Loss: 0.026104526793850, Val Loss: 0.053785101143700', 'Epoch: 132, Train Loss: 0.021977450166430, Val Loss: 0.046898046085103', 'Epoch: 133, Train Loss: 0.022271147330425, Val Loss: 0.040214195960399', 'Epoch: 134, Train Loss: 0.021157773810306, Val Loss: 0.045864527847505', 'Epoch: 135, Train Loss: 0.021746352647564, Val Loss: 0.046487080723499', 'Epoch: 136, Train Loss: 0.023210996096688, Val Loss: 0.053422095677392', 'Epoch: 137, Train Loss: 0.027184496899801, Val Loss: 0.060952123226316', 'Epoch: 138, Train Loss: 0.022948781494051, Val Loss: 0.044614315484509', 'Epoch: 139, Train Loss: 0.025810537460659, Val Loss: 0.048783886726155', 'Epoch: 140, Train Loss: 0.021899689654154, Val Loss: 0.049158415108016', 'Epoch: 141, Train Loss: 0.019551463026021, Val Loss: 0.042752491084464', 'Epoch: 142, Train Loss: 0.024974666402808, Val Loss: 0.050923964065133', 'Epoch: 143, Train Loss: 0.023246191974197, Val Loss: 0.041514566111745', 'Epoch: 144, Train Loss: 0.024186658140804, Val Loss: 0.052930227593716', 'Epoch: 145, Train Loss: 0.022931739488350, Val Loss: 0.044348211225235', 'Epoch: 146, Train Loss: 0.022123394201377, Val Loss: 0.044651013545015', 'Epoch: 147, Train Loss: 0.018366694250809, Val Loss: 0.042180061396776', 'Epoch: 148, Train Loss: 0.019840577683811, Val Loss: 0.040921897740301', 'Epoch: 149, Train Loss: 0.019540004565247, Val Loss: 0.043954151964775', 'Epoch: 150, Train Loss: 0.023906438079263, Val Loss: 0.049880897485171', 'Epoch: 151, Train Loss: 0.018306122760155, Val Loss: 0.041035620411011', 'Epoch: 152, Train Loss: 0.021195194351354, Val Loss: 0.043860130844581', 'Epoch: 153, Train Loss: 0.019405495907579, Val Loss: 0.042916603781509', 'Epoch: 154, Train Loss: 0.022212376086307, Val Loss: 0.044312773942665', 'Epoch: 155, Train Loss: 0.022980255074799, Val Loss: 0.040144409081250', 'Epoch: 156, Train Loss: 0.020411777509642, Val Loss: 0.048413234085522', 'Epoch: 157, Train Loss: 0.021054466055440, Val Loss: 0.041732903894489', 'Epoch: 158, Train Loss: 0.020178396653916, Val Loss: 0.045879780343085', 'Epoch: 159, Train Loss: 0.019891255934324, Val Loss: 0.045807306076202', 'Epoch: 160, Train Loss: 0.020106031692454, Val Loss: 0.044275780462406', 'Epoch: 161, Train Loss: 0.020531581182565, Val Loss: 0.043567471488407', 'Epoch: 162, Train Loss: 0.023244192823768, Val Loss: 0.041357883167538', 'Epoch: 163, Train Loss: 0.021622100445841, Val Loss: 0.048913445662368', 'Epoch: 164, Train Loss: 0.021090521410640, Val Loss: 0.039342388609481', 'Epoch: 165, Train Loss: 0.019356853860830, Val Loss: 0.038838439536366', 'Epoch: 166, Train Loss: 0.018491266894021, Val Loss: 0.046811939019597', 'Epoch: 167, Train Loss: 0.021123187150806, Val Loss: 0.041606071884885', 'Epoch: 168, Train Loss: 0.018078362901828, Val Loss: 0.043763017056115', 'Epoch: 169, Train Loss: 0.019391564319709, Val Loss: 0.044502686384614', 'Epoch: 170, Train Loss: 0.019222082304103, Val Loss: 0.042803800551955', 'Epoch: 171, Train Loss: 0.020412792052541, Val Loss: 0.044861001978544', 'Epoch: 172, Train Loss: 0.021114350961787, Val Loss: 0.042351777058546', 'Epoch: 173, Train Loss: 0.020539388526231, Val Loss: 0.044484989774047', 'Epoch: 174, Train Loss: 0.017898335653756, Val Loss: 0.042685221753676', 'Epoch: 175, Train Loss: 0.017304902896285, Val Loss: 0.046221175978920', 'Epoch: 176, Train Loss: 0.018638780673168, Val Loss: 0.043323347288551', 'Epoch: 177, Train Loss: 0.015896249096841, Val Loss: 0.043633614130544', 'Epoch: 178, Train Loss: 0.022455050743052, Val Loss: 0.044115476282031', 'Epoch: 179, Train Loss: 0.022312664692955, Val Loss: 0.041584270639401', 'Epoch: 180, Train Loss: 0.022483366541564, Val Loss: 0.043837077577006', 'Epoch: 181, Train Loss: 0.018756369860577, Val Loss: 0.043775570155545', 'Epoch: 182, Train Loss: 0.017919301121895, Val Loss: 0.041829709372850', 'Epoch: 183, Train Loss: 0.018687613907137, Val Loss: 0.041017847869432', 'Epoch: 184, Train Loss: 0.019378545561007, Val Loss: 0.040835395173141', 'Epoch: 185, Train Loss: 0.020467129402927, Val Loss: 0.043260554895934', 'Epoch: 186, Train Loss: 0.020933623625232, Val Loss: 0.045648681183317', 'Epoch: 187, Train Loss: 0.018410379665771, Val Loss: 0.042349965593806', 'Epoch: 188, Train Loss: 0.018263568769076, Val Loss: 0.041790213873328', 'Epoch: 189, Train Loss: 0.019261690521879, Val Loss: 0.043086865535853', 'Epoch: 190, Train Loss: 0.018155989835837, Val Loss: 0.043624571185898', 'Epoch: 191, Train Loss: 0.019763722949262, Val Loss: 0.042583475312726', 'Epoch: 192, Train Loss: 0.019367684410619, Val Loss: 0.041185258097495', 'Epoch: 193, Train Loss: 0.016580097377300, Val Loss: 0.040839734374348', 'Epoch: 194, Train Loss: 0.015911102827106, Val Loss: 0.041192228792969', 'Epoch: 195, Train Loss: 0.019816782458552, Val Loss: 0.041558469730345', 'Epoch: 196, Train Loss: 0.020054532214999, Val Loss: 0.041828484429667', 'Epoch: 197, Train Loss: 0.016790917874979, Val Loss: 0.041773774604680', 'Epoch: 198, Train Loss: 0.017317737718778, Val Loss: 0.041797673442599', 'Epoch: 199, Train Loss: 0.017236789954560, Val Loss: 0.041825749967812']","[ 471.1403     153.8793     290.7542     598.37305    325.16803
  740.4659     400.95618   1032.688      483.66537    626.5006
  337.39804     63.19983      5.4628296  531.7776     572.98
  562.8819     383.73654   1327.7366     418.3215     418.18646
 1111.6362    1044.3005     410.69217    632.6117     770.8096
  243.9403       2.0499268  617.8216     138.60297     10.239746
  259.98862    840.6533     672.4115     828.5887     491.27667
  849.557       13.723694   780.819      260.51508   1192.4822
  241.62308    334.45892     54.5943     694.4518    1219.9059
  730.69086    384.54898     48.199646   568.3642     649.0148
  279.37943     20.586472   401.69052    477.40497    838.6971
  471.95917    125.53729    384.86105    922.0249     541.7541
  564.26196     80.541504   307.5845     738.6224     417.87872
  303.49234   1132.605      649.5345     997.83997   1077.1912
  326.62158    315.92706    721.78955    895.2418     202.45238
  351.98355    608.1203     670.70856   1119.0164     517.8821
  265.24066     53.80777    915.9963    1082.7795     600.7388
  284.34714    122.99805     85.57712    284.28488    907.08356
    6.329773   485.5377      25.92746    624.78357     49.893707
 1062.8188     797.8456     404.75803    512.49774    457.61334
  277.92847    321.62332    192.59299    274.24643    893.3407
  649.3793     319.4779     479.95258    773.51013    982.65375
  559.5322     229.95102   1298.9675     991.0653     867.60095
  439.27567     41.41095    455.4604     296.6674     116.64441
  580.84143    540.8015    1137.2391     888.42957    232.84521
  578.2854    1317.5714     792.812      307.88156    220.76721
  290.97983    540.59924    909.3096     671.03394    644.0965
  604.7989     869.3708     904.1972   ]","[ 399.20752   138.42291   330.70428   436.30197   344.38074   728.6481
  415.20737  1028.3179    478.6834    577.6089    326.01068   197.82156
   70.17694   463.6925    485.9011    579.69165   379.86484  1261.4836
  469.24005   486.42957  1046.6766   1041.0613    377.13107   606.35547
  827.5133    189.2962    140.3122    449.5403    109.52669   144.60818
  280.35822   776.896     604.641     714.68744   431.19193   769.97
  102.75949   767.4138    250.64099  1270.0798    165.97354   296.19662
  103.529434  746.85095  1107.5398    631.0831    357.70425   139.41971
  546.53357   652.6526    283.16177    67.83078   359.31818   450.8718
  845.6755    493.3718     83.50519   429.37128   947.6389    744.51373
  569.84216   273.58054   359.79742   707.5124    471.55988   287.0541
 1013.4477    628.348    1045.2988    959.91      290.46753   310.84418
  663.9432    886.09607   191.10803   429.08218   554.97565   533.5234
 1175.3517    473.70056   256.3181    123.29208   944.333    1111.0034
  540.9452    286.05423   263.08765   193.48993   238.80438   878.1356
  308.7429    309.3046    143.90363   535.3367    290.85455   845.6079
  773.77637   353.4096    668.55676   551.2601    231.34346   274.91208
  192.74419   278.96344   680.42346   673.4516    352.81024   454.21774
  715.2156    892.0719    518.954     230.55562  1371.3143   1044.2661
  841.95844   415.33707    90.63109   419.42896   217.40332   145.3432
  386.5799    332.8323   1250.1375    974.80615   159.6839    331.42355
  991.6675    763.45874   295.92892   137.91656   225.37259   602.3539
  919.04944   715.9634    584.4634    597.83435   964.83044  1059.283   ]",67.101166,8403.436,91.67025442789499
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 0.386088890688760, Val Loss: 0.398876056075096', 'Epoch: 1, Train Loss: 0.385221702711923, Val Loss: 0.394869325287414', 'Epoch: 2, Train Loss: 0.383586772850582, Val Loss: 0.390499591150067', 'Epoch: 3, Train Loss: 0.367420324257442, Val Loss: 0.380726393650879', 'Epoch: 4, Train Loss: 0.347385238323893, Val Loss: 0.350614198116642', 'Epoch: 5, Train Loss: 0.282356086586203, Val Loss: 0.265284878286448', 'Epoch: 6, Train Loss: 0.181877292692661, Val Loss: 0.153131815971750', 'Epoch: 7, Train Loss: 0.127995197262083, Val Loss: 0.164246954249613', 'Epoch: 8, Train Loss: 0.115125139909131, Val Loss: 0.134579256064061', 'Epoch: 9, Train Loss: 0.119003489613533, Val Loss: 0.135811546267095', 'Epoch: 10, Train Loss: 0.099315259073462, Val Loss: 0.116147732305707', 'Epoch: 11, Train Loss: 0.083870695371713, Val Loss: 0.099638935404293', 'Epoch: 12, Train Loss: 0.075531146622130, Val Loss: 0.088536689735272', 'Epoch: 13, Train Loss: 0.074194556900433, Val Loss: 0.088299680593826', 'Epoch: 14, Train Loss: 0.077041089002575, Val Loss: 0.075934719407197', 'Epoch: 15, Train Loss: 0.062238822824189, Val Loss: 0.083124798729621', 'Epoch: 16, Train Loss: 0.075393997664962, Val Loss: 0.060955292855700', 'Epoch: 17, Train Loss: 0.054087852260896, Val Loss: 0.072965836999091', 'Epoch: 18, Train Loss: 0.053766641632787, Val Loss: 0.070016353362889', 'Epoch: 19, Train Loss: 0.057883954473904, Val Loss: 0.079084224406291', 'Epoch: 20, Train Loss: 0.052166496270469, Val Loss: 0.071814841731931', 'Epoch: 21, Train Loss: 0.055966596518244, Val Loss: 0.060672995436824', 'Epoch: 22, Train Loss: 0.057512712664902, Val Loss: 0.090392572861729', 'Epoch: 23, Train Loss: 0.058903934434056, Val Loss: 0.048107911973740', 'Epoch: 24, Train Loss: 0.046548236427563, Val Loss: 0.056391199740271', 'Epoch: 25, Train Loss: 0.041132631977754, Val Loss: 0.056329125990019', 'Epoch: 26, Train Loss: 0.060486708767712, Val Loss: 0.104743373806052', 'Epoch: 27, Train Loss: 0.070274318435362, Val Loss: 0.080518470907753', 'Epoch: 28, Train Loss: 0.054949599451252, Val Loss: 0.077706997734353', 'Epoch: 29, Train Loss: 0.041998186547841, Val Loss: 0.066496611939687', 'Epoch: 30, Train Loss: 0.045527253832136, Val Loss: 0.068694384599274', 'Epoch: 31, Train Loss: 0.044838568461793, Val Loss: 0.061891960713899', 'Epoch: 32, Train Loss: 0.047412396009479, Val Loss: 0.074653617021712', 'Epoch: 33, Train Loss: 0.042293285152742, Val Loss: 0.073356507741141', 'Epoch: 34, Train Loss: 0.058993824624590, Val Loss: 0.060782706195658', 'Epoch: 35, Train Loss: 0.061595440975257, Val Loss: 0.112709529697895', 'Epoch: 36, Train Loss: 0.069659258105925, Val Loss: 0.087473363022913', 'Epoch: 37, Train Loss: 0.054095420055091, Val Loss: 0.064179119456447', 'Epoch: 38, Train Loss: 0.049196734891406, Val Loss: 0.063222470947287', 'Epoch: 39, Train Loss: 0.039441889018885, Val Loss: 0.063395372902354', 'Epoch: 40, Train Loss: 0.045284150434392, Val Loss: 0.058066220954061', 'Epoch: 41, Train Loss: 0.049497458019427, Val Loss: 0.069655514293999', 'Epoch: 42, Train Loss: 0.049928366871817, Val Loss: 0.070468684291524', 'Epoch: 43, Train Loss: 0.047257864182549, Val Loss: 0.047383367676627', 'Epoch: 44, Train Loss: 0.035784769670240, Val Loss: 0.044875775908374', 'Epoch: 45, Train Loss: 0.058754246415836, Val Loss: 0.103509733114730', 'Epoch: 46, Train Loss: 0.054971594629543, Val Loss: 0.072897722549511', 'Epoch: 47, Train Loss: 0.046438540731158, Val Loss: 0.071779568990072', 'Epoch: 48, Train Loss: 0.040977241471410, Val Loss: 0.060368347546142', 'Epoch: 49, Train Loss: 0.037411413953773, Val Loss: 0.059388208259462', 'Epoch: 50, Train Loss: 0.046586251152413, Val Loss: 0.050250957945757', 'Epoch: 51, Train Loss: 0.049256721112345, Val Loss: 0.088094623180840', 'Epoch: 52, Train Loss: 0.063640849664807, Val Loss: 0.049107198084543', 'Epoch: 53, Train Loss: 0.044934546574950, Val Loss: 0.065548882791490', 'Epoch: 54, Train Loss: 0.036157203572137, Val Loss: 0.070495663605856', 'Epoch: 55, Train Loss: 0.038290421744542, Val Loss: 0.083425113366860', 'Epoch: 56, Train Loss: 0.037861960407879, Val Loss: 0.057072988118638', 'Epoch: 57, Train Loss: 0.035778491358672, Val Loss: 0.066519767497525', 'Epoch: 58, Train Loss: 0.036800746140735, Val Loss: 0.053184601859274', 'Epoch: 59, Train Loss: 0.037783206440508, Val Loss: 0.055146641295516', 'Epoch: 60, Train Loss: 0.034819329689656, Val Loss: 0.053831997242841', 'Epoch: 61, Train Loss: 0.032811094740672, Val Loss: 0.065399132160978', 'Epoch: 62, Train Loss: 0.035192929873509, Val Loss: 0.050992165014825', 'Epoch: 63, Train Loss: 0.028088615142873, Val Loss: 0.053440555817250', 'Epoch: 64, Train Loss: 0.035365692472884, Val Loss: 0.041721501839206', 'Epoch: 65, Train Loss: 0.032159484390702, Val Loss: 0.042790727802750', 'Epoch: 66, Train Loss: 0.030505644689713, Val Loss: 0.058878351708479', 'Epoch: 67, Train Loss: 0.025949788279831, Val Loss: 0.044681836596944', 'Epoch: 68, Train Loss: 0.028076432512275, Val Loss: 0.047318798659200', 'Epoch: 69, Train Loss: 0.027975145328258, Val Loss: 0.057343721163995', 'Epoch: 70, Train Loss: 0.027455245676850, Val Loss: 0.057813327759504', 'Epoch: 71, Train Loss: 0.025618021243385, Val Loss: 0.043342779531623', 'Epoch: 72, Train Loss: 0.031265674691115, Val Loss: 0.045498034465268', 'Epoch: 73, Train Loss: 0.028459460474551, Val Loss: 0.047955718230117', 'Epoch: 74, Train Loss: 0.027749021005418, Val Loss: 0.062355944265922', 'Epoch: 75, Train Loss: 0.027124572545290, Val Loss: 0.045261445483475', 'Epoch: 76, Train Loss: 0.034530116245151, Val Loss: 0.052709169121403', 'Epoch: 77, Train Loss: 0.029127020921026, Val Loss: 0.047143442838481', 'Epoch: 78, Train Loss: 0.032424180103200, Val Loss: 0.053524482656609', 'Epoch: 79, Train Loss: 0.037811266258359, Val Loss: 0.049424800344489', 'Epoch: 80, Train Loss: 0.030255222693086, Val Loss: 0.045009777937649', 'Epoch: 81, Train Loss: 0.036679749909256, Val Loss: 0.073628890469219', 'Epoch: 82, Train Loss: 0.033112621067890, Val Loss: 0.070897104839484', 'Epoch: 83, Train Loss: 0.030795197933912, Val Loss: 0.056134320795536', 'Epoch: 84, Train Loss: 0.025439762044698, Val Loss: 0.050354082532453', 'Epoch: 85, Train Loss: 0.029862439525979, Val Loss: 0.051525528175813', 'Epoch: 86, Train Loss: 0.029205783004207, Val Loss: 0.059444602522435', 'Epoch: 87, Train Loss: 0.025278562679887, Val Loss: 0.057498035162236', 'Epoch: 88, Train Loss: 0.028272936918906, Val Loss: 0.056531104287415', 'Epoch: 89, Train Loss: 0.026259137184492, Val Loss: 0.065413242445864', 'Epoch: 90, Train Loss: 0.031828292911606, Val Loss: 0.075586509298195', 'Epoch: 91, Train Loss: 0.030023139236229, Val Loss: 0.049965474980347', 'Epoch: 92, Train Loss: 0.026121956030173, Val Loss: 0.058794872270841', 'Epoch: 93, Train Loss: 0.027725290640124, Val Loss: 0.054311936664762', 'Epoch: 94, Train Loss: 0.029790641473872, Val Loss: 0.056048429147764', 'Epoch: 95, Train Loss: 0.027504754252732, Val Loss: 0.053465784047589', 'Epoch: 96, Train Loss: 0.027253093464034, Val Loss: 0.054698514385205', 'Epoch: 97, Train Loss: 0.024327935850514, Val Loss: 0.063135492192073', 'Epoch: 98, Train Loss: 0.026163487961250, Val Loss: 0.046029745826893', 'Epoch: 99, Train Loss: 0.023990769604487, Val Loss: 0.055414832112464', 'Epoch: 100, Train Loss: 0.027024618749108, Val Loss: 0.053741111674092', 'Epoch: 101, Train Loss: 0.026963143875556, Val Loss: 0.043460613116622', 'Epoch: 102, Train Loss: 0.030402498984975, Val Loss: 0.047781144240589', 'Epoch: 103, Train Loss: 0.025743526273540, Val Loss: 0.060874076616583', 'Epoch: 104, Train Loss: 0.027434020702328, Val Loss: 0.053009444113934', 'Epoch: 105, Train Loss: 0.027177893423608, Val Loss: 0.047704067137657', 'Epoch: 106, Train Loss: 0.027219245808997, Val Loss: 0.059064593279000', 'Epoch: 107, Train Loss: 0.026264804548451, Val Loss: 0.066126545044509', 'Epoch: 108, Train Loss: 0.026266614573875, Val Loss: 0.061322244900194', 'Epoch: 109, Train Loss: 0.024711824887033, Val Loss: 0.055134003812617', 'Epoch: 110, Train Loss: 0.021190266723612, Val Loss: 0.054910647428849', 'Epoch: 111, Train Loss: 0.023263802552330, Val Loss: 0.042978969148614', 'Epoch: 112, Train Loss: 0.026839056451406, Val Loss: 0.056872135931344', 'Epoch: 113, Train Loss: 0.024450017604977, Val Loss: 0.052477651247472', 'Epoch: 114, Train Loss: 0.025258768083794, Val Loss: 0.055720192464915', 'Epoch: 115, Train Loss: 0.019724164557244, Val Loss: 0.047178435054692', 'Epoch: 116, Train Loss: 0.025705592839846, Val Loss: 0.050669599832459', 'Epoch: 117, Train Loss: 0.020324235249843, Val Loss: 0.052232668706865', 'Epoch: 118, Train Loss: 0.024382215858038, Val Loss: 0.063083133011153', 'Epoch: 119, Train Loss: 0.025724002492747, Val Loss: 0.049227960181959', 'Epoch: 120, Train Loss: 0.021778289694339, Val Loss: 0.053002809541243', 'Epoch: 121, Train Loss: 0.021755977467235, Val Loss: 0.052744395353577', 'Epoch: 122, Train Loss: 0.023090707869934, Val Loss: 0.055956714137486', 'Epoch: 123, Train Loss: 0.022243376289095, Val Loss: 0.058773044186334', 'Epoch: 124, Train Loss: 0.023343674040266, Val Loss: 0.053870080546899', 'Epoch: 125, Train Loss: 0.026981095184705, Val Loss: 0.055361546350248', 'Epoch: 126, Train Loss: 0.023793969369893, Val Loss: 0.053283887999979', 'Epoch: 127, Train Loss: 0.024297247507742, Val Loss: 0.047784264340545', 'Epoch: 128, Train Loss: 0.027488189483328, Val Loss: 0.051515886842301', 'Epoch: 129, Train Loss: 0.024914700072259, Val Loss: 0.051826989052422', 'Epoch: 130, Train Loss: 0.025032514972346, Val Loss: 0.055301148049308', 'Epoch: 131, Train Loss: 0.024017438891211, Val Loss: 0.055941379657297', 'Epoch: 132, Train Loss: 0.022011358091342, Val Loss: 0.053334522032828', 'Epoch: 133, Train Loss: 0.021289308089763, Val Loss: 0.049577954253464', 'Epoch: 134, Train Loss: 0.022921009920537, Val Loss: 0.051878489723260', 'Epoch: 135, Train Loss: 0.022468600289098, Val Loss: 0.054976812394505', 'Epoch: 136, Train Loss: 0.021201774477959, Val Loss: 0.056383955094850', 'Epoch: 137, Train Loss: 0.024274325596967, Val Loss: 0.066011808869062', 'Epoch: 138, Train Loss: 0.022431909239718, Val Loss: 0.054112817753445', 'Epoch: 139, Train Loss: 0.026502684157874, Val Loss: 0.052285530350425', 'Epoch: 140, Train Loss: 0.020794338214078, Val Loss: 0.053604171131596', 'Epoch: 141, Train Loss: 0.019528120223965, Val Loss: 0.050112673730561', 'Epoch: 142, Train Loss: 0.023806293361953, Val Loss: 0.052695034466910', 'Epoch: 143, Train Loss: 0.023669184385134, Val Loss: 0.047061329707503', 'Epoch: 144, Train Loss: 0.023581145198217, Val Loss: 0.065236507886738', 'Epoch: 145, Train Loss: 0.023999022785574, Val Loss: 0.049565103300142', 'Epoch: 146, Train Loss: 0.021617515943944, Val Loss: 0.052438595755534', 'Epoch: 147, Train Loss: 0.019075465787734, Val Loss: 0.057013849586700', 'Epoch: 148, Train Loss: 0.020305722885366, Val Loss: 0.049362660865441', 'Epoch: 149, Train Loss: 0.019419658130833, Val Loss: 0.051566311807343', 'Epoch: 150, Train Loss: 0.023048291714596, Val Loss: 0.055391667072069', 'Epoch: 151, Train Loss: 0.017583667167595, Val Loss: 0.050489169686581', 'Epoch: 152, Train Loss: 0.020752372286682, Val Loss: 0.054325625243964', 'Epoch: 153, Train Loss: 0.021092290524393, Val Loss: 0.053161786022511', 'Epoch: 154, Train Loss: 0.021051737679435, Val Loss: 0.052448827970886', 'Epoch: 155, Train Loss: 0.022499262222222, Val Loss: 0.050947698962056', 'Epoch: 156, Train Loss: 0.021873315264072, Val Loss: 0.060443705794486', 'Epoch: 157, Train Loss: 0.021421278161662, Val Loss: 0.051461793200085', 'Epoch: 158, Train Loss: 0.020150753203779, Val Loss: 0.057913336112644', 'Epoch: 159, Train Loss: 0.018973978369364, Val Loss: 0.053198882068197', 'Epoch: 160, Train Loss: 0.019627716990986, Val Loss: 0.051865055310455', 'Epoch: 161, Train Loss: 0.019578433928213, Val Loss: 0.050931442585407', 'Epoch: 162, Train Loss: 0.023125471148108, Val Loss: 0.047346066062649', 'Epoch: 163, Train Loss: 0.021889851095953, Val Loss: 0.057706523122209', 'Epoch: 164, Train Loss: 0.020380972485457, Val Loss: 0.048069697212089', 'Epoch: 165, Train Loss: 0.020152315364352, Val Loss: 0.049104483854590', 'Epoch: 166, Train Loss: 0.018223789254470, Val Loss: 0.055558280172673', 'Epoch: 167, Train Loss: 0.020935258229396, Val Loss: 0.050136805483789', 'Epoch: 168, Train Loss: 0.019016842956522, Val Loss: 0.052739606888005', 'Epoch: 169, Train Loss: 0.019182458586459, Val Loss: 0.053343059720867', 'Epoch: 170, Train Loss: 0.018627739045769, Val Loss: 0.050379272437457', 'Epoch: 171, Train Loss: 0.019573470644121, Val Loss: 0.052380592421149', 'Epoch: 172, Train Loss: 0.021436404037688, Val Loss: 0.050606507356420', 'Epoch: 173, Train Loss: 0.020652815832623, Val Loss: 0.054082728245042', 'Epoch: 174, Train Loss: 0.018910491839051, Val Loss: 0.051765580351154', 'Epoch: 175, Train Loss: 0.017506921863449, Val Loss: 0.054815906071753', 'Epoch: 176, Train Loss: 0.019002201102142, Val Loss: 0.051372605234836', 'Epoch: 177, Train Loss: 0.016303750686347, Val Loss: 0.052292099448316', 'Epoch: 178, Train Loss: 0.021187927440873, Val Loss: 0.050140355572556', 'Epoch: 179, Train Loss: 0.024452309523310, Val Loss: 0.048353134908459', 'Epoch: 180, Train Loss: 0.022533988047923, Val Loss: 0.050724342804063', 'Epoch: 181, Train Loss: 0.017618899366685, Val Loss: 0.050857575440949', 'Epoch: 182, Train Loss: 0.019652609447283, Val Loss: 0.051018652760170', 'Epoch: 183, Train Loss: 0.018855752556452, Val Loss: 0.050931082078905', 'Epoch: 184, Train Loss: 0.019385483648096, Val Loss: 0.049407773284298', 'Epoch: 185, Train Loss: 0.019033386638122, Val Loss: 0.051749250315356', 'Epoch: 186, Train Loss: 0.021851057718907, Val Loss: 0.056414426219734', 'Epoch: 187, Train Loss: 0.019025769417307, Val Loss: 0.052840012831218', 'Epoch: 188, Train Loss: 0.018609400905137, Val Loss: 0.051854225948001', 'Epoch: 189, Train Loss: 0.017785900405475, Val Loss: 0.052616985684091', 'Epoch: 190, Train Loss: 0.016528976615518, Val Loss: 0.052366845309734', 'Epoch: 191, Train Loss: 0.018627847744418, Val Loss: 0.050385894761844', 'Epoch: 192, Train Loss: 0.020280675230814, Val Loss: 0.050039568238638', 'Epoch: 193, Train Loss: 0.015697011125407, Val Loss: 0.050443899055774', 'Epoch: 194, Train Loss: 0.016431605443358, Val Loss: 0.050312720577825', 'Epoch: 195, Train Loss: 0.017718679870346, Val Loss: 0.050239353920474', 'Epoch: 196, Train Loss: 0.019964732229710, Val Loss: 0.050466282914082', 'Epoch: 197, Train Loss: 0.018365738048617, Val Loss: 0.050034636405833', 'Epoch: 198, Train Loss: 0.015951599659664, Val Loss: 0.049824590484301', 'Epoch: 199, Train Loss: 0.017105972527393, Val Loss: 0.049861334151391']","[ 471.1403     153.8793     290.7542     598.37305    325.16803
  740.4659     400.95618   1032.688      483.66537    626.5006
  337.39804     63.19983      5.4628296  531.7776     572.98
  562.8819     383.73654   1327.7366     418.3215     418.18646
 1111.6362    1044.3005     410.69217    632.6117     770.8096
  243.9403       2.0499268  617.8216     138.60297     10.239746
  259.98862    840.6533     672.4115     828.5887     491.27667
  849.557       13.723694   780.819      260.51508   1192.4822
  241.62308    334.45892     54.5943     694.4518    1219.9059
  730.69086    384.54898     48.199646   568.3642     649.0148
  279.37943     20.586472   401.69052    477.40497    838.6971
  471.95917    125.53729    384.86105    922.0249     541.7541
  564.26196     80.541504   307.5845     738.6224     417.87872
  303.49234   1132.605      649.5345     997.83997   1077.1912
  326.62158    315.92706    721.78955    895.2418     202.45238
  351.98355    608.1203     670.70856   1119.0164     517.8821
  265.24066     53.80777    915.9963    1082.7795     600.7388
  284.34714    122.99805     85.57712    284.28488    907.08356
    6.329773   485.5377      25.92746    624.78357     49.893707
 1062.8188     797.8456     404.75803    512.49774    457.61334
  277.92847    321.62332    192.59299    274.24643    893.3407
  649.3793     319.4779     479.95258    773.51013    982.65375
  559.5322     229.95102   1298.9675     991.0653     867.60095
  439.27567     41.41095    455.4604     296.6674     116.64441
  580.84143    540.8015    1137.2391     888.42957    232.84521
  578.2854    1317.5714     792.812      307.88156    220.76721
  290.97983    540.59924    909.3096     671.03394    644.0965
  604.7989     869.3708     904.1972   ]","[ 434.76526   120.85657   320.21362   460.04727   327.5703    716.8709
  402.33755  1048.7004    468.4096    549.53406   321.95593   170.32922
   50.031067  485.17877   465.40375   534.6643    419.42105  1284.1902
  486.79794   488.17322  1069.8529   1035.3921    336.84106   577.6615
  776.1471    212.34155   103.54321   465.39865    85.145325  145.96115
  285.48856   812.94543   640.8273    727.60114   392.80197   755.1835
   82.75696   782.58936   274.68073  1216.9954    200.0202    299.75952
  126.245514  694.0492   1122.3246    684.9766    361.8763    177.55853
  576.3059    618.83954   281.9622     64.18913   332.44183   452.97412
  845.4156    477.64722    48.59192   472.51358   971.39624   739.93835
  571.3512    272.06012   364.36768   716.41516   422.2661    280.8691
 1024.3152    605.488     983.16724   989.3228    269.53754   338.5129
  669.48145   876.2656    209.45627   373.2909    565.5133    560.8887
 1197.6312    470.7753    266.46848   116.52013   943.6497   1099.8782
  549.66284   305.0366    286.70947   236.77887   221.1099    873.62964
  271.0979    307.395     100.79379   515.51807   348.08246   866.17834
  759.7446    342.56628   656.53845   529.37506   204.2626    244.4444
  201.20769   281.5099    703.9574    670.3415    364.61862   457.5808
  729.79175   927.12964   542.76465   245.20494  1346.5365   1030.1301
  884.4741    419.86096    99.81117   411.1022    210.15454   164.7905
  393.78345   313.31525  1181.9541    918.31055   157.47534   337.2462
  949.60175   745.5299    347.66254   192.78311   217.9797    650.3584
 1000.2163    749.7705    593.9128    617.6859    982.8574   1077.4359  ]",65.99782,8358.3125,91.42380707452517
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 0.452513903379440, Val Loss: 0.416110956307613', 'Epoch: 1, Train Loss: 0.432177117892674, Val Loss: 0.392234357920560', 'Epoch: 2, Train Loss: 0.424111230032785, Val Loss: 0.377154875885357', 'Epoch: 3, Train Loss: 0.393540667636054, Val Loss: 0.372848303029031', 'Epoch: 4, Train Loss: 0.403607675007411, Val Loss: 0.374612902150010', 'Epoch: 5, Train Loss: 0.406327711684363, Val Loss: 0.374499480832707', 'Epoch: 6, Train Loss: 0.402580142021179, Val Loss: 0.373410938364087', 'Epoch: 7, Train Loss: 0.389060697385243, Val Loss: 0.367971205350124', 'Epoch: 8, Train Loss: 0.384960434266499, Val Loss: 0.364779676451828', 'Epoch: 9, Train Loss: 0.402777829340526, Val Loss: 0.362407039512287', 'Epoch: 10, Train Loss: 0.385072857141495, Val Loss: 0.361736778056983', 'Epoch: 11, Train Loss: 0.382437688963754, Val Loss: 0.357100463274753', 'Epoch: 12, Train Loss: 0.374353579112462, Val Loss: 0.354329698013537', 'Epoch: 13, Train Loss: 0.385542175599507, Val Loss: 0.346078693866730', 'Epoch: 14, Train Loss: 0.358832265649523, Val Loss: 0.343490627678958', 'Epoch: 15, Train Loss: 0.369609645434788, Val Loss: 0.345229046814369', 'Epoch: 16, Train Loss: 0.354330258710044, Val Loss: 0.331650808905110', 'Epoch: 17, Train Loss: 0.347466809409005, Val Loss: 0.325447669534972', 'Epoch: 18, Train Loss: 0.347646466323308, Val Loss: 0.322265583457369', 'Epoch: 19, Train Loss: 0.330065614410809, Val Loss: 0.311135492541573', 'Epoch: 20, Train Loss: 0.317612858755248, Val Loss: 0.302581826845805', 'Epoch: 21, Train Loss: 0.312210551330021, Val Loss: 0.289768366199551', 'Epoch: 22, Train Loss: 0.301712870597839, Val Loss: 0.276283131404357', 'Epoch: 23, Train Loss: 0.277570339185851, Val Loss: 0.260092421914592', 'Epoch: 24, Train Loss: 0.266614447746958, Val Loss: 0.239295682220748', 'Epoch: 25, Train Loss: 0.231070199183055, Val Loss: 0.212185506567811', 'Epoch: 26, Train Loss: 0.199729844927788, Val Loss: 0.180247594912847', 'Epoch: 27, Train Loss: 0.172967163579805, Val Loss: 0.143045073205774', 'Epoch: 28, Train Loss: 0.135991443480764, Val Loss: 0.104412857104432', 'Epoch: 29, Train Loss: 0.105823251817908, Val Loss: 0.075775643979961', 'Epoch: 30, Train Loss: 0.088492074183055, Val Loss: 0.053885230596996', 'Epoch: 31, Train Loss: 0.075749723506825, Val Loss: 0.051181550335252', 'Epoch: 32, Train Loss: 0.069515978119203, Val Loss: 0.051976445638998', 'Epoch: 33, Train Loss: 0.061474958700793, Val Loss: 0.042864719642129', 'Epoch: 34, Train Loss: 0.061038018337318, Val Loss: 0.047079063613306', 'Epoch: 35, Train Loss: 0.056924133428505, Val Loss: 0.049427318019849', 'Epoch: 36, Train Loss: 0.060356194951705, Val Loss: 0.042379815244313', 'Epoch: 37, Train Loss: 0.054732204547950, Val Loss: 0.043659455904906', 'Epoch: 38, Train Loss: 0.056821417063475, Val Loss: 0.047532678327777', 'Epoch: 39, Train Loss: 0.057011230183499, Val Loss: 0.049656942599651', 'Epoch: 40, Train Loss: 0.053358390395130, Val Loss: 0.048074248275070', 'Epoch: 41, Train Loss: 0.049902344388621, Val Loss: 0.041331154378978', 'Epoch: 42, Train Loss: 0.053774878914867, Val Loss: 0.039964747191830', 'Epoch: 43, Train Loss: 0.053478330905948, Val Loss: 0.045487594310984', 'Epoch: 44, Train Loss: 0.051447439938784, Val Loss: 0.038812740282579', 'Epoch: 45, Train Loss: 0.048747633716890, Val Loss: 0.040441621885155', 'Epoch: 46, Train Loss: 0.048379351517984, Val Loss: 0.035669474552075', 'Epoch: 47, Train Loss: 0.047494292791401, Val Loss: 0.038497121948184', 'Epoch: 48, Train Loss: 0.045705383377416, Val Loss: 0.039692721809402', 'Epoch: 49, Train Loss: 0.045361268201045, Val Loss: 0.034772754054178', 'Epoch: 50, Train Loss: 0.042511167270797, Val Loss: 0.034707286987792', 'Epoch: 51, Train Loss: 0.045758211719138, Val Loss: 0.041143185713074', 'Epoch: 52, Train Loss: 0.044725069510085, Val Loss: 0.033748096250223', 'Epoch: 53, Train Loss: 0.041074593950595, Val Loss: 0.032736920723409', 'Epoch: 54, Train Loss: 0.039234134235552, Val Loss: 0.036513972575917', 'Epoch: 55, Train Loss: 0.045610202742474, Val Loss: 0.033986420455304', 'Epoch: 56, Train Loss: 0.046599610575608, Val Loss: 0.031424926424568', 'Epoch: 57, Train Loss: 0.042126631098134, Val Loss: 0.032373971221122', 'Epoch: 58, Train Loss: 0.044553977570363, Val Loss: 0.033799875640508', 'Epoch: 59, Train Loss: 0.040549999369042, Val Loss: 0.031309839338064', 'Epoch: 60, Train Loss: 0.040154713339039, Val Loss: 0.030244152146307', 'Epoch: 61, Train Loss: 0.044539311634643, Val Loss: 0.031628158733700', 'Epoch: 62, Train Loss: 0.045219319207328, Val Loss: 0.030093738527009', 'Epoch: 63, Train Loss: 0.038301320214357, Val Loss: 0.029674593246344', 'Epoch: 64, Train Loss: 0.043366236878293, Val Loss: 0.033113183058573', 'Epoch: 65, Train Loss: 0.039266131286110, Val Loss: 0.031815470168085', 'Epoch: 66, Train Loss: 0.037736023111003, Val Loss: 0.028481737400095', 'Epoch: 67, Train Loss: 0.045495091272252, Val Loss: 0.034054491781827', 'Epoch: 68, Train Loss: 0.044468770601920, Val Loss: 0.032531289440213', 'Epoch: 69, Train Loss: 0.043505001813173, Val Loss: 0.027881510555744', 'Epoch: 70, Train Loss: 0.038846761520420, Val Loss: 0.029024019498717', 'Epoch: 71, Train Loss: 0.038088618378554, Val Loss: 0.031121917972059', 'Epoch: 72, Train Loss: 0.035840079986623, Val Loss: 0.026917084261323', 'Epoch: 73, Train Loss: 0.038284246144550, Val Loss: 0.027075888758356', 'Epoch: 74, Train Loss: 0.034532016675387, Val Loss: 0.027314411871361', 'Epoch: 75, Train Loss: 0.035749142191240, Val Loss: 0.026763705254504', 'Epoch: 76, Train Loss: 0.037001020408102, Val Loss: 0.028002642433752', 'Epoch: 77, Train Loss: 0.036202366064702, Val Loss: 0.027393261140043', 'Epoch: 78, Train Loss: 0.033701143626656, Val Loss: 0.032281340748975', 'Epoch: 79, Train Loss: 0.039370416796633, Val Loss: 0.025378117055604', 'Epoch: 80, Train Loss: 0.036886638030410, Val Loss: 0.027330380046006', 'Epoch: 81, Train Loss: 0.036339951146926, Val Loss: 0.027560782929262', 'Epoch: 82, Train Loss: 0.035452805459499, Val Loss: 0.025144393076048', 'Epoch: 83, Train Loss: 0.036411404343588, Val Loss: 0.029233871422934', 'Epoch: 84, Train Loss: 0.035546125045844, Val Loss: 0.025563340295445', 'Epoch: 85, Train Loss: 0.035695955955556, Val Loss: 0.026883606657837', 'Epoch: 86, Train Loss: 0.035770751535892, Val Loss: 0.026474765868801', 'Epoch: 87, Train Loss: 0.036914944382651, Val Loss: 0.025024222040718', 'Epoch: 88, Train Loss: 0.035041563745056, Val Loss: 0.026212667086811', 'Epoch: 89, Train Loss: 0.034083844029478, Val Loss: 0.027031955393878', 'Epoch: 90, Train Loss: 0.033399570733309, Val Loss: 0.023299597937501', 'Epoch: 91, Train Loss: 0.032776681174125, Val Loss: 0.026327281287222', 'Epoch: 92, Train Loss: 0.035456518509558, Val Loss: 0.022771688234625', 'Epoch: 93, Train Loss: 0.033540033602289, Val Loss: 0.026827838158969', 'Epoch: 94, Train Loss: 0.034081735249077, Val Loss: 0.022305188813444', 'Epoch: 95, Train Loss: 0.034480908619506, Val Loss: 0.024091515464313', 'Epoch: 96, Train Loss: 0.036106756755284, Val Loss: 0.024379435926676', 'Epoch: 97, Train Loss: 0.035859754309058, Val Loss: 0.023203204470602', 'Epoch: 98, Train Loss: 0.034151359062110, Val Loss: 0.023285280235789', 'Epoch: 99, Train Loss: 0.035985470084207, Val Loss: 0.021643793718381', 'Epoch: 100, Train Loss: 0.030999687101160, Val Loss: 0.025104825300249', 'Epoch: 101, Train Loss: 0.033755355913724, Val Loss: 0.022407616403970', 'Epoch: 102, Train Loss: 0.036450907055821, Val Loss: 0.022934975384763', 'Epoch: 103, Train Loss: 0.032178301098091, Val Loss: 0.023959836612145', 'Epoch: 104, Train Loss: 0.032095627060958, Val Loss: 0.022211899472909', 'Epoch: 105, Train Loss: 0.033708585160119, Val Loss: 0.022145078602162', 'Epoch: 106, Train Loss: 0.032982469669410, Val Loss: 0.022230076067375', 'Epoch: 107, Train Loss: 0.031918689342482, Val Loss: 0.022576160616044', 'Epoch: 108, Train Loss: 0.034951819373029, Val Loss: 0.023125034615849', 'Epoch: 109, Train Loss: 0.032977890223265, Val Loss: 0.021818563906532', 'Epoch: 110, Train Loss: 0.031872059351632, Val Loss: 0.022278966325702', 'Epoch: 111, Train Loss: 0.029662826231548, Val Loss: 0.021203622899272', 'Epoch: 112, Train Loss: 0.032482367541109, Val Loss: 0.022762722025315', 'Epoch: 113, Train Loss: 0.029376583173871, Val Loss: 0.020738261441390', 'Epoch: 114, Train Loss: 0.033811237929123, Val Loss: 0.021928567100655', 'Epoch: 115, Train Loss: 0.030215188860893, Val Loss: 0.020749954111648', 'Epoch: 116, Train Loss: 0.031084232032299, Val Loss: 0.021223272563833', 'Epoch: 117, Train Loss: 0.030724490593587, Val Loss: 0.020729602060535', 'Epoch: 118, Train Loss: 0.029526730201074, Val Loss: 0.022293228768941', 'Epoch: 119, Train Loss: 0.032066702310528, Val Loss: 0.020735991102728', 'Epoch: 120, Train Loss: 0.031304207763502, Val Loss: 0.020442521651134', 'Epoch: 121, Train Loss: 0.029535477182695, Val Loss: 0.022082573198008', 'Epoch: 122, Train Loss: 0.032478234597615, Val Loss: 0.020451836965301', 'Epoch: 123, Train Loss: 0.031570454527225, Val Loss: 0.023332182543747', 'Epoch: 124, Train Loss: 0.029110999777913, Val Loss: 0.020731806613956', 'Epoch: 125, Train Loss: 0.031919815444521, Val Loss: 0.021755438241543', 'Epoch: 126, Train Loss: 0.030441916148577, Val Loss: 0.021187007201440', 'Epoch: 127, Train Loss: 0.031660099912967, Val Loss: 0.021993081565156', 'Epoch: 128, Train Loss: 0.028754444526775, Val Loss: 0.019778140792341', 'Epoch: 129, Train Loss: 0.030137025884220, Val Loss: 0.021672292584271', 'Epoch: 130, Train Loss: 0.030732534825802, Val Loss: 0.020080830845417', 'Epoch: 131, Train Loss: 0.029013694663133, Val Loss: 0.020935303954916', 'Epoch: 132, Train Loss: 0.031364363219057, Val Loss: 0.020496429367499', 'Epoch: 133, Train Loss: 0.029700863308140, Val Loss: 0.020932133902203', 'Epoch: 134, Train Loss: 0.029455792957119, Val Loss: 0.020212247121063', 'Epoch: 135, Train Loss: 0.030253588621105, Val Loss: 0.020444893362847', 'Epoch: 136, Train Loss: 0.029876044286149, Val Loss: 0.019562961364334', 'Epoch: 137, Train Loss: 0.027999760050859, Val Loss: 0.020075703604203', 'Epoch: 138, Train Loss: 0.027872025168368, Val Loss: 0.020024102519859', 'Epoch: 139, Train Loss: 0.026830559596419, Val Loss: 0.021013017856713', 'Epoch: 140, Train Loss: 0.031685878921832, Val Loss: 0.019804019142281', 'Epoch: 141, Train Loss: 0.029179049389703, Val Loss: 0.021034721849543', 'Epoch: 142, Train Loss: 0.027706675231457, Val Loss: 0.019828265307076', 'Epoch: 143, Train Loss: 0.028607014300568, Val Loss: 0.019586143902305', 'Epoch: 144, Train Loss: 0.030405525650297, Val Loss: 0.020873393073226', 'Epoch: 145, Train Loss: 0.027732152225716, Val Loss: 0.019397549274744', 'Epoch: 146, Train Loss: 0.027824952400156, Val Loss: 0.020209761900884', 'Epoch: 147, Train Loss: 0.028270592646939, Val Loss: 0.020945808709119', 'Epoch: 148, Train Loss: 0.030394092734371, Val Loss: 0.019887848446767', 'Epoch: 149, Train Loss: 0.029409684506910, Val Loss: 0.020098017077103', 'Epoch: 150, Train Loss: 0.028058800580246, Val Loss: 0.020158635678165', 'Epoch: 151, Train Loss: 0.027158568214093, Val Loss: 0.019357456233014', 'Epoch: 152, Train Loss: 0.027904095394271, Val Loss: 0.019741783087904', 'Epoch: 153, Train Loss: 0.027434520689504, Val Loss: 0.020231274379925', 'Epoch: 154, Train Loss: 0.027804049796292, Val Loss: 0.020131416844599', 'Epoch: 155, Train Loss: 0.031067609254803, Val Loss: 0.019612975079905', 'Epoch: 156, Train Loss: 0.027189713769725, Val Loss: 0.020483380127134', 'Epoch: 157, Train Loss: 0.027741394937038, Val Loss: 0.019776714909257', 'Epoch: 158, Train Loss: 0.028539760570441, Val Loss: 0.019678972661495', 'Epoch: 159, Train Loss: 0.027164587751031, Val Loss: 0.019530003833951', 'Epoch: 160, Train Loss: 0.028814852769886, Val Loss: 0.019421153165626', 'Epoch: 161, Train Loss: 0.030784598684737, Val Loss: 0.019983576723572', 'Epoch: 162, Train Loss: 0.025606018091951, Val Loss: 0.019305021022305', 'Epoch: 163, Train Loss: 0.027552266738244, Val Loss: 0.020177738402377', 'Epoch: 164, Train Loss: 0.027370192908815, Val Loss: 0.019636031861107', 'Epoch: 165, Train Loss: 0.028159403375217, Val Loss: 0.019705345910607', 'Epoch: 166, Train Loss: 0.031359091401100, Val Loss: 0.019195886103041', 'Epoch: 167, Train Loss: 0.024855539202690, Val Loss: 0.019602527390375', 'Epoch: 168, Train Loss: 0.027669471289430, Val Loss: 0.020256434200388', 'Epoch: 169, Train Loss: 0.030735797647919, Val Loss: 0.020373288429145', 'Epoch: 170, Train Loss: 0.027904968974846, Val Loss: 0.019826857542450', 'Epoch: 171, Train Loss: 0.026745305795755, Val Loss: 0.019279555897370', 'Epoch: 172, Train Loss: 0.030692555808595, Val Loss: 0.019125530778459', 'Epoch: 173, Train Loss: 0.026398314163089, Val Loss: 0.019882603350914', 'Epoch: 174, Train Loss: 0.027577539905906, Val Loss: 0.019290511185924', 'Epoch: 175, Train Loss: 0.027244310293879, Val Loss: 0.018835047372814', 'Epoch: 176, Train Loss: 0.027462328651122, Val Loss: 0.018953018849998', 'Epoch: 177, Train Loss: 0.026499819276588, Val Loss: 0.018962138304205', 'Epoch: 178, Train Loss: 0.027221301836627, Val Loss: 0.018846120459564', 'Epoch: 179, Train Loss: 0.027293723076582, Val Loss: 0.018916589631276', 'Epoch: 180, Train Loss: 0.024630182023559, Val Loss: 0.019385936416008', 'Epoch: 181, Train Loss: 0.028364234204803, Val Loss: 0.019635452070471', 'Epoch: 182, Train Loss: 0.029863732733897, Val Loss: 0.019243417872172', 'Epoch: 183, Train Loss: 0.025917883962393, Val Loss: 0.018898295125726', 'Epoch: 184, Train Loss: 0.027282424537199, Val Loss: 0.018832531672987', 'Epoch: 185, Train Loss: 0.025926237393703, Val Loss: 0.019085427915508', 'Epoch: 186, Train Loss: 0.028510658868722, Val Loss: 0.019118849526752', 'Epoch: 187, Train Loss: 0.026068156052913, Val Loss: 0.019191800701347', 'Epoch: 188, Train Loss: 0.026637727261654, Val Loss: 0.019180698546045', 'Epoch: 189, Train Loss: 0.028176841193012, Val Loss: 0.019271822984923', 'Epoch: 190, Train Loss: 0.025863032521946, Val Loss: 0.019236824221232', 'Epoch: 191, Train Loss: 0.027877615498645, Val Loss: 0.019043522407160', 'Epoch: 192, Train Loss: 0.025499972647854, Val Loss: 0.019024930555712', 'Epoch: 193, Train Loss: 0.025187142725502, Val Loss: 0.018973199763533', 'Epoch: 194, Train Loss: 0.026384949151959, Val Loss: 0.019065091217106', 'Epoch: 195, Train Loss: 0.029996065955077, Val Loss: 0.019106183483294', 'Epoch: 196, Train Loss: 0.025997298370515, Val Loss: 0.019150888265082', 'Epoch: 197, Train Loss: 0.027188367875559, Val Loss: 0.019172458881230', 'Epoch: 198, Train Loss: 0.027550102610673, Val Loss: 0.019178894828215', 'Epoch: 199, Train Loss: 0.028377099228757, Val Loss: 0.019179040283868']","[ 107.41203   148.7324    227.63188   234.35152   866.7076    584.69275
  694.16235   841.59564   410.69217   632.6117   1036.4531    907.98157
  772.06335  1092.5435    627.34265   767.047     124.67966   350.94843
  322.44098   384.01755   483.34933   854.8072    401.69052   477.40497
  104.14691   608.6197    548.6123    562.0951    953.24866   152.20337
  290.97983   540.59924    75.101135  656.6618    842.1108    181.13446
   66.407135  576.35913   614.2112     88.236694  491.27667   849.557
  290.7542    598.37305   355.69678    66.21356   770.8096    243.9403
  694.1144    419.9962     29.124512  631.9739    289.0574    254.19006
  788.8866     29.240356 1148.5032    238.58505    78.374756  780.3572
  263.2079    576.7727    296.6674    116.64441  1358.4927    919.4488
  628.44556   214.72958   621.6881    219.18134   219.71365   519.78284
  332.17014   231.96283   383.73654  1327.7366    146.80591   137.8653
  134.56152    53.66916   665.5387    149.79593   837.33105   120.45026
  584.2645    592.65674    19.23111   251.85663   537.7522    771.3589
  593.2932   1454.1199    212.51854   586.0235    261.44116   427.19064
  622.09314  1156.304     796.14014   888.3277    182.2226     57.230957
  326.62158   315.92706   349.61304   200.36572   228.07365   132.37265
  609.03577   801.6498    285.84372   894.3473    580.84143   540.8015
 1298.9675    991.0653    125.53729   384.86105   456.27487   297.80258
  884.9945    719.38544   166.28964   211.36594   491.02243   165.00015
  279.57117   675.881     190.96664   197.9035   1195.2932    999.6548
  243.94936   593.6415    893.3407    649.3793    169.21231   268.91907 ]","[ 7.22468262e+01  1.42304352e+02  2.45543076e+02  2.45105240e+02
  9.12986206e+02  5.92754944e+02  6.04415894e+02  9.82694153e+02
  3.59001678e+02  7.30033936e+02  1.08462378e+03  9.54166321e+02
  8.91741760e+02  8.91375977e+02  7.07771484e+02  8.49962402e+02
  1.51184265e+02  3.70323181e+02  3.54723572e+02  3.21524872e+02
  4.60498291e+02  9.21543030e+02  3.43260254e+02  4.62642700e+02
  3.91928711e+01  6.23124207e+02  4.31881287e+02  3.41969421e+02
  9.82259399e+02  1.74986938e+02  2.06774750e+02  4.78459412e+02
  1.18423737e+02  7.88878052e+02  8.53703735e+02  8.79787598e+01
  1.56605530e+01  6.11993286e+02  5.66912231e+02  9.78036194e+01
  2.87551453e+02  7.34379028e+02  2.87216888e+02  5.94708496e+02
  2.87933380e+02  2.55543152e+02  7.87192749e+02  1.80063965e+02
  7.00445923e+02  3.98454559e+02  3.79292297e+01  5.92281250e+02
  2.80487976e+02  2.42150375e+02  8.69634399e+02  1.18414062e+02
  1.19246167e+03  1.86385376e+02  4.30526428e+01  7.39836304e+02
  3.36743103e+02  5.34294800e+02  3.04852661e+02  1.92941132e+02
  1.41175525e+03  1.01692255e+03  7.20707092e+02  1.84584045e+02
  5.69319458e+02  2.33049866e+02  2.02471985e+02  5.23667847e+02
  2.81761871e+02  2.01937424e+02  4.45119110e+02  1.34265356e+03
  9.00012817e+01  1.74967667e+02  1.46785156e+02  1.50217590e+02
  6.75727051e+02  9.44051514e+01  8.24171021e+02  2.29105225e+02
  5.20693237e+02  5.53586548e+02  8.02575684e+00  2.39358490e+02
  5.56334412e+02  8.43635010e+02  5.09955048e+02  1.40972681e+03
  1.38239044e+02  5.94105957e+02  2.86074585e+02  3.76571686e+02
  4.82237274e+02  1.12425928e+03  8.60098022e+02  8.94136902e+02
  1.93879578e+02  4.20734558e+01  3.58563385e+02  2.81610748e+02
  3.78961639e+02  1.48449402e+02  2.33223923e+02  7.18413391e+01
  5.51702026e+02  6.93840698e+02  3.62618378e+02  9.71621094e+02
  2.83793518e+02  2.31612213e+02  1.32594458e+03  9.69330322e+02
 -1.14819336e+00  4.51711609e+02  4.31934418e+02  2.39997467e+02
  8.62728699e+02  5.73140808e+02  2.56377716e+02  1.15668427e+02
  5.33278564e+02  2.02222626e+02  2.71140625e+02  6.34915649e+02
  1.13910645e+02  1.08964172e+02  1.15801245e+03  9.95738281e+02
  1.45374115e+02  6.92083984e+02  7.50642273e+02  5.41709229e+02
  1.27001465e+02  2.60460876e+02]",58.385284,6199.9736,78.73991130813204
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 0.525048877511706, Val Loss: 0.628804544607798', 'Epoch: 1, Train Loss: 0.552967731441770, Val Loss: 0.622123009628720', 'Epoch: 2, Train Loss: 0.531150839158467, Val Loss: 0.619341479407416', 'Epoch: 3, Train Loss: 0.522370457649231, Val Loss: 0.611627538998922', 'Epoch: 4, Train Loss: 0.548366150685719, Val Loss: 0.604725612534417', 'Epoch: 5, Train Loss: 0.536077844245093, Val Loss: 0.601076894336277', 'Epoch: 6, Train Loss: 0.517380446195602, Val Loss: 0.592489242553711', 'Epoch: 7, Train Loss: 0.517164277178901, Val Loss: 0.585877736409505', 'Epoch: 8, Train Loss: 0.502228868859155, Val Loss: 0.594421108563741', 'Epoch: 9, Train Loss: 0.476393729448318, Val Loss: 0.582378718588087', 'Epoch: 10, Train Loss: 0.477618230240686, Val Loss: 0.567564129829407', 'Epoch: 11, Train Loss: 0.472270271607808, Val Loss: 0.561327775319417', 'Epoch: 12, Train Loss: 0.480558812618256, Val Loss: 0.540304793251885', 'Epoch: 13, Train Loss: 0.463240883180073, Val Loss: 0.529026574558682', 'Epoch: 14, Train Loss: 0.445079258510045, Val Loss: 0.507191909684075', 'Epoch: 15, Train Loss: 0.448563482080187, Val Loss: 0.510754466056824', 'Epoch: 16, Train Loss: 0.415697272334780, Val Loss: 0.502639571825663', 'Epoch: 17, Train Loss: 0.423468862261091, Val Loss: 0.474544664223989', 'Epoch: 18, Train Loss: 0.398900670664651, Val Loss: 0.448318647013770', 'Epoch: 19, Train Loss: 0.391686941896166, Val Loss: 0.441686140166389', 'Epoch: 20, Train Loss: 0.368766703775951, Val Loss: 0.411174608601464', 'Epoch: 21, Train Loss: 0.338537365198135, Val Loss: 0.382288595040639', 'Epoch: 22, Train Loss: 0.332234463521412, Val Loss: 0.334990342458089', 'Epoch: 23, Train Loss: 0.282342657446861, Val Loss: 0.309605850113763', 'Epoch: 24, Train Loss: 0.243870036942618, Val Loss: 0.241673443052504', 'Epoch: 25, Train Loss: 0.205920753734452, Val Loss: 0.192624770932727', 'Epoch: 26, Train Loss: 0.171150267124176, Val Loss: 0.154274791479111', 'Epoch: 27, Train Loss: 0.144609031932695, Val Loss: 0.117076943318049', 'Epoch: 28, Train Loss: 0.107557233955179, Val Loss: 0.113842129707336', 'Epoch: 29, Train Loss: 0.108016033257757, Val Loss: 0.096048702796300', 'Epoch: 30, Train Loss: 0.088766230004174, Val Loss: 0.097985335522228', 'Epoch: 31, Train Loss: 0.081902568893773, Val Loss: 0.092663808001412', 'Epoch: 32, Train Loss: 0.080559810357434, Val Loss: 0.088207337591383', 'Epoch: 33, Train Loss: 0.079731054604053, Val Loss: 0.090455085039139', 'Epoch: 34, Train Loss: 0.079122726406370, Val Loss: 0.082875864373313', 'Epoch: 35, Train Loss: 0.073805482792003, Val Loss: 0.088311723536915', 'Epoch: 36, Train Loss: 0.068833618823971, Val Loss: 0.083545476198196', 'Epoch: 37, Train Loss: 0.069956576185567, Val Loss: 0.092823051744037', 'Epoch: 38, Train Loss: 0.065113302852426, Val Loss: 0.085708220799764', 'Epoch: 39, Train Loss: 0.062280838510820, Val Loss: 0.087918476925956', 'Epoch: 40, Train Loss: 0.060946555009910, Val Loss: 0.085301738646295', 'Epoch: 41, Train Loss: 0.068941005638668, Val Loss: 0.093602978520923', 'Epoch: 42, Train Loss: 0.064301712704556, Val Loss: 0.085576052467028', 'Epoch: 43, Train Loss: 0.073935452316489, Val Loss: 0.091444455915027', 'Epoch: 44, Train Loss: 0.069034027733973, Val Loss: 0.091265878743596', 'Epoch: 45, Train Loss: 0.065239677471774, Val Loss: 0.086639735433790', 'Epoch: 46, Train Loss: 0.064602166414261, Val Loss: 0.088381969266468', 'Epoch: 47, Train Loss: 0.064494761505297, Val Loss: 0.085751147733794', 'Epoch: 48, Train Loss: 0.062109697077956, Val Loss: 0.086201601558261', 'Epoch: 49, Train Loss: 0.063997519867761, Val Loss: 0.087100792262289', 'Epoch: 50, Train Loss: 0.059311074869973, Val Loss: 0.088321427504222', 'Epoch: 51, Train Loss: 0.063409861975483, Val Loss: 0.091900789075428', 'Epoch: 52, Train Loss: 0.063332272959607, Val Loss: 0.091018542647362', 'Epoch: 53, Train Loss: 0.063943762864385, Val Loss: 0.086108606722620', 'Epoch: 54, Train Loss: 0.061610429414681, Val Loss: 0.090588369303279', 'Epoch: 55, Train Loss: 0.069265688104289, Val Loss: 0.092109446724256', 'Epoch: 56, Train Loss: 0.062662786138909, Val Loss: 0.091910493042734', 'Epoch: 57, Train Loss: 0.061909306794405, Val Loss: 0.087651224599944', 'Epoch: 58, Train Loss: 0.060685488262347, Val Loss: 0.089359238743782', 'Epoch: 59, Train Loss: 0.058957971632481, Val Loss: 0.089637411965264', 'Epoch: 60, Train Loss: 0.059329763587032, Val Loss: 0.089282462994258', 'Epoch: 61, Train Loss: 0.061284585722855, Val Loss: 0.097713218794929', 'Epoch: 62, Train Loss: 0.059355800705297, Val Loss: 0.088463177283605', 'Epoch: 63, Train Loss: 0.059989368276937, Val Loss: 0.092784661385748', 'Epoch: 64, Train Loss: 0.064314660217081, Val Loss: 0.089513273702727', 'Epoch: 65, Train Loss: 0.060745109404836, Val Loss: 0.089976655112373', 'Epoch: 66, Train Loss: 0.058007171643632, Val Loss: 0.096519538097911', 'Epoch: 67, Train Loss: 0.064801543951035, Val Loss: 0.088825954331292', 'Epoch: 68, Train Loss: 0.058554582829986, Val Loss: 0.089870260821448', 'Epoch: 69, Train Loss: 0.060227732041052, Val Loss: 0.094611906343036', 'Epoch: 70, Train Loss: 0.060196234179395, Val Loss: 0.089428972866800', 'Epoch: 71, Train Loss: 0.061982000512736, Val Loss: 0.094611611631182', 'Epoch: 72, Train Loss: 0.069883864372969, Val Loss: 0.097161264883147', 'Epoch: 73, Train Loss: 0.052968521735498, Val Loss: 0.090703318516413', 'Epoch: 74, Train Loss: 0.060753885124411, Val Loss: 0.089013937446806', 'Epoch: 75, Train Loss: 0.056807287037373, Val Loss: 0.090947084956699', 'Epoch: 76, Train Loss: 0.060368066387517, Val Loss: 0.091866400506761', 'Epoch: 77, Train Loss: 0.058835309531007, Val Loss: 0.091892785496182', 'Epoch: 78, Train Loss: 0.060519178531000, Val Loss: 0.092202122012774', 'Epoch: 79, Train Loss: 0.065153057553938, Val Loss: 0.092791739437315', 'Epoch: 80, Train Loss: 0.065228323851313, Val Loss: 0.093014491928948', 'Epoch: 81, Train Loss: 0.056329151881593, Val Loss: 0.091742489073012', 'Epoch: 82, Train Loss: 0.062371412558215, Val Loss: 0.095679567919837', 'Epoch: 83, Train Loss: 0.059142690151930, Val Loss: 0.092698158489333', 'Epoch: 84, Train Loss: 0.058784517858710, Val Loss: 0.091801418198480', 'Epoch: 85, Train Loss: 0.058229473020349, Val Loss: 0.091947287321091', 'Epoch: 86, Train Loss: 0.050351132239614, Val Loss: 0.091800833741824', 'Epoch: 87, Train Loss: 0.057829287435327, Val Loss: 0.092236267195808', 'Epoch: 88, Train Loss: 0.057413313537836, Val Loss: 0.091003851758109', 'Epoch: 89, Train Loss: 0.053555065499885, Val Loss: 0.091850413216485', 'Epoch: 90, Train Loss: 0.059131863926138, Val Loss: 0.091010140048133', 'Epoch: 91, Train Loss: 0.062488255756242, Val Loss: 0.092074074678951', 'Epoch: 92, Train Loss: 0.058865009141820, Val Loss: 0.090952916277779', 'Epoch: 93, Train Loss: 0.059418349925961, Val Loss: 0.091296533743540', 'Epoch: 94, Train Loss: 0.055904901985611, Val Loss: 0.091886932651202', 'Epoch: 95, Train Loss: 0.057920049875975, Val Loss: 0.090638549791442', 'Epoch: 96, Train Loss: 0.057027987603630, Val Loss: 0.091547856728236', 'Epoch: 97, Train Loss: 0.056315197476319, Val Loss: 0.089149733384450', 'Epoch: 98, Train Loss: 0.057263525468963, Val Loss: 0.093078583478928', 'Epoch: 99, Train Loss: 0.058865343885762, Val Loss: 0.091392836636967', 'Epoch: 100, Train Loss: 0.056852028838226, Val Loss: 0.093470008836852', 'Epoch: 101, Train Loss: 0.056567390050207, Val Loss: 0.096009156770176', 'Epoch: 102, Train Loss: 0.056134330907038, Val Loss: 0.094885137346056', 'Epoch: 103, Train Loss: 0.057278230786324, Val Loss: 0.093967876500554', 'Epoch: 104, Train Loss: 0.055662077984640, Val Loss: 0.093394438425700', 'Epoch: 105, Train Loss: 0.061115733214787, Val Loss: 0.093291355503930', 'Epoch: 106, Train Loss: 0.057059926113912, Val Loss: 0.093130712707837', 'Epoch: 107, Train Loss: 0.054850662925414, Val Loss: 0.091216339005364', 'Epoch: 108, Train Loss: 0.058308187339987, Val Loss: 0.091308146715164', 'Epoch: 109, Train Loss: 0.057115278073720, Val Loss: 0.090929213497374', 'Epoch: 110, Train Loss: 0.059914900788239, Val Loss: 0.091404472788175', 'Epoch: 111, Train Loss: 0.053951482155493, Val Loss: 0.091757718059752', 'Epoch: 112, Train Loss: 0.061670900987727, Val Loss: 0.092026872767342', 'Epoch: 113, Train Loss: 0.057651571397270, Val Loss: 0.092447022596995', 'Epoch: 114, Train Loss: 0.051756159003292, Val Loss: 0.091808638638920', 'Epoch: 115, Train Loss: 0.060732495039701, Val Loss: 0.092131212353706', 'Epoch: 116, Train Loss: 0.058170129678079, Val Loss: 0.089931877122985', 'Epoch: 117, Train Loss: 0.056593847594091, Val Loss: 0.091101091769007', 'Epoch: 118, Train Loss: 0.056537861270564, Val Loss: 0.091362360450957', 'Epoch: 119, Train Loss: 0.057069320763860, Val Loss: 0.096937172942691', 'Epoch: 120, Train Loss: 0.055924038269690, Val Loss: 0.094810220930311', 'Epoch: 121, Train Loss: 0.057489766074078, Val Loss: 0.095355171296332', 'Epoch: 122, Train Loss: 0.056848927800144, Val Loss: 0.094055973821216', 'Epoch: 123, Train Loss: 0.052424670330116, Val Loss: 0.093806584676107', 'Epoch: 124, Train Loss: 0.054990575781890, Val Loss: 0.093652317921321', 'Epoch: 125, Train Loss: 0.059271729418210, Val Loss: 0.091927871108055', 'Epoch: 126, Train Loss: 0.058025096676179, Val Loss: 0.092156542672051', 'Epoch: 127, Train Loss: 0.057222367397376, Val Loss: 0.091452285647392', 'Epoch: 128, Train Loss: 0.057920882744449, Val Loss: 0.092124182316992', 'Epoch: 129, Train Loss: 0.052481916866132, Val Loss: 0.092121111022102', 'Epoch: 130, Train Loss: 0.053381426525967, Val Loss: 0.092302620410919', 'Epoch: 131, Train Loss: 0.053956695433174, Val Loss: 0.093065293298827', 'Epoch: 132, Train Loss: 0.057101764849254, Val Loss: 0.093356932202975', 'Epoch: 133, Train Loss: 0.058501817818199, Val Loss: 0.091661991344558', 'Epoch: 134, Train Loss: 0.050156268158129, Val Loss: 0.091076385643747', 'Epoch: 135, Train Loss: 0.053694341331720, Val Loss: 0.091204514106115', 'Epoch: 136, Train Loss: 0.051629656127521, Val Loss: 0.091125999887784', 'Epoch: 137, Train Loss: 0.052620721182653, Val Loss: 0.091348017255465', 'Epoch: 138, Train Loss: 0.060325104211058, Val Loss: 0.093846418791347', 'Epoch: 139, Train Loss: 0.054119554481336, Val Loss: 0.091651247607337', 'Epoch: 140, Train Loss: 0.055604430713824, Val Loss: 0.092213201853964', 'Epoch: 141, Train Loss: 0.052624878074442, Val Loss: 0.091896169715457', 'Epoch: 142, Train Loss: 0.052651737417494, Val Loss: 0.092530641290877', 'Epoch: 143, Train Loss: 0.051148115258132, Val Loss: 0.093700832790799', 'Epoch: 144, Train Loss: 0.050043043813535, Val Loss: 0.092782994111379', 'Epoch: 145, Train Loss: 0.057833548103060, Val Loss: 0.092865877681308', 'Epoch: 146, Train Loss: 0.054575714681830, Val Loss: 0.092994072371059', 'Epoch: 147, Train Loss: 0.059570028845753, Val Loss: 0.092317579521073', 'Epoch: 148, Train Loss: 0.056433605296271, Val Loss: 0.092668096224467', 'Epoch: 149, Train Loss: 0.051299540059907, Val Loss: 0.092297373546494', 'Epoch: 150, Train Loss: 0.051025135708707, Val Loss: 0.092269462015894', 'Epoch: 151, Train Loss: 0.056385756603309, Val Loss: 0.092182440890206', 'Epoch: 152, Train Loss: 0.055218229336398, Val Loss: 0.092009266217550', 'Epoch: 153, Train Loss: 0.058101587529693, Val Loss: 0.091893007357915', 'Epoch: 154, Train Loss: 0.054751082190445, Val Loss: 0.091835293504927', 'Epoch: 155, Train Loss: 0.049860006464379, Val Loss: 0.091901555657387', 'Epoch: 156, Train Loss: 0.053136315728937, Val Loss: 0.091772766576873', 'Epoch: 157, Train Loss: 0.050957861223391, Val Loss: 0.092802113956875', 'Epoch: 158, Train Loss: 0.053347571619919, Val Loss: 0.092708971765306', 'Epoch: 159, Train Loss: 0.058685730610575, Val Loss: 0.091929912567139', 'Epoch: 160, Train Loss: 0.054068351430552, Val Loss: 0.094424827231301', 'Epoch: 161, Train Loss: 0.052583966670292, Val Loss: 0.092967978782124', 'Epoch: 162, Train Loss: 0.051517826105867, Val Loss: 0.092530442608727', 'Epoch: 163, Train Loss: 0.057480961616550, Val Loss: 0.094843612776862', 'Epoch: 164, Train Loss: 0.056238433612244, Val Loss: 0.092498206430011', 'Epoch: 165, Train Loss: 0.056324229176555, Val Loss: 0.092133528656430', 'Epoch: 166, Train Loss: 0.053803071379662, Val Loss: 0.092233131329219', 'Epoch: 167, Train Loss: 0.054450979190213, Val Loss: 0.092548524339994', 'Epoch: 168, Train Loss: 0.053980658629111, Val Loss: 0.091390904453066', 'Epoch: 169, Train Loss: 0.049229220088039, Val Loss: 0.091484328111013', 'Epoch: 170, Train Loss: 0.049089238579784, Val Loss: 0.092222435606851', 'Epoch: 171, Train Loss: 0.052311863218035, Val Loss: 0.092192267378171', 'Epoch: 172, Train Loss: 0.053837344050407, Val Loss: 0.092138709293471', 'Epoch: 173, Train Loss: 0.049384088920695, Val Loss: 0.092306044366625', 'Epoch: 174, Train Loss: 0.055063475987741, Val Loss: 0.092523177464803', 'Epoch: 175, Train Loss: 0.050653938736234, Val Loss: 0.092473220494058', 'Epoch: 176, Train Loss: 0.047380587086082, Val Loss: 0.092410514752070', 'Epoch: 177, Train Loss: 0.051720392491136, Val Loss: 0.092327844765451', 'Epoch: 178, Train Loss: 0.051425991313798, Val Loss: 0.092167342702548', 'Epoch: 179, Train Loss: 0.056275493864502, Val Loss: 0.092218693759706', 'Epoch: 180, Train Loss: 0.048785125570638, Val Loss: 0.091916547881232', 'Epoch: 181, Train Loss: 0.048503212630749, Val Loss: 0.091692212555144', 'Epoch: 182, Train Loss: 0.050072268183742, Val Loss: 0.091549898187319', 'Epoch: 183, Train Loss: 0.055714908455099, Val Loss: 0.091431159112189', 'Epoch: 184, Train Loss: 0.050215919635126, Val Loss: 0.091363565789329', 'Epoch: 185, Train Loss: 0.052186992019415, Val Loss: 0.091394298606449', 'Epoch: 186, Train Loss: 0.047457576330219, Val Loss: 0.091474312875006', 'Epoch: 187, Train Loss: 0.049902791955641, Val Loss: 0.091322989927398', 'Epoch: 188, Train Loss: 0.050664757777538, Val Loss: 0.091358022557365', 'Epoch: 189, Train Loss: 0.050411330269916, Val Loss: 0.091422774725490', 'Epoch: 190, Train Loss: 0.051366666597979, Val Loss: 0.091562708218892', 'Epoch: 191, Train Loss: 0.052483781640019, Val Loss: 0.091600317094061', 'Epoch: 192, Train Loss: 0.049450834414789, Val Loss: 0.091543937722842', 'Epoch: 193, Train Loss: 0.052305441349745, Val Loss: 0.091565233137872', 'Epoch: 194, Train Loss: 0.051155272871256, Val Loss: 0.091646798782878', 'Epoch: 195, Train Loss: 0.053450880306108, Val Loss: 0.091598118344943', 'Epoch: 196, Train Loss: 0.052358847111464, Val Loss: 0.091541027029355', 'Epoch: 197, Train Loss: 0.051260927425964, Val Loss: 0.091483871142070', 'Epoch: 198, Train Loss: 0.051323147756713, Val Loss: 0.091459797488319', 'Epoch: 199, Train Loss: 0.052906169955220, Val Loss: 0.091457489464018']","[1.12062622e+02 4.04204010e+02 7.89340820e+02 1.29847107e+02
 7.36517944e+02 2.41183990e+02 3.46545807e+02 6.66880920e+02
 2.30275238e+02 8.57477783e+02 4.23375732e+02 9.38733582e+02
 7.30420837e+02 4.65585938e+01 9.53491211e+00 2.33792206e+02
 7.69853394e+02 1.04559082e+03 5.27572632e+00 1.03431854e+02
 7.42673340e+01 2.11741699e+02 7.04199585e+02 6.09689392e+02
 9.47666870e+02 1.02406219e+02 8.78111267e+02 5.71229980e+02
 4.66583984e+02 7.23343262e+02 8.82951477e+02 1.98872864e+02
 9.66843262e+02 8.02557495e+02 7.16733582e+02 9.11866394e+02
 8.71341736e+02 6.53889893e+02 3.92328064e+02 7.26825439e+02
 1.16376453e+03 9.52069580e+02 5.23101624e+02 1.03284863e+03
 2.01206863e+02 3.41093628e+02 5.53470215e+02 1.04463562e+03
 1.10413623e+03 7.65909180e+02 4.97863617e+02 7.84930420e+01
 1.21911987e+03 8.73925171e+02 6.82403442e+02 7.26762573e+02
 3.43290863e+02 1.08125073e+03 3.74251312e+02 2.29724884e+02
 4.43395416e+02 1.17552368e+02 1.65651184e+02 3.78562622e+02
 8.57335754e+02 5.25377808e+02 3.91949127e+02 9.47766785e+02
 9.03670044e+02 2.02886414e+02 2.24115143e+02 1.58994202e+02
 2.61103760e+02 9.26631958e+02 5.28355164e+02 2.18857727e+01
 1.07608618e+03 8.40567017e+02 2.44042847e+02 5.67224731e+02
 4.07460876e+02 7.11104431e+02 1.08503821e+03 3.38475800e+02
 4.94750977e-01 5.42716187e+02 1.07945117e+03 5.68444214e+01
 3.88212738e+02 1.82214249e+02 3.47495422e+01 3.73102356e+02
 1.15993909e+03 5.92535767e+02 9.83921753e+02 4.80153839e+02
 4.32826477e+02 3.99857483e+02 8.61186218e+02 9.62885986e+02
 8.69757935e+02 1.72630615e+02 3.76274231e+02 5.84907593e+02
 1.21490601e+02 2.93843262e+02 2.98168030e+02 1.01031885e+03
 7.27753113e+02 5.80149292e+02 4.08021973e+02 2.38431900e+02
 4.72177734e+02 7.04212036e+01 2.57280457e+02 5.03024536e+02
 5.15408447e+02 5.84277588e+02 7.99440308e+01 1.07993542e+03
 3.56022430e+02 8.56417297e+02 6.41333008e+00 3.64197510e+02
 6.38392944e+02 3.23172943e+02 4.68850616e+02 6.34227417e+02
 4.74083038e+02 6.48171021e+02 8.59571289e+02 1.10814484e+02
 8.96622437e+02 3.00078674e+02 7.00550171e+02 2.74852173e+02
 2.05837296e+02 3.57466339e+02 1.37161865e+01 5.62222168e+02
 5.79930664e+02 6.17623901e+02 1.17018018e+03 9.49477661e+02
 4.83920868e+02 4.80773315e+02]","[  69.5809    344.0003    598.1926    271.29773   805.98315   189.99344
  244.63188   682.64636   336.3922    929.16235   373.2793   1034.8267
  685.0515    -51.116333   71.4245    233.36209   893.4799   1122.291
  131.76662   145.38202   350.62973   350.9137    754.74207   532.16754
  610.1443    275.64264   731.7494    577.62897   548.81396   766.1858
  791.67004    85.37558   877.7582    911.26935   692.62006  1160.9204
  799.9957    666.1293    382.3454    819.4054    909.47925   666.5381
  478.17377   860.7538     78.93353   382.06763   689.46594  1176.1073
 1110.2627    833.5317    622.87463   207.42596  1242.4077   1061.6931
  754.25946   832.2842    496.53976  1039.2185    437.03268   159.09637
  426.75214   265.47266   251.13211   356.34494   826.01965   421.0171
  482.03055  1016.62787   782.7677    153.19287   195.57233    92.72772
  365.85294   951.06067   421.42316   114.951294 1081.2842    837.54944
  187.54991   585.266     384.24652   905.8002   1185.6284    331.0992
   86.06091   472.28674   816.7529    317.98193   484.62552   130.82788
  106.41609   422.26526  1234.5824    518.0052    935.2363    493.50775
  428.86618   465.70062   765.522     779.874     803.5562    276.2207
  346.5202    638.5049     99.0014    308.0353    254.34357  1055.6951
  819.32715   678.6642    479.8379    230.1038    404.1544    224.43365
  217.54306   511.85345   464.85477   585.70404   196.0481    841.5389
  402.49023   886.5711     55.19568   414.02164   702.2516    317.52847
  430.81543   699.8828    492.95648   834.4592    648.44385   204.92538
  858.4697    307.15186   709.0282    266.83954    50.34207   304.6492
   92.210754  571.8404    718.2062    838.1816   1137.3744   1005.3196
  369.1739    474.39996 ]",83.481804,11494.871,107.21413663202256
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 0.580612508580089, Val Loss: 0.346434880644083', 'Epoch: 1, Train Loss: 0.315476518762963, Val Loss: 0.309348187707365', 'Epoch: 2, Train Loss: 0.294502653830818, Val Loss: 0.288804459720850', 'Epoch: 3, Train Loss: 0.281228010164840, Val Loss: 0.278869825899601', 'Epoch: 4, Train Loss: 0.264710630087980, Val Loss: 0.288779770657420', 'Epoch: 5, Train Loss: 0.260702846925706, Val Loss: 0.278340367190540', 'Epoch: 6, Train Loss: 0.247129859775305, Val Loss: 0.247625677101314', 'Epoch: 7, Train Loss: 0.241219106231417, Val Loss: 0.256320299878716', 'Epoch: 8, Train Loss: 0.235846360384354, Val Loss: 0.245346442051232', 'Epoch: 9, Train Loss: 0.227820084177490, Val Loss: 0.277662575356662', 'Epoch: 10, Train Loss: 0.223301003902618, Val Loss: 0.256442594677210', 'Epoch: 11, Train Loss: 0.214142886293786, Val Loss: 0.239082488007843', 'Epoch: 12, Train Loss: 0.219397791326046, Val Loss: 0.294271070361137', 'Epoch: 13, Train Loss: 0.210196309850684, Val Loss: 0.223208814505488', 'Epoch: 14, Train Loss: 0.214075824155339, Val Loss: 0.238458767253906', 'Epoch: 15, Train Loss: 0.205715551227331, Val Loss: 0.277285235598683', 'Epoch: 16, Train Loss: 0.200934325201171, Val Loss: 0.211825148612261', 'Epoch: 17, Train Loss: 0.199001119160759, Val Loss: 0.255519906952977', 'Epoch: 18, Train Loss: 0.198185441954327, Val Loss: 0.200988446660340', 'Epoch: 19, Train Loss: 0.194437697934253, Val Loss: 0.216341069303453', 'Epoch: 20, Train Loss: 0.188717665547239, Val Loss: 0.204610840901732', 'Epoch: 21, Train Loss: 0.186131427149688, Val Loss: 0.198565329350531', 'Epoch: 22, Train Loss: 0.176721635458193, Val Loss: 0.213672391846776', 'Epoch: 23, Train Loss: 0.175395823898060, Val Loss: 0.189098815768957', 'Epoch: 24, Train Loss: 0.171496905295977, Val Loss: 0.184061931483448', 'Epoch: 25, Train Loss: 0.167084275300481, Val Loss: 0.201021272726357', 'Epoch: 26, Train Loss: 0.165954562622522, Val Loss: 0.178210014626384', 'Epoch: 27, Train Loss: 0.165708531505827, Val Loss: 0.234368090834469', 'Epoch: 28, Train Loss: 0.159262071406203, Val Loss: 0.187373290993273', 'Epoch: 29, Train Loss: 0.157118322867900, Val Loss: 0.218075101915747', 'Epoch: 30, Train Loss: 0.157381886042921, Val Loss: 0.178084448054433', 'Epoch: 31, Train Loss: 0.152245926782489, Val Loss: 0.192732426729053', 'Epoch: 32, Train Loss: 0.152399095541665, Val Loss: 0.205090919993818', 'Epoch: 33, Train Loss: 0.146397427677044, Val Loss: 0.198241299036890', 'Epoch: 34, Train Loss: 0.143597729639815, Val Loss: 0.185687830932438', 'Epoch: 35, Train Loss: 0.143500387788351, Val Loss: 0.180692054424435', 'Epoch: 36, Train Loss: 0.140123438624931, Val Loss: 0.194220460616052', 'Epoch: 37, Train Loss: 0.135660300427782, Val Loss: 0.175161333652213', 'Epoch: 38, Train Loss: 0.138872683152024, Val Loss: 0.179471129812300', 'Epoch: 39, Train Loss: 0.132905283415956, Val Loss: 0.175473380330950', 'Epoch: 40, Train Loss: 0.132897196340242, Val Loss: 0.173560565076768', 'Epoch: 41, Train Loss: 0.126697770067091, Val Loss: 0.179844308402389', 'Epoch: 42, Train Loss: 0.124786998435323, Val Loss: 0.188171978741884', 'Epoch: 43, Train Loss: 0.121621424667537, Val Loss: 0.179904725886881', 'Epoch: 44, Train Loss: 0.118313589545765, Val Loss: 0.183583773896098', 'Epoch: 45, Train Loss: 0.113085498772562, Val Loss: 0.168885395359248', 'Epoch: 46, Train Loss: 0.115841219861593, Val Loss: 0.184111606925726', 'Epoch: 47, Train Loss: 0.111676756979099, Val Loss: 0.176284597795457', 'Epoch: 48, Train Loss: 0.108739536880915, Val Loss: 0.191404007794335', 'Epoch: 49, Train Loss: 0.100788664905620, Val Loss: 0.192143943663687', 'Epoch: 50, Train Loss: 0.101106910388917, Val Loss: 0.176964222639799', 'Epoch: 51, Train Loss: 0.099176237639040, Val Loss: 0.178831404075027', 'Epoch: 52, Train Loss: 0.095284797067621, Val Loss: 0.175462529379874', 'Epoch: 53, Train Loss: 0.093249725722043, Val Loss: 0.183050738861784', 'Epoch: 54, Train Loss: 0.096334025428763, Val Loss: 0.181339721977711', 'Epoch: 55, Train Loss: 0.091332068573684, Val Loss: 0.168152674296871', 'Epoch: 56, Train Loss: 0.085423359136496, Val Loss: 0.175996649768204', 'Epoch: 57, Train Loss: 0.084889025382165, Val Loss: 0.186613422790542', 'Epoch: 58, Train Loss: 0.083399156011375, Val Loss: 0.190885379500687', 'Epoch: 59, Train Loss: 0.083181832669569, Val Loss: 0.183473879899830', 'Epoch: 60, Train Loss: 0.078200427096869, Val Loss: 0.186590401567519', 'Epoch: 61, Train Loss: 0.077419712089800, Val Loss: 0.193522584270686', 'Epoch: 62, Train Loss: 0.076790930647403, Val Loss: 0.183714819680899', 'Epoch: 63, Train Loss: 0.075318815919704, Val Loss: 0.188201196640730', 'Epoch: 64, Train Loss: 0.076555900158627, Val Loss: 0.181578890481032', 'Epoch: 65, Train Loss: 0.069596650705540, Val Loss: 0.183361165514216', 'Epoch: 66, Train Loss: 0.066975632722356, Val Loss: 0.188921936862171', 'Epoch: 67, Train Loss: 0.068714836319642, Val Loss: 0.180023122932762', 'Epoch: 68, Train Loss: 0.067997742003894, Val Loss: 0.181915315501392', 'Epoch: 69, Train Loss: 0.064279281127134, Val Loss: 0.183486789297312', 'Epoch: 70, Train Loss: 0.065070689524125, Val Loss: 0.188631335571408', 'Epoch: 71, Train Loss: 0.065521625626300, Val Loss: 0.193642327338457', 'Epoch: 72, Train Loss: 0.063237878697525, Val Loss: 0.200165392132476', 'Epoch: 73, Train Loss: 0.062156409615917, Val Loss: 0.181125760488212', 'Epoch: 74, Train Loss: 0.058790232044246, Val Loss: 0.179432665826753', 'Epoch: 75, Train Loss: 0.058247684874971, Val Loss: 0.178519665962085', 'Epoch: 76, Train Loss: 0.057038190400760, Val Loss: 0.180848633237183', 'Epoch: 77, Train Loss: 0.058492616726352, Val Loss: 0.189634825419635', 'Epoch: 78, Train Loss: 0.057629337608814, Val Loss: 0.188171769231558', 'Epoch: 79, Train Loss: 0.054881877096902, Val Loss: 0.182837898349389', 'Epoch: 80, Train Loss: 0.052671601981191, Val Loss: 0.184187210323289', 'Epoch: 81, Train Loss: 0.051543647399438, Val Loss: 0.173771305065602', 'Epoch: 82, Train Loss: 0.053578495596136, Val Loss: 0.191109856218100', 'Epoch: 83, Train Loss: 0.053066162890089, Val Loss: 0.195566111896187', 'Epoch: 84, Train Loss: 0.050005000109252, Val Loss: 0.180524334032089', 'Epoch: 85, Train Loss: 0.052381274042917, Val Loss: 0.192497349269688', 'Epoch: 86, Train Loss: 0.048819716669885, Val Loss: 0.192145509505644', 'Epoch: 87, Train Loss: 0.049313259865823, Val Loss: 0.184001606181264', 'Epoch: 88, Train Loss: 0.049023391901116, Val Loss: 0.175736568979919', 'Epoch: 89, Train Loss: 0.046077894540504, Val Loss: 0.181877689957619', 'Epoch: 90, Train Loss: 0.046305982954135, Val Loss: 0.178668534960598', 'Epoch: 91, Train Loss: 0.045729666080858, Val Loss: 0.177795440200716', 'Epoch: 92, Train Loss: 0.044700227044523, Val Loss: 0.189681096412241', 'Epoch: 93, Train Loss: 0.044961105126089, Val Loss: 0.186789171081036', 'Epoch: 94, Train Loss: 0.045672960950594, Val Loss: 0.185874264687300', 'Epoch: 95, Train Loss: 0.043952066923625, Val Loss: 0.187121005598456', 'Epoch: 96, Train Loss: 0.044545501587646, Val Loss: 0.180290683554485', 'Epoch: 97, Train Loss: 0.041667365745774, Val Loss: 0.178418598873541', 'Epoch: 98, Train Loss: 0.042411720223193, Val Loss: 0.178991500111297', 'Epoch: 99, Train Loss: 0.043025640903839, Val Loss: 0.173852042546496', 'Epoch: 100, Train Loss: 0.042709332329354, Val Loss: 0.179736342653632', 'Epoch: 101, Train Loss: 0.041527373459456, Val Loss: 0.182117937542498', 'Epoch: 102, Train Loss: 0.041240283441065, Val Loss: 0.184028358664364', 'Epoch: 103, Train Loss: 0.040016965562744, Val Loss: 0.175390316378325', 'Epoch: 104, Train Loss: 0.040126976811194, Val Loss: 0.177509788097814', 'Epoch: 105, Train Loss: 0.039167990532837, Val Loss: 0.184497448373586', 'Epoch: 106, Train Loss: 0.040621286254110, Val Loss: 0.179253933578730', 'Epoch: 107, Train Loss: 0.039458581509867, Val Loss: 0.184552070964128', 'Epoch: 108, Train Loss: 0.038131888450256, Val Loss: 0.180398131180555', 'Epoch: 109, Train Loss: 0.038288971916107, Val Loss: 0.183782304357737', 'Epoch: 110, Train Loss: 0.037816192547658, Val Loss: 0.189032706758007', 'Epoch: 111, Train Loss: 0.036845262035994, Val Loss: 0.178889900855720', 'Epoch: 112, Train Loss: 0.036599201542724, Val Loss: 0.180429364666343', 'Epoch: 113, Train Loss: 0.037854923596606, Val Loss: 0.185163870025426', 'Epoch: 114, Train Loss: 0.036647645596947, Val Loss: 0.186376072866842', 'Epoch: 115, Train Loss: 0.034961668729250, Val Loss: 0.178372663343325', 'Epoch: 116, Train Loss: 0.035002740620236, Val Loss: 0.181113444082439', 'Epoch: 117, Train Loss: 0.034396996335792, Val Loss: 0.179890364259481', 'Epoch: 118, Train Loss: 0.035622576179781, Val Loss: 0.176833119587973', 'Epoch: 119, Train Loss: 0.034700462782889, Val Loss: 0.181596382586285', 'Epoch: 120, Train Loss: 0.035276022465633, Val Loss: 0.179326564921066', 'Epoch: 121, Train Loss: 0.032608146360144, Val Loss: 0.181643819827586', 'Epoch: 122, Train Loss: 0.032987771168617, Val Loss: 0.188930569086224', 'Epoch: 123, Train Loss: 0.034200088027865, Val Loss: 0.177630596086383', 'Epoch: 124, Train Loss: 0.034307660634762, Val Loss: 0.180851760338992', 'Epoch: 125, Train Loss: 0.032387133854042, Val Loss: 0.180598930707201', 'Epoch: 126, Train Loss: 0.032892181551350, Val Loss: 0.186768924724311', 'Epoch: 127, Train Loss: 0.031697498224676, Val Loss: 0.181917404988781', 'Epoch: 128, Train Loss: 0.032631204639828, Val Loss: 0.173857375252992', 'Epoch: 129, Train Loss: 0.031595389788438, Val Loss: 0.179109296146780', 'Epoch: 130, Train Loss: 0.032248003647131, Val Loss: 0.176161154918373', 'Epoch: 131, Train Loss: 0.033414103796573, Val Loss: 0.177514171637595', 'Epoch: 132, Train Loss: 0.031047852107191, Val Loss: 0.177902958896011', 'Epoch: 133, Train Loss: 0.030520420493558, Val Loss: 0.183152769589797', 'Epoch: 134, Train Loss: 0.031164745189516, Val Loss: 0.178412184882909', 'Epoch: 135, Train Loss: 0.030633909293850, Val Loss: 0.176894102375954', 'Epoch: 136, Train Loss: 0.028627584957784, Val Loss: 0.179738464215770', 'Epoch: 137, Train Loss: 0.029901911028927, Val Loss: 0.179924124199897', 'Epoch: 138, Train Loss: 0.029781594641640, Val Loss: 0.179345310870558', 'Epoch: 139, Train Loss: 0.029220493344058, Val Loss: 0.179979868233204', 'Epoch: 140, Train Loss: 0.029124462706303, Val Loss: 0.176711716139689', 'Epoch: 141, Train Loss: 0.029086926491665, Val Loss: 0.178601408097893', 'Epoch: 142, Train Loss: 0.029108882865735, Val Loss: 0.182437950512394', 'Epoch: 143, Train Loss: 0.028354148270030, Val Loss: 0.183343286691234', 'Epoch: 144, Train Loss: 0.028489994573673, Val Loss: 0.179618465052918', 'Epoch: 145, Train Loss: 0.028435313539313, Val Loss: 0.174984656190500', 'Epoch: 146, Train Loss: 0.027319595914866, Val Loss: 0.178193967090920', 'Epoch: 147, Train Loss: 0.028308226239335, Val Loss: 0.180183189343661', 'Epoch: 148, Train Loss: 0.028174323861354, Val Loss: 0.177011607056484', 'Epoch: 149, Train Loss: 0.026695571470607, Val Loss: 0.178518337709829', 'Epoch: 150, Train Loss: 0.026788445860147, Val Loss: 0.181405263915658', 'Epoch: 151, Train Loss: 0.027917810005934, Val Loss: 0.176625287681818', 'Epoch: 152, Train Loss: 0.025668322006906, Val Loss: 0.178828905373812', 'Epoch: 153, Train Loss: 0.025836028443383, Val Loss: 0.179799067890272', 'Epoch: 154, Train Loss: 0.026164650806625, Val Loss: 0.178937355596572', 'Epoch: 155, Train Loss: 0.026644029229480, Val Loss: 0.174901607334614', 'Epoch: 156, Train Loss: 0.025866743737300, Val Loss: 0.180918484861031', 'Epoch: 157, Train Loss: 0.026315158044121, Val Loss: 0.176648896522820', 'Epoch: 158, Train Loss: 0.026286158976810, Val Loss: 0.180745294429362', 'Epoch: 159, Train Loss: 0.025341485089489, Val Loss: 0.176048228573054', 'Epoch: 160, Train Loss: 0.025977525300612, Val Loss: 0.178139564571902', 'Epoch: 161, Train Loss: 0.025667181742111, Val Loss: 0.177620432991534', 'Epoch: 162, Train Loss: 0.025687690363931, Val Loss: 0.176152981016785', 'Epoch: 163, Train Loss: 0.024550415797026, Val Loss: 0.175421320851892', 'Epoch: 164, Train Loss: 0.024862385572466, Val Loss: 0.184048686884344', 'Epoch: 165, Train Loss: 0.025809428212898, Val Loss: 0.180043546091765', 'Epoch: 166, Train Loss: 0.024558395901695, Val Loss: 0.177837662491947', 'Epoch: 167, Train Loss: 0.024174548481325, Val Loss: 0.177555959336460', 'Epoch: 168, Train Loss: 0.024864969459761, Val Loss: 0.180064009688795', 'Epoch: 169, Train Loss: 0.023800797656045, Val Loss: 0.178871947200969', 'Epoch: 170, Train Loss: 0.023753735480963, Val Loss: 0.177156392084435', 'Epoch: 171, Train Loss: 0.023013398228213, Val Loss: 0.178444620505907', 'Epoch: 172, Train Loss: 0.024526648918566, Val Loss: 0.177367074638605', 'Epoch: 173, Train Loss: 0.023493327169147, Val Loss: 0.178892581565306', 'Epoch: 174, Train Loss: 0.023499240538638, Val Loss: 0.180615239255130', 'Epoch: 175, Train Loss: 0.023517086428058, Val Loss: 0.179365310370922', 'Epoch: 176, Train Loss: 0.023199047321188, Val Loss: 0.178886121781543', 'Epoch: 177, Train Loss: 0.022376674865372, Val Loss: 0.177712268680334', 'Epoch: 178, Train Loss: 0.022292623370221, Val Loss: 0.179466481544077', 'Epoch: 179, Train Loss: 0.022775330574119, Val Loss: 0.180864092959091', 'Epoch: 180, Train Loss: 0.022913846666259, Val Loss: 0.177972953701392', 'Epoch: 181, Train Loss: 0.022210026292263, Val Loss: 0.177759225498885', 'Epoch: 182, Train Loss: 0.022002336120765, Val Loss: 0.175431653801352', 'Epoch: 183, Train Loss: 0.022376689199757, Val Loss: 0.177904488425702', 'Epoch: 184, Train Loss: 0.022177206147462, Val Loss: 0.177638202719390', 'Epoch: 185, Train Loss: 0.022219386819883, Val Loss: 0.178106542434543', 'Epoch: 186, Train Loss: 0.021776015586220, Val Loss: 0.178549869526178', 'Epoch: 187, Train Loss: 0.021622060915854, Val Loss: 0.179268205082044', 'Epoch: 188, Train Loss: 0.021557731410888, Val Loss: 0.180550723765045', 'Epoch: 189, Train Loss: 0.021717878837538, Val Loss: 0.176850683055818', 'Epoch: 190, Train Loss: 0.021403734715922, Val Loss: 0.177678344035521', 'Epoch: 191, Train Loss: 0.021320759205015, Val Loss: 0.178890955373645', 'Epoch: 192, Train Loss: 0.020855599196761, Val Loss: 0.178039645338431', 'Epoch: 193, Train Loss: 0.021361285692879, Val Loss: 0.177571459235623', 'Epoch: 194, Train Loss: 0.020937626568401, Val Loss: 0.176592839164659', 'Epoch: 195, Train Loss: 0.020866540030443, Val Loss: 0.178161987178028', 'Epoch: 196, Train Loss: 0.020977493007002, Val Loss: 0.178098174389452', 'Epoch: 197, Train Loss: 0.021416203855936, Val Loss: 0.177382763288915', 'Epoch: 198, Train Loss: 0.020497928038239, Val Loss: 0.177756860964000', 'Epoch: 199, Train Loss: 0.020387219126735, Val Loss: 0.177736979415640']",[ 612.9419   694.49774  404.76917 ...  576.16833 1494.562   1339.2822 ],[ 574.23596  398.057    426.0746  ...  790.7044  1495.6553  1251.4768 ],82.83197,22305.633,149.3507040910755
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 0.719108751373632, Val Loss: 0.314211489856243', 'Epoch: 1, Train Loss: 0.273976054138371, Val Loss: 0.244917063042521', 'Epoch: 2, Train Loss: 0.240173312297889, Val Loss: 0.201102085188031', 'Epoch: 3, Train Loss: 0.208321785213692, Val Loss: 0.196214297935367', 'Epoch: 4, Train Loss: 0.199737652465701, Val Loss: 0.179745723158121', 'Epoch: 5, Train Loss: 0.181423967022981, Val Loss: 0.157116577699780', 'Epoch: 6, Train Loss: 0.180772230231336, Val Loss: 0.155807652324438', 'Epoch: 7, Train Loss: 0.171543144306966, Val Loss: 0.133851038664579', 'Epoch: 8, Train Loss: 0.158697521494968, Val Loss: 0.154043021872640', 'Epoch: 9, Train Loss: 0.148342495129577, Val Loss: 0.121022517643869', 'Epoch: 10, Train Loss: 0.137436896323093, Val Loss: 0.130247777886689', 'Epoch: 11, Train Loss: 0.146875061893037, Val Loss: 0.114455328844488', 'Epoch: 12, Train Loss: 0.131431402212807, Val Loss: 0.119210672341287', 'Epoch: 13, Train Loss: 0.126016917888607, Val Loss: 0.106458814442158', 'Epoch: 14, Train Loss: 0.120106764441090, Val Loss: 0.089261500351131', 'Epoch: 15, Train Loss: 0.118836268442018, Val Loss: 0.101428108327091', 'Epoch: 16, Train Loss: 0.110394156447479, Val Loss: 0.102792597673833', 'Epoch: 17, Train Loss: 0.114895497166685, Val Loss: 0.103197400402278', 'Epoch: 18, Train Loss: 0.113141400984355, Val Loss: 0.084160997588187', 'Epoch: 19, Train Loss: 0.114809027138565, Val Loss: 0.088919587135315', 'Epoch: 20, Train Loss: 0.099923368883984, Val Loss: 0.087540884483606', 'Epoch: 21, Train Loss: 0.105067028387317, Val Loss: 0.103632634542882', 'Epoch: 22, Train Loss: 0.095081015069570, Val Loss: 0.069963692706078', 'Epoch: 23, Train Loss: 0.103940435887447, Val Loss: 0.089684889651835', 'Epoch: 24, Train Loss: 0.089274263562901, Val Loss: 0.127690258882940', 'Epoch: 25, Train Loss: 0.090991029350885, Val Loss: 0.079342662245035', 'Epoch: 26, Train Loss: 0.091364767522152, Val Loss: 0.079173871539533', 'Epoch: 27, Train Loss: 0.090840380489826, Val Loss: 0.072095961440355', 'Epoch: 28, Train Loss: 0.087287666222879, Val Loss: 0.072423906922340', 'Epoch: 29, Train Loss: 0.085296663482274, Val Loss: 0.126073366552591', 'Epoch: 30, Train Loss: 0.084649976694158, Val Loss: 0.068407896272838', 'Epoch: 31, Train Loss: 0.086927084060652, Val Loss: 0.071328467335552', 'Epoch: 32, Train Loss: 0.077100327605648, Val Loss: 0.061949527245015', 'Epoch: 33, Train Loss: 0.077927060236356, Val Loss: 0.124304102919996', 'Epoch: 34, Train Loss: 0.073867799416184, Val Loss: 0.066114974450320', 'Epoch: 35, Train Loss: 0.084627233387104, Val Loss: 0.061824017949402', 'Epoch: 36, Train Loss: 0.071827832955335, Val Loss: 0.065599731020629', 'Epoch: 37, Train Loss: 0.077099228895136, Val Loss: 0.076148480270058', 'Epoch: 38, Train Loss: 0.074128524200725, Val Loss: 0.069078289475292', 'Epoch: 39, Train Loss: 0.071408743142549, Val Loss: 0.059422483108938', 'Epoch: 40, Train Loss: 0.069553940785783, Val Loss: 0.078906366489828', 'Epoch: 41, Train Loss: 0.072299893431898, Val Loss: 0.057559208925813', 'Epoch: 42, Train Loss: 0.067696459806923, Val Loss: 0.061740257963538', 'Epoch: 43, Train Loss: 0.061287183838763, Val Loss: 0.059488471103832', 'Epoch: 44, Train Loss: 0.065300493716661, Val Loss: 0.060367845632136', 'Epoch: 45, Train Loss: 0.060485204013863, Val Loss: 0.064408731795847', 'Epoch: 46, Train Loss: 0.065129836092570, Val Loss: 0.068521082438529', 'Epoch: 47, Train Loss: 0.063248045330069, Val Loss: 0.060535742919892', 'Epoch: 48, Train Loss: 0.058344622102699, Val Loss: 0.055543957976624', 'Epoch: 49, Train Loss: 0.058146012707480, Val Loss: 0.056443267520517', 'Epoch: 50, Train Loss: 0.060051923721497, Val Loss: 0.058924029208720', 'Epoch: 51, Train Loss: 0.056130459987159, Val Loss: 0.052605254249647', 'Epoch: 52, Train Loss: 0.055583278914647, Val Loss: 0.057568775620311', 'Epoch: 53, Train Loss: 0.062607081854450, Val Loss: 0.057894854862243', 'Epoch: 54, Train Loss: 0.057009378176715, Val Loss: 0.048666760623455', 'Epoch: 55, Train Loss: 0.050561672989279, Val Loss: 0.064290083367378', 'Epoch: 56, Train Loss: 0.051688457224518, Val Loss: 0.053901496324688', 'Epoch: 57, Train Loss: 0.051270772838699, Val Loss: 0.057123177954927', 'Epoch: 58, Train Loss: 0.051488241401634, Val Loss: 0.049897760832682', 'Epoch: 59, Train Loss: 0.051185261663049, Val Loss: 0.048617386547849', 'Epoch: 60, Train Loss: 0.049200415967831, Val Loss: 0.061546542979777', 'Epoch: 61, Train Loss: 0.047508172233190, Val Loss: 0.048395978529006', 'Epoch: 62, Train Loss: 0.048069750407178, Val Loss: 0.070161210875958', 'Epoch: 63, Train Loss: 0.049614834136197, Val Loss: 0.046484975619242', 'Epoch: 64, Train Loss: 0.045877335140748, Val Loss: 0.054880200363696', 'Epoch: 65, Train Loss: 0.045856870263815, Val Loss: 0.062162189334631', 'Epoch: 66, Train Loss: 0.049010639517967, Val Loss: 0.053343498166651', 'Epoch: 67, Train Loss: 0.046245153152517, Val Loss: 0.050613066432998', 'Epoch: 68, Train Loss: 0.047088289008077, Val Loss: 0.053455619849265', 'Epoch: 69, Train Loss: 0.047350452228316, Val Loss: 0.056851117778569', 'Epoch: 70, Train Loss: 0.042621328367719, Val Loss: 0.053773733926937', 'Epoch: 71, Train Loss: 0.044212641697377, Val Loss: 0.050900836549699', 'Epoch: 72, Train Loss: 0.045110733386661, Val Loss: 0.044745024880394', 'Epoch: 73, Train Loss: 0.041945900217231, Val Loss: 0.051102360207587', 'Epoch: 74, Train Loss: 0.042548932254847, Val Loss: 0.050503957904875', 'Epoch: 75, Train Loss: 0.043566552874233, Val Loss: 0.053785531856120', 'Epoch: 76, Train Loss: 0.041675574953801, Val Loss: 0.044386646719649', 'Epoch: 77, Train Loss: 0.040821436981538, Val Loss: 0.049187267329544', 'Epoch: 78, Train Loss: 0.043838970296617, Val Loss: 0.041166755594313', 'Epoch: 79, Train Loss: 0.041040189597490, Val Loss: 0.052319706780836', 'Epoch: 80, Train Loss: 0.039918142679547, Val Loss: 0.049297952409834', 'Epoch: 81, Train Loss: 0.038756366209792, Val Loss: 0.048224250031635', 'Epoch: 82, Train Loss: 0.040294500051865, Val Loss: 0.045905334800482', 'Epoch: 83, Train Loss: 0.039151980332764, Val Loss: 0.046496421424672', 'Epoch: 84, Train Loss: 0.040516061008509, Val Loss: 0.052829520944506', 'Epoch: 85, Train Loss: 0.037590400983713, Val Loss: 0.047104887114838', 'Epoch: 86, Train Loss: 0.038755654666041, Val Loss: 0.045818523894995', 'Epoch: 87, Train Loss: 0.037974101909037, Val Loss: 0.053031122479588', 'Epoch: 88, Train Loss: 0.038800458862845, Val Loss: 0.048665076131001', 'Epoch: 89, Train Loss: 0.037551557383101, Val Loss: 0.063432371653616', 'Epoch: 90, Train Loss: 0.038044258655448, Val Loss: 0.053200896345079', 'Epoch: 91, Train Loss: 0.037468874302826, Val Loss: 0.051494795428589', 'Epoch: 92, Train Loss: 0.037715678321464, Val Loss: 0.043620577426627', 'Epoch: 93, Train Loss: 0.036506821382791, Val Loss: 0.044619446881115', 'Epoch: 94, Train Loss: 0.036445518069501, Val Loss: 0.046203678781167', 'Epoch: 95, Train Loss: 0.037318544645927, Val Loss: 0.053934792662039', 'Epoch: 96, Train Loss: 0.037154118400067, Val Loss: 0.052700072284788', 'Epoch: 97, Train Loss: 0.035382940117270, Val Loss: 0.044205309106037', 'Epoch: 98, Train Loss: 0.037893645760736, Val Loss: 0.046334702894092', 'Epoch: 99, Train Loss: 0.035626354361219, Val Loss: 0.049879978606477', 'Epoch: 100, Train Loss: 0.036664459284927, Val Loss: 0.052549623632804', 'Epoch: 101, Train Loss: 0.038294782776918, Val Loss: 0.055378256663680', 'Epoch: 102, Train Loss: 0.034385484488947, Val Loss: 0.046412952961400', 'Epoch: 103, Train Loss: 0.032942244402532, Val Loss: 0.047847067266703', 'Epoch: 104, Train Loss: 0.034636975446982, Val Loss: 0.047904178677127', 'Epoch: 105, Train Loss: 0.034683090461684, Val Loss: 0.047308211987838', 'Epoch: 106, Train Loss: 0.033730727217293, Val Loss: 0.046935649216175', 'Epoch: 107, Train Loss: 0.032946196813136, Val Loss: 0.048278967728838', 'Epoch: 108, Train Loss: 0.035260574342683, Val Loss: 0.049894235990942', 'Epoch: 109, Train Loss: 0.034929945056460, Val Loss: 0.042617685580626', 'Epoch: 110, Train Loss: 0.034823533504137, Val Loss: 0.044002772378735', 'Epoch: 111, Train Loss: 0.033048740234226, Val Loss: 0.047992519112304', 'Epoch: 112, Train Loss: 0.031406106677439, Val Loss: 0.042614383189939', 'Epoch: 113, Train Loss: 0.032315217509334, Val Loss: 0.052479809299111', 'Epoch: 114, Train Loss: 0.033307358557358, Val Loss: 0.047299807574600', 'Epoch: 115, Train Loss: 0.033172127781436, Val Loss: 0.043520522834733', 'Epoch: 116, Train Loss: 0.033413508007569, Val Loss: 0.042973699504510', 'Epoch: 117, Train Loss: 0.031863423365035, Val Loss: 0.047965316623449', 'Epoch: 118, Train Loss: 0.032543125880350, Val Loss: 0.042475244421512', 'Epoch: 119, Train Loss: 0.032447399470423, Val Loss: 0.042769438978285', 'Epoch: 120, Train Loss: 0.031567486533895, Val Loss: 0.040539462016895', 'Epoch: 121, Train Loss: 0.032025799356135, Val Loss: 0.039664297085255', 'Epoch: 122, Train Loss: 0.030760397164683, Val Loss: 0.042009129379876', 'Epoch: 123, Train Loss: 0.031651918446379, Val Loss: 0.045545384259894', 'Epoch: 124, Train Loss: 0.031786586385486, Val Loss: 0.050459822183475', 'Epoch: 125, Train Loss: 0.031794912916209, Val Loss: 0.048044846197590', 'Epoch: 126, Train Loss: 0.031550773148026, Val Loss: 0.045969073502347', 'Epoch: 127, Train Loss: 0.030744396232601, Val Loss: 0.048572885636240', 'Epoch: 128, Train Loss: 0.030125247361138, Val Loss: 0.043127006934956', 'Epoch: 129, Train Loss: 0.029317477550358, Val Loss: 0.046215179786086', 'Epoch: 130, Train Loss: 0.030499852428745, Val Loss: 0.048262087958865', 'Epoch: 131, Train Loss: 0.030890364744035, Val Loss: 0.048008311102167', 'Epoch: 132, Train Loss: 0.029668667377638, Val Loss: 0.041385774873197', 'Epoch: 133, Train Loss: 0.030568843236459, Val Loss: 0.045311721535400', 'Epoch: 134, Train Loss: 0.030743061909452, Val Loss: 0.049184398697689', 'Epoch: 135, Train Loss: 0.031079446444554, Val Loss: 0.048356196740642', 'Epoch: 136, Train Loss: 0.030379098444911, Val Loss: 0.045976009555161', 'Epoch: 137, Train Loss: 0.029609768787133, Val Loss: 0.045372404009104', 'Epoch: 138, Train Loss: 0.029613450568702, Val Loss: 0.044662336204201', 'Epoch: 139, Train Loss: 0.027966411472963, Val Loss: 0.046232405877672', 'Epoch: 140, Train Loss: 0.028710471516741, Val Loss: 0.042693739589304', 'Epoch: 141, Train Loss: 0.030966405421495, Val Loss: 0.042713504061103', 'Epoch: 142, Train Loss: 0.028734499259985, Val Loss: 0.043453619321808', 'Epoch: 143, Train Loss: 0.026973562671670, Val Loss: 0.045409140232950', 'Epoch: 144, Train Loss: 0.029822491372802, Val Loss: 0.052181421071291', 'Epoch: 145, Train Loss: 0.028932744402971, Val Loss: 0.049688868001103', 'Epoch: 146, Train Loss: 0.028401697826173, Val Loss: 0.051164285717532', 'Epoch: 147, Train Loss: 0.028085953617202, Val Loss: 0.044280459238216', 'Epoch: 148, Train Loss: 0.027444529751582, Val Loss: 0.046109927967191', 'Epoch: 149, Train Loss: 0.027092179956713, Val Loss: 0.046842217715457', 'Epoch: 150, Train Loss: 0.028255758805733, Val Loss: 0.043161230403930', 'Epoch: 151, Train Loss: 0.027118212474244, Val Loss: 0.041989997904748', 'Epoch: 152, Train Loss: 0.027356290096151, Val Loss: 0.049297229954973', 'Epoch: 153, Train Loss: 0.027757023812405, Val Loss: 0.042726588174701', 'Epoch: 154, Train Loss: 0.027728606258918, Val Loss: 0.041914046192542', 'Epoch: 155, Train Loss: 0.028569845110178, Val Loss: 0.044197636945173', 'Epoch: 156, Train Loss: 0.026969708041953, Val Loss: 0.049414953896776', 'Epoch: 157, Train Loss: 0.026475512219061, Val Loss: 0.047673294367269', 'Epoch: 158, Train Loss: 0.026298900061686, Val Loss: 0.044941244367510', 'Epoch: 159, Train Loss: 0.027792322610372, Val Loss: 0.045930238110013', 'Epoch: 160, Train Loss: 0.026648132268872, Val Loss: 0.044302532747388', 'Epoch: 161, Train Loss: 0.025734632056473, Val Loss: 0.043637013500556', 'Epoch: 162, Train Loss: 0.026697440751429, Val Loss: 0.044389274669811', 'Epoch: 163, Train Loss: 0.026291053060974, Val Loss: 0.045022067558020', 'Epoch: 164, Train Loss: 0.025418180086251, Val Loss: 0.043294565845281', 'Epoch: 165, Train Loss: 0.026224947324289, Val Loss: 0.044470005854964', 'Epoch: 166, Train Loss: 0.025431061643841, Val Loss: 0.043882883833721', 'Epoch: 167, Train Loss: 0.025391479217048, Val Loss: 0.043663801997900', 'Epoch: 168, Train Loss: 0.025967694139108, Val Loss: 0.044703705133870', 'Epoch: 169, Train Loss: 0.025293005333681, Val Loss: 0.046969229103997', 'Epoch: 170, Train Loss: 0.026389549574150, Val Loss: 0.044778054151684', 'Epoch: 171, Train Loss: 0.025208745033347, Val Loss: 0.044217431852594', 'Epoch: 172, Train Loss: 0.025451181803697, Val Loss: 0.042847078260966', 'Epoch: 173, Train Loss: 0.024517711148198, Val Loss: 0.043633099193685', 'Epoch: 174, Train Loss: 0.024736881161641, Val Loss: 0.045384463933297', 'Epoch: 175, Train Loss: 0.025189708388810, Val Loss: 0.046201560292393', 'Epoch: 176, Train Loss: 0.025059670731425, Val Loss: 0.046650421386585', 'Epoch: 177, Train Loss: 0.024439653669085, Val Loss: 0.045967591544613', 'Epoch: 178, Train Loss: 0.024980431691344, Val Loss: 0.044427410494536', 'Epoch: 179, Train Loss: 0.023960065789787, Val Loss: 0.044083801433444', 'Epoch: 180, Train Loss: 0.024239276374823, Val Loss: 0.045854705888778', 'Epoch: 181, Train Loss: 0.024917651001098, Val Loss: 0.042999309678562', 'Epoch: 182, Train Loss: 0.023951922947807, Val Loss: 0.042837039739825', 'Epoch: 183, Train Loss: 0.025275353275772, Val Loss: 0.046804862665012', 'Epoch: 184, Train Loss: 0.023736140239718, Val Loss: 0.047084653750062', 'Epoch: 185, Train Loss: 0.023345747450367, Val Loss: 0.044522024965845', 'Epoch: 186, Train Loss: 0.023780218934906, Val Loss: 0.045103996451944', 'Epoch: 187, Train Loss: 0.023346637867923, Val Loss: 0.044431309802458', 'Epoch: 188, Train Loss: 0.023460122686146, Val Loss: 0.044807998579927', 'Epoch: 189, Train Loss: 0.024085611369727, Val Loss: 0.046261981138960', 'Epoch: 190, Train Loss: 0.022893362758415, Val Loss: 0.045086270463653', 'Epoch: 191, Train Loss: 0.023777693419584, Val Loss: 0.044603361412883', 'Epoch: 192, Train Loss: 0.024107163472633, Val Loss: 0.044611683292314', 'Epoch: 193, Train Loss: 0.023330584466457, Val Loss: 0.045322885653004', 'Epoch: 194, Train Loss: 0.022985345532319, Val Loss: 0.044988440750167', 'Epoch: 195, Train Loss: 0.022974253111918, Val Loss: 0.044538316000253', 'Epoch: 196, Train Loss: 0.023426428948130, Val Loss: 0.044838695949875', 'Epoch: 197, Train Loss: 0.022949747658734, Val Loss: 0.045073421359994', 'Epoch: 198, Train Loss: 0.023833110983084, Val Loss: 0.044731928361580', 'Epoch: 199, Train Loss: 0.022545739066388, Val Loss: 0.044866074915044']",[ 792.2136   641.5792   742.0836  ... 1090.7566   531.37384 1346.9658 ],[ 777.6913   632.2401   746.9979  ... 1035.6436   507.06573 1297.6847 ],41.98997,8122.774,90.1264330026505
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 0.371297136988751, Val Loss: 0.350261583328247', 'Epoch: 1, Train Loss: 0.324971092301746, Val Loss: 0.272560498714447', 'Epoch: 2, Train Loss: 0.228721113399018, Val Loss: 0.147665952444077', 'Epoch: 3, Train Loss: 0.108056336554677, Val Loss: 0.061626744270325', 'Epoch: 4, Train Loss: 0.072431614319252, Val Loss: 0.055458161830902', 'Epoch: 5, Train Loss: 0.064838176593184, Val Loss: 0.045786535590887', 'Epoch: 6, Train Loss: 0.055113875155532, Val Loss: 0.039119842499495', 'Epoch: 7, Train Loss: 0.053174936234258, Val Loss: 0.039052223637700', 'Epoch: 8, Train Loss: 0.044246022784433, Val Loss: 0.037495600134134', 'Epoch: 9, Train Loss: 0.043161393208213, Val Loss: 0.035068523585796', 'Epoch: 10, Train Loss: 0.038032168175939, Val Loss: 0.024152543842793', 'Epoch: 11, Train Loss: 0.030794200249190, Val Loss: 0.018901753760874', 'Epoch: 12, Train Loss: 0.024174322374165, Val Loss: 0.020054539777339', 'Epoch: 13, Train Loss: 0.022872001430843, Val Loss: 0.015696276351810', 'Epoch: 14, Train Loss: 0.024981843524201, Val Loss: 0.025693709924817', 'Epoch: 15, Train Loss: 0.022721485646312, Val Loss: 0.017662511616945', 'Epoch: 16, Train Loss: 0.017809314436691, Val Loss: 0.012115165591240', 'Epoch: 17, Train Loss: 0.020813516882616, Val Loss: 0.020110575184226', 'Epoch: 18, Train Loss: 0.025123800324319, Val Loss: 0.012628838568926', 'Epoch: 19, Train Loss: 0.022710143415214, Val Loss: 0.016448397357017', 'Epoch: 20, Train Loss: 0.019415745143454, Val Loss: 0.018700671941042', 'Epoch: 21, Train Loss: 0.021335646228562, Val Loss: 0.015093845613301', 'Epoch: 22, Train Loss: 0.019933544315918, Val Loss: 0.022675359547138', 'Epoch: 23, Train Loss: 0.019069691513513, Val Loss: 0.014624433591962', 'Epoch: 24, Train Loss: 0.017968552685234, Val Loss: 0.011373575981706', 'Epoch: 25, Train Loss: 0.019239920104832, Val Loss: 0.015534903388470', 'Epoch: 26, Train Loss: 0.020821679751714, Val Loss: 0.018159940317273', 'Epoch: 27, Train Loss: 0.019139685061609, Val Loss: 0.012865287698805', 'Epoch: 28, Train Loss: 0.017097704209994, Val Loss: 0.010447909198701', 'Epoch: 29, Train Loss: 0.020527598112388, Val Loss: 0.024568593651056', 'Epoch: 30, Train Loss: 0.021417081789222, Val Loss: 0.018950901776552', 'Epoch: 31, Train Loss: 0.017677456920230, Val Loss: 0.011967888604850', 'Epoch: 32, Train Loss: 0.018319216199479, Val Loss: 0.022686393558979', 'Epoch: 33, Train Loss: 0.019289733917821, Val Loss: 0.012421590592712', 'Epoch: 34, Train Loss: 0.016448105143946, Val Loss: 0.013287960812449', 'Epoch: 35, Train Loss: 0.018055243114399, Val Loss: 0.020324448421597', 'Epoch: 36, Train Loss: 0.017900254100908, Val Loss: 0.012975009083748', 'Epoch: 37, Train Loss: 0.016302197489368, Val Loss: 0.013805074393749', 'Epoch: 38, Train Loss: 0.018698515034779, Val Loss: 0.011120117064565', 'Epoch: 39, Train Loss: 0.018880341407778, Val Loss: 0.012994603067636', 'Epoch: 40, Train Loss: 0.018438085155605, Val Loss: 0.011698212847114', 'Epoch: 41, Train Loss: 0.016956802966550, Val Loss: 0.010189433135092', 'Epoch: 42, Train Loss: 0.015908168569251, Val Loss: 0.015652755498886', 'Epoch: 43, Train Loss: 0.019754462658839, Val Loss: 0.013306899368763', 'Epoch: 44, Train Loss: 0.017098110959714, Val Loss: 0.010868541151285', 'Epoch: 45, Train Loss: 0.016263193613308, Val Loss: 0.010469601415098', 'Epoch: 46, Train Loss: 0.015937760309858, Val Loss: 0.013184384629130', 'Epoch: 47, Train Loss: 0.015953104022544, Val Loss: 0.016141881719232', 'Epoch: 48, Train Loss: 0.016673218578014, Val Loss: 0.011598151288927', 'Epoch: 49, Train Loss: 0.016530157998204, Val Loss: 0.010251601077616', 'Epoch: 50, Train Loss: 0.015057018643981, Val Loss: 0.010728903003037', 'Epoch: 51, Train Loss: 0.018074700338116, Val Loss: 0.013260082248598', 'Epoch: 52, Train Loss: 0.015517907303780, Val Loss: 0.011676511038095', 'Epoch: 53, Train Loss: 0.016545347620322, Val Loss: 0.011479669008404', 'Epoch: 54, Train Loss: 0.014668760658783, Val Loss: 0.012542213052511', 'Epoch: 55, Train Loss: 0.015608146505127, Val Loss: 0.013029102161527', 'Epoch: 56, Train Loss: 0.014378486601852, Val Loss: 0.012710435688496', 'Epoch: 57, Train Loss: 0.013779028741166, Val Loss: 0.009515497069806', 'Epoch: 58, Train Loss: 0.016786949524959, Val Loss: 0.010134373102337', 'Epoch: 59, Train Loss: 0.014483349960904, Val Loss: 0.011456302590668', 'Epoch: 60, Train Loss: 0.014884035731124, Val Loss: 0.011897855717689', 'Epoch: 61, Train Loss: 0.017280505374507, Val Loss: 0.014348509460688', 'Epoch: 62, Train Loss: 0.016011711448258, Val Loss: 0.011009506545961', 'Epoch: 63, Train Loss: 0.013801401459374, Val Loss: 0.010702139660716', 'Epoch: 64, Train Loss: 0.014428593608183, Val Loss: 0.008406232353300', 'Epoch: 65, Train Loss: 0.015444110017703, Val Loss: 0.010458133295178', 'Epoch: 66, Train Loss: 0.013591817558505, Val Loss: 0.010178157631308', 'Epoch: 67, Train Loss: 0.015725722828837, Val Loss: 0.010405945740640', 'Epoch: 68, Train Loss: 0.013543385070164, Val Loss: 0.009553528316319', 'Epoch: 69, Train Loss: 0.013539624292144, Val Loss: 0.012424518130720', 'Epoch: 70, Train Loss: 0.015117633448870, Val Loss: 0.011465317495167', 'Epoch: 71, Train Loss: 0.011994424893326, Val Loss: 0.009903808292001', 'Epoch: 72, Train Loss: 0.014271888816946, Val Loss: 0.010800818130374', 'Epoch: 73, Train Loss: 0.014807103537456, Val Loss: 0.010707390382886', 'Epoch: 74, Train Loss: 0.012765729929819, Val Loss: 0.009810960786417', 'Epoch: 75, Train Loss: 0.013706951954424, Val Loss: 0.011711870990694', 'Epoch: 76, Train Loss: 0.012589828040841, Val Loss: 0.011784536950290', 'Epoch: 77, Train Loss: 0.013236467185062, Val Loss: 0.009157231599092', 'Epoch: 78, Train Loss: 0.013040224339293, Val Loss: 0.010864978805184', 'Epoch: 79, Train Loss: 0.012764995332894, Val Loss: 0.015015437826514', 'Epoch: 80, Train Loss: 0.014447553527303, Val Loss: 0.012727691233158', 'Epoch: 81, Train Loss: 0.013954886137833, Val Loss: 0.010236031040549', 'Epoch: 82, Train Loss: 0.013387547849223, Val Loss: 0.009247519206256', 'Epoch: 83, Train Loss: 0.014335150862936, Val Loss: 0.009706547427922', 'Epoch: 84, Train Loss: 0.015183596373644, Val Loss: 0.009064289517701', 'Epoch: 85, Train Loss: 0.011618494727584, Val Loss: 0.009078241139650', 'Epoch: 86, Train Loss: 0.012233648774062, Val Loss: 0.010304747242481', 'Epoch: 87, Train Loss: 0.013958962628791, Val Loss: 0.011280896551907', 'Epoch: 88, Train Loss: 0.012519868188213, Val Loss: 0.012685457281768', 'Epoch: 89, Train Loss: 0.012312762071054, Val Loss: 0.009651850089431', 'Epoch: 90, Train Loss: 0.012109898030758, Val Loss: 0.010042881891131', 'Epoch: 91, Train Loss: 0.014488241765215, Val Loss: 0.011372910048813', 'Epoch: 92, Train Loss: 0.012679877420238, Val Loss: 0.008897771164775', 'Epoch: 93, Train Loss: 0.012381919204842, Val Loss: 0.011777431890368', 'Epoch: 94, Train Loss: 0.012238460506291, Val Loss: 0.008489348515868', 'Epoch: 95, Train Loss: 0.013149827253073, Val Loss: 0.012084515988827', 'Epoch: 96, Train Loss: 0.012745705357385, Val Loss: 0.011482407394797', 'Epoch: 97, Train Loss: 0.012645402576688, Val Loss: 0.011852498650551', 'Epoch: 98, Train Loss: 0.013300974528457, Val Loss: 0.009718351904303', 'Epoch: 99, Train Loss: 0.011763239506805, Val Loss: 0.009236826039851', 'Epoch: 100, Train Loss: 0.014151821194520, Val Loss: 0.012211501300335', 'Epoch: 101, Train Loss: 0.013379387503360, Val Loss: 0.010009041801095', 'Epoch: 102, Train Loss: 0.012708182360024, Val Loss: 0.009940884765238', 'Epoch: 103, Train Loss: 0.011684889342029, Val Loss: 0.009616003846750', 'Epoch: 104, Train Loss: 0.010861495184864, Val Loss: 0.011744770556688', 'Epoch: 105, Train Loss: 0.013545692979553, Val Loss: 0.010507198758423', 'Epoch: 106, Train Loss: 0.012750353555866, Val Loss: 0.009222811367363', 'Epoch: 107, Train Loss: 0.012467594844354, Val Loss: 0.011121137421578', 'Epoch: 108, Train Loss: 0.011824367156382, Val Loss: 0.010239183250815', 'Epoch: 109, Train Loss: 0.011155984483573, Val Loss: 0.010060518570244', 'Epoch: 110, Train Loss: 0.012675033654844, Val Loss: 0.010447686221451', 'Epoch: 111, Train Loss: 0.011807399444542, Val Loss: 0.008360237870365', 'Epoch: 112, Train Loss: 0.011786589528932, Val Loss: 0.010185804665089', 'Epoch: 113, Train Loss: 0.011483039317089, Val Loss: 0.008823041794822', 'Epoch: 114, Train Loss: 0.011248175466303, Val Loss: 0.009131739959121', 'Epoch: 115, Train Loss: 0.011331022901157, Val Loss: 0.010309236943722', 'Epoch: 116, Train Loss: 0.011344715075697, Val Loss: 0.009437332637608', 'Epoch: 117, Train Loss: 0.011055859867050, Val Loss: 0.009883689004928', 'Epoch: 118, Train Loss: 0.013051031135716, Val Loss: 0.010533090736717', 'Epoch: 119, Train Loss: 0.011438421417721, Val Loss: 0.009829705357552', 'Epoch: 120, Train Loss: 0.011168448785103, Val Loss: 0.009189877826720', 'Epoch: 121, Train Loss: 0.011619922889093, Val Loss: 0.012217153608799', 'Epoch: 122, Train Loss: 0.013542536689445, Val Loss: 0.008655049651861', 'Epoch: 123, Train Loss: 0.011579986217670, Val Loss: 0.009023437323049', 'Epoch: 124, Train Loss: 0.010915343649685, Val Loss: 0.010328564792871', 'Epoch: 125, Train Loss: 0.011878128596690, Val Loss: 0.008320857491344', 'Epoch: 126, Train Loss: 0.012856523430538, Val Loss: 0.010645320769399', 'Epoch: 127, Train Loss: 0.012737637916363, Val Loss: 0.010183587670326', 'Epoch: 128, Train Loss: 0.011126183536510, Val Loss: 0.009463804848492', 'Epoch: 129, Train Loss: 0.010748092345027, Val Loss: 0.008533090827987', 'Epoch: 130, Train Loss: 0.010263358037052, Val Loss: 0.008605808131397', 'Epoch: 131, Train Loss: 0.010497138174900, Val Loss: 0.009951913459226', 'Epoch: 132, Train Loss: 0.011757389138734, Val Loss: 0.011397498771548', 'Epoch: 133, Train Loss: 0.011413467679779, Val Loss: 0.008885332792997', 'Epoch: 134, Train Loss: 0.010147845426704, Val Loss: 0.008958627991378', 'Epoch: 135, Train Loss: 0.011690752840666, Val Loss: 0.009428892973810', 'Epoch: 136, Train Loss: 0.010869688213651, Val Loss: 0.009592010211200', 'Epoch: 137, Train Loss: 0.011013635694114, Val Loss: 0.009193126559258', 'Epoch: 138, Train Loss: 0.010627408522766, Val Loss: 0.008519028387964', 'Epoch: 139, Train Loss: 0.010891727615841, Val Loss: 0.008960017701611', 'Epoch: 140, Train Loss: 0.010087112744534, Val Loss: 0.009365860950202', 'Epoch: 141, Train Loss: 0.010531631070947, Val Loss: 0.009011026211083', 'Epoch: 142, Train Loss: 0.010648060698322, Val Loss: 0.009887131117284', 'Epoch: 143, Train Loss: 0.010458093472258, Val Loss: 0.008836442325264', 'Epoch: 144, Train Loss: 0.011719075020749, Val Loss: 0.008671436812729', 'Epoch: 145, Train Loss: 0.010178257981965, Val Loss: 0.008447581790388', 'Epoch: 146, Train Loss: 0.010849610631636, Val Loss: 0.009866488017142', 'Epoch: 147, Train Loss: 0.011183584358023, Val Loss: 0.009013597499579', 'Epoch: 148, Train Loss: 0.010859234215215, Val Loss: 0.009472767040133', 'Epoch: 149, Train Loss: 0.010476899376616, Val Loss: 0.012024320606142', 'Epoch: 150, Train Loss: 0.011545408538781, Val Loss: 0.008750985655934', 'Epoch: 151, Train Loss: 0.009951090283129, Val Loss: 0.009644233845174', 'Epoch: 152, Train Loss: 0.009636082394092, Val Loss: 0.010078826397657', 'Epoch: 153, Train Loss: 0.009242386995750, Val Loss: 0.009296521879733', 'Epoch: 154, Train Loss: 0.009412289786607, Val Loss: 0.008866012506187', 'Epoch: 155, Train Loss: 0.009630426277168, Val Loss: 0.008990020323545', 'Epoch: 156, Train Loss: 0.010761166684503, Val Loss: 0.008691019322723', 'Epoch: 157, Train Loss: 0.009630153995267, Val Loss: 0.008801240622997', 'Epoch: 158, Train Loss: 0.009381812769746, Val Loss: 0.008882219903171', 'Epoch: 159, Train Loss: 0.009887670740745, Val Loss: 0.009329013042152', 'Epoch: 160, Train Loss: 0.009161910626951, Val Loss: 0.009139384087175', 'Epoch: 161, Train Loss: 0.009996375263950, Val Loss: 0.008987996075302', 'Epoch: 162, Train Loss: 0.009443173423236, Val Loss: 0.008652135143057', 'Epoch: 163, Train Loss: 0.009985108491640, Val Loss: 0.009802737664431', 'Epoch: 164, Train Loss: 0.009789892580620, Val Loss: 0.010456899218261', 'Epoch: 165, Train Loss: 0.010219220581010, Val Loss: 0.009620751794428', 'Epoch: 166, Train Loss: 0.009684918924820, Val Loss: 0.008680282533169', 'Epoch: 167, Train Loss: 0.009309777129052, Val Loss: 0.009360049888492', 'Epoch: 168, Train Loss: 0.009231461206624, Val Loss: 0.008593688681722', 'Epoch: 169, Train Loss: 0.009117202979491, Val Loss: 0.010093287918717', 'Epoch: 170, Train Loss: 0.009626851514588, Val Loss: 0.009645247347653', 'Epoch: 171, Train Loss: 0.009463900407820, Val Loss: 0.009550218367949', 'Epoch: 172, Train Loss: 0.010069956050016, Val Loss: 0.009419923573732', 'Epoch: 173, Train Loss: 0.009693241060906, Val Loss: 0.008719730889425', 'Epoch: 174, Train Loss: 0.008593624549766, Val Loss: 0.008968567689881', 'Epoch: 175, Train Loss: 0.009609213835278, Val Loss: 0.008311496721581', 'Epoch: 176, Train Loss: 0.008637719733511, Val Loss: 0.008519411101006', 'Epoch: 177, Train Loss: 0.008906220811484, Val Loss: 0.008796863202006', 'Epoch: 178, Train Loss: 0.009042326463820, Val Loss: 0.009802437312901', 'Epoch: 179, Train Loss: 0.008907097153539, Val Loss: 0.008612430961803', 'Epoch: 180, Train Loss: 0.008788299757641, Val Loss: 0.008408786868677', 'Epoch: 181, Train Loss: 0.009798980762012, Val Loss: 0.008460601968691', 'Epoch: 182, Train Loss: 0.008574222257837, Val Loss: 0.008566351206973', 'Epoch: 183, Train Loss: 0.008598991252785, Val Loss: 0.008316822201014', 'Epoch: 184, Train Loss: 0.008904061009458, Val Loss: 0.008535126931965', 'Epoch: 185, Train Loss: 0.008912126858567, Val Loss: 0.008617236930877', 'Epoch: 186, Train Loss: 0.009258880518204, Val Loss: 0.008730541048571', 'Epoch: 187, Train Loss: 0.009064375238796, Val Loss: 0.008536174353212', 'Epoch: 188, Train Loss: 0.008663890601764, Val Loss: 0.008475589007139', 'Epoch: 189, Train Loss: 0.008514774161889, Val Loss: 0.008461202420294', 'Epoch: 190, Train Loss: 0.008610400133008, Val Loss: 0.008617545431480', 'Epoch: 191, Train Loss: 0.009091093031646, Val Loss: 0.008600022085011', 'Epoch: 192, Train Loss: 0.008786311048235, Val Loss: 0.008791614286602', 'Epoch: 193, Train Loss: 0.009096868590690, Val Loss: 0.008771635461599', 'Epoch: 194, Train Loss: 0.008849108597090, Val Loss: 0.008593316152692', 'Epoch: 195, Train Loss: 0.008290196335766, Val Loss: 0.008718323279172', 'Epoch: 196, Train Loss: 0.008142761333824, Val Loss: 0.008888696227223', 'Epoch: 197, Train Loss: 0.008323454157298, Val Loss: 0.008662962988019', 'Epoch: 198, Train Loss: 0.007848293932025, Val Loss: 0.008650217568502', 'Epoch: 199, Train Loss: 0.008058301368079, Val Loss: 0.008668025592342']","[1049.1262    1128.428      550.1985     668.393       65.746826
  581.4909     376.20593    163.74164    810.5076     489.53128
 1322.9875     728.09155    718.38214   1213.4163     451.3122
  268.338      716.83936    440.21274    898.68463    627.5302
  520.70856     28.836334   220.12024   1055.197      485.8756
  338.38098    121.86899    618.21625    775.7213     371.5333
 1182.6387     799.1945     990.07495    656.16785    228.64641
  931.3541     524.9467     202.58578     61.705383   258.97784
  248.55992      5.939575   465.29904     98.30032    588.36536
  386.37152    616.4218      15.48999    281.56277    234.76913
  791.2859     145.95404    692.04755    161.28119    267.62082
  436.06293    551.7031     144.52527     58.86377     18.882751
  451.16336     50.22644    724.11664    224.60101    132.43939
  233.03748    946.689      641.5893     668.82935    643.04346
  653.7397    1366.3656    1259.5774     165.81598    188.09778
  370.26712     81.55298    354.22437    887.37634   1178.6833
  373.6819     434.34247    933.3108     768.27527    606.8325
   55.31909    396.92435   1245.9294     733.4381     428.4064
 1447.2749    1352.4832     748.48895    816.8513     853.8888
  894.53723    702.18115   1139.1514     100.83212    916.68945
  645.12756    644.6581      58.134216   304.5973     760.2761
   99.867004  1069.0924      47.510437     2.4596558   77.78531
  174.5168     501.3334    1048.5381     168.85193    132.60524
  164.47195    142.4024     476.1663    1073.6771     264.031
   74.64227    944.06616    631.166     1152.8608     239.10406
  512.8183     598.573      165.1131    1014.9177     685.7241
 1054.269      713.42206    232.36176    269.29596    337.04852
  158.77872    694.5744     167.34776   1338.6365     457.30292
  191.52509    292.75436    454.23788    815.3774     948.83606
  646.66406    234.85086    361.8753     339.47943    419.15527
  703.0818     639.4236    1260.8076     934.5391     130.69714
  355.19598    466.37634     84.011444   526.02563     62.72522
  482.90488    301.49557   1002.7989     440.3371     963.3172
 1141.5808     488.075      198.01303    322.92505    554.52655
 1360.6355     226.37567    744.9992      24.3443     111.58301
  529.1666     752.489      162.8277      43.393555   818.9028
  151.72333    391.37814    720.04504    522.4109     517.46454
  219.93356     67.32391    525.526      787.4158    1098.989
  209.14429     83.97748    345.76126     17.123749   153.66727
  593.99536    310.76184     73.29352    933.9858    1094.0817
  235.13425    815.22363    473.82803    437.9303     143.79788
  391.3157     469.965      559.         722.75336    609.15076
    7.731018   984.85333    683.8025     770.3344     452.39896
   91.3259     244.47614    209.24628   1070.127      700.2815
  222.61328    598.0923     837.87024    205.05557    880.19147
  236.58978    892.11646    114.25757    331.885       16.929108
  791.92474    287.4045     192.25894    585.0569     376.2718
  266.56348    852.5684     672.9807     294.56686    626.95154
 1390.0975     895.10236    910.84814    971.7527     413.6665
 1010.4247     466.90137    425.62314    221.93257    465.8768
  438.6479     751.7284     523.47034     20.315826   908.30646
  675.4296     491.52155     37.304047    16.02237    181.3934
  264.585      126.4801     524.7284     120.64322    715.0277
  145.23853    624.8772     880.6892     271.20236   1365.0287
 1018.391      912.11786    164.0799     579.68225   1164.2903
 1107.9663     955.51495    416.09647    305.2096     489.01016
   86.29349    310.9952     646.59827    473.4579     564.0579
  813.64087    192.15337    321.28857      9.604126   290.63617
  733.11707    668.07965    497.1421       8.989868   587.9883
  290.73505     78.1485     381.6427     689.6207     260.69092
  278.37152    521.1315    1154.5919    1317.2036     947.3563
  998.0026     696.13776    674.3711     275.652      416.3858
  104.763306   817.03766    589.1347     445.08502   1047.901
 1027.9983    1069.0494     108.15082    304.00848    100.5061
  185.79712     14.494263   163.43457    126.71835    190.06348
  977.72253    121.824005   882.16705    264.3579    1010.9782
  640.8393     983.26227    189.42734    360.08478     58.663086
  314.77393    279.42593     91.33356    207.39575    956.542
  100.07106    190.09413    326.05457    124.05591    264.98227
  706.648      636.05774      5.9016724   59.308594   128.531
  312.18015    140.3169      67.48328    251.7325     407.50546
  800.19855    496.97302    634.6661     307.93555    704.51373
  505.02246   1327.7084     863.0652     756.9429     733.48615
  175.55066    866.3864     274.30576   1071.561      404.57928
 1315.3657     225.34317    346.4177     914.3395     604.9614
  213.46893    916.0236     883.59674    411.09955     31.073425
   33.17099    748.2058      48.25064    904.5343    1008.3588
  794.1654     740.313      895.37573    858.843      254.45024
    3.4224548  300.22534    263.78772    838.3502       8.0937195
  294.11392    434.13223    306.89346   1244.928      995.98883  ]","[1102.8983   1207.1927    549.1537    684.4887     55.400146  593.668
  377.98907   159.90845   793.1533    490.48843  1265.5127    720.1341
  716.2548   1192.7908    445.22675   270.7323    708.30054   439.9086
  874.5404    623.4705    508.66605    29.986206  195.04431  1082.8661
  502.44925   348.4484    139.76198   602.6327    747.47314   377.31253
 1142.3757    778.601     971.9894    660.3193    241.9841    911.47546
  533.71515   189.12708    64.89755   259.20715   246.77411    12.085754
  493.8634     58.05841   579.0884    384.16852   595.7159     60.281036
  288.72583   233.58412   759.86475   179.03207   676.26807   172.01825
  270.85287   423.56323   514.6482    167.85078   349.15225   319.2624
  442.37955    57.42363   735.9416    213.216     127.53882   232.77313
  923.0407    638.4069    744.91266   712.19336   655.9086   1345.9094
 1180.4941    253.8794    197.93858   363.6252     87.59363   355.81668
  875.63434  1145.3845    377.8505    440.7256    926.4537    767.7642
  585.19806    88.3378    330.70627  1349.0032    709.6199    425.6253
 1381.761    1310.3726    725.7989    796.6384    957.44354  1014.36816
  694.7918   1122.6487    103.23709   918.82275   704.0398    713.51074
  135.91266   357.40686   760.9699     86.74469  1051.171      85.49762
   67.21805   126.33157   181.70412   500.4081   1052.8911    159.73892
   97.278564  138.43417   152.41327   472.43866  1060.6063    274.12512
   74.58832   946.7308    641.8055   1139.5933    260.017     522.2586
  596.65295   170.86702   988.9932    682.4572   1022.30524   706.23157
  191.02878   237.91629   337.33694   168.33055   719.3818    148.6514
 1397.4749    398.89514   180.4342    295.3687    453.16156   807.9683
  918.77405   627.53754   243.5155    354.85522   344.58316   432.44434
  636.9663    593.68384  1197.1553    906.7766    148.01782   356.52567
  471.4688     87.0531    519.5867     59.67517   483.31976   306.77304
 1003.9821    438.06738   992.3593   1162.6072    491.4779    204.90195
  324.54526   552.4122   1295.189     266.76483   739.4276     44.404938
   35.142456  610.7528    738.3754    163.22192    71.13104   820.73346
  118.075745  384.55515   707.4613    516.87256   477.017     231.97377
   64.21442   513.8007    796.8651   1100.4706    255.7659    154.59424
  342.6143     19.353424  163.50743   573.92163   312.1422     75.87157
  925.70544  1102.9414    238.51474   813.0622    475.8413    455.5218
  158.73462   393.81558   487.4672    583.37134   727.25494   611.6285
   56.70166   977.4238    679.3992    741.97095   446.64862   107.23386
  182.46332   145.23395  1045.9692    695.0152    229.10583   597.4802
  840.7886    206.44989   917.68      206.75885   878.87415   132.90247
  312.4198     33.193314  828.3293    259.3098    190.62585   586.0885
  361.8046    245.5227    858.1608    666.8607    308.8457    629.0212
 1390.0487    886.2669    900.41754   951.0656    443.11517   992.873
  444.79956   416.9822    226.22073   450.69098   439.0126    748.17444
  507.5862     50.788513  900.17255   668.95245   483.2859     70.138596
   34.391663  192.76942   267.76205   119.797226  514.81793   130.55261
  688.67267   172.3558    621.492     888.89484   292.2293   1334.2455
 1010.168     910.59625   176.13174   578.95624  1162.441    1098.9299
  946.7922    426.5543    303.06442   475.75775    16.485596  321.22064
  637.0792    468.68762   573.6407    825.3544    191.02022   319.40213
   63.629974  310.36728   715.6035    661.86414   428.2771     75.70955
  604.0133    294.68494   113.985596  407.5105    681.15625   275.12558
  277.70676   516.77216  1112.5807   1270.4236   1041.8718   1110.4521
  784.88574   754.65027   282.87018   414.3712     94.013     824.04193
  600.03674   450.8718   1000.86926   987.3308   1065.6185    131.06622
  333.25104    86.059235  186.67369    20.108795  115.60132    73.0636
  186.43835   982.5929    173.02856   812.4974    276.09235   984.31085
  646.4495    985.80347   209.01358   359.68948   111.15662   340.79086
  276.63663    65.85986   221.32645   931.46533    90.57266   188.1612
  329.92407   120.976715  270.45395   711.1307    616.4177     57.390656
   80.03331   141.07034   312.2936    137.26038    63.49878   242.5386
  415.0038    798.74414   473.31628   589.17725   322.26154   691.2765
  504.78186  1332.9017    897.4064    782.0148    728.27844   191.83688
  881.28845   242.4924   1038.6355    426.1089   1262.2458    264.4731
  351.20325   900.05255   616.00684   214.54529  1086.7197   1047.0339
  406.1392     55.711914   75.41501   724.9291     98.93387   873.44324
 1046.0758    808.278     754.657     928.82153   791.65436   291.51743
   62.625793  323.52023   233.28278   878.7174     31.602142  297.0353
  437.96768   302.3701   1243.7871    992.0722  ]",22.177378,1447.566,38.04689264629981
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 0.498237225898477, Val Loss: 0.547910313606262', 'Epoch: 1, Train Loss: 0.446898970493050, Val Loss: 0.488284802436829', 'Epoch: 2, Train Loss: 0.348196061891179, Val Loss: 0.321362661719322', 'Epoch: 3, Train Loss: 0.185447737401308, Val Loss: 0.116465323269367', 'Epoch: 4, Train Loss: 0.095600069002357, Val Loss: 0.078155717104673', 'Epoch: 5, Train Loss: 0.079605979368437, Val Loss: 0.093428377956152', 'Epoch: 6, Train Loss: 0.072285177922526, Val Loss: 0.051452216841280', 'Epoch: 7, Train Loss: 0.062372169782256, Val Loss: 0.058448484316468', 'Epoch: 8, Train Loss: 0.057763763551795, Val Loss: 0.045541094020009', 'Epoch: 9, Train Loss: 0.057293777245768, Val Loss: 0.047019600197673', 'Epoch: 10, Train Loss: 0.056566999575426, Val Loss: 0.058462554961443', 'Epoch: 11, Train Loss: 0.054876094987226, Val Loss: 0.058923727571964', 'Epoch: 12, Train Loss: 0.053299293615097, Val Loss: 0.052195506989956', 'Epoch: 13, Train Loss: 0.046638883000543, Val Loss: 0.047751624584198', 'Epoch: 14, Train Loss: 0.044783271632569, Val Loss: 0.040212894529104', 'Epoch: 15, Train Loss: 0.047233859943443, Val Loss: 0.044757902622223', 'Epoch: 16, Train Loss: 0.046356739779544, Val Loss: 0.049461651444435', 'Epoch: 17, Train Loss: 0.045412088029606, Val Loss: 0.055743801593781', 'Epoch: 18, Train Loss: 0.046940134621637, Val Loss: 0.038270959593356', 'Epoch: 19, Train Loss: 0.043011734305426, Val Loss: 0.040191086754203', 'Epoch: 20, Train Loss: 0.046448418502371, Val Loss: 0.041334696933627', 'Epoch: 21, Train Loss: 0.047367337701279, Val Loss: 0.056365895941854', 'Epoch: 22, Train Loss: 0.042137053080423, Val Loss: 0.029871872514486', 'Epoch: 23, Train Loss: 0.041925796112695, Val Loss: 0.035995471775532', 'Epoch: 24, Train Loss: 0.042226885033901, Val Loss: 0.034834733158350', 'Epoch: 25, Train Loss: 0.041957454539316, Val Loss: 0.036547177135944', 'Epoch: 26, Train Loss: 0.040060354353384, Val Loss: 0.040584939867258', 'Epoch: 27, Train Loss: 0.039646288553296, Val Loss: 0.039876640141010', 'Epoch: 28, Train Loss: 0.036945998322132, Val Loss: 0.029418938010931', 'Epoch: 29, Train Loss: 0.040350235608775, Val Loss: 0.037603449672461', 'Epoch: 30, Train Loss: 0.036802529703912, Val Loss: 0.034936877787113', 'Epoch: 31, Train Loss: 0.040242346393508, Val Loss: 0.027094083875418', 'Epoch: 32, Train Loss: 0.039808189453081, Val Loss: 0.026953716501594', 'Epoch: 33, Train Loss: 0.036632063387092, Val Loss: 0.030664361417294', 'Epoch: 34, Train Loss: 0.033054877419111, Val Loss: 0.035794931426644', 'Epoch: 35, Train Loss: 0.042592712309818, Val Loss: 0.030607195645571', 'Epoch: 36, Train Loss: 0.035774599890723, Val Loss: 0.041414429992437', 'Epoch: 37, Train Loss: 0.036512543339022, Val Loss: 0.028205088078976', 'Epoch: 38, Train Loss: 0.031191381235975, Val Loss: 0.021103298142552', 'Epoch: 39, Train Loss: 0.032396681823356, Val Loss: 0.033278231322765', 'Epoch: 40, Train Loss: 0.035028165531193, Val Loss: 0.037221017777920', 'Epoch: 41, Train Loss: 0.034817341346900, Val Loss: 0.041513011157513', 'Epoch: 42, Train Loss: 0.026026515528386, Val Loss: 0.020647533386946', 'Epoch: 43, Train Loss: 0.029473699802576, Val Loss: 0.026268967688084', 'Epoch: 44, Train Loss: 0.030166057804816, Val Loss: 0.023465575277805', 'Epoch: 45, Train Loss: 0.026196340553809, Val Loss: 0.030514319390059', 'Epoch: 46, Train Loss: 0.030738379719645, Val Loss: 0.030785246491432', 'Epoch: 47, Train Loss: 0.034031208886137, Val Loss: 0.028381105959415', 'Epoch: 48, Train Loss: 0.024951701052487, Val Loss: 0.019922171980143', 'Epoch: 49, Train Loss: 0.026711766824646, Val Loss: 0.021535762399435', 'Epoch: 50, Train Loss: 0.027566235469178, Val Loss: 0.034972154498100', 'Epoch: 51, Train Loss: 0.030708327867784, Val Loss: 0.019702576547861', 'Epoch: 52, Train Loss: 0.024378882959312, Val Loss: 0.020804685391486', 'Epoch: 53, Train Loss: 0.023402653288010, Val Loss: 0.019250596016645', 'Epoch: 54, Train Loss: 0.024070876585536, Val Loss: 0.022672290578485', 'Epoch: 55, Train Loss: 0.024812689094349, Val Loss: 0.020288765802979', 'Epoch: 56, Train Loss: 0.021962160244584, Val Loss: 0.015260696113110', 'Epoch: 57, Train Loss: 0.023129156140914, Val Loss: 0.023888876885176', 'Epoch: 58, Train Loss: 0.020730139969220, Val Loss: 0.019958247244358', 'Epoch: 59, Train Loss: 0.020962910531738, Val Loss: 0.019700806885958', 'Epoch: 60, Train Loss: 0.024993024203320, Val Loss: 0.016411651372910', 'Epoch: 61, Train Loss: 0.025760920696654, Val Loss: 0.019431544616818', 'Epoch: 62, Train Loss: 0.024073883068076, Val Loss: 0.022013405337930', 'Epoch: 63, Train Loss: 0.020049245075084, Val Loss: 0.028065181225538', 'Epoch: 64, Train Loss: 0.022270584045801, Val Loss: 0.017125734090805', 'Epoch: 65, Train Loss: 0.020323234003817, Val Loss: 0.024994743317366', 'Epoch: 66, Train Loss: 0.020400291547006, Val Loss: 0.017862212359905', 'Epoch: 67, Train Loss: 0.020319527903095, Val Loss: 0.019594080224633', 'Epoch: 68, Train Loss: 0.019486425357849, Val Loss: 0.013609135206789', 'Epoch: 69, Train Loss: 0.020180916348689, Val Loss: 0.021268963404000', 'Epoch: 70, Train Loss: 0.022428154295614, Val Loss: 0.024085463732481', 'Epoch: 71, Train Loss: 0.020575675810146, Val Loss: 0.013892119880766', 'Epoch: 72, Train Loss: 0.018552467010395, Val Loss: 0.019668879136443', 'Epoch: 73, Train Loss: 0.019537648186088, Val Loss: 0.014780950844288', 'Epoch: 74, Train Loss: 0.019708197953743, Val Loss: 0.012946867533028', 'Epoch: 75, Train Loss: 0.022577554940484, Val Loss: 0.019365015551448', 'Epoch: 76, Train Loss: 0.019348828685145, Val Loss: 0.015852359831333', 'Epoch: 77, Train Loss: 0.018382905116088, Val Loss: 0.015308954343200', 'Epoch: 78, Train Loss: 0.019055067193370, Val Loss: 0.017989256512374', 'Epoch: 79, Train Loss: 0.022113950338301, Val Loss: 0.017346500828862', 'Epoch: 80, Train Loss: 0.018826767932190, Val Loss: 0.017469815611839', 'Epoch: 81, Train Loss: 0.021613125256154, Val Loss: 0.029282738417387', 'Epoch: 82, Train Loss: 0.018685610011913, Val Loss: 0.014998564943671', 'Epoch: 83, Train Loss: 0.017253188827876, Val Loss: 0.014290336035192', 'Epoch: 84, Train Loss: 0.017927373542862, Val Loss: 0.014154101312160', 'Epoch: 85, Train Loss: 0.018765298519717, Val Loss: 0.020642676874995', 'Epoch: 86, Train Loss: 0.018437624952301, Val Loss: 0.013997647091746', 'Epoch: 87, Train Loss: 0.017947394855667, Val Loss: 0.016783979535103', 'Epoch: 88, Train Loss: 0.016837116200910, Val Loss: 0.015760750025511', 'Epoch: 89, Train Loss: 0.015676995241191, Val Loss: 0.018064102903008', 'Epoch: 90, Train Loss: 0.018218320783574, Val Loss: 0.018464212939143', 'Epoch: 91, Train Loss: 0.017324913466393, Val Loss: 0.018305513374507', 'Epoch: 92, Train Loss: 0.017654140219959, Val Loss: 0.012877227887511', 'Epoch: 93, Train Loss: 0.019968630031271, Val Loss: 0.012505062930286', 'Epoch: 94, Train Loss: 0.017023068116328, Val Loss: 0.017697423696518', 'Epoch: 95, Train Loss: 0.015476589242733, Val Loss: 0.012647267393768', 'Epoch: 96, Train Loss: 0.015693206632467, Val Loss: 0.014265603311360', 'Epoch: 97, Train Loss: 0.015273675149263, Val Loss: 0.017481694445014', 'Epoch: 98, Train Loss: 0.022040776691811, Val Loss: 0.019123881682754', 'Epoch: 99, Train Loss: 0.019427719634286, Val Loss: 0.016823463328183', 'Epoch: 100, Train Loss: 0.017817842839069, Val Loss: 0.015244010910392', 'Epoch: 101, Train Loss: 0.016594880141404, Val Loss: 0.021419753581285', 'Epoch: 102, Train Loss: 0.016180440480279, Val Loss: 0.012432067077607', 'Epoch: 103, Train Loss: 0.014680476252769, Val Loss: 0.013299586251378', 'Epoch: 104, Train Loss: 0.016382880909585, Val Loss: 0.018619199022651', 'Epoch: 105, Train Loss: 0.016074574227596, Val Loss: 0.015643371641636', 'Epoch: 106, Train Loss: 0.017607132557693, Val Loss: 0.011806728988886', 'Epoch: 107, Train Loss: 0.017487794485723, Val Loss: 0.014027708508074', 'Epoch: 108, Train Loss: 0.016721546704080, Val Loss: 0.016460412200540', 'Epoch: 109, Train Loss: 0.017033353686159, Val Loss: 0.025190900564194', 'Epoch: 110, Train Loss: 0.015181407819740, Val Loss: 0.014957807436585', 'Epoch: 111, Train Loss: 0.014743660663276, Val Loss: 0.016830467619002', 'Epoch: 112, Train Loss: 0.014949566879591, Val Loss: 0.010126663334668', 'Epoch: 113, Train Loss: 0.014621283501647, Val Loss: 0.013474311158061', 'Epoch: 114, Train Loss: 0.014155461474560, Val Loss: 0.013143783211708', 'Epoch: 115, Train Loss: 0.015407659340823, Val Loss: 0.016890112683177', 'Epoch: 116, Train Loss: 0.016339248154572, Val Loss: 0.009558364190161', 'Epoch: 117, Train Loss: 0.013096127377520, Val Loss: 0.012013065591455', 'Epoch: 118, Train Loss: 0.016949949287918, Val Loss: 0.010828656791709', 'Epoch: 119, Train Loss: 0.014576151111531, Val Loss: 0.014259568117559', 'Epoch: 120, Train Loss: 0.014439907542235, Val Loss: 0.011580952685326', 'Epoch: 121, Train Loss: 0.014025981743755, Val Loss: 0.011356282792985', 'Epoch: 122, Train Loss: 0.014051171203772, Val Loss: 0.010636837705970', 'Epoch: 123, Train Loss: 0.013641006237459, Val Loss: 0.015537808053195', 'Epoch: 124, Train Loss: 0.016373436887164, Val Loss: 0.012028032708913', 'Epoch: 125, Train Loss: 0.014030949158464, Val Loss: 0.010290073491633', 'Epoch: 126, Train Loss: 0.012321570844844, Val Loss: 0.012263312228024', 'Epoch: 127, Train Loss: 0.013243274145955, Val Loss: 0.012605716399848', 'Epoch: 128, Train Loss: 0.013218171428889, Val Loss: 0.008471017647535', 'Epoch: 129, Train Loss: 0.014060695969695, Val Loss: 0.009575048051775', 'Epoch: 130, Train Loss: 0.014182810162649, Val Loss: 0.010323455873877', 'Epoch: 131, Train Loss: 0.011909588738236, Val Loss: 0.009888104461133', 'Epoch: 132, Train Loss: 0.013783811840640, Val Loss: 0.012222698628902', 'Epoch: 133, Train Loss: 0.012400988944221, Val Loss: 0.009115773141384', 'Epoch: 134, Train Loss: 0.013869106228095, Val Loss: 0.013887911513448', 'Epoch: 135, Train Loss: 0.012281499618968, Val Loss: 0.011683960650116', 'Epoch: 136, Train Loss: 0.011678972357321, Val Loss: 0.010474965367466', 'Epoch: 137, Train Loss: 0.013175747563066, Val Loss: 0.013325652815402', 'Epoch: 138, Train Loss: 0.015017881567135, Val Loss: 0.010466730054468', 'Epoch: 139, Train Loss: 0.013641758778587, Val Loss: 0.011482899375260', 'Epoch: 140, Train Loss: 0.014790897474213, Val Loss: 0.011487738369033', 'Epoch: 141, Train Loss: 0.012998374763790, Val Loss: 0.013211575597525', 'Epoch: 142, Train Loss: 0.013289213722009, Val Loss: 0.013091347143054', 'Epoch: 143, Train Loss: 0.014818927175690, Val Loss: 0.011493335478008', 'Epoch: 144, Train Loss: 0.013919785954491, Val Loss: 0.008758062310517', 'Epoch: 145, Train Loss: 0.012110895444747, Val Loss: 0.009755169320852', 'Epoch: 146, Train Loss: 0.013804284725771, Val Loss: 0.009368137922138', 'Epoch: 147, Train Loss: 0.012320988551649, Val Loss: 0.010602921508253', 'Epoch: 148, Train Loss: 0.011931702873648, Val Loss: 0.010285469330847', 'Epoch: 149, Train Loss: 0.012601112210473, Val Loss: 0.013521086769179', 'Epoch: 150, Train Loss: 0.012650623311137, Val Loss: 0.009532054550946', 'Epoch: 151, Train Loss: 0.011460880440292, Val Loss: 0.009615679793060', 'Epoch: 152, Train Loss: 0.013548833523812, Val Loss: 0.011474297381938', 'Epoch: 153, Train Loss: 0.013312849876752, Val Loss: 0.010914289597422', 'Epoch: 154, Train Loss: 0.013366437203056, Val Loss: 0.008947006370872', 'Epoch: 155, Train Loss: 0.011837882650366, Val Loss: 0.009428333155811', 'Epoch: 156, Train Loss: 0.011778241261667, Val Loss: 0.010334578491747', 'Epoch: 157, Train Loss: 0.012125027636716, Val Loss: 0.009202064080164', 'Epoch: 158, Train Loss: 0.011254938151471, Val Loss: 0.010169260520488', 'Epoch: 159, Train Loss: 0.011913168103283, Val Loss: 0.011576485559344', 'Epoch: 160, Train Loss: 0.011622359607975, Val Loss: 0.009054161235690', 'Epoch: 161, Train Loss: 0.010435312369102, Val Loss: 0.008789680507034', 'Epoch: 162, Train Loss: 0.011863508001836, Val Loss: 0.010076499888673', 'Epoch: 163, Train Loss: 0.012279585805223, Val Loss: 0.009056013785303', 'Epoch: 164, Train Loss: 0.011274117998086, Val Loss: 0.010282805636525', 'Epoch: 165, Train Loss: 0.011200018941836, Val Loss: 0.009875057432801', 'Epoch: 166, Train Loss: 0.011929543028304, Val Loss: 0.008474212582223', 'Epoch: 167, Train Loss: 0.011067862990637, Val Loss: 0.008693386018276', 'Epoch: 168, Train Loss: 0.010783728277094, Val Loss: 0.010053703822196', 'Epoch: 169, Train Loss: 0.011771817063523, Val Loss: 0.008998977532610', 'Epoch: 170, Train Loss: 0.010649597375156, Val Loss: 0.009666329342872', 'Epoch: 171, Train Loss: 0.010355092271036, Val Loss: 0.009312080945820', 'Epoch: 172, Train Loss: 0.011304001822028, Val Loss: 0.009223166587763', 'Epoch: 173, Train Loss: 0.010888102756770, Val Loss: 0.008908538613468', 'Epoch: 174, Train Loss: 0.010683804902053, Val Loss: 0.008426382392645', 'Epoch: 175, Train Loss: 0.011826254059236, Val Loss: 0.010406810073182', 'Epoch: 176, Train Loss: 0.011449115773186, Val Loss: 0.008186168093234', 'Epoch: 177, Train Loss: 0.010334762051528, Val Loss: 0.007896810229868', 'Epoch: 178, Train Loss: 0.010693792686906, Val Loss: 0.008485804079100', 'Epoch: 179, Train Loss: 0.010649021411704, Val Loss: 0.008764217402786', 'Epoch: 180, Train Loss: 0.011012538975148, Val Loss: 0.009212644696236', 'Epoch: 181, Train Loss: 0.010963479766276, Val Loss: 0.007957527255639', 'Epoch: 182, Train Loss: 0.010614166621032, Val Loss: 0.007973090177402', 'Epoch: 183, Train Loss: 0.010914924337940, Val Loss: 0.008034845888615', 'Epoch: 184, Train Loss: 0.010275623003064, Val Loss: 0.007800131477416', 'Epoch: 185, Train Loss: 0.010150620237339, Val Loss: 0.007739469767548', 'Epoch: 186, Train Loss: 0.010980879822963, Val Loss: 0.010101583041251', 'Epoch: 187, Train Loss: 0.010610036519464, Val Loss: 0.008755938308313', 'Epoch: 188, Train Loss: 0.010529327655731, Val Loss: 0.008322030892596', 'Epoch: 189, Train Loss: 0.010330498077755, Val Loss: 0.008276901571080', 'Epoch: 190, Train Loss: 0.010015748971857, Val Loss: 0.007739298269153', 'Epoch: 191, Train Loss: 0.009901259570967, Val Loss: 0.007405049894005', 'Epoch: 192, Train Loss: 0.008709833448276, Val Loss: 0.008028477830812', 'Epoch: 193, Train Loss: 0.009660211462138, Val Loss: 0.007401548586786', 'Epoch: 194, Train Loss: 0.010060632428111, Val Loss: 0.007835819749162', 'Epoch: 195, Train Loss: 0.009468116375163, Val Loss: 0.007668558899313', 'Epoch: 196, Train Loss: 0.010169377712923, Val Loss: 0.007868202254176', 'Epoch: 197, Train Loss: 0.010477737761861, Val Loss: 0.007385789100081', 'Epoch: 198, Train Loss: 0.010324015574486, Val Loss: 0.007434897590429', 'Epoch: 199, Train Loss: 0.010550498041909, Val Loss: 0.007401112066582']","[4.19147644e+01 3.27628479e+01 5.50385437e+02 3.50236298e+02
 6.65586365e+02 1.16055945e+03 6.04203979e+02 9.10430054e+02
 4.52342987e+02 4.81106995e+02 1.01187805e+02 9.02488403e+02
 5.91128174e+02 1.75948853e+02 6.65840942e+02 1.52123657e+02
 1.26693726e+02 8.20963257e+02 3.28229309e+02 4.82737305e+02
 4.51076843e+02 6.60454102e+01 3.84812195e+02 5.10440613e+02
 4.76400757e+02 1.42394974e+02 2.24579819e+02 1.80094421e+02
 3.67840881e+02 2.31299881e+02 8.25084534e+02 8.44299133e+02
 1.89390259e+02 2.41622742e+02 2.90270294e+02 8.35363770e+02
 1.71832001e+02 2.90451233e+02 9.15861450e+02 3.36892517e+02
 7.81784058e+01 1.01915863e+03 4.70890259e+02 7.92287109e+02
 5.16518311e+02 2.15496613e+02 2.92731934e+01 3.00740601e+02
 1.32959290e+01 5.83875977e+02 3.92289032e+02 6.24782593e+02
 4.96308868e+02 2.66155640e+02 3.59767700e+02 6.88383667e+02
 5.98436523e+02 5.30014648e+02 1.10838965e+03 5.94796753e+01
 1.33139600e+03 4.94574188e+02 9.56621643e+02 6.94957764e+02
 3.00823181e+02 1.12052856e+03 1.33014282e+03 9.74518188e+02
 1.00098651e+03 9.15561890e+02 2.13177948e+02 8.28802307e+02
 9.31904907e+02 3.48679565e+02 3.70109253e+02 9.43348083e+02
 3.44584351e+02 2.89184845e+02 9.91057861e+02 4.56368103e+02
 6.27195923e+02 8.74377319e+02 1.15482373e+03 2.42815247e+02
 1.03431592e+03 8.61880005e+02 7.34628418e+02 2.12199371e+02
 3.51230225e+02 3.09537842e+02 4.29880707e+02 2.51725128e+02
 4.44779266e+02 6.99163940e+02 7.99246582e+02 4.03210327e+02
 5.93811035e+01 4.51551331e+02 5.77968262e+02 5.63006836e+02
 6.86690674e+01 4.64410217e+02 6.49452515e+02 6.28732666e+02
 3.46554321e+02 1.22079163e+02 2.76094299e+02 6.11637512e+02
 6.02526672e+02 7.09408752e+02 2.11570435e+01 8.18123901e+02
 4.10534485e+02 2.89976685e+02 3.93641296e+02 7.97568054e+01
 1.01229480e+03 8.72834473e+02 6.07771606e+01 8.94979614e+02
 3.75418213e+02 4.39457397e+02 6.53367188e+02 3.46270599e+02
 2.59317719e+02 5.71671997e+02 9.97524048e+02 8.21032593e+02
 3.42932922e+02 2.25861359e+02 3.52537659e+02 4.29914032e+02
 5.40863037e+02 1.22314746e+03 5.94052979e+02 1.25140991e+03
 1.11424609e+03 5.71476440e+01 1.35494873e+02 9.33118530e+02
 4.89032349e+02 1.36541962e+02 3.87585480e+02 7.75530212e+02
 4.83139191e+01 1.90884140e+02 5.23829590e+02 4.57000763e+02
 6.66471985e+02 2.87308533e+02 1.59234436e+02 1.26604883e+03
 4.88765045e+02 9.72184814e+02 2.98525604e+02 1.63002899e+02
 2.66681641e+02 4.18338013e+02 1.24915253e+02 3.09208038e+02
 8.30044434e+02 7.46705322e+02 1.64400085e+02 1.09578003e+03
 9.20858765e+01 1.85588211e+02 1.10186951e+02 5.58471558e+02
 8.65299683e+02 8.22223938e+02 7.98971252e+02 7.34321167e+02
 5.24957336e+02 2.52889175e+02 1.42117310e+01 7.51452393e+02
 1.96086273e+02 6.13277649e+02 9.29136658e+02 1.00697333e+03
 1.08562732e+03 6.78546021e+02 4.13241608e+02 2.28836670e+01
 1.21064355e+03 6.27451904e+02 2.56912262e+02 2.97991333e+01
 1.88401779e+02 6.84545288e+02 1.40925415e+02 5.87698364e+01
 8.89108154e+02 1.10030298e+03 1.18172485e+03 1.27065918e+03
 4.40526367e+02 6.01857544e+02 2.50043793e+02 4.26634613e+02
 4.73905487e+02 1.13307739e+03 2.59389648e+01 1.47851181e+02
 6.52137573e+02 3.49949707e+02 4.22646210e+02 9.25948425e+02
 3.31196350e+02 3.85195923e+02 1.31167053e+02 7.72255493e+02
 1.17014984e+02 2.60631531e+02 3.78782135e+02 1.07195386e+03
 6.42694824e+02 1.11688293e+02 9.42403076e+02 8.12150635e+02
 6.67120850e+02 7.78526489e+02 6.14301819e+02 9.70095032e+02
 9.26430298e+02 5.27934570e+02 8.65403076e+02 6.77683716e+02
 6.28753235e+02 5.10276215e+02 1.96557678e+02 7.45917969e+02
 1.85638641e+02 7.49498230e+02 5.94125183e+02 6.25662537e+02
 5.02094116e+01 4.53450623e+01 1.13248096e+03 3.52630768e+02
 4.82880219e+02 6.97521118e+02 5.57027039e+02 3.19512939e+02
 7.30966187e+02 1.92250793e+02 4.73009460e+02 2.74981628e+02
 4.73835693e+02 2.20550537e-01 1.12181458e+03 4.28407562e+02
 1.32358630e+03 1.04921777e+03 3.57073669e+01 3.58290619e+02
 1.19795593e+02 2.61291138e+02 2.83657898e+02 5.45966736e+02
 4.37917328e+02 6.27887390e+02 5.47135376e+02 2.80724182e+01
 2.21009140e+02 5.80075684e+02 1.67694946e+02 5.44125854e+02
 6.28269775e+02 3.74772369e+02 7.13240540e+02 1.14034131e+03
 6.82478027e+02 1.10843835e+03 3.57071686e+02 4.22107483e+02
 4.01114349e+02 2.11608780e+02 3.70582947e+02 1.68556717e+02
 4.56727356e+02 9.33457520e+02 5.26440918e+02 3.94339142e+02
 1.81781631e+02 1.17771820e+02 2.43561066e+02 5.78382446e+02
 7.32877197e+02 6.36897827e+02 1.04955688e+03 6.01223572e+02
 4.70375366e+01 3.16528625e+02 5.70060913e+02 5.14717285e+02
 4.24877228e+02 6.43962402e+01 2.72094849e+02 2.37954712e+00
 1.75922546e+01 1.56318970e+01 4.30151581e+02 5.40861694e+02
 4.09079590e+02 7.26473389e+02 9.83086792e+02 7.91408752e+02
 7.18316406e+02 6.71704529e+02 1.47787231e+02 5.14219849e+02
 3.53125458e+02 4.59351776e+02 5.33774109e+02 9.14173401e+02
 1.71581161e+02 3.69570618e+01 3.39874115e+02 7.33129272e+02
 3.45515167e+02 3.61169312e+02 6.60489197e+02 2.19239822e+02
 9.81721863e+02 4.29600891e+02 4.48238831e+01 5.60199585e+02
 1.03535291e+03 7.66127319e+02 3.81887939e+02 2.15388306e+02
 3.33689575e+01 2.08344650e+02 7.61135803e+02 1.37303833e+02
 9.57819092e+02 8.94468933e+02 1.68712677e+02 5.63619019e+02
 8.89840088e+01 1.10149207e+03 9.86698669e+02 1.23773328e+03
 4.82972107e+02 6.67986877e+02 9.50329956e+02 4.85087189e+02
 2.81716309e+02 3.68419617e+02 9.21404724e+02 1.45373145e+03
 1.73746826e+02 5.46730225e+02 3.40038788e+02 3.24595032e+02
 1.04013147e+03 7.11610291e+02 8.21389587e+02 1.66343262e+02
 2.86310394e+02 6.35111328e+02 4.87007111e+02 6.61782227e+01
 9.83435547e+02 8.22486572e+02 5.73960693e+02 2.78925751e+02
 1.12634186e+02 4.20606689e+01 4.14403748e+02 4.86681580e+02
 1.58692078e+02 6.30048889e+02 3.35184845e+02 4.76024536e+02
 1.72552078e+02 5.74363159e+02 3.50373871e+02 1.10084375e+03
 3.22025757e+02 1.48571625e+02 3.53822510e+02 4.90463898e+02
 1.35073865e+03 3.48558594e+02 5.77197021e+02 4.65679932e+02
 6.95466919e+02 1.00272510e+03 8.99457764e+02 4.34244141e+02
 4.68223053e+02 5.89208130e+02 6.81818359e+02 6.03018921e+02
 1.00906091e+03 7.01567627e+02 1.24434106e+03 5.71556152e+02]","[ 106.809814  100.4382    526.3496    340.83514   668.6408   1116.7385
  635.0854    942.729     446.8463    461.7457    105.06122   917.79407
  597.0861    257.09122   650.03186   187.45648   111.48511   841.81537
  319.28027   469.7506    418.69818   110.07181   379.65723   486.37122
  475.20377   146.48764   253.90067   213.35196   348.97247   238.70903
  891.2877    957.22644   135.15915   195.12958   270.1454    810.46313
  177.1218    282.13196   875.5206    344.84677    98.83969   986.8769
  384.9014    867.66675   504.987     234.35043    61.210938  315.3962
   36.117737  613.0725    384.6422    600.0658    560.31946   260.87732
  395.26416   700.80347   604.768     555.0531    997.6346    171.66275
 1366.7808    473.65826   975.014     662.8762    305.14447  1110.4215
 1364.8342   1028.0402   1007.0293    935.3303    216.53925   818.6274
  916.6225    293.95715   371.98584  1001.2697    341.33456   274.22766
  952.4164    467.82483   616.2394    911.31854  1116.6152    256.6732
 1261.2488    895.9656    718.005     231.5682    349.4779    290.55054
  428.7924    237.22003   464.86783   676.3966    817.79065   363.165
   81.2198    423.1814    557.1902    539.7676     77.37463   452.78748
  650.5199    604.05035   320.841     111.11664   268.90955   607.2388
  659.1316    783.5488     32.154602  829.42444   411.76596   280.2721
  376.8623     69.107574 1241.7067    904.96326    79.44107   898.91144
  371.45087   412.0046    623.1321    345.93726   215.58644   661.11334
  985.3127    824.4852    369.07867   192.03545   299.24814   387.3937
  536.7628   1209.5232    611.60846  1166.7239   1101.1188     52.73938
  143.21097   942.78467   494.0716    137.6021    295.61774   710.98834
   34.332123  186.27437   516.50073   440.405     644.25146   279.82385
  135.37085  1260.3151    514.295     952.5791    339.57138   202.5438
  266.50964   436.42072    49.610535  265.03586   810.3347    778.32935
  157.38065  1083.3511     87.21301   171.81496   118.684235  572.8142
  799.0166    780.11414   790.6183    730.9455    536.599     250.76175
   43.187134  765.59784   158.71118   627.3606    938.88855   987.5782
 1064.1648    727.5126    429.19904    52.691162 1138.4141    620.23566
  276.4566     72.126465  185.96246   695.86475   148.56268    82.82263
  960.55066  1313.168    1147.2681   1267.6554    455.53326   600.42566
  261.39197   409.41855   465.4549   1207.2385     93.49933   186.30591
  676.56525   337.7599    448.18625   830.71277   325.57755   360.34683
  172.96246   761.81494   143.85909   253.54964   366.37225  1065.6672
  676.10315   155.21774   961.286     825.5172    659.05505   763.6659
  621.07367   964.9461    906.50745   533.90125   864.4078    682.8178
  630.58704   516.25256   270.51367   732.9475    193.04141   751.01355
  619.98816   661.5209     63.48239    56.668915 1069.036     352.45346
  476.5366    671.9767    544.41583   362.8829    831.52277   126.225525
  475.35062   278.5157    464.9998     37.06009  1079.6901    442.96494
 1346.574    1052.0969     49.171967  366.73767   103.03839   233.00009
  288.09793   546.5602    416.12848   607.4338    552.3598     20.903748
  168.19075   663.48267   177.92029   539.7945    625.82043   406.91525
  697.3312   1201.626     696.8664   1226.4049    367.93774   433.41388
  390.76535   206.72432   377.98373   166.11134   437.81897   922.6448
  597.4487    389.57526   193.73666   114.81601   221.90266   581.84515
  706.6892    609.8926   1048.2582    594.8356     95.30731   341.25113
  553.57684   488.5365    434.52728    45.772552  275.9456     46.974136
   95.32788    71.044785  432.84332   513.84326   399.5147    690.2843
  943.7537    791.2482    707.5278    690.6952     88.88516   572.21423
  355.0305    449.2879    455.40424   965.1227    159.27885    33.858856
  357.04575   734.8573    329.00266   359.57748   675.67377   221.85826
 1025.2651    428.68076    93.011505  577.6562   1070.1802    766.95355
  395.46985   252.56561    65.932556  211.97234   770.2735    100.01117
  993.0716    928.6629    229.40479   541.59247   108.817444 1087.7074
 1004.8215   1219.1378    470.78412   639.5394    954.6931    450.9378
  272.25613   367.9037    858.6535   1369.3982    159.82605   533.19977
  304.09302   364.27054  1116.2091    706.2379    830.2126    152.69556
  263.70892   670.7717    451.4346    102.719604  998.25793   801.82
  576.07684   278.80048   135.99823    57.196167  402.08948   467.99246
  204.56824   669.3618    344.2616    472.59958   169.48792   601.5327
  342.3405   1104.1365    368.91318   188.52402   330.49994   492.58633
 1292.2606    371.7508    540.7103    418.51776   696.86505   995.3025
  905.3756    401.68857   444.47162   566.53186   656.13245   585.72253
  964.04614   679.7501   1192.2246    557.99945 ]",25.816826,1465.8259,38.286106197083754
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 0.371786001809808, Val Loss: 0.359070004224777', 'Epoch: 1, Train Loss: 0.321646621060926, Val Loss: 0.290966370105743', 'Epoch: 2, Train Loss: 0.217900071726289, Val Loss: 0.151035568714142', 'Epoch: 3, Train Loss: 0.098405537130528, Val Loss: 0.066211449950933', 'Epoch: 4, Train Loss: 0.075998726712410, Val Loss: 0.059866919517517', 'Epoch: 5, Train Loss: 0.059440705838592, Val Loss: 0.043327382802963', 'Epoch: 6, Train Loss: 0.058558133842294, Val Loss: 0.043322122693062', 'Epoch: 7, Train Loss: 0.052731827897734, Val Loss: 0.037710842788219', 'Epoch: 8, Train Loss: 0.044864161459859, Val Loss: 0.024980634450912', 'Epoch: 9, Train Loss: 0.039389422250002, Val Loss: 0.032158900052309', 'Epoch: 10, Train Loss: 0.031142419593972, Val Loss: 0.017200853973627', 'Epoch: 11, Train Loss: 0.025687222282381, Val Loss: 0.014008960574865', 'Epoch: 12, Train Loss: 0.024253319450762, Val Loss: 0.009815837144852', 'Epoch: 13, Train Loss: 0.021506800088858, Val Loss: 0.011235795989633', 'Epoch: 14, Train Loss: 0.022451084518675, Val Loss: 0.016618477106094', 'Epoch: 15, Train Loss: 0.021230692585367, Val Loss: 0.008664990216494', 'Epoch: 16, Train Loss: 0.021317685910955, Val Loss: 0.009450432583690', 'Epoch: 17, Train Loss: 0.025056994011149, Val Loss: 0.014771172404289', 'Epoch: 18, Train Loss: 0.020464014955038, Val Loss: 0.018149704337120', 'Epoch: 19, Train Loss: 0.019214945108911, Val Loss: 0.008541112430394', 'Epoch: 20, Train Loss: 0.023330763177296, Val Loss: 0.011971651092172', 'Epoch: 21, Train Loss: 0.021723065546952, Val Loss: 0.008558409065008', 'Epoch: 22, Train Loss: 0.018973732702867, Val Loss: 0.016109414398670', 'Epoch: 23, Train Loss: 0.022177397836606, Val Loss: 0.020017479360104', 'Epoch: 24, Train Loss: 0.019867949588441, Val Loss: 0.010069087967277', 'Epoch: 25, Train Loss: 0.018676273871300, Val Loss: 0.016050274670124', 'Epoch: 26, Train Loss: 0.018841254741473, Val Loss: 0.008553330153227', 'Epoch: 27, Train Loss: 0.018425735060212, Val Loss: 0.007033128552139', 'Epoch: 28, Train Loss: 0.017867025919259, Val Loss: 0.015333745628595', 'Epoch: 29, Train Loss: 0.017965520992009, Val Loss: 0.016047826707363', 'Epoch: 30, Train Loss: 0.018424946760629, Val Loss: 0.013178411871195', 'Epoch: 31, Train Loss: 0.018601188479468, Val Loss: 0.010251284874976', 'Epoch: 32, Train Loss: 0.018230170314742, Val Loss: 0.009556959010661', 'Epoch: 33, Train Loss: 0.018809758668202, Val Loss: 0.015401028171182', 'Epoch: 34, Train Loss: 0.018290970322871, Val Loss: 0.009099911525846', 'Epoch: 35, Train Loss: 0.018547211134763, Val Loss: 0.009656944572926', 'Epoch: 36, Train Loss: 0.020504758021859, Val Loss: 0.015321036949754', 'Epoch: 37, Train Loss: 0.020064473043867, Val Loss: 0.008050742894411', 'Epoch: 38, Train Loss: 0.018828774195944, Val Loss: 0.012352745682001', 'Epoch: 39, Train Loss: 0.020072057290912, Val Loss: 0.017247486561537', 'Epoch: 40, Train Loss: 0.019123726784317, Val Loss: 0.009325318820775', 'Epoch: 41, Train Loss: 0.016236327718510, Val Loss: 0.009467459022999', 'Epoch: 42, Train Loss: 0.015963137561325, Val Loss: 0.007840494364500', 'Epoch: 43, Train Loss: 0.020909105113513, Val Loss: 0.010684313550591', 'Epoch: 44, Train Loss: 0.017953457765628, Val Loss: 0.008886442445219', 'Epoch: 45, Train Loss: 0.015333202082750, Val Loss: 0.008082871362567', 'Epoch: 46, Train Loss: 0.019984113972981, Val Loss: 0.010407938063145', 'Epoch: 47, Train Loss: 0.016216796129769, Val Loss: 0.009030720889568', 'Epoch: 48, Train Loss: 0.016633451872960, Val Loss: 0.009499342516065', 'Epoch: 49, Train Loss: 0.017792780385461, Val Loss: 0.010561777278781', 'Epoch: 50, Train Loss: 0.017768008439520, Val Loss: 0.007633012682199', 'Epoch: 51, Train Loss: 0.017306155059487, Val Loss: 0.006597068198025', 'Epoch: 52, Train Loss: 0.015150333927988, Val Loss: 0.006956735998392', 'Epoch: 53, Train Loss: 0.015402794891405, Val Loss: 0.005872928649187', 'Epoch: 54, Train Loss: 0.015959507320076, Val Loss: 0.009757379814982', 'Epoch: 55, Train Loss: 0.014944477634894, Val Loss: 0.006202373765409', 'Epoch: 56, Train Loss: 0.014926106387446, Val Loss: 0.008362715616822', 'Epoch: 57, Train Loss: 0.015361982376076, Val Loss: 0.007308530882001', 'Epoch: 58, Train Loss: 0.015775823196786, Val Loss: 0.009439718797803', 'Epoch: 59, Train Loss: 0.014826676115220, Val Loss: 0.007039143368602', 'Epoch: 60, Train Loss: 0.015269482302544, Val Loss: 0.007901329211891', 'Epoch: 61, Train Loss: 0.013900547613238, Val Loss: 0.008505701683462', 'Epoch: 62, Train Loss: 0.016973002358925, Val Loss: 0.013610022440553', 'Epoch: 63, Train Loss: 0.016381993814003, Val Loss: 0.007911148071289', 'Epoch: 64, Train Loss: 0.013628852553666, Val Loss: 0.008555409777910', 'Epoch: 65, Train Loss: 0.014902103648976, Val Loss: 0.008690319061279', 'Epoch: 66, Train Loss: 0.013902949331718, Val Loss: 0.007681279927492', 'Epoch: 67, Train Loss: 0.014312531701614, Val Loss: 0.005255456268787', 'Epoch: 68, Train Loss: 0.015259540488207, Val Loss: 0.005085299015045', 'Epoch: 69, Train Loss: 0.013722411096962, Val Loss: 0.006919063143432', 'Epoch: 70, Train Loss: 0.014944347217246, Val Loss: 0.007301199659705', 'Epoch: 71, Train Loss: 0.015644380725314, Val Loss: 0.007108809761703', 'Epoch: 72, Train Loss: 0.013287220735016, Val Loss: 0.006229603365064', 'Epoch: 73, Train Loss: 0.016597561364950, Val Loss: 0.009992940425873', 'Epoch: 74, Train Loss: 0.013936539407993, Val Loss: 0.005235287547112', 'Epoch: 75, Train Loss: 0.013241637054138, Val Loss: 0.009040707796812', 'Epoch: 76, Train Loss: 0.014309884417196, Val Loss: 0.009350157082081', 'Epoch: 77, Train Loss: 0.014366117197760, Val Loss: 0.009932720661163', 'Epoch: 78, Train Loss: 0.014030935513505, Val Loss: 0.008314352184534', 'Epoch: 79, Train Loss: 0.014703531717059, Val Loss: 0.006563148126006', 'Epoch: 80, Train Loss: 0.014269095498982, Val Loss: 0.006832547336817', 'Epoch: 81, Train Loss: 0.014918484205250, Val Loss: 0.005483575463295', 'Epoch: 82, Train Loss: 0.013583806624939, Val Loss: 0.006259911414236', 'Epoch: 83, Train Loss: 0.014791871930018, Val Loss: 0.009481091871858', 'Epoch: 84, Train Loss: 0.013453642258334, Val Loss: 0.006741259619594', 'Epoch: 85, Train Loss: 0.013460270941344, Val Loss: 0.007546372413635', 'Epoch: 86, Train Loss: 0.012484367720263, Val Loss: 0.006630429849029', 'Epoch: 87, Train Loss: 0.012849894135671, Val Loss: 0.006222248002887', 'Epoch: 88, Train Loss: 0.013393833507719, Val Loss: 0.007823422923684', 'Epoch: 89, Train Loss: 0.012361102131044, Val Loss: 0.005780324973166', 'Epoch: 90, Train Loss: 0.013294790730660, Val Loss: 0.006999155431986', 'Epoch: 91, Train Loss: 0.013852456811989, Val Loss: 0.008750677704811', 'Epoch: 92, Train Loss: 0.012896302307761, Val Loss: 0.005484218224883', 'Epoch: 93, Train Loss: 0.012999481824768, Val Loss: 0.005905887335539', 'Epoch: 94, Train Loss: 0.012853618375524, Val Loss: 0.005731998048723', 'Epoch: 95, Train Loss: 0.013656088075232, Val Loss: 0.010745743513107', 'Epoch: 96, Train Loss: 0.013768120105703, Val Loss: 0.005961150191724', 'Epoch: 97, Train Loss: 0.013044693409790, Val Loss: 0.007992870435119', 'Epoch: 98, Train Loss: 0.012587812458447, Val Loss: 0.004790734983981', 'Epoch: 99, Train Loss: 0.013248666936835, Val Loss: 0.009761226400733', 'Epoch: 100, Train Loss: 0.012490849812017, Val Loss: 0.007429217807949', 'Epoch: 101, Train Loss: 0.012698971763860, Val Loss: 0.009017249159515', 'Epoch: 102, Train Loss: 0.013081907836157, Val Loss: 0.005618268214166', 'Epoch: 103, Train Loss: 0.012955010554558, Val Loss: 0.005532406084239', 'Epoch: 104, Train Loss: 0.012857095977335, Val Loss: 0.007052704766393', 'Epoch: 105, Train Loss: 0.011308790303680, Val Loss: 0.006552916653454', 'Epoch: 106, Train Loss: 0.011840310922369, Val Loss: 0.007757988497615', 'Epoch: 107, Train Loss: 0.012386671105010, Val Loss: 0.006373347863555', 'Epoch: 108, Train Loss: 0.012505549298556, Val Loss: 0.006880766414106', 'Epoch: 109, Train Loss: 0.012768459105648, Val Loss: 0.009154024645686', 'Epoch: 110, Train Loss: 0.011912607273823, Val Loss: 0.005599666461349', 'Epoch: 111, Train Loss: 0.012754340536979, Val Loss: 0.006038890443742', 'Epoch: 112, Train Loss: 0.012485215093854, Val Loss: 0.006489693820477', 'Epoch: 113, Train Loss: 0.012585623904543, Val Loss: 0.005767345540226', 'Epoch: 114, Train Loss: 0.011793627143773, Val Loss: 0.005703080520034', 'Epoch: 115, Train Loss: 0.011856545315146, Val Loss: 0.005848640892655', 'Epoch: 116, Train Loss: 0.012893057980596, Val Loss: 0.011803931258619', 'Epoch: 117, Train Loss: 0.012475463323468, Val Loss: 0.005334998928010', 'Epoch: 118, Train Loss: 0.012528210477687, Val Loss: 0.007023006975651', 'Epoch: 119, Train Loss: 0.012254524088010, Val Loss: 0.008350956588984', 'Epoch: 120, Train Loss: 0.011822951481093, Val Loss: 0.005341679267585', 'Epoch: 121, Train Loss: 0.011675368593789, Val Loss: 0.005912633910775', 'Epoch: 122, Train Loss: 0.013229766730652, Val Loss: 0.005250332839787', 'Epoch: 123, Train Loss: 0.011054686324801, Val Loss: 0.008249349035323', 'Epoch: 124, Train Loss: 0.011855581612868, Val Loss: 0.006242422088981', 'Epoch: 125, Train Loss: 0.011873616187205, Val Loss: 0.006757937669754', 'Epoch: 126, Train Loss: 0.011524412120411, Val Loss: 0.006599886678159', 'Epoch: 127, Train Loss: 0.011022634251953, Val Loss: 0.006925930753350', 'Epoch: 128, Train Loss: 0.011944667241255, Val Loss: 0.005892204307020', 'Epoch: 129, Train Loss: 0.011058538686484, Val Loss: 0.005983238704503', 'Epoch: 130, Train Loss: 0.011455000573119, Val Loss: 0.005421245917678', 'Epoch: 131, Train Loss: 0.012068915982233, Val Loss: 0.006860191822052', 'Epoch: 132, Train Loss: 0.010785039790451, Val Loss: 0.006398332007229', 'Epoch: 133, Train Loss: 0.011248054481003, Val Loss: 0.006224013753235', 'Epoch: 134, Train Loss: 0.011972141744526, Val Loss: 0.007971335090697', 'Epoch: 135, Train Loss: 0.011025960389308, Val Loss: 0.006251668557525', 'Epoch: 136, Train Loss: 0.011293902159344, Val Loss: 0.004839602299035', 'Epoch: 137, Train Loss: 0.010514376923269, Val Loss: 0.006110302470624', 'Epoch: 138, Train Loss: 0.011743070265322, Val Loss: 0.005999301597476', 'Epoch: 139, Train Loss: 0.011948512206504, Val Loss: 0.005880429707468', 'Epoch: 140, Train Loss: 0.012395988944052, Val Loss: 0.006120132282376', 'Epoch: 141, Train Loss: 0.010412590155854, Val Loss: 0.005013432390988', 'Epoch: 142, Train Loss: 0.009968897977541, Val Loss: 0.005328543558717', 'Epoch: 143, Train Loss: 0.010852431916350, Val Loss: 0.005012217722833', 'Epoch: 144, Train Loss: 0.010731140888015, Val Loss: 0.006168696917593', 'Epoch: 145, Train Loss: 0.009955685022612, Val Loss: 0.004948874711990', 'Epoch: 146, Train Loss: 0.011292151716906, Val Loss: 0.005702277179807', 'Epoch: 147, Train Loss: 0.011598681706155, Val Loss: 0.005815688818693', 'Epoch: 148, Train Loss: 0.011511581689986, Val Loss: 0.004819200765342', 'Epoch: 149, Train Loss: 0.011386951063435, Val Loss: 0.006331035271287', 'Epoch: 150, Train Loss: 0.011675679330649, Val Loss: 0.005983636975288', 'Epoch: 151, Train Loss: 0.010938535032924, Val Loss: 0.005463182553649', 'Epoch: 152, Train Loss: 0.011001275245880, Val Loss: 0.005342997387052', 'Epoch: 153, Train Loss: 0.010701461500207, Val Loss: 0.007452480457723', 'Epoch: 154, Train Loss: 0.011323673758916, Val Loss: 0.005872778631747', 'Epoch: 155, Train Loss: 0.011241858976698, Val Loss: 0.004957690425217', 'Epoch: 156, Train Loss: 0.011874485121997, Val Loss: 0.006480262428522', 'Epoch: 157, Train Loss: 0.010848019391212, Val Loss: 0.006669738180935', 'Epoch: 158, Train Loss: 0.009985846261559, Val Loss: 0.005026077702641', 'Epoch: 159, Train Loss: 0.009766902298082, Val Loss: 0.006135413944721', 'Epoch: 160, Train Loss: 0.010612264600431, Val Loss: 0.004782683439553', 'Epoch: 161, Train Loss: 0.010120072661964, Val Loss: 0.004744875039905', 'Epoch: 162, Train Loss: 0.010245035272525, Val Loss: 0.005126757360995', 'Epoch: 163, Train Loss: 0.009937219814462, Val Loss: 0.006205413416028', 'Epoch: 164, Train Loss: 0.009569708257914, Val Loss: 0.005275189988315', 'Epoch: 165, Train Loss: 0.009839344109127, Val Loss: 0.005615197755396', 'Epoch: 166, Train Loss: 0.010252491787596, Val Loss: 0.004659035690129', 'Epoch: 167, Train Loss: 0.010135458040506, Val Loss: 0.005321736969054', 'Epoch: 168, Train Loss: 0.010237098476568, Val Loss: 0.005185448601842', 'Epoch: 169, Train Loss: 0.009380715763803, Val Loss: 0.004739748202264', 'Epoch: 170, Train Loss: 0.009846575666479, Val Loss: 0.005392184853554', 'Epoch: 171, Train Loss: 0.009596744606401, Val Loss: 0.005456988029182', 'Epoch: 172, Train Loss: 0.009821815578657, Val Loss: 0.004811289496720', 'Epoch: 173, Train Loss: 0.009449077109525, Val Loss: 0.005324310511351', 'Epoch: 174, Train Loss: 0.009436935430046, Val Loss: 0.004836609289050', 'Epoch: 175, Train Loss: 0.009506255041721, Val Loss: 0.004585124999285', 'Epoch: 176, Train Loss: 0.009992237007895, Val Loss: 0.004792248904705', 'Epoch: 177, Train Loss: 0.009538087858494, Val Loss: 0.004387142732739', 'Epoch: 178, Train Loss: 0.009705721806778, Val Loss: 0.004551650919020', 'Epoch: 179, Train Loss: 0.009904149757308, Val Loss: 0.004846530482173', 'Epoch: 180, Train Loss: 0.008737020497752, Val Loss: 0.004493125975132', 'Epoch: 181, Train Loss: 0.009333633557828, Val Loss: 0.004992271177471', 'Epoch: 182, Train Loss: 0.008745942692554, Val Loss: 0.004421096555889', 'Epoch: 183, Train Loss: 0.009789818859941, Val Loss: 0.005313469581306', 'Epoch: 184, Train Loss: 0.009611092480766, Val Loss: 0.004575926661491', 'Epoch: 185, Train Loss: 0.010447465977090, Val Loss: 0.004413888622075', 'Epoch: 186, Train Loss: 0.008937463657064, Val Loss: 0.004478589147329', 'Epoch: 187, Train Loss: 0.008481607869874, Val Loss: 0.004806628748775', 'Epoch: 188, Train Loss: 0.008873203119566, Val Loss: 0.004583583623171', 'Epoch: 189, Train Loss: 0.009152458774922, Val Loss: 0.004960762113333', 'Epoch: 190, Train Loss: 0.008945560559284, Val Loss: 0.004789928495884', 'Epoch: 191, Train Loss: 0.009489128057477, Val Loss: 0.004853066466749', 'Epoch: 192, Train Loss: 0.009077504558792, Val Loss: 0.004814103692770', 'Epoch: 193, Train Loss: 0.009451200091822, Val Loss: 0.004776093550026', 'Epoch: 194, Train Loss: 0.008279776633825, Val Loss: 0.004486196152866', 'Epoch: 195, Train Loss: 0.009223688058122, Val Loss: 0.004742553830147', 'Epoch: 196, Train Loss: 0.008642909804706, Val Loss: 0.004465819485486', 'Epoch: 197, Train Loss: 0.009279527187044, Val Loss: 0.004552482515574', 'Epoch: 198, Train Loss: 0.009447443418118, Val Loss: 0.004681686758995', 'Epoch: 199, Train Loss: 0.009055522822797, Val Loss: 0.004660466238856']","[ 252.10623    342.32315    500.02664    436.95026    466.90137
  425.62314    731.7682     358.6015     458.19626    685.0853
  213.42737    356.42993    685.8684     793.6204     450.49466
  166.70853    583.506      951.36285    814.6467     377.12247
  887.37634   1178.6833    1014.83716     13.931213   194.1443
  187.40633    101.76599    140.68954    697.8105    1081.8796
  853.8888     894.53723   1355.679      674.94324    264.3579
 1010.9782     197.94139      8.328308    67.48328    251.7325
  747.8096     924.88434    373.04672     63.446228   163.64844
  984.54175    551.0658     261.24246     77.433075   381.35654
  690.5305     167.96272    263.78772    838.3502     194.42873
   31.631958    81.94191    196.68387    716.83936    440.21274
 1070.1981     282.05576    729.456      829.3789     227.90411
  508.7641      80.20863    436.7722    1049.1262    1128.428
  415.74966     78.96753    752.489      162.8277     386.59607
  255.1908     603.5883     296.05533    179.51056    778.29285
  329.13022    949.2604     775.7213     371.5333     520.70856
   28.836334  1076.0759    1181.0833       8.0937195  294.11392
  852.2298     879.20056    863.1534    1364.458      993.09
  625.0578     244.47614    209.24628    760.2761      99.867004
  768.8644    1024.4585     192.77472    268.58893    478.3073
  571.1041      71.84616    206.6427     679.4364     384.58603
  908.30646    675.4296     482.8926     401.78888   1033.9443
  230.74231   1129.0771     931.52325   1153.4462     395.43466
  844.17566    355.82538    791.92474    287.4045     187.13297
   37.23352    129.32611    773.4279     564.67834    833.6509
   89.58124    356.12808    343.07925    547.42773     58.134216
  304.5973     163.43457    126.71835    946.689      641.5893
  888.7378     470.6633    1127.4213     827.50616    218.76979
  495.11533    525.0601     344.36618    155.84552    327.0334
  733.4381     428.4064     231.924      513.0198     760.12024
  798.3622     166.73749    311.9203     263.0904     128.60095
   59.615585     2.3528137  156.45807    668.4883      41.43109
  873.8623     351.15796     80.15848    910.6379     572.24884
  692.04755    161.28119    451.3122     268.338      248.55992
    5.939575  1164.2903    1107.9663     228.57727     10.024841
  125.59061    262.8157     772.2794      82.21231   1145.981
  720.6018      25.63324    501.2207      59.999878   704.3665
  408.65613   1071.8062      80.669556  1350.3513     357.99686
 1238.5195    1230.3768     938.0993     527.2666      77.950165
  603.15       166.74304    442.21387     64.523254   103.2995
  579.9398     903.26184    794.58       699.7852     221.72285
  165.9837     570.5147     758.6748     924.943      113.92502
  153.21765   1302.7776    1076.3243     391.4549     698.6737
  614.36096    479.50333   1058.6035    1299.6074     349.78918
  698.157      180.03424    995.08075    161.80109    712.2954
  407.50546    800.19855    947.3563     998.0026      28.539185
  570.9669     513.58417    516.3956     198.32573    136.85205
    7.731018   984.85333    343.31348    381.04382    517.46454
  219.93356    451.16336     50.22644    430.58322    519.70776
  418.74313      5.4289856 1071.561      404.57928    278.63605
  521.7844     305.2096     489.01016    184.6051     804.5561
   23.344147   226.97658   1030.1096     987.383      403.55582
  410.59897    235.01639    430.5794     855.667      454.63138
  126.97705   1060.7654     523.47034     20.315826   211.42548
    4.4783325  706.0718     756.5896     645.12756    644.6581
  776.415      811.00287    101.87463    489.93912    505.02246
 1327.7084     798.0379     945.0262     235.04716    472.4281
   16.549774   923.88055    729.4663     511.5774      60.87619
  873.3093     759.59235    405.8256      59.308594   128.531
 1009.2853    1128.4799     830.3671     546.83203     24.65686
  473.71637    104.13179    332.42163   1254.3264     259.2678
   33.17099    748.2058     389.7858      20.289307   257.84396
 1063.742     1405.8685     696.6922     376.20593    163.74164
  737.4894    1174.1045    1144.5984    1255.5939     396.7655
    8.84256   1081.6173     758.58655    564.20325    687.3385
  116.38202    452.01477   1401.469      225.969      522.5653
  252.2995     285.51892     17.882294   203.89001     91.545105
  923.0101     363.9577     396.92435   1245.9294     741.70905
  870.19586   1235.5638     238.28796    191.52509    292.75436
  813.6898      22.564972   307.93555    704.51373    471.84802
  345.8343     111.58301    529.1666     831.02814    155.02722
   67.32391    525.526      150.60254     42.981964   513.9387
  333.57578    416.24612   1009.1282     330.4423    1116.3213
  790.89764     59.27951    460.3272     260.91183    526.02563
   62.72522    711.4884     317.93323    121.86899    618.21625
  200.03366    196.53543    127.679565   377.54785    279.42593
   91.33356    276.33224    618.58936    128.93533     28.005402
  373.6819     434.34247    231.7154     777.25946   1235.9727
  435.57764    947.00714     49.222595   702.0123     704.55676  ]","[ 252.66736    349.34305    505.02286    428.92056    462.91083
  420.02344    720.88824    357.4852     453.73184    670.46106
  194.77997    353.27026    675.4302     796.4397     471.6719
  197.2586     577.7671     933.2089     783.1865     383.1815
  864.7312    1137.9397     971.5486      87.39398    179.71251
  173.72188     79.3183     119.651306   690.8337    1066.9741
  942.70215    993.4728    1307.4056     685.3245     273.0243
  996.82135    214.11876     40.337463    51.247955   244.38504
  752.538      930.08466    368.13315     56.68985    135.72906
 1012.2467     565.9546     302.86432     80.25583    381.39655
  718.1803     145.33344    227.13696    879.70685    203.11589
   52.83072     54.1315     178.55916    708.805      438.84433
 1083.8228     271.99744    715.77234    814.1142     217.5886
  505.88004     56.62451    454.11972   1103.5334    1201.9791
  423.08276     87.97241    746.0272     155.74323    230.84738
   65.05713    603.89386    303.64615    116.055176   845.1985
  320.4944     984.2368     755.8979     376.57446    513.4104
   12.481537  1049.5037    1164.4525      28.898987   297.27
  934.0886     971.1638     843.6217    1330.4607     985.43933
  622.3158     150.83167    119.15762    780.49664     65.60248
  759.59247   1024.9525     168.30664    249.27512    446.2216
  519.0458      75.7325     210.18506    671.1001     385.7123
  913.1583     670.88324    537.9407     418.71335   1051.0242
  216.50836   1066.1417     889.02      1151.2596     385.23337
  843.39655    366.94623    825.5852     262.49875    181.39424
   60.16632    160.80865    744.27014    548.9676     857.8312
   55.091797   343.34225    340.47095    534.48035     58.34839
  302.1993     103.89636     66.00214    923.85596    634.1357
  880.06805    473.71405   1132.9261     814.96124    224.84798
  486.5511     539.0896     345.99252    130.17566    323.18494
  713.8131     423.1125     236.75447    511.40305    727.49475
  774.6279     106.25232    272.01068    264.29953    135.1526
   93.25665     54.07509    143.19482    669.24207    115.89572
  821.4661     350.90433     83.75499    897.15656    572.6065
  674.72845    171.20793    445.45636    266.79596    249.79715
   11.998291  1168.7549    1118.1411     262.20334     80.62396
   61.7045     215.61986    780.08704     68.558624  1123.925
  721.96515     51.187195   496.96683     69.22485    710.81354
  413.2523    1083.4749     239.58667   1202.5146     311.50815
 1317.5466    1235.8545     923.289      531.2216      88.96588
  646.6916     134.80598    428.98312     58.32727    124.86139
  558.53       846.9933     756.9036     764.9972     168.4928
  186.8739     585.2596     730.1151     874.70825     78.11487
  123.35016   1282.2563    1064.1719     399.14847    681.9407
  623.879      480.99905   1034.3898    1242.6476     355.84265
  685.7988     120.56653   1041.3584     123.137726   750.9125
  411.7303     798.1469    1038.1262    1101.148       73.210464
  537.8078     464.74817    463.73944    194.64258    137.13786
   61.462036   965.42786    349.62155    385.5972     469.61786
  232.08008    449.5279      52.727966   419.83063    511.22394
  414.35315     20.042908  1048.5314     428.777      283.67743
  516.66876    303.91956    475.26932    203.17035    794.32404
    3.6063232  214.72545    971.02356    939.4607     389.8212
  395.40286    237.25218    417.3491     837.0731     456.74533
  102.31195   1075.5448     510.45435     55.0784     216.51149
   13.108185   707.3299     777.577      706.6854     712.13025
  821.0029     867.9451     105.62958    495.68854    499.55478
 1337.4392     805.0268     949.4609     239.3052     469.17667
  124.298096   849.57367    751.3336     524.3117      85.39673
  859.8782     742.7351     410.51068     68.18552    136.72842
 1057.4321    1212.7025     825.2905     541.08875    110.162476
  514.5795      99.175964   337.50275   1244.974      270.02756
   78.93616    722.36145    399.01465     57.550293   266.12732
 1061.3921    1401.3439     696.6662     384.10132    163.77536
  726.0716    1135.5549    1096.258     1226.6011     398.9503
   38.13855   1079.7614     741.93994    564.39136    703.3876
  121.76727    461.75012   1314.6464     281.54898    515.3199
  257.28687    286.8233      22.656189   208.         104.87537
  905.6929     385.2763     337.9876    1350.0098     766.9936
  908.06464   1229.7488     239.57104     62.488586   186.45078
  801.71606     56.32434    327.88696    690.0517     467.35635
  344.87994     47.23584    600.4995     798.31696    180.15259
   43.657104   522.4334     149.42451     42.984528   492.39914
  302.41818    432.06573    981.1754     266.12704   1220.7076
  799.3326      53.734894   463.6115     273.3175     521.19
   65.098755   705.296      330.07135    140.8791     601.83344
  158.99304    152.9541     110.03253    375.42795    280.44217
   73.904755   289.49515    626.53595    130.09875     47.612854
  383.84253    456.31146    237.02284    772.3495    1229.5376
  451.01346    922.69305     91.69736    673.07214    681.3961   ]",23.817232,1314.5328,36.25648682531255
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 0.385013136752816, Val Loss: 0.393914785385132', 'Epoch: 1, Train Loss: 0.349811674203984, Val Loss: 0.352729187011719', 'Epoch: 2, Train Loss: 0.278498991977337, Val Loss: 0.264260314702988', 'Epoch: 3, Train Loss: 0.147743057372958, Val Loss: 0.101401466578245', 'Epoch: 4, Train Loss: 0.059818654429427, Val Loss: 0.051096711605787', 'Epoch: 5, Train Loss: 0.054333448150130, Val Loss: 0.051198011785746', 'Epoch: 6, Train Loss: 0.044403974486645, Val Loss: 0.055997620224953', 'Epoch: 7, Train Loss: 0.046229508943682, Val Loss: 0.047998734414577', 'Epoch: 8, Train Loss: 0.041619986988777, Val Loss: 0.044539049565792', 'Epoch: 9, Train Loss: 0.044096666236603, Val Loss: 0.046092787981033', 'Epoch: 10, Train Loss: 0.041085899482633, Val Loss: 0.038939403742552', 'Epoch: 11, Train Loss: 0.036245511281629, Val Loss: 0.034269580245018', 'Epoch: 12, Train Loss: 0.037033976510514, Val Loss: 0.035197054296732', 'Epoch: 13, Train Loss: 0.035389026973483, Val Loss: 0.034700599163771', 'Epoch: 14, Train Loss: 0.032038008014477, Val Loss: 0.046307838559151', 'Epoch: 15, Train Loss: 0.031629118007110, Val Loss: 0.035099976360798', 'Epoch: 16, Train Loss: 0.028000732602248, Val Loss: 0.028338320627809', 'Epoch: 17, Train Loss: 0.027174268979146, Val Loss: 0.025412358343601', 'Epoch: 18, Train Loss: 0.032122573403772, Val Loss: 0.029517521783710', 'Epoch: 19, Train Loss: 0.028192033817948, Val Loss: 0.023945747688413', 'Epoch: 20, Train Loss: 0.023975793478014, Val Loss: 0.021844187229872', 'Epoch: 21, Train Loss: 0.026483802882911, Val Loss: 0.021443258225918', 'Epoch: 22, Train Loss: 0.025722173497427, Val Loss: 0.045043109506369', 'Epoch: 23, Train Loss: 0.028582835158463, Val Loss: 0.022295537889004', 'Epoch: 24, Train Loss: 0.018819497627488, Val Loss: 0.022083892375231', 'Epoch: 25, Train Loss: 0.018430836672007, Val Loss: 0.017013408206403', 'Epoch: 26, Train Loss: 0.018322855634831, Val Loss: 0.014213595129550', 'Epoch: 27, Train Loss: 0.019732950688448, Val Loss: 0.022069232910872', 'Epoch: 28, Train Loss: 0.019084018936684, Val Loss: 0.018068409264088', 'Epoch: 29, Train Loss: 0.021252890572298, Val Loss: 0.013945169672370', 'Epoch: 30, Train Loss: 0.016696385032129, Val Loss: 0.014566215090454', 'Epoch: 31, Train Loss: 0.016883397236640, Val Loss: 0.014942063577473', 'Epoch: 32, Train Loss: 0.017786976621421, Val Loss: 0.021760121006519', 'Epoch: 33, Train Loss: 0.014656702511359, Val Loss: 0.012307908926159', 'Epoch: 34, Train Loss: 0.016279528556435, Val Loss: 0.015071141514927', 'Epoch: 35, Train Loss: 0.018846279887353, Val Loss: 0.014802064709365', 'Epoch: 36, Train Loss: 0.016495533125085, Val Loss: 0.017672870159149', 'Epoch: 37, Train Loss: 0.014684351735077, Val Loss: 0.023714902102947', 'Epoch: 38, Train Loss: 0.017623121222091, Val Loss: 0.016393406614661', 'Epoch: 39, Train Loss: 0.016256809418718, Val Loss: 0.015715074241161', 'Epoch: 40, Train Loss: 0.018272914696312, Val Loss: 0.011823902782053', 'Epoch: 41, Train Loss: 0.014257377435908, Val Loss: 0.038479573428631', 'Epoch: 42, Train Loss: 0.012935193634570, Val Loss: 0.012437412943691', 'Epoch: 43, Train Loss: 0.015667091686885, Val Loss: 0.012635636180639', 'Epoch: 44, Train Loss: 0.017450238036555, Val Loss: 0.016167167499661', 'Epoch: 45, Train Loss: 0.016066337805675, Val Loss: 0.011189662236720', 'Epoch: 46, Train Loss: 0.012377982872517, Val Loss: 0.017438841909170', 'Epoch: 47, Train Loss: 0.013378142455030, Val Loss: 0.015884458161891', 'Epoch: 48, Train Loss: 0.016110982041979, Val Loss: 0.018995904177427', 'Epoch: 49, Train Loss: 0.016900636125789, Val Loss: 0.009277352001518', 'Epoch: 50, Train Loss: 0.012198907084936, Val Loss: 0.010540904570371', 'Epoch: 51, Train Loss: 0.012822745346226, Val Loss: 0.009195717517287', 'Epoch: 52, Train Loss: 0.012072334537109, Val Loss: 0.009986593537033', 'Epoch: 53, Train Loss: 0.013865171108655, Val Loss: 0.010471466425806', 'Epoch: 54, Train Loss: 0.015603901720931, Val Loss: 0.014386790581048', 'Epoch: 55, Train Loss: 0.013300175507834, Val Loss: 0.012542005442083', 'Epoch: 56, Train Loss: 0.013915054153564, Val Loss: 0.010693977065384', 'Epoch: 57, Train Loss: 0.014257625460105, Val Loss: 0.008639530139044', 'Epoch: 58, Train Loss: 0.012247795304067, Val Loss: 0.010337318591774', 'Epoch: 59, Train Loss: 0.011565816859433, Val Loss: 0.006876517683268', 'Epoch: 60, Train Loss: 0.011700542264640, Val Loss: 0.013078234530985', 'Epoch: 61, Train Loss: 0.012051279884005, Val Loss: 0.011271614991128', 'Epoch: 62, Train Loss: 0.010778920735817, Val Loss: 0.010472761224955', 'Epoch: 63, Train Loss: 0.012841613134802, Val Loss: 0.009857690893114', 'Epoch: 64, Train Loss: 0.011891234796061, Val Loss: 0.008561901450157', 'Epoch: 65, Train Loss: 0.012220332279888, Val Loss: 0.008544128965586', 'Epoch: 66, Train Loss: 0.011351813448506, Val Loss: 0.010189915951341', 'Epoch: 67, Train Loss: 0.011262323653195, Val Loss: 0.010207576453686', 'Epoch: 68, Train Loss: 0.012700820135949, Val Loss: 0.010262896995991', 'Epoch: 69, Train Loss: 0.011733331955796, Val Loss: 0.007543138610199', 'Epoch: 70, Train Loss: 0.011831041815322, Val Loss: 0.006157121360302', 'Epoch: 71, Train Loss: 0.010541432374698, Val Loss: 0.009618277736008', 'Epoch: 72, Train Loss: 0.011080888955486, Val Loss: 0.009215365350246', 'Epoch: 73, Train Loss: 0.010634922725690, Val Loss: 0.008898442611098', 'Epoch: 74, Train Loss: 0.010584156602881, Val Loss: 0.009396037701517', 'Epoch: 75, Train Loss: 0.012068823099050, Val Loss: 0.009313475117087', 'Epoch: 76, Train Loss: 0.010888022879615, Val Loss: 0.007855202667415', 'Epoch: 77, Train Loss: 0.011677186026476, Val Loss: 0.010359331984073', 'Epoch: 78, Train Loss: 0.011219278291994, Val Loss: 0.007726957928389', 'Epoch: 79, Train Loss: 0.012825110818931, Val Loss: 0.008886413546279', 'Epoch: 80, Train Loss: 0.011513088077177, Val Loss: 0.006944670500234', 'Epoch: 81, Train Loss: 0.010148474188565, Val Loss: 0.008982340451330', 'Epoch: 82, Train Loss: 0.011034555126761, Val Loss: 0.007220477275550', 'Epoch: 83, Train Loss: 0.010237309848890, Val Loss: 0.007966521885246', 'Epoch: 84, Train Loss: 0.010618770706229, Val Loss: 0.007316085584462', 'Epoch: 85, Train Loss: 0.009519159631414, Val Loss: 0.005552471396513', 'Epoch: 86, Train Loss: 0.010292920727976, Val Loss: 0.009408797584474', 'Epoch: 87, Train Loss: 0.010329943069062, Val Loss: 0.007290392685682', 'Epoch: 88, Train Loss: 0.013906172752857, Val Loss: 0.012425519563258', 'Epoch: 89, Train Loss: 0.012887476748505, Val Loss: 0.009200521828607', 'Epoch: 90, Train Loss: 0.011290095015537, Val Loss: 0.010204553622752', 'Epoch: 91, Train Loss: 0.010050715023089, Val Loss: 0.005281568756327', 'Epoch: 92, Train Loss: 0.009316018555140, Val Loss: 0.007303776908666', 'Epoch: 93, Train Loss: 0.010055357005534, Val Loss: 0.005242304783314', 'Epoch: 94, Train Loss: 0.009853361553491, Val Loss: 0.009301034435630', 'Epoch: 95, Train Loss: 0.011332471497617, Val Loss: 0.010026275403798', 'Epoch: 96, Train Loss: 0.011540499044756, Val Loss: 0.008092034272850', 'Epoch: 97, Train Loss: 0.009842671226537, Val Loss: 0.006277459701523', 'Epoch: 98, Train Loss: 0.010621807819536, Val Loss: 0.004313649460673', 'Epoch: 99, Train Loss: 0.009157408153378, Val Loss: 0.006325456146151', 'Epoch: 100, Train Loss: 0.009953245845472, Val Loss: 0.007727259411477', 'Epoch: 101, Train Loss: 0.011012981310054, Val Loss: 0.005688495594077', 'Epoch: 102, Train Loss: 0.010332231263652, Val Loss: 0.007745237033814', 'Epoch: 103, Train Loss: 0.009874472903564, Val Loss: 0.009202215038240', 'Epoch: 104, Train Loss: 0.009095598813580, Val Loss: 0.006904312074184', 'Epoch: 105, Train Loss: 0.009304418889156, Val Loss: 0.004886414259672', 'Epoch: 106, Train Loss: 0.009352794967505, Val Loss: 0.006952413581312', 'Epoch: 107, Train Loss: 0.009283677284974, Val Loss: 0.006173007804900', 'Epoch: 108, Train Loss: 0.012095302754883, Val Loss: 0.008961885459721', 'Epoch: 109, Train Loss: 0.009612400734494, Val Loss: 0.005751308044419', 'Epoch: 110, Train Loss: 0.009182026642266, Val Loss: 0.006310765231028', 'Epoch: 111, Train Loss: 0.008649523700263, Val Loss: 0.005556417647749', 'Epoch: 112, Train Loss: 0.010200979220573, Val Loss: 0.005138100888580', 'Epoch: 113, Train Loss: 0.010426729549329, Val Loss: 0.005705398125574', 'Epoch: 114, Train Loss: 0.009292253856222, Val Loss: 0.005547325853258', 'Epoch: 115, Train Loss: 0.009284654870456, Val Loss: 0.004874345278367', 'Epoch: 116, Train Loss: 0.009078865811272, Val Loss: 0.006152095999569', 'Epoch: 117, Train Loss: 0.010970412006298, Val Loss: 0.008729528710246', 'Epoch: 118, Train Loss: 0.009449205036427, Val Loss: 0.007351353000849', 'Epoch: 119, Train Loss: 0.011351121871104, Val Loss: 0.009272098541260', 'Epoch: 120, Train Loss: 0.010812757493452, Val Loss: 0.009406673256308', 'Epoch: 121, Train Loss: 0.009719692847453, Val Loss: 0.008299364531413', 'Epoch: 122, Train Loss: 0.009423427846889, Val Loss: 0.004934638729319', 'Epoch: 123, Train Loss: 0.009092788899664, Val Loss: 0.005643738405779', 'Epoch: 124, Train Loss: 0.008024676556721, Val Loss: 0.007311828080565', 'Epoch: 125, Train Loss: 0.009235876493243, Val Loss: 0.005496863583103', 'Epoch: 126, Train Loss: 0.008917069853132, Val Loss: 0.005942864604294', 'Epoch: 127, Train Loss: 0.008875974432327, Val Loss: 0.003930633910932', 'Epoch: 128, Train Loss: 0.008101475251795, Val Loss: 0.004834227920510', 'Epoch: 129, Train Loss: 0.009490714690020, Val Loss: 0.007369926040992', 'Epoch: 130, Train Loss: 0.009224941304257, Val Loss: 0.005777694396675', 'Epoch: 131, Train Loss: 0.008509201046383, Val Loss: 0.003900492535904', 'Epoch: 132, Train Loss: 0.009455185345656, Val Loss: 0.003411950119771', 'Epoch: 133, Train Loss: 0.007769784094159, Val Loss: 0.004096691105515', 'Epoch: 134, Train Loss: 0.008611164911282, Val Loss: 0.004399275220931', 'Epoch: 135, Train Loss: 0.008993035723823, Val Loss: 0.004242375902832', 'Epoch: 136, Train Loss: 0.007254113805978, Val Loss: 0.003642327953130', 'Epoch: 137, Train Loss: 0.007887922189480, Val Loss: 0.004848170350306', 'Epoch: 138, Train Loss: 0.008387419281441, Val Loss: 0.005791992656887', 'Epoch: 139, Train Loss: 0.008808084287096, Val Loss: 0.004705309490673', 'Epoch: 140, Train Loss: 0.008182900741177, Val Loss: 0.004555092900991', 'Epoch: 141, Train Loss: 0.008611014405222, Val Loss: 0.004153696848080', 'Epoch: 142, Train Loss: 0.008378729218790, Val Loss: 0.004173838412389', 'Epoch: 143, Train Loss: 0.008538173078451, Val Loss: 0.005901705143042', 'Epoch: 144, Train Loss: 0.008265679003671, Val Loss: 0.006351159065962', 'Epoch: 145, Train Loss: 0.009249470407836, Val Loss: 0.005466813333333', 'Epoch: 146, Train Loss: 0.008133611468555, Val Loss: 0.005139906662516', 'Epoch: 147, Train Loss: 0.007416127953505, Val Loss: 0.004523934209719', 'Epoch: 148, Train Loss: 0.007120878181182, Val Loss: 0.003516749897972', 'Epoch: 149, Train Loss: 0.008291987908008, Val Loss: 0.005476341135800', 'Epoch: 150, Train Loss: 0.007889405022873, Val Loss: 0.004749996475875', 'Epoch: 151, Train Loss: 0.007964103190272, Val Loss: 0.005808879686520', 'Epoch: 152, Train Loss: 0.008339675002580, Val Loss: 0.003496084529907', 'Epoch: 153, Train Loss: 0.008628599887151, Val Loss: 0.003732283283025', 'Epoch: 154, Train Loss: 0.007982011927768, Val Loss: 0.004211421334185', 'Epoch: 155, Train Loss: 0.007828756235540, Val Loss: 0.003659095950425', 'Epoch: 156, Train Loss: 0.007346902345849, Val Loss: 0.003569325488061', 'Epoch: 157, Train Loss: 0.007794745185218, Val Loss: 0.003168277749792', 'Epoch: 158, Train Loss: 0.008799182640952, Val Loss: 0.004625704782084', 'Epoch: 159, Train Loss: 0.007513865844758, Val Loss: 0.004309740513563', 'Epoch: 160, Train Loss: 0.007588167555717, Val Loss: 0.003865549508482', 'Epoch: 161, Train Loss: 0.007269553450304, Val Loss: 0.003976618750021', 'Epoch: 162, Train Loss: 0.007290428336493, Val Loss: 0.003594160936773', 'Epoch: 163, Train Loss: 0.007874451550590, Val Loss: 0.003788129519671', 'Epoch: 164, Train Loss: 0.007867841607739, Val Loss: 0.003357618516311', 'Epoch: 165, Train Loss: 0.007418562365739, Val Loss: 0.003580413304735', 'Epoch: 166, Train Loss: 0.008563674466555, Val Loss: 0.004962898343801', 'Epoch: 167, Train Loss: 0.007206435087895, Val Loss: 0.004554854771122', 'Epoch: 168, Train Loss: 0.007536789651440, Val Loss: 0.005025152154267', 'Epoch: 169, Train Loss: 0.007695182995481, Val Loss: 0.003771099410951', 'Epoch: 170, Train Loss: 0.008124589075356, Val Loss: 0.006858951114118', 'Epoch: 171, Train Loss: 0.007428601714458, Val Loss: 0.003845153502189', 'Epoch: 172, Train Loss: 0.008141749581799, Val Loss: 0.004546074848622', 'Epoch: 173, Train Loss: 0.008356697814063, Val Loss: 0.004219691082835', 'Epoch: 174, Train Loss: 0.007957134255056, Val Loss: 0.003541455697268', 'Epoch: 175, Train Loss: 0.006988108970311, Val Loss: 0.003132783388719', 'Epoch: 176, Train Loss: 0.006813665705755, Val Loss: 0.003850296521559', 'Epoch: 177, Train Loss: 0.007638824887054, Val Loss: 0.003694558311254', 'Epoch: 178, Train Loss: 0.008639226949146, Val Loss: 0.003331543444656', 'Epoch: 179, Train Loss: 0.006815076074671, Val Loss: 0.004016545917839', 'Epoch: 180, Train Loss: 0.007298481639821, Val Loss: 0.003228431013413', 'Epoch: 181, Train Loss: 0.007099943414201, Val Loss: 0.003299728424754', 'Epoch: 182, Train Loss: 0.007191871969722, Val Loss: 0.003586516552605', 'Epoch: 183, Train Loss: 0.007144688493247, Val Loss: 0.003376271449961', 'Epoch: 184, Train Loss: 0.007168601521529, Val Loss: 0.004331448469311', 'Epoch: 185, Train Loss: 0.007372514101092, Val Loss: 0.002913884213194', 'Epoch: 186, Train Loss: 0.006742947632014, Val Loss: 0.002745406622998', 'Epoch: 187, Train Loss: 0.007524220716901, Val Loss: 0.003610829352401', 'Epoch: 188, Train Loss: 0.007360225348452, Val Loss: 0.002853508270346', 'Epoch: 189, Train Loss: 0.006481259774287, Val Loss: 0.003152077710256', 'Epoch: 190, Train Loss: 0.006685312377116, Val Loss: 0.002827198016457', 'Epoch: 191, Train Loss: 0.006332052064800, Val Loss: 0.002909810901619', 'Epoch: 192, Train Loss: 0.006614652651817, Val Loss: 0.002773548937403', 'Epoch: 193, Train Loss: 0.006926015853275, Val Loss: 0.002931127129123', 'Epoch: 194, Train Loss: 0.007317614324694, Val Loss: 0.002816649358720', 'Epoch: 195, Train Loss: 0.006978346451814, Val Loss: 0.003120510084555', 'Epoch: 196, Train Loss: 0.006461519536801, Val Loss: 0.002987540718168', 'Epoch: 197, Train Loss: 0.006845901157101, Val Loss: 0.002766904686578', 'Epoch: 198, Train Loss: 0.006802518619224, Val Loss: 0.002800108790398', 'Epoch: 199, Train Loss: 0.006417576066587, Val Loss: 0.002915793615393']","[3.23252869e+01 9.66445618e+02 8.65661621e+00 1.32939423e+02
 9.59991699e+02 1.33697861e+02 2.34289322e+02 4.73648468e+02
 7.01365356e+01 1.94952148e+02 4.18600922e+02 1.28511108e+02
 3.64400391e+02 4.58468170e+01 5.62084351e+02 4.19402100e+02
 1.78424072e+01 2.05252274e+02 3.65205994e+02 6.45799500e+02
 1.96140656e+02 9.82977295e+02 2.99064484e+02 6.98907959e+02
 6.03244385e+02 5.44520203e+02 4.98360657e+02 2.08817612e+02
 1.03370483e+03 7.56312134e+02 3.15287872e+02 9.31703003e+02
 4.07577698e+02 1.98320480e+02 7.77812378e+02 2.26886719e+02
 4.80270752e+02 1.25862862e+02 1.27293549e+02 8.85972290e+01
 5.37583435e+02 2.07571335e+02 2.54512268e+02 4.48970062e+02
 9.44091248e+02 9.77098633e+02 5.57801880e+02 8.87057495e+01
 7.46502808e+02 4.06878021e+02 4.24910889e+02 1.18432739e+02
 1.10002960e+02 5.21835876e+02 4.58169067e+02 1.93472702e+02
 7.12149811e+01 8.82696533e+00 4.87102692e+02 4.30180206e+02
 7.86459229e+02 6.07408142e+02 6.87257324e+02 8.43194519e+02
 1.20645691e+02 1.75451202e+02 6.33912048e+02 5.62428131e+01
 3.11272430e+02 5.78035767e+02 5.56758850e+02 5.04146179e+02
 3.67535156e+02 5.21375000e+02 2.57837524e+01 5.18591858e+02
 4.20405884e+02 1.11229565e+03 5.46964539e+02 2.03873886e+02
 6.79670410e+02 3.59077148e+02 8.61625061e+01 5.47593811e+02
 1.21575806e+02 7.92437073e+02 3.96367279e+02 2.26334106e+02
 5.16641113e+02 8.65141830e+01 5.32687927e+02 7.01478333e+02
 1.31813855e+03 7.09061829e+02 1.82123413e+01 2.19617950e+02
 3.06555725e+02 5.48130371e+02 8.41235657e+02 5.21264587e+02
 1.03214380e+03 9.95943848e+02 1.85480408e+02 1.11516174e+02
 1.03568225e+03 1.02420691e+03 7.59454712e+02 8.17519836e+01
 1.15576019e+02 9.12541199e+02 6.11118958e+02 4.29005585e+01
 4.56854553e+01 2.60541382e+02 6.55511475e+01 5.35045227e+02
 6.28399902e+02 7.22438599e+02 7.61858887e+02 2.66129913e+02
 7.30365906e+01 2.82222046e+02 4.31819275e+02 2.23747955e+02
 6.82862488e+02 3.73486328e+01 8.63175354e+02 3.48026215e+02
 5.16348877e+02 1.83082489e+02 1.16922754e+03 1.32710022e+02
 8.73880127e+02 6.39834229e+02 4.62005615e+00 9.56995728e+02
 9.69321228e+02 1.04465259e+03 3.57172546e+01 4.19868469e+01
 5.65090027e+02 2.77690857e+02 3.89880981e+01 7.94816895e+01
 2.57871063e+02 2.57501434e+02 5.06189362e+02 1.34683972e+03
 6.15376648e+02 3.39809692e+02 6.86256470e+02 3.84766327e+02
 9.75615723e+02 1.00552490e+03 9.46953979e+02 1.40483521e+03
 6.75279480e+02 6.85915039e+02 7.33699219e+02 5.36420288e+02
 2.85764862e+02 4.64190186e+02 8.72881775e+02 4.27423187e+02
 5.61616211e+01 6.49700867e+02 1.08261792e+03 8.01694214e+02
 2.38115448e+02 5.19696960e+01 8.67332764e+02 8.48591064e+02
 4.75399200e+02 2.81271210e+02 5.11893921e+02 1.13028496e+02
 2.16934204e+00 6.44771851e+02 1.03052502e+03 9.68968140e+02
 5.14833679e+01 5.61874329e+02 5.42622437e+02 6.38440857e+02
 6.49778748e+02 1.36110962e+02 9.99475098e+00 4.22168030e+02
 7.70291016e+02 1.27978088e+03 5.25564209e+02 3.74127563e+02
 7.01511230e+01 4.53457855e+02 9.09783813e+02 1.71901062e+02
 8.58692017e+02 7.96170288e+02 2.91383331e+02 2.90276733e+02
 8.51273865e+02 1.89114120e+02 7.79604980e+02 7.44106262e+02
 3.58670349e+02 1.18386633e+03 7.57648438e+02 2.33595139e+02
 6.75589783e+02 1.07416003e+03 1.42890320e+02 1.02989685e+03
 2.04697769e+02 2.09915863e+02 1.65816589e+02 1.02264642e+03
 1.93745544e+02 2.76808807e+02 7.63154907e+02 4.32863739e+02
 1.00200110e+03 2.10129211e+02 2.86170563e+02 6.56825928e+02
 9.72358704e+02 6.67851929e+02 1.19136353e+01 2.99226013e+02
 1.18674609e+03 9.38099426e+02 2.09026596e+02 2.39920197e+02
 3.79282440e+02 6.19046570e+02 4.91319855e+02 3.69224396e+02
 7.53294250e+02 1.91546112e+02 7.75158813e+02 4.56350708e+00
 3.16993378e+02 6.61129837e+01 1.91241455e+01 2.50439346e+02
 3.47688782e+02 2.99373199e+02 3.75028992e+01 5.51579651e+02
 5.72965240e+01 1.01672493e+02 6.39096863e+02 1.00194873e+03
 1.55642609e+02 5.50455933e+02 5.18964050e+02 7.77473083e+02
 2.08735199e+02 8.62209778e+02 1.60353821e+02 4.34272766e+02
 5.20981506e+02 2.40944763e+02 7.50657593e+02 7.33526550e+02
 6.92029175e+02 2.76721649e+02 1.43819229e+02 1.12649994e+02
 3.30078125e-01 6.74315369e+02 6.26579895e+01 4.00171967e+02
 7.51348877e+01 1.69953339e+02 4.61405121e+02 6.81046082e+02
 5.44568359e+02 6.68129028e+02 6.91579102e+02 2.94840668e+02
 2.67625732e+02 2.40088318e+02 8.44013062e+02 6.14692017e+02
 2.04135132e+02 6.77572083e+02 4.80290710e+02 3.16608002e+02
 7.54953674e+02 1.45591370e+02 2.30959045e+02 6.19585571e+02
 3.95747620e+02 2.75421661e+02 3.09355377e+02 5.88014099e+02
 1.93131470e+02 2.62738708e+02 1.18458435e+02 1.04764526e+02
 2.55728394e+02 5.51210449e+02 7.20260071e+02 3.29792145e+02
 2.90396545e+02 1.36669312e+03 2.53061371e+02 3.87629517e+02
 5.30989136e+02 3.73332489e+02 5.10933807e+02 2.35656235e+02
 5.15827881e+02 2.34348938e+02 1.07550781e+02 1.56590027e+02
 1.03181702e+03 3.51136414e+02 8.52809937e+02 2.18169098e+02
 9.56966003e+02 4.34150726e+02 1.96512985e+02 6.06556396e+02
 6.95225525e+01 2.49368866e+02 5.79269897e+02 1.36499130e+02
 1.24940918e+02 6.08947998e+02 1.92165268e+02 8.62341766e+01
 1.70612305e+02 8.40054504e+02 5.95995239e+02 6.57641296e+01
 4.52878967e+02 6.91430237e+02 2.66684021e+02 8.48788696e+02
 1.61406494e+02 8.87859619e+02 4.31268433e+02 2.40869431e+02
 8.10169800e+02 9.42627380e+02 1.68854919e+02 5.83420410e+01
 1.36084213e+02 5.23010864e+02 4.72779175e+02 6.02039490e+01
 4.33767548e+02 7.40850647e+02 1.35332016e+02 1.90555099e+02
 1.29746887e+02 5.26597107e+02 2.06767075e+02 2.08907974e+02
 7.91065613e+02 7.76825256e+01 2.08013275e+02 3.26334351e+02
 2.20951065e+02 3.07266602e+02 1.40119034e+02 1.47761536e+01
 1.03406219e+02 6.48752563e+02 6.28548584e+01 1.17149551e+02
 1.14018494e+02 4.54705841e+02 7.48538208e+00 2.90384277e+02
 3.39995636e+02 1.61064178e+02 1.25761938e+03 4.10146027e+02
 7.02472412e+02 5.93820801e+01 2.40838852e+02 5.23807129e+02
 1.90614151e+02 1.04012238e+02 2.46244186e+02 5.39972107e+02
 4.32470795e+02 6.40625916e+02 1.28643661e+02 2.13813538e+02
 6.31753723e+02 3.20431244e+02 4.79105835e+02 5.16916748e+02
 1.60602478e+02 7.18901123e+02 6.52217773e+02 4.41581085e+02]","[  55.704742   920.92645     19.99173    144.33754    975.7613
  145.41751    232.60214    481.85513     75.03119    191.61816
  425.2047     144.96854    370.1252      47.661987   552.7833
  421.38702     25.420868   197.00127    356.3353     621.89624
  192.30481    981.23975    308.7951     703.92975    567.4538
  604.1745     483.65546    203.8647    1021.46783    760.033
  333.3695     957.7737     399.1765     198.62155    764.16724
  227.93547    474.23953    120.71015    133.26501     91.0502
  534.3127     193.83363    254.3783     442.3119     915.2878
  989.4786     552.67706     87.480865   740.96533    398.3869
  413.082      132.71991    104.36453    506.9679     460.59183
  200.829       73.78175     22.315384   482.67114    436.6988
  772.6083     609.4136     674.83466    840.9754     135.15959
  176.00305    630.61475     54.866013   318.30457    576.47925
  554.1934     500.63852    370.2236     526.3088      22.947113
  494.93616    426.30084   1112.3978     544.27264    208.55284
  671.72815    354.51987     93.22034    543.9331     140.06384
  747.8182     399.40945    223.49155    506.86414     98.65602
  546.98926    629.3602    1309.3278     697.24335     13.415039
  231.20026    317.64383    553.5269     842.30945    516.6508
 1010.55383    976.27014    189.17285    121.64392   1042.9287
  996.29895    758.17645    101.24475    118.93475    909.11475
  606.51117     42.692978    49.27289    267.1336     104.00836
  544.0074     624.97864    732.9105     764.4946     258.07953
   76.52289    288.6581     435.3149     229.55557    672.0752
   31.589417   853.6135     349.7125     517.9044     222.16678
 1137.5973     137.61987    877.9921     631.7609      -7.6503906
  954.94165    973.0098    1002.9627      44.033447    53.87195
  561.6595     270.2008      49.967712    70.92078    268.82208
  256.70914    526.0943    1287.8105     600.9194     330.38043
  703.37726    395.86493    931.22253    976.9682     963.1775
 1384.9578     658.6672     689.0377     726.44727    546.68164
  288.43927    457.87457    862.4728     418.4483      75.91785
  649.8565    1072.4951     824.5101     241.96335     45.428833
  821.7299     796.12054    499.44095    303.55768    477.02173
  120.5691       8.601044   680.46576   1009.3322     983.8426
   52.906036   540.30414    532.5593     665.8683     641.9735
  145.23444     42.950928   423.48212    774.02747   1193.3549
  520.80005    366.81198     74.0061     454.74048    921.77106
  156.35223    834.3422     685.479      290.90054    287.08557
  857.37415    201.31332    775.69574    742.5046     356.93997
 1254.0664     755.2126     230.69838    680.02075   1060.6528
  152.35675   1041.512      203.68185    219.65788    171.78256
 1029.9508     216.276      271.78214    777.5411     421.32263
 1002.7123     218.51978    280.2728     645.21967    965.3545
  637.91534     23.945496   298.5254    1192.1006     946.2455
  203.96815    241.9737     362.9807     547.25903    494.22256
  367.97324    742.75745    198.24556    741.77875     39.693665
  325.3373      67.97583     22.094635   241.24554    350.8799
  294.27542     42.643402   559.0392      56.871918   106.69338
  617.1576     996.7935     159.46136    557.7957     506.39886
  766.0181     207.86038    824.40857    163.92249    431.8724
  512.9078     237.26944    756.1711     729.0223     699.7237
  278.66223    158.06047    116.03114     48.44153    664.9891
   75.44635    388.6998      78.92621    170.36467    472.59042
  688.32697    540.7095     678.26184    689.29663    290.10498
  274.8595     248.43289    832.841      620.81836    209.4812
  658.23083    492.03928    362.76974    762.586      152.27284
  233.59442    624.52313    400.233      268.54538    314.99405
  585.9094     202.44922    268.73474    121.971344   116.92651
  251.59985    542.6566     718.5011     317.06046    285.78055
 1398.4681     249.98473    358.6011     534.4421     378.3639
  512.3111     240.09554    513.2025     236.02252    118.382996
  179.28323   1033.8197     350.03952    852.639      242.10828
  956.2344     422.99838    202.68501    610.7733      63.59082
  240.37384    582.2066     144.03835    135.51147    631.6938
  195.2925      92.13495    183.40247    869.18146    584.58984
   81.27713    447.77106    675.0745     268.92004    847.47205
  176.15277    886.05005    431.33646    235.0231     826.35803
  950.56714    172.24695     37.424194   130.07957    510.60272
  456.72986     55.45407    426.73523    738.2367     143.08383
  189.8906     144.90948    515.0547     210.62117    214.73659
  767.19104     75.918976   210.39426    336.1122     220.14357
  307.65005    142.903       14.124939   108.827484   632.653
   58.85623    125.08521    119.41019    460.57202      7.216339
  298.6293     342.55756    170.60834   1260.2812     419.95633
  704.2986      58.29315    260.217      561.6034     183.12097
  118.508064   250.16998    549.12024    426.8886     637.2876
  136.17697    214.07062    638.5752     330.2857     485.67227
  513.5101     185.44867    694.4765     643.70154    450.4026   ]",10.87119,285.9932,16.911333317632828
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 0.400686170819194, Val Loss: 0.372662804126740', 'Epoch: 1, Train Loss: 0.367295700450276, Val Loss: 0.324533766508102', 'Epoch: 2, Train Loss: 0.303412855364556, Val Loss: 0.225534802675247', 'Epoch: 3, Train Loss: 0.183914937252222, Val Loss: 0.103858083486557', 'Epoch: 4, Train Loss: 0.097187757405431, Val Loss: 0.069841861128807', 'Epoch: 5, Train Loss: 0.081049255940110, Val Loss: 0.068354502916336', 'Epoch: 6, Train Loss: 0.072941750114740, Val Loss: 0.060469155907631', 'Epoch: 7, Train Loss: 0.070067552849650, Val Loss: 0.064691708683968', 'Epoch: 8, Train Loss: 0.070901255708101, Val Loss: 0.053708906471729', 'Epoch: 9, Train Loss: 0.067571294169093, Val Loss: 0.063024913072586', 'Epoch: 10, Train Loss: 0.060955247950069, Val Loss: 0.050314909517765', 'Epoch: 11, Train Loss: 0.064035635008368, Val Loss: 0.057407549321651', 'Epoch: 12, Train Loss: 0.058872470458926, Val Loss: 0.043579969406128', 'Epoch: 13, Train Loss: 0.053264663273165, Val Loss: 0.047317273467779', 'Epoch: 14, Train Loss: 0.048693455105951, Val Loss: 0.031348278671503', 'Epoch: 15, Train Loss: 0.044045156647646, Val Loss: 0.030823581516743', 'Epoch: 16, Train Loss: 0.045774127378367, Val Loss: 0.039540404230356', 'Epoch: 17, Train Loss: 0.043002350862290, Val Loss: 0.037673969417810', 'Epoch: 18, Train Loss: 0.039236033811819, Val Loss: 0.020607617720962', 'Epoch: 19, Train Loss: 0.038968357084276, Val Loss: 0.020960050970316', 'Epoch: 20, Train Loss: 0.039123484106778, Val Loss: 0.019924580827355', 'Epoch: 21, Train Loss: 0.028561380713485, Val Loss: 0.025766154676676', 'Epoch: 22, Train Loss: 0.033187109673786, Val Loss: 0.024625813886523', 'Epoch: 23, Train Loss: 0.031984266153602, Val Loss: 0.023194921165705', 'Epoch: 24, Train Loss: 0.029559779977209, Val Loss: 0.017706406004727', 'Epoch: 25, Train Loss: 0.031851784239501, Val Loss: 0.015835849717259', 'Epoch: 26, Train Loss: 0.028571311319463, Val Loss: 0.014732017479837', 'Epoch: 27, Train Loss: 0.027868523110831, Val Loss: 0.020895074009895', 'Epoch: 28, Train Loss: 0.030766176276429, Val Loss: 0.021853900104761', 'Epoch: 29, Train Loss: 0.028251124156076, Val Loss: 0.013293419703841', 'Epoch: 30, Train Loss: 0.027314371970850, Val Loss: 0.017997838035226', 'Epoch: 31, Train Loss: 0.027601632159636, Val Loss: 0.014046168476343', 'Epoch: 32, Train Loss: 0.029159186342948, Val Loss: 0.015096630975604', 'Epoch: 33, Train Loss: 0.028552363691635, Val Loss: 0.027503515034914', 'Epoch: 34, Train Loss: 0.036037280939000, Val Loss: 0.022025903984904', 'Epoch: 35, Train Loss: 0.026477213472474, Val Loss: 0.015198379866779', 'Epoch: 36, Train Loss: 0.029048955024675, Val Loss: 0.018033158555627', 'Epoch: 37, Train Loss: 0.029693927226025, Val Loss: 0.017388409823179', 'Epoch: 38, Train Loss: 0.030596571259720, Val Loss: 0.017093146368861', 'Epoch: 39, Train Loss: 0.028416296478014, Val Loss: 0.014033676646650', 'Epoch: 40, Train Loss: 0.024778174929494, Val Loss: 0.017588689401746', 'Epoch: 41, Train Loss: 0.027405169164372, Val Loss: 0.029203167855740', 'Epoch: 42, Train Loss: 0.029422011594613, Val Loss: 0.024314271658659', 'Epoch: 43, Train Loss: 0.024394434638495, Val Loss: 0.015372009277344', 'Epoch: 44, Train Loss: 0.024140229676092, Val Loss: 0.022768411710858', 'Epoch: 45, Train Loss: 0.025666998136182, Val Loss: 0.016457144841552', 'Epoch: 46, Train Loss: 0.028719156547341, Val Loss: 0.021722253561020', 'Epoch: 47, Train Loss: 0.032214281993896, Val Loss: 0.018988896757364', 'Epoch: 48, Train Loss: 0.025363821384692, Val Loss: 0.017977628782392', 'Epoch: 49, Train Loss: 0.021113341024449, Val Loss: 0.014494898617268', 'Epoch: 50, Train Loss: 0.023520384806880, Val Loss: 0.017219253517687', 'Epoch: 51, Train Loss: 0.023144608428485, Val Loss: 0.015674208179116', 'Epoch: 52, Train Loss: 0.019961780911788, Val Loss: 0.015040101706982', 'Epoch: 53, Train Loss: 0.020828598536291, Val Loss: 0.015769149363041', 'Epoch: 54, Train Loss: 0.019627813444754, Val Loss: 0.019353811591864', 'Epoch: 55, Train Loss: 0.022621358961387, Val Loss: 0.016458527967334', 'Epoch: 56, Train Loss: 0.020878574496872, Val Loss: 0.020316221117973', 'Epoch: 57, Train Loss: 0.019003942154001, Val Loss: 0.015899910330772', 'Epoch: 58, Train Loss: 0.019655678724480, Val Loss: 0.013290722742677', 'Epoch: 59, Train Loss: 0.017839777554104, Val Loss: 0.011962261088192', 'Epoch: 60, Train Loss: 0.019316591474033, Val Loss: 0.029338022731245', 'Epoch: 61, Train Loss: 0.020032201135574, Val Loss: 0.016057537347078', 'Epoch: 62, Train Loss: 0.018867409354899, Val Loss: 0.015316307768226', 'Epoch: 63, Train Loss: 0.021168453813812, Val Loss: 0.013800830803812', 'Epoch: 64, Train Loss: 0.017978638540520, Val Loss: 0.024648959226906', 'Epoch: 65, Train Loss: 0.019403123805776, Val Loss: 0.015297469012439', 'Epoch: 66, Train Loss: 0.022343790591803, Val Loss: 0.016458066701889', 'Epoch: 67, Train Loss: 0.017953991337658, Val Loss: 0.025236798003316', 'Epoch: 68, Train Loss: 0.018931179913844, Val Loss: 0.012442910764366', 'Epoch: 69, Train Loss: 0.016597237827819, Val Loss: 0.014980609342456', 'Epoch: 70, Train Loss: 0.017700410534649, Val Loss: 0.013189858011901', 'Epoch: 71, Train Loss: 0.018681546803131, Val Loss: 0.013447025250643', 'Epoch: 72, Train Loss: 0.017703699890178, Val Loss: 0.011599322259426', 'Epoch: 73, Train Loss: 0.015387637778943, Val Loss: 0.014159903302789', 'Epoch: 74, Train Loss: 0.016105135382954, Val Loss: 0.010550589002669', 'Epoch: 75, Train Loss: 0.016858916773006, Val Loss: 0.014292162656784', 'Epoch: 76, Train Loss: 0.014236541508242, Val Loss: 0.011724950782955', 'Epoch: 77, Train Loss: 0.015928538321236, Val Loss: 0.021740480698645', 'Epoch: 78, Train Loss: 0.016648549326631, Val Loss: 0.012458518538624', 'Epoch: 79, Train Loss: 0.016052321563367, Val Loss: 0.015937636196613', 'Epoch: 80, Train Loss: 0.017257292884900, Val Loss: 0.016105373278260', 'Epoch: 81, Train Loss: 0.017146061217889, Val Loss: 0.012659956850111', 'Epoch: 82, Train Loss: 0.013612970731459, Val Loss: 0.013038557730615', 'Epoch: 83, Train Loss: 0.015803236687599, Val Loss: 0.012324414197356', 'Epoch: 84, Train Loss: 0.016390132436226, Val Loss: 0.010254875216633', 'Epoch: 85, Train Loss: 0.015415622625327, Val Loss: 0.012993692904711', 'Epoch: 86, Train Loss: 0.014597362080632, Val Loss: 0.013950780965388', 'Epoch: 87, Train Loss: 0.012736965447318, Val Loss: 0.012268655113876', 'Epoch: 88, Train Loss: 0.014834361551546, Val Loss: 0.012650142796338', 'Epoch: 89, Train Loss: 0.015417717635458, Val Loss: 0.014985207542777', 'Epoch: 90, Train Loss: 0.015346908855230, Val Loss: 0.012315637357533', 'Epoch: 91, Train Loss: 0.015758200711029, Val Loss: 0.018434850797057', 'Epoch: 92, Train Loss: 0.017061998894395, Val Loss: 0.011519888415933', 'Epoch: 93, Train Loss: 0.013393204897469, Val Loss: 0.017903296947479', 'Epoch: 94, Train Loss: 0.015250713683578, Val Loss: 0.012676714789122', 'Epoch: 95, Train Loss: 0.013897117649660, Val Loss: 0.012371102897450', 'Epoch: 96, Train Loss: 0.016715020612749, Val Loss: 0.015394192263484', 'Epoch: 97, Train Loss: 0.014053815499295, Val Loss: 0.011685230322182', 'Epoch: 98, Train Loss: 0.012621737475139, Val Loss: 0.015177351869643', 'Epoch: 99, Train Loss: 0.013956157349830, Val Loss: 0.019026256725192', 'Epoch: 100, Train Loss: 0.013898040579502, Val Loss: 0.011981473937631', 'Epoch: 101, Train Loss: 0.013291608607180, Val Loss: 0.012722875513136', 'Epoch: 102, Train Loss: 0.013972928996609, Val Loss: 0.013173982016742', 'Epoch: 103, Train Loss: 0.013172249602111, Val Loss: 0.010273191519082', 'Epoch: 104, Train Loss: 0.012519846377938, Val Loss: 0.011811699606478', 'Epoch: 105, Train Loss: 0.012412066159900, Val Loss: 0.012524929195642', 'Epoch: 106, Train Loss: 0.011093081668193, Val Loss: 0.017120573557913', 'Epoch: 107, Train Loss: 0.012607470328032, Val Loss: 0.013694210499525', 'Epoch: 108, Train Loss: 0.011878871922056, Val Loss: 0.010922737773508', 'Epoch: 109, Train Loss: 0.013999520324517, Val Loss: 0.010386258438230', 'Epoch: 110, Train Loss: 0.012297463787416, Val Loss: 0.011395471543074', 'Epoch: 111, Train Loss: 0.013124144484484, Val Loss: 0.013204624354839', 'Epoch: 112, Train Loss: 0.012308356828641, Val Loss: 0.014313427582383', 'Epoch: 113, Train Loss: 0.012092326507839, Val Loss: 0.012830564752221', 'Epoch: 114, Train Loss: 0.011367738181942, Val Loss: 0.011414221785963', 'Epoch: 115, Train Loss: 0.012003334076685, Val Loss: 0.010239926315844', 'Epoch: 116, Train Loss: 0.013473191266056, Val Loss: 0.012175234146416', 'Epoch: 117, Train Loss: 0.011052772846766, Val Loss: 0.010786483362317', 'Epoch: 118, Train Loss: 0.010603643802190, Val Loss: 0.014618254601955', 'Epoch: 119, Train Loss: 0.011331106698530, Val Loss: 0.014168688505888', 'Epoch: 120, Train Loss: 0.012411028601576, Val Loss: 0.015908559188247', 'Epoch: 121, Train Loss: 0.013524263339160, Val Loss: 0.011835664613172', 'Epoch: 122, Train Loss: 0.010809851214723, Val Loss: 0.010480023343116', 'Epoch: 123, Train Loss: 0.011142024012326, Val Loss: 0.012030166760087', 'Epoch: 124, Train Loss: 0.011064133780120, Val Loss: 0.011767743639648', 'Epoch: 125, Train Loss: 0.013766315029284, Val Loss: 0.014041473418474', 'Epoch: 126, Train Loss: 0.012954805138369, Val Loss: 0.013769923467189', 'Epoch: 127, Train Loss: 0.011342230615704, Val Loss: 0.010322692543268', 'Epoch: 128, Train Loss: 0.010947170526569, Val Loss: 0.011799211241305', 'Epoch: 129, Train Loss: 0.009726308784339, Val Loss: 0.010288227256387', 'Epoch: 130, Train Loss: 0.010440145218528, Val Loss: 0.010915360376239', 'Epoch: 131, Train Loss: 0.009501715613053, Val Loss: 0.010166413886473', 'Epoch: 132, Train Loss: 0.009421167137145, Val Loss: 0.012093915715814', 'Epoch: 133, Train Loss: 0.010032381288447, Val Loss: 0.011020158417523', 'Epoch: 134, Train Loss: 0.009591777440767, Val Loss: 0.009816972538829', 'Epoch: 135, Train Loss: 0.011820219262222, Val Loss: 0.011589783374220', 'Epoch: 136, Train Loss: 0.011434180510425, Val Loss: 0.011934619322419', 'Epoch: 137, Train Loss: 0.010965563367706, Val Loss: 0.012442046999931', 'Epoch: 138, Train Loss: 0.010580841191979, Val Loss: 0.010524217281491', 'Epoch: 139, Train Loss: 0.011570980999792, Val Loss: 0.013625102099031', 'Epoch: 140, Train Loss: 0.010545865914156, Val Loss: 0.014329038225114', 'Epoch: 141, Train Loss: 0.010881683209824, Val Loss: 0.010366494134068', 'Epoch: 142, Train Loss: 0.009477051635554, Val Loss: 0.012355994898826', 'Epoch: 143, Train Loss: 0.010542141111178, Val Loss: 0.011999929621816', 'Epoch: 144, Train Loss: 0.009791068635275, Val Loss: 0.011880158185959', 'Epoch: 145, Train Loss: 0.009178413164824, Val Loss: 0.010340675413609', 'Epoch: 146, Train Loss: 0.009572051573805, Val Loss: 0.011736279055476', 'Epoch: 147, Train Loss: 0.010413581505418, Val Loss: 0.011669414751232', 'Epoch: 148, Train Loss: 0.010151216987694, Val Loss: 0.010194150693715', 'Epoch: 149, Train Loss: 0.009504208969342, Val Loss: 0.011025254614651', 'Epoch: 150, Train Loss: 0.010628716738591, Val Loss: 0.011112998947501', 'Epoch: 151, Train Loss: 0.008409311610469, Val Loss: 0.011108913123608', 'Epoch: 152, Train Loss: 0.009369396674988, Val Loss: 0.010141208339483', 'Epoch: 153, Train Loss: 0.009070886634723, Val Loss: 0.010143071971834', 'Epoch: 154, Train Loss: 0.010205327316599, Val Loss: 0.011825846321881', 'Epoch: 155, Train Loss: 0.009218282905559, Val Loss: 0.010789257371798', 'Epoch: 156, Train Loss: 0.009381603720316, Val Loss: 0.011681269258261', 'Epoch: 157, Train Loss: 0.008951184123235, Val Loss: 0.009593375213444', 'Epoch: 158, Train Loss: 0.008787965770204, Val Loss: 0.010702048707753', 'Epoch: 159, Train Loss: 0.008837346669806, Val Loss: 0.009572826288640', 'Epoch: 160, Train Loss: 0.009218063422067, Val Loss: 0.012540657445788', 'Epoch: 161, Train Loss: 0.008870158030457, Val Loss: 0.010556080844253', 'Epoch: 162, Train Loss: 0.008686138436112, Val Loss: 0.009752817228436', 'Epoch: 163, Train Loss: 0.008499287783580, Val Loss: 0.010054885875434', 'Epoch: 164, Train Loss: 0.009071074615687, Val Loss: 0.010638457164168', 'Epoch: 165, Train Loss: 0.009236907077477, Val Loss: 0.010645705722272', 'Epoch: 166, Train Loss: 0.008746418809562, Val Loss: 0.010302968043834', 'Epoch: 167, Train Loss: 0.007770091463097, Val Loss: 0.010841330941767', 'Epoch: 168, Train Loss: 0.008310077251693, Val Loss: 0.010554945133626', 'Epoch: 169, Train Loss: 0.009148451266810, Val Loss: 0.010832300446928', 'Epoch: 170, Train Loss: 0.008514998269506, Val Loss: 0.010241510346532', 'Epoch: 171, Train Loss: 0.008209965895688, Val Loss: 0.010339001230896', 'Epoch: 172, Train Loss: 0.008304502197736, Val Loss: 0.010857969895005', 'Epoch: 173, Train Loss: 0.008038075223868, Val Loss: 0.009886074662209', 'Epoch: 174, Train Loss: 0.009252328154913, Val Loss: 0.010092864371836', 'Epoch: 175, Train Loss: 0.008241523024734, Val Loss: 0.011007935460657', 'Epoch: 176, Train Loss: 0.009049549904587, Val Loss: 0.011760244928300', 'Epoch: 177, Train Loss: 0.008991119224405, Val Loss: 0.010951081998646', 'Epoch: 178, Train Loss: 0.007982123507793, Val Loss: 0.010389894507825', 'Epoch: 179, Train Loss: 0.008330883913089, Val Loss: 0.010280140005052', 'Epoch: 180, Train Loss: 0.008582873535234, Val Loss: 0.009982690848410', 'Epoch: 181, Train Loss: 0.008541891838662, Val Loss: 0.010001499988139', 'Epoch: 182, Train Loss: 0.008626058730188, Val Loss: 0.010571629069746', 'Epoch: 183, Train Loss: 0.008343818960278, Val Loss: 0.010873090708628', 'Epoch: 184, Train Loss: 0.008017097063752, Val Loss: 0.010388327799737', 'Epoch: 185, Train Loss: 0.008087821348115, Val Loss: 0.010028594769537', 'Epoch: 186, Train Loss: 0.008306327698276, Val Loss: 0.010043854285032', 'Epoch: 187, Train Loss: 0.007575422086818, Val Loss: 0.009804989323020', 'Epoch: 188, Train Loss: 0.008144543760694, Val Loss: 0.010123966652900', 'Epoch: 189, Train Loss: 0.007581813114717, Val Loss: 0.009887742064893', 'Epoch: 190, Train Loss: 0.007845532544347, Val Loss: 0.010418915264308', 'Epoch: 191, Train Loss: 0.008507869173881, Val Loss: 0.009556671511382', 'Epoch: 192, Train Loss: 0.007725194908765, Val Loss: 0.010136860013008', 'Epoch: 193, Train Loss: 0.007496431085476, Val Loss: 0.009810613095760', 'Epoch: 194, Train Loss: 0.007607511472130, Val Loss: 0.009840936698020', 'Epoch: 195, Train Loss: 0.006800504688303, Val Loss: 0.010034904908389', 'Epoch: 196, Train Loss: 0.007031265207631, Val Loss: 0.009780866540968', 'Epoch: 197, Train Loss: 0.007752636555842, Val Loss: 0.009711419343948', 'Epoch: 198, Train Loss: 0.008103570554319, Val Loss: 0.009645852595568', 'Epoch: 199, Train Loss: 0.007166373792516, Val Loss: 0.009600035883486']","[ 215.40222    984.0629     453.49554    387.87408    700.9108
  648.56396   1411.8518     312.22897    441.79794    258.12103
  280.8277     633.9198     110.10739    495.32343    250.22534
   52.51416    128.8404     503.72635    205.2522     117.6492
  214.56255    402.56665    634.9649     452.48102     15.68689
  966.34106    222.81041     48.927856   435.8883     551.3972
  458.80197     84.318756    60.161255   444.49866    453.39484
  822.7206     504.80875    101.358215   671.4245     112.58728
 1134.069      543.36945    630.26294    536.7145     115.82913
  217.02191     82.865906   264.961     1262.9597     651.2194
  905.02484    481.39963    579.45044    976.4652     630.4829
  130.20926   1185.0903      49.264893   722.7429     271.0982
  518.7912     141.6886     333.9525      40.089783   611.8394
  714.1183    1041.0232    1367.8916      71.33392    384.84113
  357.88483     66.67853     96.01614   1016.6472     164.57416
  575.84515     97.70708    551.922      311.49112    766.9763
  187.86975    420.32877    696.02893     33.167114   380.39575
  663.3662     331.86496    595.2532     147.0976    1086.8655
  373.14624    118.40799    186.27365    667.53125    822.2712
 1187.8109     740.80396    110.72113    505.51743    191.22879
 1079.6143    1245.919      981.19977    544.319       17.913147
   42.995483  1005.97      1019.5133     590.507      257.43527
  478.7178     382.27228    730.8125     519.08954   1060.6339
  361.01566    187.27203    376.09433    125.58832    693.3066
  639.9852     238.58456    309.00058    414.16342   1046.0221
  423.04395    612.17053    863.94086      8.12915    914.06494
  289.88815    292.33435    842.8398     678.27954    612.561
  707.3582     210.70232    423.2228     669.6178     280.37253
  195.19235    255.53366    694.24036    680.114      213.79437
   12.361237   767.1723     428.1589     994.0417     245.47269
  252.20459    380.9858      66.96228    783.4097     600.00726
  529.92664    685.7495     431.69388    294.4631     240.71153
 1092.6892     269.41083    919.2787     781.0615    1148.8076
  893.683     1018.87573    945.4075     559.224       82.39807
   27.56961    191.25554    386.67535   1428.6515     773.8549
  551.07666    405.0793     208.10602    523.8531     524.2605
  551.99805    243.05313    314.80203    367.92734    419.6632
  190.07964    571.83923    697.7037     345.67648     37.460693
  171.78564    206.73       175.74446    230.5716     216.62665
  681.9642      37.95459    679.91125    455.8785     409.46857
   26.197815   147.46707    540.9011     332.9388     666.59595
  348.8455     595.09375    951.27527    681.3541     653.76245
  175.2474     670.93115    573.69025    778.85956    509.63846
  675.43823     14.246521   294.21396    471.52716    687.558
  575.6211     269.47556    757.5438     466.6985     249.14374
  425.4087     748.46515    718.86096    258.824      359.7415
  739.8808     281.07928    608.0654     190.41354    675.1184
  482.74216   1177.4702     862.2593     565.97076    998.2221
   45.851868   645.2057     144.48242    339.04337    711.1218
   81.1308     540.0176     174.9151     972.8417      75.14282
  958.0963     447.44073    423.0691    1270.9604     646.9508
  413.7789     792.82306    780.55804    598.1957     300.67026
  263.21097   1066.2456     699.3856     350.82404    776.36633
  670.5692     642.69104    351.43936    168.60455    546.95624
   73.83168    391.36273    991.27435    740.3872     315.01532
  874.98267    428.55777     14.502106   922.1865      15.340515
  442.59158    706.35236     16.978394   536.3673     144.50302
  840.0757     389.06927    291.5078     564.52527    349.37335
  661.14874    516.27344    524.69775    831.47046    132.76776
  454.86145    113.26599    174.71286    722.5836     204.37659
  563.2529     260.10565    261.42126    154.92865    223.24127
  571.8718    1079.925     1060.567     1140.1165     371.77402
   99.67822    847.03174    796.2961     401.3431     699.0565
  266.79382    754.8345     527.18304    634.694      643.63745
  223.39377    528.1046     389.0538     235.26532    101.80823
  869.31946    161.29776    876.4184     100.1606     378.11044
  610.44464    851.32886    295.51416   1030.406      668.05914
  856.27386   1294.3816     760.9127     159.61209    555.49426
  376.33035    936.8702     436.10278    522.67444    208.91393
  313.93686    279.3341      32.91559    614.5963     225.62558
  902.6153      73.77289    444.55786    458.25604    922.6675
   32.68445    260.14996    187.90906     88.50902    427.06314
  194.81464    131.26135    149.31616    328.4386     450.91074
  461.2331     646.8738     117.51749     47.044067   608.7702
 1253.0215     305.9044     432.99866    231.50027    507.79056
  233.67914    397.41248    220.50195    453.0003     751.5143
  556.16113    520.1179     387.03647    806.1611    1003.0816
  577.7594     280.78467    228.16751    970.12775      1.7805786
  418.77563    868.9544     636.38116    695.30743   1243.5576
   99.82294    518.9796     155.83484    285.56216    123.82492  ]","[ 260.38354  1001.2103    447.34723   370.00748   584.4433    616.7595
 1333.6931    244.22757   403.82928   279.38025   224.16345   773.1348
  158.64108   501.44467   281.8135     98.79199    72.61441   490.1255
  177.28613    30.49231   244.16486   422.46234   642.61835   417.8321
  208.64764   898.40063   240.65599    47.724365  436.0134    563.1405
  483.0417     74.18242    14.454071  488.4706    472.33942   867.3136
  487.26678   105.08937   661.07623   161.02844  1130.1099    553.65656
  612.5767    532.8567    124.206604  137.84288   -50.24713   240.64001
 1262.5863    647.71075   933.3122    454.62387   583.5783    961.27203
  625.6898    136.36514  1085.689     104.36139   726.57587   287.13275
  502.70828   167.5357    351.7475    104.0654    671.69965   744.2379
 1089.24     1362.2555    236.33276   400.27942   363.2649    110.778564
   80.51572   942.6049    181.98094   607.2487     90.65233   560.94165
  302.9552    790.1312    114.41818   401.30298   713.8739     89.40045
  370.5245    652.9714    320.6862    597.78705   100.743835 1154.4487
  372.1112    165.05284   211.95486   637.23975   805.94714  1259.9037
  725.2658    144.41785   596.27246   246.78285  1107.3582   1213.179
 1010.032     562.2045    228.65097   197.44067   954.2465    986.8194
  568.60077   169.99298   470.67404   382.69476   715.7064    542.88336
 1055.5652    388.6084    178.54883   388.99448   137.23676   651.0991
  590.1221    219.3585    347.03995   427.97607  1087.0475    395.9295
  600.204     828.5915    -13.641418  937.54645   277.31534   249.40492
  856.88544   675.13367   606.10114   662.80927   177.54982   438.7335
  656.89545   311.69626   145.37662   242.07349   743.6546    664.4265
  215.64888    78.48096   746.2656    404.34665  1006.44904   291.18396
  157.75537   400.34918    74.50455   706.81793   676.3439    581.11566
  715.89557   459.73505   264.08063   222.42635  1051.831     247.07635
  940.80817   802.003    1171.741     946.22546  1028.6292    963.22076
  556.3948     76.461426   34.68329   208.5875    481.69064  1366.0753
  754.24744   540.11487   413.77072   218.53754   532.0299    520.2782
  532.93445   241.7391    254.08635   315.95938   427.08392   207.63667
  574.8645    708.39465   362.3344     59.12993   222.93982   258.65933
  207.7433    266.8518    341.9554    740.0006    104.41965   677.6332
  451.86505   436.2793    122.04785   234.74028   479.51688   284.16812
  609.8458    270.15704   647.05396   938.8533    521.73926   574.7102
  164.70001   650.166     566.87915   756.3622    507.2547    649.44275
   76.84625   273.6037    379.0758    733.4682    498.50958   261.95056
  778.23004   443.55292   199.49274   417.00366   752.5099    693.6286
  287.45428   356.6981    698.6551    307.43857   552.83704   167.40092
  683.51587   380.4801   1130.85      826.51086   504.49704  1018.90375
  157.7591    512.7108    123.95279   351.753     722.69617   104.45108
  504.02527   104.095764 1001.25476    83.36325   992.3435    472.74582
  507.074    1296.0022    621.3307    403.68643   744.47015   770.5771
  627.8584    278.55405   268.35397  1005.1605    748.9276    364.06555
  788.55884   684.7083    643.3869    324.6267    171.91714   543.44196
  -83.03711   362.44928   960.76654   768.6067    331.55228   865.92236
  389.94965    76.34558   923.5609    -13.500916  471.10446   659.7019
   94.90402   541.89087   104.971375  841.43616   380.56125   317.59158
  571.4184    420.09647   675.79004   543.5212    485.29874   833.5464
  172.3086    464.66458    76.9718    101.80997   687.28406   123.92883
  521.58374   220.90079   236.16925   142.6001    171.68744   521.0202
 1127.3528   1049.4221   1126.4287    384.28647   190.41525   839.766
  799.1576    416.5005    672.32074   287.66193   786.5809    547.97675
  623.96783   629.3559    263.9558    543.1533    369.66776   244.83269
  114.85571   866.97626   183.50436   778.2055    110.66205   451.60745
  628.1522   1011.8236    193.98602   976.76337   644.35187   839.6621
 1223.4015    790.36206   138.34586   568.8501    397.2163    923.2516
  541.9414    469.46524   211.71889   287.72845   259.98132    44.613068
  631.8609    226.90872   805.7438    115.4079    481.08823   462.6367
  892.65      114.40289   200.8953    167.7189     63.436005  428.2113
  211.9632    116.54144    78.78992   345.51398   347.373     414.89075
  660.43604   162.44684    84.06348   594.5495   1342.1406    254.30188
  392.5467    247.5042    445.3638    174.40756   429.915     205.07922
  426.48486   788.02985   562.87244   528.4825    364.89752   775.5605
  927.59357   622.56006   144.6535    160.80902   852.8909    150.47778
  426.54202   852.4851    649.37054   711.9914   1133.6558    207.76044
  527.9525     97.578705  255.19534   175.05148 ]",35.92095,2443.4695,49.43146247504594
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 1.268151701882828, Val Loss: 0.758344056606293', 'Epoch: 1, Train Loss: 0.889625567336415, Val Loss: 0.687263791561127', 'Epoch: 2, Train Loss: 0.777953742548477, Val Loss: 0.553890850543976', 'Epoch: 3, Train Loss: 0.571052230374758, Val Loss: 0.305020785331726', 'Epoch: 4, Train Loss: 0.313156141964502, Val Loss: 0.146022444069386', 'Epoch: 5, Train Loss: 0.221768385275852, Val Loss: 0.185935902595520', 'Epoch: 6, Train Loss: 0.203925817858341, Val Loss: 0.120995340645313', 'Epoch: 7, Train Loss: 0.176342922760997, Val Loss: 0.129548034816980', 'Epoch: 8, Train Loss: 0.147808159160060, Val Loss: 0.097168583869934', 'Epoch: 9, Train Loss: 0.128445672087891, Val Loss: 0.102533248364925', 'Epoch: 10, Train Loss: 0.124593247854432, Val Loss: 0.067637750208378', 'Epoch: 11, Train Loss: 0.115747931391694, Val Loss: 0.055020073056221', 'Epoch: 12, Train Loss: 0.105790252948916, Val Loss: 0.051390298902988', 'Epoch: 13, Train Loss: 0.097637322839609, Val Loss: 0.045205362141132', 'Epoch: 14, Train Loss: 0.092713599807994, Val Loss: 0.058598644882441', 'Epoch: 15, Train Loss: 0.105206989011792, Val Loss: 0.066332563236356', 'Epoch: 16, Train Loss: 0.097603689229419, Val Loss: 0.038946981579065', 'Epoch: 17, Train Loss: 0.092229057796473, Val Loss: 0.042122206799686', 'Epoch: 18, Train Loss: 0.097909770039625, Val Loss: 0.046588242948055', 'Epoch: 19, Train Loss: 0.111853733658791, Val Loss: 0.069040123820305', 'Epoch: 20, Train Loss: 0.106659985905470, Val Loss: 0.104518687129021', 'Epoch: 21, Train Loss: 0.095139818482621, Val Loss: 0.050115139484406', 'Epoch: 22, Train Loss: 0.075240922918500, Val Loss: 0.040082251727581', 'Epoch: 23, Train Loss: 0.075804253130458, Val Loss: 0.031583303771913', 'Epoch: 24, Train Loss: 0.074273269666835, Val Loss: 0.048874506279826', 'Epoch: 25, Train Loss: 0.070301346220942, Val Loss: 0.031308328881860', 'Epoch: 26, Train Loss: 0.063612432890507, Val Loss: 0.027552850544453', 'Epoch: 27, Train Loss: 0.081665897265423, Val Loss: 0.098020455837250', 'Epoch: 28, Train Loss: 0.072502596520407, Val Loss: 0.035016163010150', 'Epoch: 29, Train Loss: 0.089972283128043, Val Loss: 0.052603759467602', 'Epoch: 30, Train Loss: 0.066605995214263, Val Loss: 0.067808832973242', 'Epoch: 31, Train Loss: 0.091189374670733, Val Loss: 0.044148635864258', 'Epoch: 32, Train Loss: 0.099358764931906, Val Loss: 0.027516412073746', 'Epoch: 33, Train Loss: 0.067370150151641, Val Loss: 0.026857099160552', 'Epoch: 34, Train Loss: 0.100909080226407, Val Loss: 0.022677498934790', 'Epoch: 35, Train Loss: 0.077289192265896, Val Loss: 0.053148609697819', 'Epoch: 36, Train Loss: 0.055173116671138, Val Loss: 0.024340639486909', 'Epoch: 37, Train Loss: 0.103598989026491, Val Loss: 0.110702157914639', 'Epoch: 38, Train Loss: 0.066622302585910, Val Loss: 0.018333675116301', 'Epoch: 39, Train Loss: 0.069584075664712, Val Loss: 0.036309389472008', 'Epoch: 40, Train Loss: 0.094656053887204, Val Loss: 0.024261993765831', 'Epoch: 41, Train Loss: 0.080876021277766, Val Loss: 0.084314005970955', 'Epoch: 42, Train Loss: 0.077650972620346, Val Loss: 0.031175725683570', 'Epoch: 43, Train Loss: 0.062181585641621, Val Loss: 0.028556097485125', 'Epoch: 44, Train Loss: 0.056445708368407, Val Loss: 0.047740606516600', 'Epoch: 45, Train Loss: 0.051700354337172, Val Loss: 0.028454088531435', 'Epoch: 46, Train Loss: 0.070329587993234, Val Loss: 0.031812502443790', 'Epoch: 47, Train Loss: 0.045252969596795, Val Loss: 0.012502252375707', 'Epoch: 48, Train Loss: 0.047557905273036, Val Loss: 0.017473749499768', 'Epoch: 49, Train Loss: 0.055358454368489, Val Loss: 0.037105599343777', 'Epoch: 50, Train Loss: 0.044207223691046, Val Loss: 0.014004539251328', 'Epoch: 51, Train Loss: 0.038548806292373, Val Loss: 0.020512562617660', 'Epoch: 52, Train Loss: 0.046561078536649, Val Loss: 0.029848625529557', 'Epoch: 53, Train Loss: 0.056120452990885, Val Loss: 0.020565704070032', 'Epoch: 54, Train Loss: 0.057774624787271, Val Loss: 0.010676770862192', 'Epoch: 55, Train Loss: 0.038754891864089, Val Loss: 0.009759252145886', 'Epoch: 56, Train Loss: 0.044447227316194, Val Loss: 0.018310107439756', 'Epoch: 57, Train Loss: 0.048829700754479, Val Loss: 0.034694333672523', 'Epoch: 58, Train Loss: 0.039224370144481, Val Loss: 0.025027859136462', 'Epoch: 59, Train Loss: 0.086246045826133, Val Loss: 0.144922288805246', 'Epoch: 60, Train Loss: 0.081946032143436, Val Loss: 0.035781549774110', 'Epoch: 61, Train Loss: 0.051475393109370, Val Loss: 0.018429966419935', 'Epoch: 62, Train Loss: 0.042581026334056, Val Loss: 0.020241818614304', 'Epoch: 63, Train Loss: 0.044883915071571, Val Loss: 0.017332522002980', 'Epoch: 64, Train Loss: 0.052938195681849, Val Loss: 0.026525186412036', 'Epoch: 65, Train Loss: 0.039500928007413, Val Loss: 0.016608357205987', 'Epoch: 66, Train Loss: 0.047814850478845, Val Loss: 0.032184056006372', 'Epoch: 67, Train Loss: 0.036687498349090, Val Loss: 0.010086547527462', 'Epoch: 68, Train Loss: 0.035772351872956, Val Loss: 0.011287278030068', 'Epoch: 69, Train Loss: 0.063005547190821, Val Loss: 0.011437075641006', 'Epoch: 70, Train Loss: 0.039063815244062, Val Loss: 0.012891972083598', 'Epoch: 71, Train Loss: 0.048441123044075, Val Loss: 0.052346761003137', 'Epoch: 72, Train Loss: 0.064305737008189, Val Loss: 0.023057369198650', 'Epoch: 73, Train Loss: 0.041257686848037, Val Loss: 0.014423587843776', 'Epoch: 74, Train Loss: 0.034507881676735, Val Loss: 0.014157567806542', 'Epoch: 75, Train Loss: 0.035387878392845, Val Loss: 0.018442618101835', 'Epoch: 76, Train Loss: 0.043317942945070, Val Loss: 0.012149306721985', 'Epoch: 77, Train Loss: 0.046310450058690, Val Loss: 0.014568191617727', 'Epoch: 78, Train Loss: 0.038827794582345, Val Loss: 0.010149841140956', 'Epoch: 79, Train Loss: 0.029986975801199, Val Loss: 0.007784541472793', 'Epoch: 80, Train Loss: 0.036698265369375, Val Loss: 0.010864657610655', 'Epoch: 81, Train Loss: 0.040102129780449, Val Loss: 0.022148256078362', 'Epoch: 82, Train Loss: 0.048034631257314, Val Loss: 0.043703910857439', 'Epoch: 83, Train Loss: 0.041619527240305, Val Loss: 0.013323575258255', 'Epoch: 84, Train Loss: 0.036311306470875, Val Loss: 0.007811712250113', 'Epoch: 85, Train Loss: 0.036817656959905, Val Loss: 0.010046198647469', 'Epoch: 86, Train Loss: 0.043293995306242, Val Loss: 0.012822688817978', 'Epoch: 87, Train Loss: 0.036539819568049, Val Loss: 0.016255616471171', 'Epoch: 88, Train Loss: 0.031633045253625, Val Loss: 0.007705908436328', 'Epoch: 89, Train Loss: 0.031066229112100, Val Loss: 0.011400326453149', 'Epoch: 90, Train Loss: 0.035574170522565, Val Loss: 0.011556061245501', 'Epoch: 91, Train Loss: 0.032576719255641, Val Loss: 0.026191426776350', 'Epoch: 92, Train Loss: 0.042868562822425, Val Loss: 0.013801491037011', 'Epoch: 93, Train Loss: 0.039209800360854, Val Loss: 0.045676343739033', 'Epoch: 94, Train Loss: 0.032185655455430, Val Loss: 0.011576743815094', 'Epoch: 95, Train Loss: 0.028422186735931, Val Loss: 0.016144330650568', 'Epoch: 96, Train Loss: 0.036994641928305, Val Loss: 0.010019402727485', 'Epoch: 97, Train Loss: 0.042189227135549, Val Loss: 0.008183535486460', 'Epoch: 98, Train Loss: 0.031189244435450, Val Loss: 0.006933868257329', 'Epoch: 99, Train Loss: 0.031361844953756, Val Loss: 0.019721317365766', 'Epoch: 100, Train Loss: 0.038017371257897, Val Loss: 0.006843389607966', 'Epoch: 101, Train Loss: 0.032785246105388, Val Loss: 0.003157714838162', 'Epoch: 102, Train Loss: 0.040023422171903, Val Loss: 0.009246970489621', 'Epoch: 103, Train Loss: 0.035069928006377, Val Loss: 0.014606585688889', 'Epoch: 104, Train Loss: 0.030121142954327, Val Loss: 0.008624813389033', 'Epoch: 105, Train Loss: 0.029800944701703, Val Loss: 0.006660885736346', 'Epoch: 106, Train Loss: 0.031813784545764, Val Loss: 0.008137258011848', 'Epoch: 107, Train Loss: 0.034824977195713, Val Loss: 0.028332756850868', 'Epoch: 108, Train Loss: 0.033286753457126, Val Loss: 0.023047875948250', 'Epoch: 109, Train Loss: 0.035255322882602, Val Loss: 0.007211442254484', 'Epoch: 110, Train Loss: 0.029372754528425, Val Loss: 0.015961037697271', 'Epoch: 111, Train Loss: 0.031446329686184, Val Loss: 0.009468816770241', 'Epoch: 112, Train Loss: 0.034792402044458, Val Loss: 0.006806628564373', 'Epoch: 113, Train Loss: 0.034351240302068, Val Loss: 0.010409252252430', 'Epoch: 114, Train Loss: 0.027272095600533, Val Loss: 0.005313530620188', 'Epoch: 115, Train Loss: 0.036520841141600, Val Loss: 0.012942913770676', 'Epoch: 116, Train Loss: 0.027355762090274, Val Loss: 0.007354712411761', 'Epoch: 117, Train Loss: 0.027324244120093, Val Loss: 0.013726942054927', 'Epoch: 118, Train Loss: 0.029877452374718, Val Loss: 0.005868867430836', 'Epoch: 119, Train Loss: 0.025337297252791, Val Loss: 0.007837108820677', 'Epoch: 120, Train Loss: 0.032305285312928, Val Loss: 0.014577040784061', 'Epoch: 121, Train Loss: 0.039009432611597, Val Loss: 0.011795649006963', 'Epoch: 122, Train Loss: 0.032308228292264, Val Loss: 0.010040762536228', 'Epoch: 123, Train Loss: 0.033747387161955, Val Loss: 0.032056327685714', 'Epoch: 124, Train Loss: 0.033285425672697, Val Loss: 0.006445775395259', 'Epoch: 125, Train Loss: 0.024788488287392, Val Loss: 0.006200498584658', 'Epoch: 126, Train Loss: 0.028599682718862, Val Loss: 0.005054457969964', 'Epoch: 127, Train Loss: 0.031589868110280, Val Loss: 0.026662351135164', 'Epoch: 128, Train Loss: 0.028866340839412, Val Loss: 0.004324609823525', 'Epoch: 129, Train Loss: 0.025545674137944, Val Loss: 0.011573544070125', 'Epoch: 130, Train Loss: 0.036237189351299, Val Loss: 0.009167692009360', 'Epoch: 131, Train Loss: 0.030966419401730, Val Loss: 0.008449920602143', 'Epoch: 132, Train Loss: 0.028315875852524, Val Loss: 0.012984520886093', 'Epoch: 133, Train Loss: 0.028288012478761, Val Loss: 0.007422814592719', 'Epoch: 134, Train Loss: 0.028289624143305, Val Loss: 0.006006906628609', 'Epoch: 135, Train Loss: 0.028776521144738, Val Loss: 0.006527493649628', 'Epoch: 136, Train Loss: 0.025830302625721, Val Loss: 0.011490507293493', 'Epoch: 137, Train Loss: 0.025052249756490, Val Loss: 0.009895592462271', 'Epoch: 138, Train Loss: 0.029001385146795, Val Loss: 0.005283209579065', 'Epoch: 139, Train Loss: 0.023838932019507, Val Loss: 0.010996655505151', 'Epoch: 140, Train Loss: 0.025484500886049, Val Loss: 0.010547619052231', 'Epoch: 141, Train Loss: 0.025894754133079, Val Loss: 0.007876215707511', 'Epoch: 142, Train Loss: 0.029062323943647, Val Loss: 0.008041516914964', 'Epoch: 143, Train Loss: 0.026206086303086, Val Loss: 0.007718862872571', 'Epoch: 144, Train Loss: 0.029555884081610, Val Loss: 0.009868143200874', 'Epoch: 145, Train Loss: 0.028966733254492, Val Loss: 0.020731646977365', 'Epoch: 146, Train Loss: 0.032593353315755, Val Loss: 0.006177689507604', 'Epoch: 147, Train Loss: 0.025258388023737, Val Loss: 0.007329566527624', 'Epoch: 148, Train Loss: 0.027305732481182, Val Loss: 0.011899233963341', 'Epoch: 149, Train Loss: 0.022961473189901, Val Loss: 0.010346485096961', 'Epoch: 150, Train Loss: 0.028222037111084, Val Loss: 0.008669489510357', 'Epoch: 151, Train Loss: 0.027677493949616, Val Loss: 0.005072241816670', 'Epoch: 152, Train Loss: 0.025710227487739, Val Loss: 0.008196821939200', 'Epoch: 153, Train Loss: 0.022653725474726, Val Loss: 0.006448862636462', 'Epoch: 154, Train Loss: 0.030218280613596, Val Loss: 0.009227731553838', 'Epoch: 155, Train Loss: 0.023307345504331, Val Loss: 0.004529046532698', 'Epoch: 156, Train Loss: 0.029362942893491, Val Loss: 0.005648300582543', 'Epoch: 157, Train Loss: 0.027422251872892, Val Loss: 0.004936393089592', 'Epoch: 158, Train Loss: 0.025669158847873, Val Loss: 0.006083013880998', 'Epoch: 159, Train Loss: 0.027179028113308, Val Loss: 0.004205813505687', 'Epoch: 160, Train Loss: 0.025031974929017, Val Loss: 0.005349903926253', 'Epoch: 161, Train Loss: 0.024729910869758, Val Loss: 0.008424938954413', 'Epoch: 162, Train Loss: 0.027507457015819, Val Loss: 0.004800850562751', 'Epoch: 163, Train Loss: 0.022157510959132, Val Loss: 0.007778914198279', 'Epoch: 164, Train Loss: 0.022094696673543, Val Loss: 0.006131857093424', 'Epoch: 165, Train Loss: 0.023714637578747, Val Loss: 0.013135124761611', 'Epoch: 166, Train Loss: 0.023581781836097, Val Loss: 0.004360728319734', 'Epoch: 167, Train Loss: 0.021895408565395, Val Loss: 0.004912007665262', 'Epoch: 168, Train Loss: 0.026142261012696, Val Loss: 0.003550701644272', 'Epoch: 169, Train Loss: 0.023225729505337, Val Loss: 0.010875492058694', 'Epoch: 170, Train Loss: 0.025168806704324, Val Loss: 0.005704379519448', 'Epoch: 171, Train Loss: 0.026889619655734, Val Loss: 0.006143487868831', 'Epoch: 172, Train Loss: 0.027510872283994, Val Loss: 0.005237110722810', 'Epoch: 173, Train Loss: 0.028702256572974, Val Loss: 0.003044286728837', 'Epoch: 174, Train Loss: 0.020880547568722, Val Loss: 0.006424232139252', 'Epoch: 175, Train Loss: 0.025450256090005, Val Loss: 0.002618712410331', 'Epoch: 176, Train Loss: 0.022000003454470, Val Loss: 0.005215961206704', 'Epoch: 177, Train Loss: 0.022843438092359, Val Loss: 0.003371651396155', 'Epoch: 178, Train Loss: 0.026936849752484, Val Loss: 0.006359437163919', 'Epoch: 179, Train Loss: 0.032622078000460, Val Loss: 0.005660037565976', 'Epoch: 180, Train Loss: 0.022484043039122, Val Loss: 0.003410499561578', 'Epoch: 181, Train Loss: 0.023282058136321, Val Loss: 0.012081836452708', 'Epoch: 182, Train Loss: 0.027313305389916, Val Loss: 0.008061010334641', 'Epoch: 183, Train Loss: 0.021344923587559, Val Loss: 0.003788397954777', 'Epoch: 184, Train Loss: 0.021610387232761, Val Loss: 0.002932564532384', 'Epoch: 185, Train Loss: 0.024956597513411, Val Loss: 0.003179577002302', 'Epoch: 186, Train Loss: 0.023734031483358, Val Loss: 0.004418028509244', 'Epoch: 187, Train Loss: 0.022043097027859, Val Loss: 0.004395853490569', 'Epoch: 188, Train Loss: 0.019472938875646, Val Loss: 0.004095467440784', 'Epoch: 189, Train Loss: 0.020590469912561, Val Loss: 0.004525073035620', 'Epoch: 190, Train Loss: 0.021273156454743, Val Loss: 0.005307182017714', 'Epoch: 191, Train Loss: 0.026578731033518, Val Loss: 0.003124360395595', 'Epoch: 192, Train Loss: 0.020608044521840, Val Loss: 0.007739554746076', 'Epoch: 193, Train Loss: 0.023722159178105, Val Loss: 0.003913912330754', 'Epoch: 194, Train Loss: 0.021616993342028, Val Loss: 0.003888237560168', 'Epoch: 195, Train Loss: 0.025650817738456, Val Loss: 0.003416372612119', 'Epoch: 196, Train Loss: 0.019546795484805, Val Loss: 0.004914833214134', 'Epoch: 197, Train Loss: 0.021755823605629, Val Loss: 0.004012423721142', 'Epoch: 198, Train Loss: 0.024330718442798, Val Loss: 0.003594519998878', 'Epoch: 199, Train Loss: 0.019812508432065, Val Loss: 0.003410943769850']","[7.22336304e+02 1.25307471e+03 5.07489838e+02 6.36630249e+02
 7.66683044e+02 8.09721436e+02 9.88839844e+02 2.23809265e+02
 7.54100952e+02 1.43612195e+03 1.28741052e+03 1.17247681e+02
 3.15839447e+02 1.22405127e+03 4.95934113e+02 1.19104932e+03
 1.39354858e+03 1.17297766e+03 1.43576904e+02 1.43980396e+03
 9.90307861e+02 1.40222791e+03 6.37763306e+02 1.33295898e+03
 1.26080469e+03 4.77953583e+02 1.14136389e+03 3.29916351e+02
 2.05271027e+02 1.45169214e+03 9.65193970e+02 1.46593152e+03
 6.16388672e+02 1.43807495e+03 1.29621155e+03 1.63466187e+01
 4.80184021e+02 1.45238843e+03 1.04850122e+03 1.30571716e+03
 1.67612183e+02 1.32552441e+03 1.48954529e+03 1.19987866e+03
 1.40868994e+03 7.05249756e+02 5.41902222e+02 1.01075854e+03
 1.38557166e+03 8.80313110e+02 5.23533264e+02 1.38574548e+03
 1.43418188e+03 4.32257324e+02 1.49796252e+03 7.36392639e+02
 2.04010437e+02 1.21086328e+03 1.25894690e+03 3.15377197e+01
 4.35215668e+02 8.42092346e+02 3.80552429e+02 1.43803992e+03
 1.48141663e+03 1.05886243e+03 4.19193542e+02 1.33104602e+03
 2.66710144e+02 1.49088281e+03 1.67654160e+02 1.26755896e+03
 1.15910864e+03 1.38461658e+03 1.13133374e+03 7.97276611e+02
 1.38653271e+03 1.48110376e+03 1.33600745e+03 1.98698776e+02
 1.34115210e+03 1.04504761e+03 5.03161072e+02 1.12725305e+03
 6.26888550e+02 1.15456519e+03 1.35624390e+02 1.01888904e+03
 1.29163013e+03 2.85447388e+02 1.08779639e+03 1.47633105e+03
 9.96026611e+01 1.27623462e+03 5.47528870e+02 1.37863184e+03
 2.53904922e+02 9.42052734e+02 1.10696863e+03 1.05936768e+03
 1.51688660e+02 1.41417554e+03 1.43510327e+03 1.45953955e+03
 1.23615247e+03 1.00058289e+02 7.10765381e+02 1.02966809e+03
 1.43314905e+03 1.03147437e+03 1.11228589e+03 1.49158838e+03
 1.14838306e+03 1.36038208e+03 9.47452637e+02 1.25918518e+03
 1.37409521e+03 8.28422485e+02 5.86058228e+02 5.34244263e+02
 1.38195325e+03 6.06383057e+02 1.18101318e+03 9.16117493e+02
 1.35514661e+03 8.25518494e+02 1.35006433e+03 1.21149023e+03
 1.36090125e+03 3.32027466e+02 9.10064758e+02 1.49933582e+03
 1.08161328e+03 1.44789771e+03 1.31644702e+03 1.46184192e+03
 5.11455963e+02 1.17764966e+03 1.37932288e+03 1.13289990e+03
 1.39770203e+03 6.14201416e+02 9.82943787e+02 1.26612024e+03
 1.42170935e+03 1.16674963e+03 1.01749365e+03 1.19769849e+03
 1.13761511e+03 1.41618607e+02 1.34900281e+03 1.39656555e+03
 7.90600708e+02 1.48760693e+03 3.28778503e+02 1.04699707e+03
 1.42408704e+03 1.84574829e+02 1.48028076e+03 9.81612854e+02
 1.32337598e+03 9.89319641e+02 1.38377856e+03 1.47278223e+03
 1.05207678e+03 5.17977112e+02 2.54776489e+02 1.24773535e+03
 1.47795068e+03 9.31653809e+02 9.48194031e+02 1.17918604e+03
 5.86759216e+02 1.40433447e+03 5.30674927e+02 1.22656567e+03
 9.83056091e+02 1.19936633e+03 1.01036890e+03 1.02513062e+03
 1.44430371e+03 1.37887610e+03 2.70588959e+02 1.28598218e+03
 1.34340552e+03 8.84075623e+02 4.74265472e+02 1.42153955e+03
 2.20502319e+02 1.39233325e+03 1.46562183e+03 1.24995679e+03
 3.23130615e+02 1.15634363e+03 1.42305798e+03 6.49728394e+02
 1.48587744e+03 8.07075989e+02 1.45601270e+03 6.37314575e+02
 1.18838232e+03 1.22342102e+03 1.10022034e+03 1.43230396e+03
 1.43868713e+03 1.16306122e+02 1.47083081e+03 4.66469421e+02
 9.15205811e+02 1.00331342e+03 7.96029907e+02 1.25445898e+03
 1.10457849e+03 1.35488745e+03 3.27551636e+02 1.49608948e+03
 1.48584619e+03 2.46294159e+02 1.40002698e+03 7.32501160e+02
 9.59629639e+02 1.43428052e+03 1.49957471e+03 7.66349548e+02
 8.57272339e+02 1.48425439e+03 1.49666345e+03 6.17458618e+02
 2.08975616e+02 1.28670605e+03 1.40745947e+03 9.40543274e+02
 1.37700073e+03 1.43015735e+03 4.24708313e+02 1.37996423e+03
 1.02250659e+03 1.28106287e+03 1.48169409e+03 1.20427954e+03
 5.61587830e+02 1.40904822e+03 1.35427722e+03 3.31688416e+02
 1.46169177e+03 6.94363281e+02 2.89995331e+02 1.38732666e+03
 1.21985059e+03 2.30877502e+02 1.17687134e+03 1.32260876e+03
 5.97259460e+02 2.43987717e+02 1.15579437e+02 1.01590063e+03
 1.11578320e+03 1.46307996e+03 7.51121216e+02 8.22488098e+01
 1.29840210e+03 1.59658142e+02 1.41261768e+03 6.56229614e+02
 4.20983276e+02 1.47392810e+03 1.37073413e+03 5.86935974e+02
 1.30135400e+03 1.38425879e+03 7.01697754e+02 3.02067749e+02
 3.11380798e+02 1.37886304e+03 1.44056641e+03 1.11812402e+03
 1.39145056e+03 1.15775757e+03 1.35509644e+03 3.96281403e+02
 1.49677075e+03 6.41629822e+02 1.39025012e+03 1.49260510e+03
 1.05272058e+03 1.44967871e+03 3.33611877e+02 1.25980261e+03
 4.70339294e+02 1.34206152e+03 4.12780212e+02 1.40465381e+03
 1.15278894e+03 8.51093506e+02 1.15439880e+03 1.97974487e+02
 1.31296899e+03 4.86168793e+02 1.44456189e+03 2.03543915e+02
 1.45952954e+03 8.94843811e+02 2.60404083e+02 6.23018188e+02
 8.76557312e+02 1.46618176e+03 8.45603516e+02 1.17195825e+03
 1.36362036e+03 1.15887512e+03 1.42259241e+03 3.34160706e+02
 5.53497314e-01 6.70010986e+02 7.04533997e+02 1.12667773e+03
 1.44885974e+03 3.04161072e+02 1.44397461e+03 1.46940881e+03
 1.30179468e+03 8.10154602e+02 3.36970245e+02 1.15090381e+03
 1.15214630e+02 6.62845642e+02 1.49098218e+03 1.36852295e+03
 7.07594177e+02 1.45952710e+03 3.56112427e+02 1.17562451e+03
 9.49276306e+02 1.42051343e+03 1.18286572e+03 6.55675171e+02
 3.37376801e+02 9.66899170e+02 7.32794556e+02 1.98380356e+02
 6.93416382e+02 1.43977771e+03 1.47620166e+03 8.72588013e+02
 8.09366028e+02 1.23460229e+03 6.03107666e+02 1.38763000e+03
 1.38387085e+03 7.27257690e+01 9.82306335e+02 1.40988123e+03
 1.41352026e+03 1.89342529e+02 3.37623779e+02 8.05369751e+02
 2.19226685e+02 1.45075684e+03 1.18582178e+03 8.49541138e+02
 1.45911023e+03 1.42153894e+03 9.53254944e+02 1.45661890e+03
 8.44539124e+02 1.31034961e+03 6.58417358e+01 1.37594458e+03
 1.30734424e+03 1.28165833e+03 8.48027649e+02 1.21139502e+03
 1.32908105e+03 1.05854626e+03 1.49081799e+03 3.61149139e+02
 1.29683594e+03 6.02100220e+02 8.56225769e+02 8.28726318e+02
 1.48859619e+03 5.53264893e+02 1.38609473e+03 3.87794617e+02
 1.46710083e+03 4.47928436e+02 1.86148560e+02 1.47574023e+03
 1.39813477e+03 1.18122998e+03 1.32871936e+03 9.56650879e+02
 1.26478101e+03 4.89485931e+02 1.15580774e+03 8.68334961e+01
 1.37219824e+03 6.71052063e+02 2.07216797e+02 1.48539551e+03]","[ 721.12354   1236.1482     500.10815    597.57587    762.8524
  806.8525    1000.37024    233.07832    752.9919    1426.3043
 1291.2522     117.16336    328.28275   1214.1152     495.77792
 1171.6466    1391.6086    1175.408      151.25116   1427.7639
  974.164     1375.4874     635.14526   1316.8069    1287.5984
  493.94565   1146.2157     347.85217    204.27014   1438.6849
  970.45416   1460.3086     608.1293    1434.9004    1261.7007
   52.274597   487.0223    1443.9036    1040.4949    1301.7625
  211.16563   1229.1416    1489.3912    1199.7291    1417.1682
  716.49225    546.27954   1013.6339    1371.953      881.0308
  513.6013    1395.5441    1447.5598     458.37958   1492.5746
  729.9861     209.33148   1202.9133    1229.6884      60.347137
  436.1557     842.3561     383.101     1425.6951    1471.7152
 1049.0952     423.20242   1324.974      273.83893   1458.2576
  193.42404   1235.8799    1153.9014    1386.9717    1118.3553
  790.80884   1382.7341    1474.7869    1192.7084     186.99303
 1322.502     1034.2627     502.9044    1112.1398     621.7512
 1128.6582     126.30383   1018.11707   1242.2162     271.02655
 1078.3823    1466.2366     106.83423   1273.9265     538.1674
 1361.7988     253.89745    926.9923    1100.4863    1054.8414
  183.42264   1351.379     1439.1321    1467.7769    1249.9395
  101.68872    705.39154   1027.0613    1443.3137    1037.6404
 1092.2345    1471.6924    1139.241     1358.8237     954.0385
 1256.9845    1380.624      829.63544    583.6188     481.10385
 1386.1465     605.7972    1194.8256     930.0425    1348.6909
  833.3189    1340.4572    1200.3867    1366.8921     338.80008
  916.7639    1488.1896    1081.6077    1447.1484    1307.9237
 1461.9677     521.0478    1188.001     1381.3219    1127.8774
 1385.5842     613.7554     981.05145   1263.9039    1415.4808
 1168.1459    1004.20917   1183.6041    1222.6985     158.32742
 1343.1154    1391.799      824.04834   1430.8035     337.3264
 1036.2719    1420.2712     196.49072   1503.6553     994.08704
 1302.0955     988.55194   1385.9885    1478.2593    1038.4794
  530.11487    248.04276   1231.9551    1456.8232     929.29266
  953.294     1182.1147     604.8533    1382.4788     521.4889
 1180.5586     982.726     1189.4305     988.35266   1004.04785
 1442.9702    1376.4006     277.5945    1280.9854    1343.5737
  887.6751     475.6961    1411.7549     245.34662   1326.6797
 1462.8708    1241.9451     331.44873   1152.9282    1418.1931
  656.5935    1468.0509     816.1629    1471.3313     646.5197
 1237.9261    1278.2823    1090.9875    1431.864     1405.8226
  138.54657   1471.8604     473.7711     909.2156     993.16565
  801.00946   1253.4185    1108.1063    1361.023      331.1377
 1444.7837    1475.2977     271.04538   1429.8926     744.70264
  977.3553    1410.4651    1442.6261     793.1078     864.67316
 1497.4062    1482.1611     633.0607     214.169     1273.8749
 1392.3313     936.71924   1369.0024    1422.2866     411.70676
 1413.0684    1012.6231    1277.865     1464.2834    1200.7334
  555.8175    1373.5244    1371.9219     336.06018   1447.2051
  695.87866    290.6541    1351.8145    1219.4186     238.69989
 1173.8661    1312.5365     596.9777     243.37257    134.83276
  976.5309    1110.9895    1467.3505     747.25604     86.81804
 1288.0951     175.24292   1410.5713     663.6377     439.7599
 1462.2181    1384.3336     588.7672    1310.3488    1395.544
  692.9221     305.13904    319.51562   1360.6965    1429.7834
 1115.0815    1383.6079    1149.0889    1283.5858     372.75818
 1508.2323     656.6195    1420.6002    1540.3667    1039.4515
 1425.311      333.6799    1243.499      493.0729    1322.3313
  417.90387   1399.2991    1148.7358     851.1276    1133.5267
  204.59523   1292.0149     497.1104    1440.2457     216.639
 1473.2516     887.4674     261.59357    640.2999     878.5341
 1454.9341     838.9479    1166.2421    1383.628     1171.2821
 1413.1992     353.40732      5.3178406  660.21313    704.1436
 1114.2479    1451.8928     306.86887   1536.0679    1533.1797
 1316.5393     815.6        339.62317   1117.5348     114.26395
  665.613     1496.4154    1368.7498     676.97815   1420.9827
  370.47714   1168.0894     950.2245    1418.3708    1172.3291
  658.5581     359.7903     918.2699     772.0961     222.14116
  687.73584   1428.0234    1468.0574     880.3782     812.1775
 1229.592      594.2167    1380.8134    1369.1902     102.28369
  997.1397    1445.1334    1384.1409     213.76788    334.5542
  802.6511     222.6817    1435.0122    1179.3322     846.91364
 1445.4855    1415.524      943.3033    1444.6753     852.8744
 1312.6729      79.14813   1377.0359    1421.9753    1374.506
  857.27295   1211.147     1301.4274    1048.3665    1483.2313
  368.12433   1336.7219     610.1105     849.8454     820.6711
 1466.356      607.6921    1356.1699     394.90823   1469.5576
  469.2271     189.35883   1480.9803    1387.5927    1171.991
 1373.7332     976.8443    1257.0433     498.2525    1117.5486
  112.56363   1347.9567     691.3839     209.78906   1470.2861   ]",13.933698,480.73813,21.925741234040625
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 1.478716398394385, Val Loss: 1.260521074533463', 'Epoch: 1, Train Loss: 1.206449774808662, Val Loss: 1.207226269245148', 'Epoch: 2, Train Loss: 1.134338377520095, Val Loss: 1.107045612335205', 'Epoch: 3, Train Loss: 0.988348041856012, Val Loss: 0.912161983847618', 'Epoch: 4, Train Loss: 0.674942829581194, Val Loss: 0.482480334043503', 'Epoch: 5, Train Loss: 0.427352459278218, Val Loss: 0.363840647935867', 'Epoch: 6, Train Loss: 0.349965195669684, Val Loss: 0.333756164908409', 'Epoch: 7, Train Loss: 0.332273555356403, Val Loss: 0.329348714351654', 'Epoch: 8, Train Loss: 0.291808112416157, Val Loss: 0.305343304276466', 'Epoch: 9, Train Loss: 0.282285823031913, Val Loss: 0.263907291889191', 'Epoch: 10, Train Loss: 0.279630945518959, Val Loss: 0.258692420721054', 'Epoch: 11, Train Loss: 0.274081125855446, Val Loss: 0.260405730009079', 'Epoch: 12, Train Loss: 0.298267564281475, Val Loss: 0.246196483969688', 'Epoch: 13, Train Loss: 0.258772896819336, Val Loss: 0.294899134635925', 'Epoch: 14, Train Loss: 0.245372936129570, Val Loss: 0.224198152422905', 'Epoch: 15, Train Loss: 0.253178232111210, Val Loss: 0.218120159506798', 'Epoch: 16, Train Loss: 0.239422717413237, Val Loss: 0.214708710312843', 'Epoch: 17, Train Loss: 0.239489279167597, Val Loss: 0.233444280624390', 'Epoch: 18, Train Loss: 0.242729841623195, Val Loss: 0.298074011206627', 'Epoch: 19, Train Loss: 0.248394637953403, Val Loss: 0.206863398253918', 'Epoch: 20, Train Loss: 0.238012389041657, Val Loss: 0.257894321680069', 'Epoch: 21, Train Loss: 0.211123586220797, Val Loss: 0.205618972778320', 'Epoch: 22, Train Loss: 0.219564304795376, Val Loss: 0.216021900177002', 'Epoch: 23, Train Loss: 0.242493493439153, Val Loss: 0.229715613126755', 'Epoch: 24, Train Loss: 0.199982087366110, Val Loss: 0.197815953195095', 'Epoch: 25, Train Loss: 0.216801909686521, Val Loss: 0.181734179854393', 'Epoch: 26, Train Loss: 0.246865871513999, Val Loss: 0.361420978903770', 'Epoch: 27, Train Loss: 0.207868631322717, Val Loss: 0.205214455723763', 'Epoch: 28, Train Loss: 0.201341153837221, Val Loss: 0.212220976948738', 'Epoch: 29, Train Loss: 0.193670055374157, Val Loss: 0.189914134144783', 'Epoch: 30, Train Loss: 0.189707422065873, Val Loss: 0.184789941012859', 'Epoch: 31, Train Loss: 0.207916012683580, Val Loss: 0.175450952053070', 'Epoch: 32, Train Loss: 0.209123447364153, Val Loss: 0.292785100936890', 'Epoch: 33, Train Loss: 0.234856932315716, Val Loss: 0.200356079339981', 'Epoch: 34, Train Loss: 0.181260599992996, Val Loss: 0.218735252618790', 'Epoch: 35, Train Loss: 0.175243348403032, Val Loss: 0.185854709446430', 'Epoch: 36, Train Loss: 0.170432557546815, Val Loss: 0.190047669112682', 'Epoch: 37, Train Loss: 0.200122662928215, Val Loss: 0.205889199972153', 'Epoch: 38, Train Loss: 0.168577777265116, Val Loss: 0.181976184248924', 'Epoch: 39, Train Loss: 0.218070737497751, Val Loss: 0.200022368431091', 'Epoch: 40, Train Loss: 0.198288215974043, Val Loss: 0.213636356592178', 'Epoch: 41, Train Loss: 0.167866631735896, Val Loss: 0.168120176792145', 'Epoch: 42, Train Loss: 0.155075431129960, Val Loss: 0.159585489630699', 'Epoch: 43, Train Loss: 0.151540546569713, Val Loss: 0.171198704838753', 'Epoch: 44, Train Loss: 0.158068768506826, Val Loss: 0.160977962315083', 'Epoch: 45, Train Loss: 0.127398651179879, Val Loss: 0.170602864623070', 'Epoch: 46, Train Loss: 0.149653418899276, Val Loss: 0.196719383001328', 'Epoch: 47, Train Loss: 0.154769002265015, Val Loss: 0.186938770413399', 'Epoch: 48, Train Loss: 0.138122714969308, Val Loss: 0.221720337569714', 'Epoch: 49, Train Loss: 0.147706678093866, Val Loss: 0.206752131581306', 'Epoch: 50, Train Loss: 0.121430186684742, Val Loss: 0.154952380061150', 'Epoch: 51, Train Loss: 0.131669946881228, Val Loss: 0.221593382656574', 'Epoch: 52, Train Loss: 0.126276836838833, Val Loss: 0.224371670484543', 'Epoch: 53, Train Loss: 0.119840238763149, Val Loss: 0.179661103785038', 'Epoch: 54, Train Loss: 0.119510449035916, Val Loss: 0.176706832051277', 'Epoch: 55, Train Loss: 0.108266635602990, Val Loss: 0.209884167313576', 'Epoch: 56, Train Loss: 0.116702098009545, Val Loss: 0.212046474516392', 'Epoch: 57, Train Loss: 0.118080865245226, Val Loss: 0.153087198138237', 'Epoch: 58, Train Loss: 0.097578974830550, Val Loss: 0.156044060885906', 'Epoch: 59, Train Loss: 0.107489474291025, Val Loss: 0.181702978014946', 'Epoch: 60, Train Loss: 0.112118617046711, Val Loss: 0.224722856581211', 'Epoch: 61, Train Loss: 0.106460366701317, Val Loss: 0.181219651103020', 'Epoch: 62, Train Loss: 0.107717274406622, Val Loss: 0.165374190211296', 'Epoch: 63, Train Loss: 0.097924288795438, Val Loss: 0.177883553802967', 'Epoch: 64, Train Loss: 0.097964389726173, Val Loss: 0.187418729066849', 'Epoch: 65, Train Loss: 0.093802532657634, Val Loss: 0.170693247765303', 'Epoch: 66, Train Loss: 0.083546251794973, Val Loss: 0.163310402631760', 'Epoch: 67, Train Loss: 0.076760308990298, Val Loss: 0.177374413311481', 'Epoch: 68, Train Loss: 0.099635220544283, Val Loss: 0.286607328653336', 'Epoch: 69, Train Loss: 0.095081913306616, Val Loss: 0.140919225513935', 'Epoch: 70, Train Loss: 0.095397940815188, Val Loss: 0.219137068092823', 'Epoch: 71, Train Loss: 0.096801843104321, Val Loss: 0.145210865586996', 'Epoch: 72, Train Loss: 0.090962521991757, Val Loss: 0.180784032046795', 'Epoch: 73, Train Loss: 0.070892202039791, Val Loss: 0.149247710108757', 'Epoch: 74, Train Loss: 0.082195000723004, Val Loss: 0.172041438221931', 'Epoch: 75, Train Loss: 0.085033033216415, Val Loss: 0.146230608522892', 'Epoch: 76, Train Loss: 0.082313882100374, Val Loss: 0.138810251951218', 'Epoch: 77, Train Loss: 0.075090574923643, Val Loss: 0.178407080471516', 'Epoch: 78, Train Loss: 0.076367617259885, Val Loss: 0.166508076637983', 'Epoch: 79, Train Loss: 0.072764225390761, Val Loss: 0.185792396068573', 'Epoch: 80, Train Loss: 0.073952616647232, Val Loss: 0.146975532025099', 'Epoch: 81, Train Loss: 0.079808680817138, Val Loss: 0.161569975763559', 'Epoch: 82, Train Loss: 0.072324405705859, Val Loss: 0.135870516747236', 'Epoch: 83, Train Loss: 0.083432631003995, Val Loss: 0.152883265018463', 'Epoch: 84, Train Loss: 0.078865151895687, Val Loss: 0.163260814845562', 'Epoch: 85, Train Loss: 0.072359892691291, Val Loss: 0.165772943943739', 'Epoch: 86, Train Loss: 0.077568819703058, Val Loss: 0.165952693223953', 'Epoch: 87, Train Loss: 0.065813693196275, Val Loss: 0.149642538428307', 'Epoch: 88, Train Loss: 0.067285130190295, Val Loss: 0.160730712562799', 'Epoch: 89, Train Loss: 0.070785939996672, Val Loss: 0.134910396933556', 'Epoch: 90, Train Loss: 0.064270803748175, Val Loss: 0.185248927474022', 'Epoch: 91, Train Loss: 0.058037345969053, Val Loss: 0.144070789515972', 'Epoch: 92, Train Loss: 0.055379703337717, Val Loss: 0.159608384072781', 'Epoch: 93, Train Loss: 0.056468704412150, Val Loss: 0.146727857142687', 'Epoch: 94, Train Loss: 0.062495855744495, Val Loss: 0.172619920969009', 'Epoch: 95, Train Loss: 0.071871873641083, Val Loss: 0.147514331936836', 'Epoch: 96, Train Loss: 0.075757681976917, Val Loss: 0.147107408940792', 'Epoch: 97, Train Loss: 0.072761418427839, Val Loss: 0.155881661176682', 'Epoch: 98, Train Loss: 0.058929357677698, Val Loss: 0.178015761375427', 'Epoch: 99, Train Loss: 0.055911622594955, Val Loss: 0.164543404579163', 'Epoch: 100, Train Loss: 0.049520844203788, Val Loss: 0.157296363711357', 'Epoch: 101, Train Loss: 0.058270050342693, Val Loss: 0.150734292864800', 'Epoch: 102, Train Loss: 0.053671516261475, Val Loss: 0.149567205607891', 'Epoch: 103, Train Loss: 0.053070300540259, Val Loss: 0.149693733453751', 'Epoch: 104, Train Loss: 0.066230475296115, Val Loss: 0.142709717154503', 'Epoch: 105, Train Loss: 0.057539863468603, Val Loss: 0.163389058038592', 'Epoch: 106, Train Loss: 0.053001283473054, Val Loss: 0.157069379240274', 'Epoch: 107, Train Loss: 0.057146848201059, Val Loss: 0.164120459258556', 'Epoch: 108, Train Loss: 0.051949976055428, Val Loss: 0.148603387176991', 'Epoch: 109, Train Loss: 0.049298133397865, Val Loss: 0.159872469305992', 'Epoch: 110, Train Loss: 0.052295996092780, Val Loss: 0.161499699354172', 'Epoch: 111, Train Loss: 0.063414716183446, Val Loss: 0.141388701051474', 'Epoch: 112, Train Loss: 0.053521297785432, Val Loss: 0.141966453269124', 'Epoch: 113, Train Loss: 0.058436939796043, Val Loss: 0.165094355046749', 'Epoch: 114, Train Loss: 0.057796317737463, Val Loss: 0.153783677816391', 'Epoch: 115, Train Loss: 0.047945880266123, Val Loss: 0.169559560716152', 'Epoch: 116, Train Loss: 0.043381619851950, Val Loss: 0.154799466207623', 'Epoch: 117, Train Loss: 0.051384205864959, Val Loss: 0.142592191025615', 'Epoch: 118, Train Loss: 0.052238531150790, Val Loss: 0.137924098521471', 'Epoch: 119, Train Loss: 0.050746525442877, Val Loss: 0.146534733623266', 'Epoch: 120, Train Loss: 0.040735925179581, Val Loss: 0.149337733238935', 'Epoch: 121, Train Loss: 0.040984662769492, Val Loss: 0.146133471876383', 'Epoch: 122, Train Loss: 0.047190622361593, Val Loss: 0.148209907710552', 'Epoch: 123, Train Loss: 0.049222515852645, Val Loss: 0.149380012750626', 'Epoch: 124, Train Loss: 0.048027725976913, Val Loss: 0.149668070077896', 'Epoch: 125, Train Loss: 0.059065242449558, Val Loss: 0.153798850625753', 'Epoch: 126, Train Loss: 0.047985040257836, Val Loss: 0.158094281852245', 'Epoch: 127, Train Loss: 0.045506018495490, Val Loss: 0.146380047798157', 'Epoch: 128, Train Loss: 0.043628781037622, Val Loss: 0.158950553834438', 'Epoch: 129, Train Loss: 0.047652415064878, Val Loss: 0.146539744436741', 'Epoch: 130, Train Loss: 0.045935151318825, Val Loss: 0.132865718975663', 'Epoch: 131, Train Loss: 0.045339769748754, Val Loss: 0.151756171882153', 'Epoch: 132, Train Loss: 0.039862352661615, Val Loss: 0.148965332359076', 'Epoch: 133, Train Loss: 0.044629725649260, Val Loss: 0.151739592403173', 'Epoch: 134, Train Loss: 0.041814324770902, Val Loss: 0.142719782739878', 'Epoch: 135, Train Loss: 0.044490814642158, Val Loss: 0.136157130599022', 'Epoch: 136, Train Loss: 0.047077786134079, Val Loss: 0.160064186751843', 'Epoch: 137, Train Loss: 0.041897602184394, Val Loss: 0.156521835774183', 'Epoch: 138, Train Loss: 0.041237902416046, Val Loss: 0.139538828209043', 'Epoch: 139, Train Loss: 0.039422524573151, Val Loss: 0.149413063377142', 'Epoch: 140, Train Loss: 0.037665511416488, Val Loss: 0.163471456617117', 'Epoch: 141, Train Loss: 0.048118557304490, Val Loss: 0.152537697553635', 'Epoch: 142, Train Loss: 0.046386429390242, Val Loss: 0.144869221150875', 'Epoch: 143, Train Loss: 0.046216430099205, Val Loss: 0.149648439437151', 'Epoch: 144, Train Loss: 0.037835065318748, Val Loss: 0.150836791992187', 'Epoch: 145, Train Loss: 0.043438114269182, Val Loss: 0.147839022278786', 'Epoch: 146, Train Loss: 0.038861720194650, Val Loss: 0.155550072640181', 'Epoch: 147, Train Loss: 0.050912179702590, Val Loss: 0.164898708760738', 'Epoch: 148, Train Loss: 0.039414292807842, Val Loss: 0.147897066771984', 'Epoch: 149, Train Loss: 0.038809636066300, Val Loss: 0.145813623666763', 'Epoch: 150, Train Loss: 0.042259074877514, Val Loss: 0.142975614070892', 'Epoch: 151, Train Loss: 0.038246798372373, Val Loss: 0.149885710030794', 'Epoch: 152, Train Loss: 0.035556699257604, Val Loss: 0.146385736912489', 'Epoch: 153, Train Loss: 0.037055952821014, Val Loss: 0.149146772176027', 'Epoch: 154, Train Loss: 0.040214560796009, Val Loss: 0.127108348608017', 'Epoch: 155, Train Loss: 0.038324770236085, Val Loss: 0.145236042588949', 'Epoch: 156, Train Loss: 0.038535153255040, Val Loss: 0.130287239700556', 'Epoch: 157, Train Loss: 0.041876305847667, Val Loss: 0.135177767276764', 'Epoch: 158, Train Loss: 0.040150676788979, Val Loss: 0.139063092768192', 'Epoch: 159, Train Loss: 0.041055400704229, Val Loss: 0.138802852481604', 'Epoch: 160, Train Loss: 0.040908074526246, Val Loss: 0.140902120769024', 'Epoch: 161, Train Loss: 0.036329866040411, Val Loss: 0.143347205519676', 'Epoch: 162, Train Loss: 0.041249819728004, Val Loss: 0.136933909058571', 'Epoch: 163, Train Loss: 0.040084822493237, Val Loss: 0.147789775282145', 'Epoch: 164, Train Loss: 0.033200325314389, Val Loss: 0.133642047047615', 'Epoch: 165, Train Loss: 0.036150419304884, Val Loss: 0.137179541140795', 'Epoch: 166, Train Loss: 0.035765756159848, Val Loss: 0.148867564052343', 'Epoch: 167, Train Loss: 0.033422921979150, Val Loss: 0.142173941433430', 'Epoch: 168, Train Loss: 0.039673892911090, Val Loss: 0.141622360944748', 'Epoch: 169, Train Loss: 0.035958599602414, Val Loss: 0.132700021862984', 'Epoch: 170, Train Loss: 0.037570261548078, Val Loss: 0.144120626449585', 'Epoch: 171, Train Loss: 0.034104487403881, Val Loss: 0.139120610356331', 'Epoch: 172, Train Loss: 0.037107983560756, Val Loss: 0.140873547121882', 'Epoch: 173, Train Loss: 0.031579123766616, Val Loss: 0.143123582601547', 'Epoch: 174, Train Loss: 0.035835400916809, Val Loss: 0.147133492380381', 'Epoch: 175, Train Loss: 0.032520063113161, Val Loss: 0.131501540243626', 'Epoch: 176, Train Loss: 0.033276885141467, Val Loss: 0.131862644851208', 'Epoch: 177, Train Loss: 0.035185011190384, Val Loss: 0.138661495521665', 'Epoch: 178, Train Loss: 0.033357244894602, Val Loss: 0.134630526602268', 'Epoch: 179, Train Loss: 0.032917706079261, Val Loss: 0.133505971580744', 'Epoch: 180, Train Loss: 0.032692647127565, Val Loss: 0.139157435745001', 'Epoch: 181, Train Loss: 0.032252784168651, Val Loss: 0.134948026537895', 'Epoch: 182, Train Loss: 0.030682605712913, Val Loss: 0.129800192564726', 'Epoch: 183, Train Loss: 0.035241196885012, Val Loss: 0.137185789048672', 'Epoch: 184, Train Loss: 0.032263400011458, Val Loss: 0.140933875814080', 'Epoch: 185, Train Loss: 0.034777062338625, Val Loss: 0.138909549713135', 'Epoch: 186, Train Loss: 0.032652815479005, Val Loss: 0.140126520544291', 'Epoch: 187, Train Loss: 0.031632665198210, Val Loss: 0.135995015427470', 'Epoch: 188, Train Loss: 0.028574569172464, Val Loss: 0.136883399635553', 'Epoch: 189, Train Loss: 0.031551406567180, Val Loss: 0.146301458925009', 'Epoch: 190, Train Loss: 0.029847571084839, Val Loss: 0.141665586084127', 'Epoch: 191, Train Loss: 0.029707207539400, Val Loss: 0.140590004622936', 'Epoch: 192, Train Loss: 0.031518637181021, Val Loss: 0.135887373089790', 'Epoch: 193, Train Loss: 0.030012381133125, Val Loss: 0.139306454211473', 'Epoch: 194, Train Loss: 0.032074922414193, Val Loss: 0.137727197259665', 'Epoch: 195, Train Loss: 0.028896758592753, Val Loss: 0.136257588192821', 'Epoch: 196, Train Loss: 0.030591375151173, Val Loss: 0.132180484980345', 'Epoch: 197, Train Loss: 0.029642710895386, Val Loss: 0.136467280536890', 'Epoch: 198, Train Loss: 0.029228126933408, Val Loss: 0.135976509302855', 'Epoch: 199, Train Loss: 0.029126487932233, Val Loss: 0.135776882395148']","[9.41358582e+02 2.42713379e+02 1.05681152e+03 1.48267603e+03
 1.11792334e+03 2.40647003e+02 8.18995728e+02 9.76199341e+02
 4.78215485e+02 6.65769287e+02 1.33582300e+03 1.11369482e+03
 8.74447449e+02 1.16142212e+02 8.78822021e+02 8.36791992e-01
 7.28514404e+02 1.02208252e+01 3.92252747e+02 1.46960498e+03
 9.46132812e+02 3.82603455e+01 1.42452637e+03 9.09312744e+02
 7.41526367e+02 1.14947644e+03 1.46200659e+03 1.05284937e+03
 1.30863452e+03 1.51989227e+02 1.63790588e+01 1.39699756e+03
 1.42805457e+03 5.53143799e+02 1.39941968e+03 4.93424255e+02
 1.47063818e+03 1.26380457e+03 1.33056641e+01 5.72426697e+02
 1.37017590e+03 1.19865698e+03 1.06183325e+03 8.67464111e+02
 5.49542603e+02 6.92651611e+02 1.45320227e+03 4.62404938e+02
 4.29472870e+02 1.33061572e+03 1.45693311e+03 9.57450928e+02
 1.25469141e+03 7.01110901e+02 1.00479590e+03 7.32365417e+02
 1.33690381e+03 2.83176758e+02 6.52345337e+02 1.19795630e+03
 1.41037256e+03 6.58859619e+02 2.88965881e+02 9.58338745e+02
 4.15541382e+01 1.19272241e+03 1.29592285e+01 1.00471014e+03
 1.41623682e+03 6.40779236e+02 1.24490186e+03 1.43414014e+03
 7.19932861e+01 9.16660400e+02 4.27544830e+02 8.15985107e+01
 9.83722656e+02 3.82583313e+01 4.60762390e+02 8.47512573e+02
 6.41457092e+02 1.42870679e+03 1.36379883e+03 1.03308057e+03
 7.69725159e+02 1.37121265e+03 8.87405273e+02 1.08826965e+03
 4.32154266e+02 1.42225464e+03 1.29587170e+03 6.45672058e+02
 1.40920642e+03 1.52134491e+02 8.46327576e+02 4.61429443e+01
 1.40971265e+03 7.99845703e+02 1.38788184e+03 3.75297241e+02
 1.47068591e+03 9.45028381e+01 1.46825073e+03 3.01187134e+01
 3.51709167e+02 1.07292676e+03 4.22520996e+02 1.45316382e+03
 4.47346191e+01 1.41888245e+03 1.42169629e+03 3.94454926e+02
 1.28439111e+03 1.35225183e+03 2.44064270e+02 9.36475525e+02
 3.31812622e+02 1.45088086e+03 1.06730151e+03 6.18150024e+02
 1.02753589e+03 2.41002106e+02 2.77104187e+02 1.01293726e+03
 1.06314734e+03 8.75441956e+02 1.38377783e+03 3.08039490e+02
 3.21944977e+02 4.41735840e+00 4.56731171e+02 1.44648560e+03
 1.18278369e+03 7.32852783e+02 3.00415649e+01 3.02994934e+02
 1.44935767e+03 1.31521167e+03 1.37151160e+03 4.42860382e+02
 1.38202539e+03 3.11075134e+02 3.82312012e+01 1.17119812e+03
 8.73814087e+02 6.39539185e+02 1.26639490e+03 6.54708801e+02
 1.22340967e+03 2.55674835e+02 1.31663037e+03 9.17671265e+02
 9.59125183e+02 1.38721997e+03 4.35853180e+02 1.34216504e+03
 4.47473145e+00 6.84588135e+02 3.89282227e+01 1.02985498e+03
 9.16346497e+02 1.36328125e+03 1.37570459e+03 9.26743408e+02
 1.65623566e+02 6.67921387e+02 5.07650208e+02 6.23887695e+02
 6.71023987e+02 1.13387036e+03 1.21255225e+03 3.25603638e+01
 1.41544116e+03 1.03923657e+03 1.34036987e+03 1.44350464e+03
 6.65717102e+02 1.44908691e+03 4.02037811e+02 1.36147473e+03
 2.69321472e+02 7.40081787e+00 5.02633759e+02 1.42933313e+03
 7.95875977e+02 1.49424963e+03 1.34802856e+03 3.61407196e+02
 4.48612671e+02 1.41242407e+03 1.34168408e+03 9.60455933e+01
 1.31872437e+03 1.25461841e+03 1.14148022e+03 6.70476257e+02
 8.41219727e+02 1.37001562e+03 2.44401184e+02 1.39127649e+03
 7.85508606e+02 1.42877966e+03 5.34123779e+02 6.32148193e+02
 1.21454150e+03 5.20420044e+02 3.17536652e+02 1.00807349e+03
 8.59117004e+02 5.42727417e+02 1.10136084e+03 6.87659302e+02
 1.35997314e+03 2.59964386e+02 1.30119775e+03 9.93767456e+02
 1.37822607e+03 5.17537170e+02 1.78273926e+02 1.23779919e+03
 9.02438477e+02 1.34451221e+03 1.46297815e+03 8.96647339e+01
 1.49854077e+03 5.63067383e+02 3.63694366e+02 1.39671094e+03
 1.23732471e+03 7.27059814e+02 1.39951599e+02 1.24574402e+03
 6.15473877e+02 8.40324341e+02 1.49368555e+03 9.57999268e+01
 2.16475632e+02 1.14535229e+03 1.21201636e+03 6.91834839e+02
 1.42144580e+03 1.48403931e+03 1.49539478e+03 1.03318750e+03
 1.40574048e+03 1.20496826e+02 2.92405121e+02 1.16225732e+03
 2.94771790e+02 1.33034558e+03 2.40954590e+01 1.38347449e+03
 4.57467957e+01 1.47866516e+03 3.73817291e+02 1.13291699e+03
 1.23382043e+03 7.95679382e+02 1.44914417e+03 6.33013184e+02
 9.73706787e+02 4.69559113e+02 1.48059412e+03 1.38307788e+03
 1.38191370e+03 4.75519562e+02 5.19604126e+02 1.38374756e+03
 1.33076575e+03 5.68065796e+02 1.48456982e+03 5.17312256e+02
 1.30232056e+03 2.07639893e+02 1.10161719e+03 1.32298547e+03
 1.46573132e+03 9.66754761e+02 6.34578979e+02 1.05712354e+03
 5.64994019e+02 1.36934326e+03 1.40595093e+03 3.92731079e+02
 4.63371216e+02 1.33241711e+03 7.94918335e+02 1.37686694e+03
 1.35741211e+03 9.68923584e+02 1.40142566e+03 5.84223694e+02
 1.22677734e+03 1.49400195e+03 1.47430103e+03 1.31734106e+03
 4.28788483e+02 2.81339111e+01 1.20568579e+03 8.14593994e+02
 8.00879211e+01 2.41539917e+01 1.18152075e+03 9.93648560e+02
 4.92537231e+01 1.40844385e+03 1.29613452e+03 1.08109387e+03
 1.14233203e+03 1.24557227e+03 1.41627515e+03 6.22927429e+02
 9.15213318e+02 5.46212769e+01 1.09326123e+03 8.33589478e+02
 1.17338013e+03 7.34665833e+02 1.23333130e+03 1.44896191e+03
 1.23923962e+03 6.09011536e+02 2.64257812e+00 1.16990259e+03
 1.78528015e+02 7.08182678e+01 1.35293860e+03 7.93812256e+02
 4.32712280e+02 1.07946411e+03 1.33519727e+03 7.87770447e+02
 1.38047241e+03 1.36589221e+03 1.24503125e+03 1.29601282e+03
 2.10717224e+02 1.37384863e+03 1.66662659e+02 1.34997131e+03
 1.40674512e+03 8.91156677e+02 6.35170898e+01 9.18762817e+02
 1.36470288e+03 9.92939087e+02 1.24558972e+03 2.32914368e+02
 1.39368970e+03 9.09036865e+02 1.08320337e+03 1.46037549e+03
 4.77070312e+01 7.18389038e+02 9.69838196e+02 1.29359607e+03
 9.09397888e+02 3.27990326e+02 4.31146118e+02 9.54814026e+02
 1.17976532e+02 7.47812012e+02 1.19263501e+03 8.82744141e+02
 1.47309521e+03 5.60237427e+01 1.30590125e+03 7.90482056e+02
 1.26175757e+03 1.44085645e+03 9.73151855e+02 2.63022919e+02
 8.51149475e+02 1.49354565e+03 1.41226318e+03 3.68916443e+02
 8.61228149e+02 5.12092590e+01 4.88495483e+02 3.20060425e+01
 1.28036926e+03 1.45880298e+03 1.17953296e+03 2.18607788e+02
 4.85650635e+00 7.91033936e+00 5.00639740e+02 1.26895459e+03
 7.85158813e+02 8.04753906e+02 1.41659607e+03 4.37518860e+02
 1.37700708e+03 1.21498999e+03 1.20193433e+03 2.58027740e+02
 7.78236877e+02 4.92651398e+02 7.28945618e+02 1.44093213e+03]","[1224.2698     241.45532    941.3268    1493.9387    1085.3049
  203.28802    783.4321     932.4817     459.31146    800.3124
 1231.7491    1127.9861     846.6237      87.547516  1029.8047
  139.59412    754.7182      34.742188   388.37982   1358.5713
  747.3772     140.3681    1653.5264    1359.4109     820.2013
 1037.0914    1541.9719    1113.6995     935.0212     208.56866
  145.42905   1118.6079    1374.4788     585.77734   1306.5115
  540.34875   1296.8473    1223.5358     -56.826294   570.8571
 1300.4358    1131.5781    1180.9303     857.79193    513.829
  617.5238    1553.9242     415.0825     415.7608    1539.6741
 1432.897      900.9029    1267.6758     675.00977    997.5078
  738.71606   1394.6836     217.77826    527.2825    1050.422
 1328.9639     664.2412     306.57593   1006.97046    172.31555
 1129.5051      35.03894   1361.4224    1368.3328     743.58826
 1220.6201    1423.6611      13.073608   912.9187     618.16003
   60.152832   755.82153     90.552155   482.78467    863.03613
  663.70526   1384.0042    1358.825     1066.9777     768.8609
 1377.0442     868.4481     961.3014     357.28918   1407.0452
 1153.2609     696.34595   1027.0181     214.21083    822.5044
   85.86713   1495.7637     799.8733    1025.3176     432.96936
 1118.4353     230.34816   1478.866       40.005432   285.5405
 1280.605      416.83017   1500.5247     109.53668   1358.4014
 1502.9148     387.62445    770.5621     926.7766     288.0783
  881.28705    284.0631    1514.1951    1000.7689     714.3582
  938.8127     268.58688    230.23581   1097.0312    1085.9807
  881.87354   1334.0256     330.7481     409.78925    -30.112915
  526.4515    1411.3076     959.1425     581.7189     -37.545715
   46.001648  1293.7756    1263.2207    1363.8751     388.45905
 1384.615      308.52026     46.509644  1121.8147    1045.2716
  660.6698    1181.239      652.2775     970.94934    226.60039
 1248.1727     880.89215    986.10486   1482.168      536.0379
 1316.1599      38.276794   619.93054    -50.47162   1057.0396
  992.3116    1397.6284    1149.085      749.1456     212.55244
  639.36084    535.71423    691.4563     648.4448    1064.6042
 1247.5195      26.729065  1363.0977     961.99316   1467.0658
 1525.8453     747.43604   1539.8773     458.3508    1342.8138
    2.3770142 -174.27362    594.29645   1372.6866     832.00336
 1582.3859    1293.3425     251.86493    421.0646    1405.9791
 1175.0815     107.22681   1294.4067    1201.6125     739.25446
  574.35803    847.27625   1440.0128     167.25647   1364.3162
  843.40857   1715.0382     965.37524   1026.4685    1270.2926
  633.25507    196.37418    956.59924    812.48004    525.355
 1072.8403     750.33685   1563.9727      84.00537   1330.7024
 1128.1582    1385.635      453.0093     256.06036   1075.5653
  909.08057   1291.4365    1305.749      147.98065   1427.1827
  586.06287    288.3193    1060.6201    1266.3782     693.27905
  258.0896    1137.2863     606.5169     814.20886   1415.2996
   -2.1365356  228.6325    1257.658     1213.7572     678.4596
 1555.9963    1642.4734    1253.1111    1016.1145    1415.0564
   16.507751   211.78703   1082.9019     144.682     1370.5186
  169.39252   1268.2274      91.015076  1228.3975     461.5144
 1095.478     1218.1171     798.1212    1479.9777     652.46936
  976.4075     546.047     1427.1212    1319.0942    1508.5935
  446.5994     536.40814   1472.0928    1437.325      665.4479
 1480.0281     520.1855    1399.3682     127.82837   1091.0474
 1342.962     1380.984      977.98865    650.5587    1089.6128
  624.1068    1338.1726    1501.0115     278.9585     459.05695
 1440.1174     756.04443   1163.721     1236.74       976.9341
 1374.3966     555.70087   1207.4836    1448.7227    1404.1697
 1383.8846     484.66714    138.93219   1212.7288     920.6239
  108.782074   348.29318   1210.7192    1012.9077     158.34052
 1293.8091    1500.9395     900.7589    1092.9299    1109.9751
 1483.3997     558.6725     999.7835      76.14633   1018.11975
  850.43115   1253.5148     848.68536   1266.7985    1413.2916
 1157.1385     597.23114     61.218628  1108.6877     108.936066
   32.15451   1452.0988     943.5812     371.62466   1949.2703
 1360.978      753.41614   1432.4978    1313.7036    1419.9954
 1177.3455      89.22162   1493.9203     250.24348   1352.5353
 1514.3875     919.94867    163.21457    913.6185    1377.1094
  986.17255   1198.0973      93.83472   1402.5247     989.18036
 1126.1001    1690.499       41.32367    728.5337    1014.56
 1399.0374     943.8008     321.34787    439.00085   1263.3567
  133.8571     728.6019    1206.6438     962.1135    1414.7031
  172.5904    1203.1102     759.10425   1189.6868    1472.9307
  960.0018     294.5072     835.7473    1564.169     1515.237
  282.03198   1062.1116      74.22516    549.5812      76.085205
 1313.3944    1387.2217    1215.9243     238.35782    131.07147
    5.6254272  541.2107    1337.7529    1009.451     1169.1798
 1538.5771     382.58615   1177.4136    1104.8749    1479.5059
   12.095154   813.95966    490.58875    750.8435    1391.2844   ]",83.6559,15782.032,125.62655860351545
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 1.273884839789812, Val Loss: 0.861871844530106', 'Epoch: 1, Train Loss: 0.996578797351482, Val Loss: 0.805014650821686', 'Epoch: 2, Train Loss: 0.898601019798323, Val Loss: 0.662062852382660', 'Epoch: 3, Train Loss: 0.658049322491468, Val Loss: 0.367357876449823', 'Epoch: 4, Train Loss: 0.419517513277919, Val Loss: 0.255395874083042', 'Epoch: 5, Train Loss: 0.315547215037568, Val Loss: 0.213451240062714', 'Epoch: 6, Train Loss: 0.272085089842940, Val Loss: 0.151683292984962', 'Epoch: 7, Train Loss: 0.231267623256805, Val Loss: 0.138652874529362', 'Epoch: 8, Train Loss: 0.222476081446160, Val Loss: 0.151245472431183', 'Epoch: 9, Train Loss: 0.217505897893462, Val Loss: 0.138199962228537', 'Epoch: 10, Train Loss: 0.219791512329911, Val Loss: 0.130622624158859', 'Epoch: 11, Train Loss: 0.205445500307305, Val Loss: 0.126234425306320', 'Epoch: 12, Train Loss: 0.162919130436210, Val Loss: 0.124824444055557', 'Epoch: 13, Train Loss: 0.185385760179786, Val Loss: 0.115586184263229', 'Epoch: 14, Train Loss: 0.162171929468249, Val Loss: 0.137010577917099', 'Epoch: 15, Train Loss: 0.168815585762955, Val Loss: 0.143708779811859', 'Epoch: 16, Train Loss: 0.144489552305881, Val Loss: 0.143131963163614', 'Epoch: 17, Train Loss: 0.173870307068492, Val Loss: 0.129600492715836', 'Epoch: 18, Train Loss: 0.182557153667128, Val Loss: 0.160571399927139', 'Epoch: 19, Train Loss: 0.161497975331406, Val Loss: 0.116587240695953', 'Epoch: 20, Train Loss: 0.138059069943983, Val Loss: 0.090460079014301', 'Epoch: 21, Train Loss: 0.156911032057779, Val Loss: 0.143867522478104', 'Epoch: 22, Train Loss: 0.140511814028371, Val Loss: 0.103220628798008', 'Epoch: 23, Train Loss: 0.131834506122179, Val Loss: 0.094452193975449', 'Epoch: 24, Train Loss: 0.152941310908212, Val Loss: 0.097033166885376', 'Epoch: 25, Train Loss: 0.144435432674580, Val Loss: 0.092508018612862', 'Epoch: 26, Train Loss: 0.129895656001429, Val Loss: 0.087434131354094', 'Epoch: 27, Train Loss: 0.135180822985117, Val Loss: 0.096094995439053', 'Epoch: 28, Train Loss: 0.121262991411048, Val Loss: 0.126224880218506', 'Epoch: 29, Train Loss: 0.186988828400540, Val Loss: 0.111345052123070', 'Epoch: 30, Train Loss: 0.151055849308884, Val Loss: 0.120882881581783', 'Epoch: 31, Train Loss: 0.141418833718743, Val Loss: 0.097704142779112', 'Epoch: 32, Train Loss: 0.122298648191053, Val Loss: 0.067979444712400', 'Epoch: 33, Train Loss: 0.127227947852293, Val Loss: 0.091835882663727', 'Epoch: 34, Train Loss: 0.115160982102849, Val Loss: 0.084881292581558', 'Epoch: 35, Train Loss: 0.109132491658593, Val Loss: 0.066620995998383', 'Epoch: 36, Train Loss: 0.117509494254062, Val Loss: 0.113827807009220', 'Epoch: 37, Train Loss: 0.147862036994030, Val Loss: 0.099869160279632', 'Epoch: 38, Train Loss: 0.124017678547737, Val Loss: 0.148320312500000', 'Epoch: 39, Train Loss: 0.139551085095073, Val Loss: 0.068569858819246', 'Epoch: 40, Train Loss: 0.100317359100594, Val Loss: 0.063493300974369', 'Epoch: 41, Train Loss: 0.102654526876502, Val Loss: 0.117664739862084', 'Epoch: 42, Train Loss: 0.135160125532123, Val Loss: 0.094426389634609', 'Epoch: 43, Train Loss: 0.129687861647717, Val Loss: 0.083731405138969', 'Epoch: 44, Train Loss: 0.106991543586171, Val Loss: 0.054437467828393', 'Epoch: 45, Train Loss: 0.105464300010786, Val Loss: 0.080957306623459', 'Epoch: 46, Train Loss: 0.109155540072987, Val Loss: 0.067726862132549', 'Epoch: 47, Train Loss: 0.105074806398777, Val Loss: 0.096578008309007', 'Epoch: 48, Train Loss: 0.105452636300131, Val Loss: 0.066554162576795', 'Epoch: 49, Train Loss: 0.086609833462294, Val Loss: 0.084632221460342', 'Epoch: 50, Train Loss: 0.099310806151046, Val Loss: 0.076781002134085', 'Epoch: 51, Train Loss: 0.109545391919308, Val Loss: 0.053045327216387', 'Epoch: 52, Train Loss: 0.098341594991642, Val Loss: 0.071307491362095', 'Epoch: 53, Train Loss: 0.094012501367996, Val Loss: 0.059787884205580', 'Epoch: 54, Train Loss: 0.080154019429587, Val Loss: 0.049550900459290', 'Epoch: 55, Train Loss: 0.075395961227112, Val Loss: 0.046424510702491', 'Epoch: 56, Train Loss: 0.078739774348431, Val Loss: 0.100792306959629', 'Epoch: 57, Train Loss: 0.094216003450890, Val Loss: 0.080632111430168', 'Epoch: 58, Train Loss: 0.087889312484930, Val Loss: 0.050204539895058', 'Epoch: 59, Train Loss: 0.077326177900960, Val Loss: 0.064625337123871', 'Epoch: 60, Train Loss: 0.080418824456459, Val Loss: 0.048302125558257', 'Epoch: 61, Train Loss: 0.072217835589897, Val Loss: 0.054116182699800', 'Epoch: 62, Train Loss: 0.080608470928530, Val Loss: 0.061897316277027', 'Epoch: 63, Train Loss: 0.072974064235770, Val Loss: 0.049529217928648', 'Epoch: 64, Train Loss: 0.071522497030538, Val Loss: 0.107436579763889', 'Epoch: 65, Train Loss: 0.079558350405721, Val Loss: 0.047723405808210', 'Epoch: 66, Train Loss: 0.070677127212633, Val Loss: 0.040720035359263', 'Epoch: 67, Train Loss: 0.088285649628487, Val Loss: 0.059214813858271', 'Epoch: 68, Train Loss: 0.074697341510030, Val Loss: 0.061364781334996', 'Epoch: 69, Train Loss: 0.066843850624769, Val Loss: 0.045729591771960', 'Epoch: 70, Train Loss: 0.066386944332788, Val Loss: 0.042522991374135', 'Epoch: 71, Train Loss: 0.087601948919338, Val Loss: 0.056041635796428', 'Epoch: 72, Train Loss: 0.056469535238521, Val Loss: 0.044181706123054', 'Epoch: 73, Train Loss: 0.069454385097637, Val Loss: 0.039358652755618', 'Epoch: 74, Train Loss: 0.073730406459681, Val Loss: 0.045612906664610', 'Epoch: 75, Train Loss: 0.074809848265939, Val Loss: 0.052945335656404', 'Epoch: 76, Train Loss: 0.069370315128634, Val Loss: 0.061118949688971', 'Epoch: 77, Train Loss: 0.058423738536793, Val Loss: 0.047020921558142', 'Epoch: 78, Train Loss: 0.061414341615556, Val Loss: 0.059066352546215', 'Epoch: 79, Train Loss: 0.057361076694242, Val Loss: 0.048687686473131', 'Epoch: 80, Train Loss: 0.055325460381979, Val Loss: 0.043271092437208', 'Epoch: 81, Train Loss: 0.057128146117510, Val Loss: 0.035769423544407', 'Epoch: 82, Train Loss: 0.077743196405124, Val Loss: 0.064543801993132', 'Epoch: 83, Train Loss: 0.076308134466756, Val Loss: 0.040400291308761', 'Epoch: 84, Train Loss: 0.072270765640708, Val Loss: 0.045003874525428', 'Epoch: 85, Train Loss: 0.069042058141772, Val Loss: 0.059010734260082', 'Epoch: 86, Train Loss: 0.049161662759129, Val Loss: 0.041071471348405', 'Epoch: 87, Train Loss: 0.053954580495524, Val Loss: 0.053819175139070', 'Epoch: 88, Train Loss: 0.060501486669446, Val Loss: 0.041543557494879', 'Epoch: 89, Train Loss: 0.057065950143476, Val Loss: 0.046930493712425', 'Epoch: 90, Train Loss: 0.059159896054933, Val Loss: 0.049251161217690', 'Epoch: 91, Train Loss: 0.060378006811059, Val Loss: 0.037652427032590', 'Epoch: 92, Train Loss: 0.051170830463254, Val Loss: 0.037507899701595', 'Epoch: 93, Train Loss: 0.056641104132977, Val Loss: 0.034441231861711', 'Epoch: 94, Train Loss: 0.050235291293194, Val Loss: 0.039347099047154', 'Epoch: 95, Train Loss: 0.056718974612480, Val Loss: 0.070063733980060', 'Epoch: 96, Train Loss: 0.063221060107787, Val Loss: 0.043468184769154', 'Epoch: 97, Train Loss: 0.058689322106020, Val Loss: 0.046504042595625', 'Epoch: 98, Train Loss: 0.045268438063389, Val Loss: 0.042390263527632', 'Epoch: 99, Train Loss: 0.051745289200267, Val Loss: 0.031802431829274', 'Epoch: 100, Train Loss: 0.047787917604627, Val Loss: 0.044530355483294', 'Epoch: 101, Train Loss: 0.044497775477032, Val Loss: 0.039012909345329', 'Epoch: 102, Train Loss: 0.050736897256832, Val Loss: 0.041954290196300', 'Epoch: 103, Train Loss: 0.052246157123252, Val Loss: 0.046884122751653', 'Epoch: 104, Train Loss: 0.042925257300741, Val Loss: 0.039869859889150', 'Epoch: 105, Train Loss: 0.046877357588951, Val Loss: 0.037607097253203', 'Epoch: 106, Train Loss: 0.040756388155873, Val Loss: 0.038114856258035', 'Epoch: 107, Train Loss: 0.044954852374314, Val Loss: 0.036224811896682', 'Epoch: 108, Train Loss: 0.045757008781440, Val Loss: 0.040255792513490', 'Epoch: 109, Train Loss: 0.042749389746161, Val Loss: 0.032676594685763', 'Epoch: 110, Train Loss: 0.052633620711953, Val Loss: 0.037054658457637', 'Epoch: 111, Train Loss: 0.049084013457908, Val Loss: 0.037940005809069', 'Epoch: 112, Train Loss: 0.045138727527025, Val Loss: 0.035362177304924', 'Epoch: 113, Train Loss: 0.046894279481886, Val Loss: 0.048559020310640', 'Epoch: 114, Train Loss: 0.045486321911043, Val Loss: 0.039972799271345', 'Epoch: 115, Train Loss: 0.046638631326861, Val Loss: 0.032336901128292', 'Epoch: 116, Train Loss: 0.040047167215583, Val Loss: 0.031447212807834', 'Epoch: 117, Train Loss: 0.043299203781888, Val Loss: 0.038093582130969', 'Epoch: 118, Train Loss: 0.033429124544180, Val Loss: 0.028699444103986', 'Epoch: 119, Train Loss: 0.042402206725159, Val Loss: 0.033517364785075', 'Epoch: 120, Train Loss: 0.038976231741524, Val Loss: 0.032704453207552', 'Epoch: 121, Train Loss: 0.047994116017985, Val Loss: 0.041649775654078', 'Epoch: 122, Train Loss: 0.044761200976926, Val Loss: 0.035003518257290', 'Epoch: 123, Train Loss: 0.045510515267419, Val Loss: 0.041093882396817', 'Epoch: 124, Train Loss: 0.039605541024790, Val Loss: 0.038956673033535', 'Epoch: 125, Train Loss: 0.037010816662291, Val Loss: 0.032547305673361', 'Epoch: 126, Train Loss: 0.038361215747373, Val Loss: 0.034681045562029', 'Epoch: 127, Train Loss: 0.037749850212835, Val Loss: 0.033812371287495', 'Epoch: 128, Train Loss: 0.038347437198079, Val Loss: 0.028835943210870', 'Epoch: 129, Train Loss: 0.044516595513668, Val Loss: 0.029122028611600', 'Epoch: 130, Train Loss: 0.043954964164038, Val Loss: 0.038565108329058', 'Epoch: 131, Train Loss: 0.037929215511784, Val Loss: 0.033549376428127', 'Epoch: 132, Train Loss: 0.035002914040761, Val Loss: 0.026944044288248', 'Epoch: 133, Train Loss: 0.032334512142941, Val Loss: 0.027879348509014', 'Epoch: 134, Train Loss: 0.039454067710700, Val Loss: 0.037702310606837', 'Epoch: 135, Train Loss: 0.037624735948305, Val Loss: 0.034102245718241', 'Epoch: 136, Train Loss: 0.033918335124157, Val Loss: 0.031694723563269', 'Epoch: 137, Train Loss: 0.040510990115446, Val Loss: 0.026731085181236', 'Epoch: 138, Train Loss: 0.046562613356252, Val Loss: 0.059876461252570', 'Epoch: 139, Train Loss: 0.039077465747331, Val Loss: 0.031189498491585', 'Epoch: 140, Train Loss: 0.034430139719747, Val Loss: 0.027371904067695', 'Epoch: 141, Train Loss: 0.036088006029469, Val Loss: 0.033109537549317', 'Epoch: 142, Train Loss: 0.039000010637696, Val Loss: 0.037714218143374', 'Epoch: 143, Train Loss: 0.043254674693873, Val Loss: 0.029676159135997', 'Epoch: 144, Train Loss: 0.035097050892059, Val Loss: 0.027530575655401', 'Epoch: 145, Train Loss: 0.040694155275475, Val Loss: 0.030633859541267', 'Epoch: 146, Train Loss: 0.037947177908622, Val Loss: 0.029281991012394', 'Epoch: 147, Train Loss: 0.033384589976523, Val Loss: 0.026112877428532', 'Epoch: 148, Train Loss: 0.035581779211413, Val Loss: 0.027966540725902', 'Epoch: 149, Train Loss: 0.031553280669763, Val Loss: 0.030254977885634', 'Epoch: 150, Train Loss: 0.044936757123228, Val Loss: 0.032525142021477', 'Epoch: 151, Train Loss: 0.034455901293387, Val Loss: 0.028535859175026', 'Epoch: 152, Train Loss: 0.036528941720378, Val Loss: 0.025862386506051', 'Epoch: 153, Train Loss: 0.035477826555888, Val Loss: 0.031517527718097', 'Epoch: 154, Train Loss: 0.035057958821918, Val Loss: 0.030411232337356', 'Epoch: 155, Train Loss: 0.030749355724385, Val Loss: 0.032714509516954', 'Epoch: 156, Train Loss: 0.042646135008612, Val Loss: 0.026415925109759', 'Epoch: 157, Train Loss: 0.038017116357074, Val Loss: 0.028580229803920', 'Epoch: 158, Train Loss: 0.032265021617329, Val Loss: 0.026774689052254', 'Epoch: 159, Train Loss: 0.031402551027578, Val Loss: 0.027367373015732', 'Epoch: 160, Train Loss: 0.035003348275326, Val Loss: 0.027377535933629', 'Epoch: 161, Train Loss: 0.030394139851249, Val Loss: 0.030265113813803', 'Epoch: 162, Train Loss: 0.031527490333416, Val Loss: 0.028283003121614', 'Epoch: 163, Train Loss: 0.032171459868550, Val Loss: 0.029270869549364', 'Epoch: 164, Train Loss: 0.036485983383690, Val Loss: 0.028254394307733', 'Epoch: 165, Train Loss: 0.035830391267704, Val Loss: 0.025445861034095', 'Epoch: 166, Train Loss: 0.031916951717332, Val Loss: 0.029783200398088', 'Epoch: 167, Train Loss: 0.038167130072103, Val Loss: 0.036187303811312', 'Epoch: 168, Train Loss: 0.029651447935680, Val Loss: 0.026350037027150', 'Epoch: 169, Train Loss: 0.034669569173698, Val Loss: 0.027996924649924', 'Epoch: 170, Train Loss: 0.030243139064243, Val Loss: 0.025305223725736', 'Epoch: 171, Train Loss: 0.032645161458573, Val Loss: 0.026854953560978', 'Epoch: 172, Train Loss: 0.029147857756809, Val Loss: 0.027920071370900', 'Epoch: 173, Train Loss: 0.034114895691705, Val Loss: 0.026946922261268', 'Epoch: 174, Train Loss: 0.034996613773496, Val Loss: 0.025351663595065', 'Epoch: 175, Train Loss: 0.027892967686057, Val Loss: 0.023385609090328', 'Epoch: 176, Train Loss: 0.027500405604410, Val Loss: 0.025015249429271', 'Epoch: 177, Train Loss: 0.027640939668514, Val Loss: 0.025492956507951', 'Epoch: 178, Train Loss: 0.030573976854252, Val Loss: 0.025740051344037', 'Epoch: 179, Train Loss: 0.028761595725840, Val Loss: 0.027806444931775', 'Epoch: 180, Train Loss: 0.031464056696656, Val Loss: 0.023870432078838', 'Epoch: 181, Train Loss: 0.030568161047995, Val Loss: 0.029141779989004', 'Epoch: 182, Train Loss: 0.029833126672392, Val Loss: 0.027223449982703', 'Epoch: 183, Train Loss: 0.027862858135513, Val Loss: 0.024498016946018', 'Epoch: 184, Train Loss: 0.026390913245810, Val Loss: 0.024180803149939', 'Epoch: 185, Train Loss: 0.028859120468761, Val Loss: 0.023543925294653', 'Epoch: 186, Train Loss: 0.030422635159867, Val Loss: 0.024240393061191', 'Epoch: 187, Train Loss: 0.028856612763606, Val Loss: 0.023362365625799', 'Epoch: 188, Train Loss: 0.026786015693878, Val Loss: 0.023960380461067', 'Epoch: 189, Train Loss: 0.025727577983987, Val Loss: 0.024122136812657', 'Epoch: 190, Train Loss: 0.027097919912532, Val Loss: 0.025143940914422', 'Epoch: 191, Train Loss: 0.028239660939678, Val Loss: 0.023009335873649', 'Epoch: 192, Train Loss: 0.027378743709347, Val Loss: 0.022936601806432', 'Epoch: 193, Train Loss: 0.028480187881478, Val Loss: 0.023484031874686', 'Epoch: 194, Train Loss: 0.027880358033229, Val Loss: 0.023153516780585', 'Epoch: 195, Train Loss: 0.028861465528174, Val Loss: 0.025495235165581', 'Epoch: 196, Train Loss: 0.026899439001153, Val Loss: 0.023840154996142', 'Epoch: 197, Train Loss: 0.032171213912756, Val Loss: 0.023323274180293', 'Epoch: 198, Train Loss: 0.028039493987900, Val Loss: 0.023119702818803', 'Epoch: 199, Train Loss: 0.026233848465910, Val Loss: 0.023388943411410']","[1221.5247     679.26117   1330.2987    1059.4661    1317.9758
  327.17197   1459.4069    1315.7358     791.1826    1116.8292
 1007.7515     150.31769    715.43896    723.91516   1428.804
  217.53181    704.8048    1142.1372     809.6446    1097.9701
  526.1854    1042.7369     284.87344   1349.6537    1435.9531
   26.362366  1490.4072    1028.7317     989.62036    157.65466
 1054.876     1317.6444     432.55783    731.5463    1499.2471
  471.5067     850.89325   1351.1415    1383.1376     453.5428
  909.75275   1251.8754    1142.2936     120.682465   961.2904
 1408.2344     841.0278    1379.851     1349.426     1490.482
 1285.5095     826.5668    1155.7556    1453.3033     575.4764
  271.97812    164.52728   1133.495      465.91953    862.18164
  224.73477   1238.9937     884.4532     872.6808    1113.9487
  827.1133    1176.1165     322.4549    1006.6737     407.38077
  801.2107    1194.9431    1032.0532     415.7993    1420.0637
  872.97754   1490.5876     403.2063     486.58215   1194.768
 1303.8766     624.32086    612.5547    1403.6465     845.45105
 1223.7511     191.49295   1060.7377       4.2955933 1417.2101
 1091.6931     339.30685   1467.7511    1480.3298    1195.5743
 1138.2083     261.8213     820.3655    1473.3964     243.80005
 1476.6365    1124.2915     491.42703   1483.6836     671.3924
  300.1291     842.4523     129.56917    775.89386   1207.0405
  963.6619    1425.319     1384.3492     256.2145     827.3801
 1196.922      590.9926     724.6224    1214.7106    1224.7018
 1257.7194     742.8929    1326.3976    1054.9164    1459.2
  276.1205    1412.3651     408.53592    363.62988   1328.8546
  972.6863    1497.418      162.47351   1429.0408     883.2368
  723.2114    1075.2095     549.34735    481.7866     727.46484
 1103.9307    1491.6371    1475.5166     204.06519    585.322
 1419.3148     722.8985     979.9915     751.4257    1219.9268
 1124.2627     769.8833     433.55243   1490.8198      98.026
  872.42523   1416.6647     648.6162      49.710083   877.4817
 1383.0387     653.6843    1330.5078    1488.0468      76.66522
 1293.5369    1187.2119     647.46814   1195.6976     706.096
  267.12814   1219.7676     323.64352    937.4784     935.8793
  295.79626    976.01514    981.4396    1414.6285    1493.0902
 1125.2296     998.5127    1000.4147    1452.6912     351.45856
 1475.0903    1484.2867    1163.6315    1240.1771    1279.2094
 1256.8141    1064.5663    1376.3134     759.2279     816.0582
  539.48114   1107.661     1414.3938     803.26434    153.85222
 1088.749     1328.4032    1336.151      299.7116    1499.8096
   17.1521    1293.5776    1380.3651     183.74353   1267.1584
  752.4112    1298.9893     612.8368    1380.389     1226.6482
 1214.0199    1141.9935     404.1381     771.5092     243.85602
  679.67426   1035.4532     130.74326   1460.9939    1282.4857
  585.25146   1319.7693     757.39264    781.7449    1281.9791
  143.20007   1227.13       913.523     1313.4098     482.56613
 1394.2578    1042.9111     426.13135    110.25      1086.9456
  284.92007   1227.849      273.74158   1228.1758    1028.9304
 1175.5155      75.2937     906.3818    1420.1295     490.25043
 1427.0814    1096.9996    1449.6664    1071.9073    1450.0553
  718.75134    214.32343   1237.5774      31.168304  1076.9857
  875.3424    1328.9232    1346.29      1234.7571    1453.7065
  710.71344    958.7745    1453.9106     260.93698    991.0093
  429.248      738.1181    1147.0278     292.90826    976.1615
  254.05406   1202.253     1450.4823     531.37384   1346.9658
  742.23206    303.49384   1194.7407     326.7587    1484.3884
  233.0706     653.25287   1056.3335    1092.8628     765.2302
 1062.5471    1303.3123    1383.868     1003.2678    1340.1898
  611.4912     218.32916   1334.149     1430.5096     994.32556
 1434.1155     343.26953    998.79156   1451.2781    1234.427
 1353.7292    1396.2112     534.1296    1176.18       516.778
  941.24384   1201.8485      73.32269   1267.9498      95.776184
 1421.8201     251.60626   1381.0527    1333.5004     211.60738
  239.05225   1223.5745    1247.572     1080.564      880.46027
 1402.9135    1474.5403    1469.0912    1425.6075     909.29504
 1260.1384     195.93723   1368.439     1462.7522     161.92776
  922.4284     818.2947    1389.4927    1139.0723    1468.8481
  620.157      760.1654    1052.8771      40.987274  1336.6495
  727.4431    1155.2762    1091.7101    1148.9177     679.4155
 1441.3884    1063.9298     959.5106     729.0851    1059.3123
   79.04999   1391.7609    1091.3048     738.2869    1442.2169
 1329.2473    1338.5997    1053.8251     472.77615    346.78494
 1060.1841    1484.2145     957.56476    408.17465   1413.1842
  909.47437   1400.0217    1475.9506      86.61273   1126.8188
 1092.7645    1423.1925     254.76642   1174.1948     132.82632
 1165.5945    1029.7682     188.08661    615.95294    235.81964
 1414.5033    1182.2421     301.1835     973.768     1470.1589
 1167.807     1242.8313    1162.431      832.4852    1355.7407
 1467.375     1331.5753    1407.7573     583.7478    1175.0725   ]","[1204.8221    674.7618   1440.8337   1013.4746   1331.774     306.07477
 1509.1094   1313.145     816.8776   1122.4445    970.3581    153.01225
  705.8432    717.61566  1451.9315    188.54727   749.0106   1110.0728
  762.5708   1060.3733    573.6805   1015.9244    226.70264  1338.1659
 1347.1271     75.5047   1474.1136   1035.3009    994.6901    151.02014
 1104.352    1327.7872    469.2762    739.2265   1492.4393    440.5961
  888.6106   1344.3475   1340.3617    454.9896   1012.3868   1296.0658
 1135.8402    153.3189    999.94507  1473.0771    896.44324  1356.6898
 1345.573    1467.098    1289.5106    753.8146   1108.813    1445.6398
  556.2834    264.07047   110.30322  1115.7742    520.35175   971.5836
  253.6088   1256.7848    847.28436   868.3188    871.68713   900.6557
 1158.1406    326.24472  1059.218     464.46332   645.73193  1162.4404
 1009.2356    408.3446   1309.6526    973.2388   1499.6294    338.0114
  391.20465  1102.8674   1264.7637    603.15125   647.2046   1436.2189
  878.5247   1241.2594    215.51006  1054.5305     85.31659  1375.8341
 1117.6877    340.3321   1382.853    1469.5159   1257.954    1119.0902
  263.93344   854.067    1495.3011    239.98581  1441.3716   1092.548
  524.1903   1492.6887    599.2458    307.62872   836.3269    137.01292
  799.05145  1243.0521    996.0485   1411.5187   1360.2433    205.06024
  801.5561   1146.2081    603.642     721.3483   1145.0261   1239.0612
 1220.6843    736.3936   1269.8302   1069.1245   1429.1218    297.05023
 1425.5575    393.6957    363.61154  1285.7683    970.99164  1540.9192
  155.67029  1403.358     869.16187   705.7882   1071.4642    539.8072
  499.80173   703.20807  1140.0353   1518.3251   1252.917     242.30902
  689.03644  1526.7808    604.70496   982.23456   813.0332   1217.3027
 1189.0719    787.6175    406.32855  1402.0315     74.28232   820.88293
 1416.7091    649.8333     50.40561   927.36145  1356.9818    665.75446
 1325.868    1458.2281    102.53815  1282.5667   1192.1113    621.5413
 1199.4565    681.9796    256.4627   1218.3585    160.33922   570.7378
  933.765     278.16003   952.6997    961.8152   1415.7993   1486.2985
 1071.8416   1030.6233   1043.3075   1545.6731    405.8011   1422.5724
 1527.4181   1115.3065   1217.1964   1249.2285   1231.2064   1049.5311
 1341.1819    755.47064   813.3997    504.64008  1063.3895   1358.7537
  788.4266    161.41177  1072.7262   1283.5459   1326.2261    307.18298
 1359.3766    169.87402  1132.6444   1401.4219    138.3518   1233.3503
  759.152    1235.4706    654.9628   1346.5101   1192.577    1208.3497
 1144.0043    396.46838   741.76544   253.70697   684.0814   1043.2673
  128.29492  1555.4048   1278.9684    582.4123   1311.3433    732.3328
  714.509    1177.1964    131.52805  1210.3809    846.97455  1230.7762
  480.78754  1345.5122    976.66846   399.0676    158.06949  1091.2122
  252.9787   1198.8623    235.4281   1369.7677   1005.4841   1201.7526
   28.098145  870.044    1381.6075    502.23138  1387.4718   1140.7145
 1397.0874   1169.9794   1516.0494    716.5014    182.33667  1213.8917
   42.019592 1037.1443    973.04535  1410.4849   1259.2035   1298.4554
 1422.7507    718.19244   978.11664  1451.7095    261.13904   867.8672
  426.8522    753.6028   1145.2162    296.84488   962.80347   246.12834
 1203.3612   1480.0746    555.4143   1279.5929    707.4949    286.01212
 1196.2028    326.20007  1543.844     220.46721   639.3577   1053.2596
 1072.7534    736.7354   1004.70856  1254.3297   1344.634    1014.30676
 1345.1473    660.8685    123.08588  1432.5234   1433.3164    961.0358
 1432.6028    350.9559   1018.5251   1504.8635   1321.0953   1379.7446
 1371.6655    549.61163  1168.4904    540.6453    929.607    1185.7454
   14.620789 1289.5792    104.02997  1403.0265    261.95364  1419.928
 1364.8488    155.74838   226.25919  1197.7285   1260.3447   1035.919
  867.7702   1398.309    1504.8912   1418.0963   1422.7151    862.7115
 1189.5066    216.10767  1353.3389   1434.1273    121.41235   893.45105
  819.2004   1390.8239    904.3629   1492.6711    642.2306    767.74493
  999.48584    82.89639  1290.2537    672.0499   1236.9459   1119.5525
 1131.9817    640.8241   1380.1376   1087.3365    977.7101    664.6309
 1051.884      94.46805  1393.4415   1059.2249    764.4598   1352.5071
 1294.593    1345.9104   1036.2406    487.81235   364.48877   943.8739
 1478.1611    992.24023   428.9521   1364.4238    874.3043   1329.532
 1446.1879    148.7655   1172.4657   1078.8612   1385.498     269.25122
 1151.7842    175.54913  1070.2654    898.1198    175.63112   625.3694
  195.55075  1386.6333   1177.4952    271.43228   929.5973   1436.5537
 1086.3341   1187.8569   1198.094     810.6775   1419.7892   1428.4082
 1301.68     1352.409     651.01465  1268.1196  ]",36.438046,2835.2231,53.24681346833113
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 2.030850288479827, Val Loss: 1.530210981369019', 'Epoch: 1, Train Loss: 1.638579483642135, Val Loss: 1.413161287307739', 'Epoch: 2, Train Loss: 1.477827754131583, Val Loss: 1.179140720367432', 'Epoch: 3, Train Loss: 1.120410831861718, Val Loss: 0.715410513877869', 'Epoch: 4, Train Loss: 0.762598537428435, Val Loss: 0.466788606643677', 'Epoch: 5, Train Loss: 0.575291478703188, Val Loss: 0.373536881804466', 'Epoch: 6, Train Loss: 0.541531451912813, Val Loss: 0.346972678899765', 'Epoch: 7, Train Loss: 0.459565939078497, Val Loss: 0.297449983358383', 'Epoch: 8, Train Loss: 0.427941107819247, Val Loss: 0.274794915318489', 'Epoch: 9, Train Loss: 0.415129939484042, Val Loss: 0.272090683281422', 'Epoch: 10, Train Loss: 0.398462226744308, Val Loss: 0.367582440972328', 'Epoch: 11, Train Loss: 0.451678114575009, Val Loss: 0.266631770431995', 'Epoch: 12, Train Loss: 0.400551164046276, Val Loss: 0.283981053829193', 'Epoch: 13, Train Loss: 0.432610913937868, Val Loss: 0.252937196195126', 'Epoch: 14, Train Loss: 0.385173072302064, Val Loss: 0.227792916446924', 'Epoch: 15, Train Loss: 0.356340598574905, Val Loss: 0.257037942707539', 'Epoch: 16, Train Loss: 0.335906159739162, Val Loss: 0.257528600096703', 'Epoch: 17, Train Loss: 0.384797541208045, Val Loss: 0.264604773819447', 'Epoch: 18, Train Loss: 0.330490259237068, Val Loss: 0.289144919514656', 'Epoch: 19, Train Loss: 0.310245280695516, Val Loss: 0.224268659651279', 'Epoch: 20, Train Loss: 0.325679866380470, Val Loss: 0.191397629082203', 'Epoch: 21, Train Loss: 0.342704863915610, Val Loss: 0.277575755119324', 'Epoch: 22, Train Loss: 0.306176579622335, Val Loss: 0.233270179629326', 'Epoch: 23, Train Loss: 0.291740497270989, Val Loss: 0.188704276680946', 'Epoch: 24, Train Loss: 0.372397774700509, Val Loss: 0.238530983626842', 'Epoch: 25, Train Loss: 0.301859853919162, Val Loss: 0.205016548335552', 'Epoch: 26, Train Loss: 0.306417502116325, Val Loss: 0.250822895169258', 'Epoch: 27, Train Loss: 0.347353171124015, Val Loss: 0.226628256738186', 'Epoch: 28, Train Loss: 0.303956474329150, Val Loss: 0.192611761391163', 'Epoch: 29, Train Loss: 0.284293003380299, Val Loss: 0.247938354611397', 'Epoch: 30, Train Loss: 0.339814568328303, Val Loss: 0.397848420739174', 'Epoch: 31, Train Loss: 0.304394667405029, Val Loss: 0.223235175609589', 'Epoch: 32, Train Loss: 0.283417480629544, Val Loss: 0.230607018470764', 'Epoch: 33, Train Loss: 0.326867229023645, Val Loss: 0.297961404025555', 'Epoch: 34, Train Loss: 0.294617501022511, Val Loss: 0.195636056065559', 'Epoch: 35, Train Loss: 0.282507518696231, Val Loss: 0.204730769395828', 'Epoch: 36, Train Loss: 0.324723037349623, Val Loss: 0.211808957457542', 'Epoch: 37, Train Loss: 0.309364228920881, Val Loss: 0.299668204188347', 'Epoch: 38, Train Loss: 0.279708618947933, Val Loss: 0.243983349800110', 'Epoch: 39, Train Loss: 0.256760156431863, Val Loss: 0.204529154300690', 'Epoch: 40, Train Loss: 0.292111896498259, Val Loss: 0.223242229819298', 'Epoch: 41, Train Loss: 0.274950970224170, Val Loss: 0.233216367959976', 'Epoch: 42, Train Loss: 0.233409575684819, Val Loss: 0.171440144181252', 'Epoch: 43, Train Loss: 0.272546026769073, Val Loss: 0.188518992662430', 'Epoch: 44, Train Loss: 0.236704246335944, Val Loss: 0.269951559454203', 'Epoch: 45, Train Loss: 0.278479842252510, Val Loss: 0.242691322267056', 'Epoch: 46, Train Loss: 0.254019531399705, Val Loss: 0.215189626216888', 'Epoch: 47, Train Loss: 0.249705237358115, Val Loss: 0.314546473771334', 'Epoch: 48, Train Loss: 0.220597489628681, Val Loss: 0.195495766401291', 'Epoch: 49, Train Loss: 0.219541370435510, Val Loss: 0.164537737369537', 'Epoch: 50, Train Loss: 0.204159307791743, Val Loss: 0.289288198947906', 'Epoch: 51, Train Loss: 0.249896290257227, Val Loss: 0.213164653778076', 'Epoch: 52, Train Loss: 0.231394040549910, Val Loss: 0.254640869796276', 'Epoch: 53, Train Loss: 0.201722386531359, Val Loss: 0.178239193558693', 'Epoch: 54, Train Loss: 0.190371938829505, Val Loss: 0.165712369680405', 'Epoch: 55, Train Loss: 0.181701320201852, Val Loss: 0.220567013621330', 'Epoch: 56, Train Loss: 0.183496674999248, Val Loss: 0.191869672536850', 'Epoch: 57, Train Loss: 0.191656802282777, Val Loss: 0.146442052274942', 'Epoch: 58, Train Loss: 0.189893519722445, Val Loss: 0.164771540164948', 'Epoch: 59, Train Loss: 0.152066938752352, Val Loss: 0.164291874766350', 'Epoch: 60, Train Loss: 0.176079460441373, Val Loss: 0.150047540664673', 'Epoch: 61, Train Loss: 0.171025872750338, Val Loss: 0.158982306718826', 'Epoch: 62, Train Loss: 0.168196642987950, Val Loss: 0.219981729984283', 'Epoch: 63, Train Loss: 0.158066025307012, Val Loss: 0.224758739471436', 'Epoch: 64, Train Loss: 0.154873274093451, Val Loss: 0.140040581524372', 'Epoch: 65, Train Loss: 0.120328333142192, Val Loss: 0.128311126232147', 'Epoch: 66, Train Loss: 0.149569075208071, Val Loss: 0.163035991191864', 'Epoch: 67, Train Loss: 0.175079306717529, Val Loss: 0.133247922658920', 'Epoch: 68, Train Loss: 0.164685293685558, Val Loss: 0.149031509757042', 'Epoch: 69, Train Loss: 0.143268007958351, Val Loss: 0.132508906126022', 'Epoch: 70, Train Loss: 0.138177341673263, Val Loss: 0.110041445493698', 'Epoch: 71, Train Loss: 0.125777333108492, Val Loss: 0.133203703761101', 'Epoch: 72, Train Loss: 0.114040674425142, Val Loss: 0.113328215479851', 'Epoch: 73, Train Loss: 0.113609647594912, Val Loss: 0.139642090797424', 'Epoch: 74, Train Loss: 0.129806333156519, Val Loss: 0.110770963430405', 'Epoch: 75, Train Loss: 0.133547788442567, Val Loss: 0.108429865241051', 'Epoch: 76, Train Loss: 0.105640103044205, Val Loss: 0.127201047837734', 'Epoch: 77, Train Loss: 0.124592233882394, Val Loss: 0.125698850154877', 'Epoch: 78, Train Loss: 0.122483603829561, Val Loss: 0.115150188803673', 'Epoch: 79, Train Loss: 0.115343055492917, Val Loss: 0.187909520864487', 'Epoch: 80, Train Loss: 0.124507595113544, Val Loss: 0.099314568340778', 'Epoch: 81, Train Loss: 0.119705486003050, Val Loss: 0.125493497848511', 'Epoch: 82, Train Loss: 0.119830525371917, Val Loss: 0.152268656641245', 'Epoch: 83, Train Loss: 0.115349533166303, Val Loss: 0.124614881873131', 'Epoch: 84, Train Loss: 0.100536719484385, Val Loss: 0.099064598083496', 'Epoch: 85, Train Loss: 0.117772731670113, Val Loss: 0.129414388239384', 'Epoch: 86, Train Loss: 0.085751393246789, Val Loss: 0.103881229460239', 'Epoch: 87, Train Loss: 0.086406709756269, Val Loss: 0.112920824289322', 'Epoch: 88, Train Loss: 0.082773306168789, Val Loss: 0.103413425087929', 'Epoch: 89, Train Loss: 0.118304737605328, Val Loss: 0.193723700046539', 'Epoch: 90, Train Loss: 0.111117653375448, Val Loss: 0.085389101803303', 'Epoch: 91, Train Loss: 0.075689646307119, Val Loss: 0.086072011590004', 'Epoch: 92, Train Loss: 0.105744289970675, Val Loss: 0.107331760525703', 'Epoch: 93, Train Loss: 0.091142500209254, Val Loss: 0.121335586309433', 'Epoch: 94, Train Loss: 0.101211950096280, Val Loss: 0.104063543975353', 'Epoch: 95, Train Loss: 0.105526399993619, Val Loss: 0.111022765636444', 'Epoch: 96, Train Loss: 0.090122341676507, Val Loss: 0.124490930438042', 'Epoch: 97, Train Loss: 0.077461921848183, Val Loss: 0.090043142735958', 'Epoch: 98, Train Loss: 0.079654595836304, Val Loss: 0.095740703642368', 'Epoch: 99, Train Loss: 0.094048908240227, Val Loss: 0.143466998040676', 'Epoch: 100, Train Loss: 0.078199632032666, Val Loss: 0.090991553962231', 'Epoch: 101, Train Loss: 0.100811136280035, Val Loss: 0.116513358354568', 'Epoch: 102, Train Loss: 0.098227252707232, Val Loss: 0.099884387254715', 'Epoch: 103, Train Loss: 0.077780374694009, Val Loss: 0.118622034788132', 'Epoch: 104, Train Loss: 0.078769577277261, Val Loss: 0.098694350123405', 'Epoch: 105, Train Loss: 0.077817829888920, Val Loss: 0.124169783294201', 'Epoch: 106, Train Loss: 0.083185797340648, Val Loss: 0.092961169481277', 'Epoch: 107, Train Loss: 0.065611615603746, Val Loss: 0.091617423892021', 'Epoch: 108, Train Loss: 0.066335872855297, Val Loss: 0.081473652720451', 'Epoch: 109, Train Loss: 0.061439851602150, Val Loss: 0.087167802751064', 'Epoch: 110, Train Loss: 0.063327585845146, Val Loss: 0.079733595252037', 'Epoch: 111, Train Loss: 0.065176468559129, Val Loss: 0.075941195487976', 'Epoch: 112, Train Loss: 0.092081419213913, Val Loss: 0.096160934567451', 'Epoch: 113, Train Loss: 0.072812912422557, Val Loss: 0.078269574642181', 'Epoch: 114, Train Loss: 0.073613633423351, Val Loss: 0.079948109984398', 'Epoch: 115, Train Loss: 0.077070470942661, Val Loss: 0.095095061659813', 'Epoch: 116, Train Loss: 0.066302955410508, Val Loss: 0.096751435250044', 'Epoch: 117, Train Loss: 0.069992892704038, Val Loss: 0.119003487527370', 'Epoch: 118, Train Loss: 0.087666660893795, Val Loss: 0.088207239806652', 'Epoch: 119, Train Loss: 0.060778634795962, Val Loss: 0.087648720741272', 'Epoch: 120, Train Loss: 0.072480155241697, Val Loss: 0.079628525674343', 'Epoch: 121, Train Loss: 0.067705230267588, Val Loss: 0.076760558933020', 'Epoch: 122, Train Loss: 0.053229848789268, Val Loss: 0.083341552615166', 'Epoch: 123, Train Loss: 0.059532513408813, Val Loss: 0.073301267474890', 'Epoch: 124, Train Loss: 0.062165490936401, Val Loss: 0.078718573451042', 'Epoch: 125, Train Loss: 0.057563906102333, Val Loss: 0.100426432192326', 'Epoch: 126, Train Loss: 0.072668342266318, Val Loss: 0.089289569258690', 'Epoch: 127, Train Loss: 0.069512232791546, Val Loss: 0.094354112446308', 'Epoch: 128, Train Loss: 0.094084165340593, Val Loss: 0.114715863764286', 'Epoch: 129, Train Loss: 0.059157421465876, Val Loss: 0.067155999541283', 'Epoch: 130, Train Loss: 0.063489510439510, Val Loss: 0.067225976139307', 'Epoch: 131, Train Loss: 0.066669969061433, Val Loss: 0.084979491233826', 'Epoch: 132, Train Loss: 0.061397870569382, Val Loss: 0.093287060409784', 'Epoch: 133, Train Loss: 0.059336808791687, Val Loss: 0.080360765457153', 'Epoch: 134, Train Loss: 0.061760698423483, Val Loss: 0.081363076865673', 'Epoch: 135, Train Loss: 0.052192984625351, Val Loss: 0.071592692434788', 'Epoch: 136, Train Loss: 0.053265201577614, Val Loss: 0.073759749531746', 'Epoch: 137, Train Loss: 0.054074444743090, Val Loss: 0.078848038613796', 'Epoch: 138, Train Loss: 0.072183236089903, Val Loss: 0.084613272547722', 'Epoch: 139, Train Loss: 0.054838275493577, Val Loss: 0.074859039485455', 'Epoch: 140, Train Loss: 0.049843000378027, Val Loss: 0.083733093440533', 'Epoch: 141, Train Loss: 0.052682785750475, Val Loss: 0.068443593680859', 'Epoch: 142, Train Loss: 0.047021218207340, Val Loss: 0.068905733525753', 'Epoch: 143, Train Loss: 0.055484008044004, Val Loss: 0.068204856663942', 'Epoch: 144, Train Loss: 0.060304267505227, Val Loss: 0.066207559108734', 'Epoch: 145, Train Loss: 0.057834454357278, Val Loss: 0.066624940037727', 'Epoch: 146, Train Loss: 0.048232433277854, Val Loss: 0.086409638524055', 'Epoch: 147, Train Loss: 0.054948439734966, Val Loss: 0.067722266167402', 'Epoch: 148, Train Loss: 0.051677131548870, Val Loss: 0.075300074815750', 'Epoch: 149, Train Loss: 0.050424808549673, Val Loss: 0.085718222260475', 'Epoch: 150, Train Loss: 0.048366959986472, Val Loss: 0.063438394665718', 'Epoch: 151, Train Loss: 0.056031430854874, Val Loss: 0.068691939115524', 'Epoch: 152, Train Loss: 0.050231469405252, Val Loss: 0.072677328884602', 'Epoch: 153, Train Loss: 0.051705480878090, Val Loss: 0.061779884546995', 'Epoch: 154, Train Loss: 0.058465884955123, Val Loss: 0.086798277497292', 'Epoch: 155, Train Loss: 0.046578862336139, Val Loss: 0.068795139491558', 'Epoch: 156, Train Loss: 0.045208171053335, Val Loss: 0.072529874742031', 'Epoch: 157, Train Loss: 0.047357792597870, Val Loss: 0.067933469563723', 'Epoch: 158, Train Loss: 0.045785744912749, Val Loss: 0.067179208099842', 'Epoch: 159, Train Loss: 0.042335005455412, Val Loss: 0.060485613644123', 'Epoch: 160, Train Loss: 0.055298108390944, Val Loss: 0.068460992574692', 'Epoch: 161, Train Loss: 0.056162110248277, Val Loss: 0.075198753476143', 'Epoch: 162, Train Loss: 0.048806324081365, Val Loss: 0.068863547146320', 'Epoch: 163, Train Loss: 0.047738502105308, Val Loss: 0.070410091280937', 'Epoch: 164, Train Loss: 0.049945172875427, Val Loss: 0.062775096446276', 'Epoch: 165, Train Loss: 0.051057886787105, Val Loss: 0.068605737537146', 'Epoch: 166, Train Loss: 0.047620748104744, Val Loss: 0.069243864715099', 'Epoch: 167, Train Loss: 0.045580982815388, Val Loss: 0.061973375231028', 'Epoch: 168, Train Loss: 0.043633429593472, Val Loss: 0.076096356362104', 'Epoch: 169, Train Loss: 0.051396223239947, Val Loss: 0.070384611189365', 'Epoch: 170, Train Loss: 0.041550122656275, Val Loss: 0.057785376608372', 'Epoch: 171, Train Loss: 0.039600543894393, Val Loss: 0.065318611711264', 'Epoch: 172, Train Loss: 0.041805216479440, Val Loss: 0.066389285922050', 'Epoch: 173, Train Loss: 0.050841193083067, Val Loss: 0.081953402161598', 'Epoch: 174, Train Loss: 0.042159890192886, Val Loss: 0.068301776349545', 'Epoch: 175, Train Loss: 0.037433642200952, Val Loss: 0.062936984747648', 'Epoch: 176, Train Loss: 0.044047913340808, Val Loss: 0.060228157937527', 'Epoch: 177, Train Loss: 0.039146057741587, Val Loss: 0.067610868811607', 'Epoch: 178, Train Loss: 0.043578394060565, Val Loss: 0.063590143769979', 'Epoch: 179, Train Loss: 0.048297113154170, Val Loss: 0.065527224540710', 'Epoch: 180, Train Loss: 0.053849321768381, Val Loss: 0.063177468776703', 'Epoch: 181, Train Loss: 0.049909447146536, Val Loss: 0.059914334863424', 'Epoch: 182, Train Loss: 0.040825305939760, Val Loss: 0.064130832701921', 'Epoch: 183, Train Loss: 0.041093715379924, Val Loss: 0.073791587650776', 'Epoch: 184, Train Loss: 0.041790633159148, Val Loss: 0.059920178055763', 'Epoch: 185, Train Loss: 0.043690732095477, Val Loss: 0.060809785872698', 'Epoch: 186, Train Loss: 0.045317973378439, Val Loss: 0.055596040189266', 'Epoch: 187, Train Loss: 0.041775134088861, Val Loss: 0.061343159526587', 'Epoch: 188, Train Loss: 0.039491512054621, Val Loss: 0.061990359276533', 'Epoch: 189, Train Loss: 0.041569453989004, Val Loss: 0.057325214147568', 'Epoch: 190, Train Loss: 0.042554003857943, Val Loss: 0.057879822552204', 'Epoch: 191, Train Loss: 0.041093580511420, Val Loss: 0.060788960158825', 'Epoch: 192, Train Loss: 0.042315433841459, Val Loss: 0.060094148516655', 'Epoch: 193, Train Loss: 0.038034841093386, Val Loss: 0.059847571104765', 'Epoch: 194, Train Loss: 0.039099131429265, Val Loss: 0.060780596137047', 'Epoch: 195, Train Loss: 0.041750457267775, Val Loss: 0.060096517503262', 'Epoch: 196, Train Loss: 0.037029508587926, Val Loss: 0.060360038578510', 'Epoch: 197, Train Loss: 0.041069658278206, Val Loss: 0.060351719260216', 'Epoch: 198, Train Loss: 0.041959464593336, Val Loss: 0.060694327205420', 'Epoch: 199, Train Loss: 0.043299198800395, Val Loss: 0.059357051700354']","[ 698.4699   1338.4492    175.88763  1269.4756   1160.6389     74.14899
 1477.8551    466.13403  1375.6978    584.21436  1380.1345    340.4566
  586.87933   475.39343   637.1222   1115.477    1480.5557    408.11102
 1257.0161   1065.5535   1344.752      28.072693 1057.6398    239.17117
 1254.7863   1485.5491    941.80963  1326.514     287.3689   1370.195
  887.0292    703.7573   1189.1436    417.06412  1187.8511     16.167236
  579.11664  1148.2974   1065.3143    185.18118   957.4538   1128.1732
 1320.2323    725.19617  1080.5503    556.7899     38.419006 1340.4641
 1264.357     435.27902   760.9852    418.34445   948.16394   864.88586
 1297.5103   1119.7516   1192.2241    171.71837   159.81628  1050.0085
  756.0376    890.5029     18.127014  693.30194  1151.5725   1372.7338
 1004.80255   296.18207  1127.626    1114.5088   1260.3438   1059.8218
 1205.9797    136.23422   796.7041    173.87738   545.4221   1098.6543
  637.1611   1444.8756   1263.5051    170.0412    190.26578   181.24731
  506.01187  1038.9556    131.31464   262.70514   399.8982   1161.2095
   40.59424   619.8385   1107.3207    810.3854   1372.3138    512.36426
   44.69757   516.745     941.4065   1315.5906     17.060547   88.05676
 1062.4895    784.7203    417.79086   158.66156  1184.4263    190.72852
 1375.2451   1093.4529     85.23926   688.71643    32.668274  212.11487
  105.88666  1363.0984     19.00653   702.4489   1262.6746    531.8203
  446.38498  1156.3569    934.35803   500.1501   1001.8384   1058.7773
  967.814    1430.2565   1349.6244   1285.2103   1148.3973   1177.1262
 1496.3368   1426.4531   1358.291      95.094086 1012.77686   205.86273
 1234.0023     56.968323  564.2154   1037.4299    201.33533  1167.9438
   48.173584  861.7853   1427.684     153.5542    642.96155  1083.9604
  646.3725   1186.1531     56.724     873.4855   1459.0754     34.50415
 1233.2117   1264.3232    887.69775  1378.0674   1462.9746    251.32764
 1058.9346   1160.6729   1153.8671   1311.9187    734.5254    863.496
  706.8159   1257.6821    602.90643  1466.822     604.3594    870.45056
 1184.2427    703.6915   1296.0408    942.3477   1258.8971    206.94382
 1153.6588   1134.0894     76.7708    370.8208    711.48096  1278.2991
  883.65765    49.466064 1239.5159    489.37946   893.2463    811.3948
  108.10129  1213.1602    171.91023   175.58081    98.947754  534.2696
 1259.7407    136.95302  1455.6342    875.82983  1271.9653    346.1935
  647.14685   799.16077   328.76147  1486.9941    754.52     1018.87384
   72.845215  695.4485   1174.0735   1017.10443  1442.1941    831.95447
  198.54285   798.37616  1389.4717    563.0894    435.96832   872.1594
  878.19006   243.77063   640.7131   1257.3401    476.01727  1451.8174
  790.5161     32.176544 1007.91296   555.4341   1063.3013    786.92175
 1164.3903    123.54993   774.0481    601.02344   411.39426  1320.0239
  834.60406   149.2833    916.5155   1407.5908   1494.4989    794.81006
  532.2554   1079.6855    373.56274  1149.8402   1124.192    1123.814
   28.042938  496.31958  1110.813      41.438293  760.1305   1050.635
  244.84525  1407.9136   1362.8274    150.70996  1350.061     526.92206
  203.28229  1082.3978    738.34656  1062.2849   1089.5162    132.76709
  328.95886  1428.0706   1463.1674    387.382    1363.6838   1228.8374
  986.149    1395.2181   1167.8208    219.84653   530.65784   127.127014
   28.340332  162.48526   485.25912  1387.5806    916.9951     18.857635
   51.18506  1135.9775   1335.6047    197.80054  1098.9016     72.75009
 1084.293    1253.388     972.06366   801.7367   1115.1304    549.8417
  880.8408    663.8787   1205.9727    184.99359  1286.4392    841.1932
  248.4881    255.87762   207.09778  1474.1775   1414.2524    559.66516
  542.6645     33.061157  187.98038   451.3662   1164.6074   1190.7858
 1354.6516   1447.144     301.2325    947.162     843.89294    90.693924
  330.90173  1151.4156    697.181     570.8585    712.5116   1307.4182
  967.3589    997.2878    515.34753  1391.2676   1341.54     1081.984
  940.42816  1498.2609     26.081787 1174.1395    904.8345    331.998
  139.026     204.40247  1342.2224    679.353    1241.1227   1341.7405
  109.734436  420.9949     37.360535  460.01822   515.9024   1286.1364
 1372.6436    701.60516   729.1405     33.987396  507.88882  1224.754
 1386.8457    558.4408     79.38226   341.0751    924.01294  1001.91235
   56.898407  477.9026    585.02     1143.7937    583.4846   1309.5034
 1196.0437    641.2331   1375.2205    285.42535  1278.106    1418.4114
  321.51636  1093.8492     63.595947  855.51306   476.38586   202.67288
   41.366272   62.81845   884.23083   173.23581  1460.8783    928.04126
  899.3925   1401.5437   1189.6431    203.78836   241.24738  1182.1528
  524.2395    436.55914   215.05751  1018.1863  ]","[ 6.73436218e+02  1.40105408e+03  2.53198944e+02  1.23234814e+03
  1.19108081e+03  9.50887451e+01  1.51464941e+03  4.93406952e+02
  1.19669934e+03  4.68356201e+02  1.36668384e+03  3.36625122e+02
  5.44423035e+02  4.19462799e+02  6.57913391e+02  1.12058789e+03
  1.55425244e+03  3.77081482e+02  1.23019165e+03  1.04850562e+03
  1.25688525e+03  1.29542786e+02  9.89128601e+02  2.85614777e+02
  1.26492285e+03  1.47965247e+03  8.89153442e+02  1.22339624e+03
  2.53809570e+02  1.38134961e+03  8.84934204e+02  7.08646362e+02
  1.14967651e+03  4.25957245e+02  1.13215210e+03  7.73269958e+01
  5.72867249e+02  1.18342236e+03  1.09304822e+03  1.56973877e+02
  9.39410461e+02  1.11248059e+03  1.40293066e+03  7.54112854e+02
  1.06663257e+03  5.02871338e+02  7.32042847e+01  1.31604785e+03
  1.25436047e+03  4.20925079e+02  7.55805908e+02  4.32028931e+02
  9.91555542e+02  8.89241577e+02  1.27317529e+03  1.13194702e+03
  1.19021851e+03  1.32012466e+02  1.30686676e+02  1.07711621e+03
  7.45080200e+02  8.54686035e+02  4.20689087e+01  6.43738770e+02
  1.29206006e+03  1.49021167e+03  9.94252075e+02  2.97617004e+02
  1.13392529e+03  1.10817407e+03  1.21350586e+03  1.06166052e+03
  1.18905200e+03  1.69388214e+02  8.15728027e+02  1.69878235e+02
  5.64184692e+02  1.06103650e+03  6.98703613e+02  1.44707153e+03
  1.34213611e+03  1.06717041e+02  1.15388489e+02  1.37912170e+02
  5.07605560e+02  1.03524097e+03  1.44078461e+02  2.31864243e+02
  3.14906281e+02  1.15954236e+03  3.11867065e+01  6.29734741e+02
  1.09210632e+03  7.78743164e+02  1.21233813e+03  4.89220428e+02
  4.68849487e+01  5.54792969e+02  9.48717163e+02  1.32956555e+03
  1.95151764e+02  1.54110840e+02  1.05043555e+03  7.73967224e+02
  3.88840759e+02  1.02924255e+02  1.17316125e+03  1.45880981e+02
  1.40573511e+03  1.27895898e+03  7.80496826e+01  6.25588013e+02
  8.78482666e+01  1.52649902e+02  1.27623718e+02  1.36257495e+03
 -2.57369385e+01  7.36126831e+02  1.41031824e+03  5.12612366e+02
  4.16949188e+02  1.21790454e+03  9.25871277e+02  5.26050903e+02
  1.01299451e+03  1.06253894e+03  9.45150452e+02  1.40914856e+03
  1.36478296e+03  1.30809216e+03  1.04555908e+03  1.09444629e+03
  1.84932764e+03  1.74610767e+03  1.32312720e+03  1.27414246e+02
  1.07400562e+03  2.17685516e+02  1.20265564e+03  1.06356323e+02
  5.99337769e+02  1.10746924e+03  2.04698914e+02  7.59850037e+02
  4.23644409e+01  9.02859131e+02  1.37661926e+03  2.23435059e+02
  6.42998169e+02  1.06714636e+03  6.82805176e+02  1.16412744e+03
  7.61987305e+00  1.00615857e+03  1.39987012e+03  1.05927979e+02
  1.22511670e+03  1.28370544e+03  8.49769836e+02  1.39909912e+03
  1.35833984e+03  2.90279602e+02  1.08990356e+03  1.19747925e+03
  1.21591602e+03  1.34110547e+03  6.79404175e+02  7.69979004e+02
  6.99285095e+02  1.26740308e+03  6.26600891e+02  1.44140381e+03
  6.42345947e+02  9.07089050e+02  1.13264111e+03  6.73965088e+02
  1.23470557e+03  9.35982056e+02  1.34475745e+03  1.30812592e+02
  1.13823108e+03  1.11448657e+03  8.11166382e+01  3.61182220e+02
  6.95954102e+02  1.25210303e+03  1.19082861e+03  1.01782227e+00
  1.22784326e+03  4.99619659e+02  8.86927185e+02  7.61381226e+02
  1.41699219e+02  1.16345471e+03  1.55874756e+02  1.54600800e+02
  4.76781006e+01  4.76887390e+02  1.24720923e+03  1.59960754e+02
  1.42834534e+03  9.12035217e+02  1.24377441e+03  3.33386688e+02
  6.48576355e+02  7.48568359e+02  4.11047607e+02  1.30572839e+03
  7.75002319e+02  9.50741150e+02  1.38675262e+02  6.03846802e+02
  1.21580908e+03  1.05331494e+03  1.51394507e+03  7.74958069e+02
  1.25164307e+02  8.03742737e+02  1.38836609e+03  5.83890320e+02
  4.31650269e+02  8.44618347e+02  8.96840454e+02  2.07183167e+02
  6.32864929e+02  1.29747852e+03  5.02009644e+02  1.44349365e+03
  8.01217163e+02  7.36053772e+01  9.83607544e+02  5.78724487e+02
  1.05248743e+03  7.37731812e+02  1.03180115e+03  2.01170959e+02
  8.00832153e+02  5.98955078e+02  4.07018188e+02  1.28628955e+03
  8.75643494e+02  1.42298584e+02  9.08236450e+02  1.42885718e+03
  1.00153021e+03  5.55702271e+02  5.22221558e+02  1.09624780e+03
  3.44634125e+02  1.16826355e+03  1.10979150e+03  1.14481836e+03
  1.59850159e+01  5.01731476e+02  1.12145923e+03  1.30810547e+02
  6.96328003e+02  9.33977600e+02  2.81498108e+02  1.39183325e+03
  1.35945825e+03  1.93673157e+02  1.42398145e+03  4.96620087e+02
  1.94129333e+02  1.12281360e+03  7.28268921e+02  1.08577051e+03
  1.18593652e+03  8.81301270e+01  3.85802277e+02  1.33392517e+03
  1.45595703e+03  3.58160553e+02  1.38192712e+03  1.29860254e+03
  1.03007886e+03  1.25280530e+03  1.11492529e+03  2.59870789e+02
  5.60771606e+02  1.56094971e+02  9.12624207e+01  1.84664795e+02
  5.54939514e+02  1.34215430e+03  8.54508179e+02  1.00335632e+02
  1.40289124e+02  1.08853406e+03  1.31526245e+03  2.42103821e+02
  1.11474780e+03  8.86960144e+01  1.08250830e+03  1.19802942e+03
  9.74559692e+02  8.44320618e+02  1.11610779e+03  5.33305664e+02
  1.13981738e+03  8.59161438e+02  1.19821753e+03  2.42956970e+02
  1.35203101e+03  8.63798584e+02  2.36335266e+02  2.04153992e+02
  2.44873062e+02  1.40531982e+03  1.27073730e+03  5.23330261e+02
  5.18960144e+02 -8.84851074e+00  1.94806610e+02  4.48122528e+02
  1.10302808e+03  1.21533240e+03  1.32043286e+03  1.39736365e+03
  3.16115417e+02  9.14201172e+02  8.97613770e+02  3.59655457e+01
  3.28431183e+02  1.16162683e+03  6.86549377e+02  6.07239807e+02
  7.11423828e+02  1.32686768e+03  9.31335449e+02  1.03964380e+03
  7.10499207e+02  1.34570129e+03  1.27990356e+03  9.88183289e+02
  9.23023743e+02  1.21931396e+03  6.13956909e+01  1.16117456e+03
  9.14486450e+02  3.43045898e+02  9.12657471e+01  1.62532471e+02
  1.11930957e+03  5.86609985e+02  1.23486951e+03  1.32497070e+03
  7.08945312e+01  3.88886749e+02  3.83366089e+01  4.11665833e+02
  5.21272888e+02  1.09458228e+03  1.37318408e+03  7.36499023e+02
  7.63234558e+02  5.88166199e+01  5.00262939e+02  1.19169678e+03
  1.38343091e+03  5.55201782e+02  1.71124939e+02  3.16281555e+02
  9.39263245e+02  1.02645276e+03  7.59069214e+01  4.62747101e+02
  5.74560425e+02  1.18567920e+03  5.25698425e+02  1.27175488e+03
  1.26851367e+03  6.61571960e+02  1.34635327e+03  2.96661682e+02
  1.29088086e+03  1.42173120e+03  3.02242004e+02  1.07034131e+03
  6.78730469e+01  8.23718506e+02  4.69822021e+02  1.45446777e+02
  3.74533997e+01  7.63805542e+01  8.48522705e+02  1.96430939e+02
  1.45172742e+03  9.63192871e+02  1.02907788e+03  1.51363599e+03
  1.12764258e+03  2.90504181e+02  1.38360962e+02  1.30891382e+03
  4.78994598e+02  3.99206970e+02  1.98082687e+02  1.04226257e+03]",44.970097,5187.504,72.02432857201794
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 0.866050929938044, Val Loss: 0.573937970995903', 'Epoch: 1, Train Loss: 0.440329634823969, Val Loss: 0.367430463135242', 'Epoch: 2, Train Loss: 0.389051876068115, Val Loss: 0.350394669324160', 'Epoch: 3, Train Loss: 0.367919686436653, Val Loss: 0.331689070761204', 'Epoch: 4, Train Loss: 0.352655973285437, Val Loss: 0.311139536350965', 'Epoch: 5, Train Loss: 0.339271445934262, Val Loss: 0.327980714887381', 'Epoch: 6, Train Loss: 0.335099925845861, Val Loss: 0.290302628576756', 'Epoch: 7, Train Loss: 0.323754252014416, Val Loss: 0.293653316050768', 'Epoch: 8, Train Loss: 0.304097914493510, Val Loss: 0.292707194089890', 'Epoch: 9, Train Loss: 0.292726367648159, Val Loss: 0.269917368739843', 'Epoch: 10, Train Loss: 0.295353013905031, Val Loss: 0.282247062176466', 'Epoch: 11, Train Loss: 0.292180324154241, Val Loss: 0.286562817543745', 'Epoch: 12, Train Loss: 0.282617169214146, Val Loss: 0.284361670315266', 'Epoch: 13, Train Loss: 0.277117423649345, Val Loss: 0.261494180113077', 'Epoch: 14, Train Loss: 0.269101071645107, Val Loss: 0.266817772611976', 'Epoch: 15, Train Loss: 0.270948352547629, Val Loss: 0.256946745514870', 'Epoch: 16, Train Loss: 0.272431336694530, Val Loss: 0.303282518833876', 'Epoch: 17, Train Loss: 0.262652269484741, Val Loss: 0.263366531208158', 'Epoch: 18, Train Loss: 0.272369911000133, Val Loss: 0.260856658443809', 'Epoch: 19, Train Loss: 0.262566351784127, Val Loss: 0.288175671175122', 'Epoch: 20, Train Loss: 0.254547415269273, Val Loss: 0.259468493759632', 'Epoch: 21, Train Loss: 0.250744558476976, Val Loss: 0.262336937189102', 'Epoch: 22, Train Loss: 0.258081867269107, Val Loss: 0.307199904322624', 'Epoch: 23, Train Loss: 0.257859156248825, Val Loss: 0.262603380680084', 'Epoch: 24, Train Loss: 0.250965253295643, Val Loss: 0.285736559778452', 'Epoch: 25, Train Loss: 0.246765375807881, Val Loss: 0.310480536669493', 'Epoch: 26, Train Loss: 0.242839677291257, Val Loss: 0.259476519525051', 'Epoch: 27, Train Loss: 0.233549238805260, Val Loss: 0.263556076139212', 'Epoch: 28, Train Loss: 0.236725239849516, Val Loss: 0.261007365286350', 'Epoch: 29, Train Loss: 0.238594781958631, Val Loss: 0.256817998141050', 'Epoch: 30, Train Loss: 0.232318679195430, Val Loss: 0.279679857715964', 'Epoch: 31, Train Loss: 0.225245654561690, Val Loss: 0.262208811119199', 'Epoch: 32, Train Loss: 0.218786865526012, Val Loss: 0.270416735559702', 'Epoch: 33, Train Loss: 0.223705916926265, Val Loss: 0.271269481927156', 'Epoch: 34, Train Loss: 0.219305942926024, Val Loss: 0.263491295650601', 'Epoch: 35, Train Loss: 0.218265777198332, Val Loss: 0.263142888844013', 'Epoch: 36, Train Loss: 0.213464263230562, Val Loss: 0.296823316887021', 'Epoch: 37, Train Loss: 0.213448441997170, Val Loss: 0.285334511920810', 'Epoch: 38, Train Loss: 0.208126730737942, Val Loss: 0.273906356468797', 'Epoch: 39, Train Loss: 0.213244516040598, Val Loss: 0.264958881586790', 'Epoch: 40, Train Loss: 0.209095973037183, Val Loss: 0.262751809433103', 'Epoch: 41, Train Loss: 0.196932333356568, Val Loss: 0.263678919374943', 'Epoch: 42, Train Loss: 0.187535177756633, Val Loss: 0.246310391277075', 'Epoch: 43, Train Loss: 0.188191965147853, Val Loss: 0.258231695964932', 'Epoch: 44, Train Loss: 0.180732779002615, Val Loss: 0.259358273744583', 'Epoch: 45, Train Loss: 0.176593305096030, Val Loss: 0.258119817227125', 'Epoch: 46, Train Loss: 0.173816045799426, Val Loss: 0.251100463941693', 'Epoch: 47, Train Loss: 0.174884960624788, Val Loss: 0.251313321888447', 'Epoch: 48, Train Loss: 0.159816325711352, Val Loss: 0.247718117609620', 'Epoch: 49, Train Loss: 0.157010866329074, Val Loss: 0.262083204835653', 'Epoch: 50, Train Loss: 0.153811496198177, Val Loss: 0.278683718889952', 'Epoch: 51, Train Loss: 0.151590376900775, Val Loss: 0.255702067986131', 'Epoch: 52, Train Loss: 0.150502639231937, Val Loss: 0.256937811151147', 'Epoch: 53, Train Loss: 0.141084132194519, Val Loss: 0.262325703948736', 'Epoch: 54, Train Loss: 0.138444191824113, Val Loss: 0.261095595359802', 'Epoch: 55, Train Loss: 0.135887428032500, Val Loss: 0.252487592324615', 'Epoch: 56, Train Loss: 0.135401878468692, Val Loss: 0.275636948831379', 'Epoch: 57, Train Loss: 0.133259709818023, Val Loss: 0.293320413976908', 'Epoch: 58, Train Loss: 0.124491675708975, Val Loss: 0.282541651353240', 'Epoch: 59, Train Loss: 0.124763571295355, Val Loss: 0.263925399929285', 'Epoch: 60, Train Loss: 0.114595054744610, Val Loss: 0.271782415285707', 'Epoch: 61, Train Loss: 0.111874391420611, Val Loss: 0.270235554948449', 'Epoch: 62, Train Loss: 0.116784289372819, Val Loss: 0.267120737135410', 'Epoch: 63, Train Loss: 0.107212972986911, Val Loss: 0.270803812295198', 'Epoch: 64, Train Loss: 0.106383021585643, Val Loss: 0.262285189107060', 'Epoch: 65, Train Loss: 0.105585334668202, Val Loss: 0.259305103421211', 'Epoch: 66, Train Loss: 0.103351649530232, Val Loss: 0.270840395763516', 'Epoch: 67, Train Loss: 0.099713841032769, Val Loss: 0.267011444419622', 'Epoch: 68, Train Loss: 0.096223168570016, Val Loss: 0.286590971723199', 'Epoch: 69, Train Loss: 0.090773219200117, Val Loss: 0.269230246618390', 'Epoch: 70, Train Loss: 0.093270244731435, Val Loss: 0.264181097075343', 'Epoch: 71, Train Loss: 0.089693266749382, Val Loss: 0.277558727115393', 'Epoch: 72, Train Loss: 0.087094844372145, Val Loss: 0.293859072551131', 'Epoch: 73, Train Loss: 0.093215268562947, Val Loss: 0.265528865084052', 'Epoch: 74, Train Loss: 0.082572704468455, Val Loss: 0.283786602318287', 'Epoch: 75, Train Loss: 0.085014298547591, Val Loss: 0.260516719594598', 'Epoch: 76, Train Loss: 0.080185850502125, Val Loss: 0.265855315551162', 'Epoch: 77, Train Loss: 0.074351657293737, Val Loss: 0.269931662455201', 'Epoch: 78, Train Loss: 0.072428418227604, Val Loss: 0.277781111896038', 'Epoch: 79, Train Loss: 0.076679546577590, Val Loss: 0.274214323908091', 'Epoch: 80, Train Loss: 0.073205634525844, Val Loss: 0.263180238381028', 'Epoch: 81, Train Loss: 0.071634684016130, Val Loss: 0.269920335933566', 'Epoch: 82, Train Loss: 0.069462552097227, Val Loss: 0.267686092257500', 'Epoch: 83, Train Loss: 0.065962057411671, Val Loss: 0.269784052446485', 'Epoch: 84, Train Loss: 0.067087150790862, Val Loss: 0.263696327358484', 'Epoch: 85, Train Loss: 0.067020079429661, Val Loss: 0.269074734374881', 'Epoch: 86, Train Loss: 0.065612230428628, Val Loss: 0.283604474663734', 'Epoch: 87, Train Loss: 0.058934059957308, Val Loss: 0.279438718035817', 'Epoch: 88, Train Loss: 0.059981972080256, Val Loss: 0.280386825129390', 'Epoch: 89, Train Loss: 0.061997917906514, Val Loss: 0.284371178746223', 'Epoch: 90, Train Loss: 0.061161835795002, Val Loss: 0.276331321820617', 'Epoch: 91, Train Loss: 0.057428539187780, Val Loss: 0.278899391740561', 'Epoch: 92, Train Loss: 0.055597276453461, Val Loss: 0.272934383526444', 'Epoch: 93, Train Loss: 0.063267953417131, Val Loss: 0.270753881037235', 'Epoch: 94, Train Loss: 0.054780015551618, Val Loss: 0.288729101940989', 'Epoch: 95, Train Loss: 0.054349562121289, Val Loss: 0.272451291084290', 'Epoch: 96, Train Loss: 0.051333952639252, Val Loss: 0.274348485842347', 'Epoch: 97, Train Loss: 0.049627431644393, Val Loss: 0.266957512125373', 'Epoch: 98, Train Loss: 0.051747540666589, Val Loss: 0.273062849566340', 'Epoch: 99, Train Loss: 0.049200021933232, Val Loss: 0.271786062866449', 'Epoch: 100, Train Loss: 0.050451365012143, Val Loss: 0.269200098365545', 'Epoch: 101, Train Loss: 0.047814293945474, Val Loss: 0.268887932673097', 'Epoch: 102, Train Loss: 0.046362749503127, Val Loss: 0.269784310534596', 'Epoch: 103, Train Loss: 0.048194617607764, Val Loss: 0.266955608502030', 'Epoch: 104, Train Loss: 0.046837694126048, Val Loss: 0.282551117241383', 'Epoch: 105, Train Loss: 0.047337123123663, Val Loss: 0.274315337166190', 'Epoch: 106, Train Loss: 0.046013277516301, Val Loss: 0.270291391536593', 'Epoch: 107, Train Loss: 0.046262120053704, Val Loss: 0.277414656206965', 'Epoch: 108, Train Loss: 0.044878996291331, Val Loss: 0.280056296139956', 'Epoch: 109, Train Loss: 0.043055460498269, Val Loss: 0.278003806620836', 'Epoch: 110, Train Loss: 0.044098635895976, Val Loss: 0.268564815074205', 'Epoch: 111, Train Loss: 0.045912356738533, Val Loss: 0.274553071856499', 'Epoch: 112, Train Loss: 0.039227931103004, Val Loss: 0.275181911587715', 'Epoch: 113, Train Loss: 0.041316295066582, Val Loss: 0.278212563246489', 'Epoch: 114, Train Loss: 0.039701242912561, Val Loss: 0.263416162207723', 'Epoch: 115, Train Loss: 0.041142649860787, Val Loss: 0.275672303363681', 'Epoch: 116, Train Loss: 0.041913376642125, Val Loss: 0.283325285986066', 'Epoch: 117, Train Loss: 0.039640149535345, Val Loss: 0.271596237644553', 'Epoch: 118, Train Loss: 0.038175185152463, Val Loss: 0.281600697860122', 'Epoch: 119, Train Loss: 0.040218779686838, Val Loss: 0.271480821594596', 'Epoch: 120, Train Loss: 0.038735328713166, Val Loss: 0.272633256390691', 'Epoch: 121, Train Loss: 0.036871416092451, Val Loss: 0.275917673781514', 'Epoch: 122, Train Loss: 0.037711144661797, Val Loss: 0.278861862048507', 'Epoch: 123, Train Loss: 0.036847313392375, Val Loss: 0.271390527412295', 'Epoch: 124, Train Loss: 0.034073377264930, Val Loss: 0.270152715966105', 'Epoch: 125, Train Loss: 0.034479745602501, Val Loss: 0.274719211980700', 'Epoch: 126, Train Loss: 0.035456392094493, Val Loss: 0.271932174637914', 'Epoch: 127, Train Loss: 0.034765318552298, Val Loss: 0.270330843031406', 'Epoch: 128, Train Loss: 0.032846121279789, Val Loss: 0.269670866727829', 'Epoch: 129, Train Loss: 0.033348339109548, Val Loss: 0.272828522026539', 'Epoch: 130, Train Loss: 0.033172325036888, Val Loss: 0.269014266654849', 'Epoch: 131, Train Loss: 0.033829556035676, Val Loss: 0.270287820100784', 'Epoch: 132, Train Loss: 0.032161811451827, Val Loss: 0.271406549885869', 'Epoch: 133, Train Loss: 0.032308226485870, Val Loss: 0.267721523419023', 'Epoch: 134, Train Loss: 0.032424815573863, Val Loss: 0.267179120630026', 'Epoch: 135, Train Loss: 0.032252595690744, Val Loss: 0.275253319144249', 'Epoch: 136, Train Loss: 0.031676061874522, Val Loss: 0.269051224216819', 'Epoch: 137, Train Loss: 0.031009118530367, Val Loss: 0.272732744961977', 'Epoch: 138, Train Loss: 0.031169331967831, Val Loss: 0.269594845324755', 'Epoch: 139, Train Loss: 0.031192620669359, Val Loss: 0.270880547761917', 'Epoch: 140, Train Loss: 0.031167778463236, Val Loss: 0.267527328655124', 'Epoch: 141, Train Loss: 0.029130889009684, Val Loss: 0.278289817050099', 'Epoch: 142, Train Loss: 0.029126539988709, Val Loss: 0.274344338029623', 'Epoch: 143, Train Loss: 0.029138210888154, Val Loss: 0.266622047424316', 'Epoch: 144, Train Loss: 0.029023075570752, Val Loss: 0.272224031835794', 'Epoch: 145, Train Loss: 0.028813302652644, Val Loss: 0.275603440329433', 'Epoch: 146, Train Loss: 0.028380451830370, Val Loss: 0.269425826519728', 'Epoch: 147, Train Loss: 0.029530687688717, Val Loss: 0.270036114901304', 'Epoch: 148, Train Loss: 0.027357339644805, Val Loss: 0.271997062712908', 'Epoch: 149, Train Loss: 0.027002830776785, Val Loss: 0.276217016130686', 'Epoch: 150, Train Loss: 0.028041382861723, Val Loss: 0.272408478558063', 'Epoch: 151, Train Loss: 0.027607090270945, Val Loss: 0.272147551774979', 'Epoch: 152, Train Loss: 0.027008839803083, Val Loss: 0.271541101485491', 'Epoch: 153, Train Loss: 0.027014970767445, Val Loss: 0.270079157054424', 'Epoch: 154, Train Loss: 0.026725524693195, Val Loss: 0.273654146865010', 'Epoch: 155, Train Loss: 0.027141130050378, Val Loss: 0.264986337572336', 'Epoch: 156, Train Loss: 0.027288992152150, Val Loss: 0.269779716879129', 'Epoch: 157, Train Loss: 0.025680028214785, Val Loss: 0.276366785466671', 'Epoch: 158, Train Loss: 0.026437024551311, Val Loss: 0.269721529781818', 'Epoch: 159, Train Loss: 0.025315023788384, Val Loss: 0.271356067955494', 'Epoch: 160, Train Loss: 0.025247002885278, Val Loss: 0.270100009813905', 'Epoch: 161, Train Loss: 0.025508186475241, Val Loss: 0.273253617063165', 'Epoch: 162, Train Loss: 0.025967453385570, Val Loss: 0.270859357342124', 'Epoch: 163, Train Loss: 0.024713433172022, Val Loss: 0.273427992612123', 'Epoch: 164, Train Loss: 0.024067207754457, Val Loss: 0.270163762569427', 'Epoch: 165, Train Loss: 0.025112509698208, Val Loss: 0.270892908945680', 'Epoch: 166, Train Loss: 0.023959943375417, Val Loss: 0.266637140139937', 'Epoch: 167, Train Loss: 0.023847727285964, Val Loss: 0.273810818642378', 'Epoch: 168, Train Loss: 0.023197700946725, Val Loss: 0.272269002273679', 'Epoch: 169, Train Loss: 0.023095292277368, Val Loss: 0.272163867801428', 'Epoch: 170, Train Loss: 0.022856384470527, Val Loss: 0.268596414104104', 'Epoch: 171, Train Loss: 0.022840704420315, Val Loss: 0.264910664260387', 'Epoch: 172, Train Loss: 0.023018467769559, Val Loss: 0.267935037538409', 'Epoch: 173, Train Loss: 0.022022270701293, Val Loss: 0.273948644921184', 'Epoch: 174, Train Loss: 0.021847521955413, Val Loss: 0.273088797926903', 'Epoch: 175, Train Loss: 0.022704016209713, Val Loss: 0.274840299189091', 'Epoch: 176, Train Loss: 0.021983559574666, Val Loss: 0.272166481167078', 'Epoch: 177, Train Loss: 0.023268659734832, Val Loss: 0.272195052430034', 'Epoch: 178, Train Loss: 0.022530051310148, Val Loss: 0.271087455749512', 'Epoch: 179, Train Loss: 0.021287552067744, Val Loss: 0.269201607853174', 'Epoch: 180, Train Loss: 0.021728949706469, Val Loss: 0.271815083101392', 'Epoch: 181, Train Loss: 0.022827256987137, Val Loss: 0.269087778925896', 'Epoch: 182, Train Loss: 0.020779677891572, Val Loss: 0.270375272706151', 'Epoch: 183, Train Loss: 0.020533765989489, Val Loss: 0.269139958769083', 'Epoch: 184, Train Loss: 0.021316564825497, Val Loss: 0.271857412606478', 'Epoch: 185, Train Loss: 0.021255927812308, Val Loss: 0.271244072690606', 'Epoch: 186, Train Loss: 0.020561152983989, Val Loss: 0.267861517518759', 'Epoch: 187, Train Loss: 0.020188973906583, Val Loss: 0.271387402936816', 'Epoch: 188, Train Loss: 0.021166806588215, Val Loss: 0.272759772464633', 'Epoch: 189, Train Loss: 0.020806638092867, Val Loss: 0.266967858076096', 'Epoch: 190, Train Loss: 0.020975655645930, Val Loss: 0.270546615868807', 'Epoch: 191, Train Loss: 0.019764572109229, Val Loss: 0.268076573237777', 'Epoch: 192, Train Loss: 0.020010532267126, Val Loss: 0.269326652139425', 'Epoch: 193, Train Loss: 0.019588447914326, Val Loss: 0.270724939331412', 'Epoch: 194, Train Loss: 0.019654189989503, Val Loss: 0.270621573626995', 'Epoch: 195, Train Loss: 0.020101647611175, Val Loss: 0.271058973893523', 'Epoch: 196, Train Loss: 0.019257122352719, Val Loss: 0.270085320770740', 'Epoch: 197, Train Loss: 0.018843415056222, Val Loss: 0.269370828643441', 'Epoch: 198, Train Loss: 0.019765349482851, Val Loss: 0.269868389442563', 'Epoch: 199, Train Loss: 0.019100486451228, Val Loss: 0.269855553135276']",[ 626.1049  1346.7102    87.91559 ... 1318.2734   625.9475  1203.6821 ],[ 546.8647  1424.8615    48.91812 ... 1268.8794   662.18335 1591.5476 ],121.136696,36576.176,191.24898896791586
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 0.363583282675854, Val Loss: 0.326214181184769', 'Epoch: 1, Train Loss: 0.332377229665601, Val Loss: 0.285993850231171', 'Epoch: 2, Train Loss: 0.265084392456121, Val Loss: 0.195940275192261', 'Epoch: 3, Train Loss: 0.151123476409635, Val Loss: 0.068739208579063', 'Epoch: 4, Train Loss: 0.063130750299193, Val Loss: 0.051129415184259', 'Epoch: 5, Train Loss: 0.054512779986443, Val Loss: 0.044358408898115', 'Epoch: 6, Train Loss: 0.051492151002898, Val Loss: 0.046083535552025', 'Epoch: 7, Train Loss: 0.045807902982762, Val Loss: 0.045153800100088', 'Epoch: 8, Train Loss: 0.047021943469380, Val Loss: 0.040860132575035', 'Epoch: 9, Train Loss: 0.048328925357308, Val Loss: 0.042277598083019', 'Epoch: 10, Train Loss: 0.045456259403118, Val Loss: 0.041638979464769', 'Epoch: 11, Train Loss: 0.043204288279941, Val Loss: 0.039312176406384', 'Epoch: 12, Train Loss: 0.045378160987829, Val Loss: 0.041710731014609', 'Epoch: 13, Train Loss: 0.040534520738347, Val Loss: 0.043359936475754', 'Epoch: 14, Train Loss: 0.042434951420440, Val Loss: 0.036552599519491', 'Epoch: 15, Train Loss: 0.036993455271735, Val Loss: 0.033265955001116', 'Epoch: 16, Train Loss: 0.039495219801401, Val Loss: 0.033859161436558', 'Epoch: 17, Train Loss: 0.040632090509631, Val Loss: 0.034977641403675', 'Epoch: 18, Train Loss: 0.035311862219905, Val Loss: 0.037630062103271', 'Epoch: 19, Train Loss: 0.035504414894900, Val Loss: 0.030572816729546', 'Epoch: 20, Train Loss: 0.040214124027380, Val Loss: 0.044763956069946', 'Epoch: 21, Train Loss: 0.037712433310442, Val Loss: 0.035574705153704', 'Epoch: 22, Train Loss: 0.035017654429688, Val Loss: 0.038959539532661', 'Epoch: 23, Train Loss: 0.031991942677387, Val Loss: 0.029268944859505', 'Epoch: 24, Train Loss: 0.033930790632270, Val Loss: 0.034326009750366', 'Epoch: 25, Train Loss: 0.038134748765896, Val Loss: 0.045940580070019', 'Epoch: 26, Train Loss: 0.040004124605032, Val Loss: 0.027879993766546', 'Epoch: 27, Train Loss: 0.029888008244682, Val Loss: 0.030195662975311', 'Epoch: 28, Train Loss: 0.032503944453458, Val Loss: 0.039878168925643', 'Epoch: 29, Train Loss: 0.033679697922496, Val Loss: 0.025302575379610', 'Epoch: 30, Train Loss: 0.032456507776366, Val Loss: 0.028674106150866', 'Epoch: 31, Train Loss: 0.030258286311183, Val Loss: 0.029976933002472', 'Epoch: 32, Train Loss: 0.031447741614525, Val Loss: 0.025619540065527', 'Epoch: 33, Train Loss: 0.029588799598778, Val Loss: 0.027452622056007', 'Epoch: 34, Train Loss: 0.031714153432742, Val Loss: 0.027026601284742', 'Epoch: 35, Train Loss: 0.032564941533776, Val Loss: 0.032430899888277', 'Epoch: 36, Train Loss: 0.030379738355445, Val Loss: 0.027259719669819', 'Epoch: 37, Train Loss: 0.032457506089190, Val Loss: 0.032752488404512', 'Epoch: 38, Train Loss: 0.029767914826787, Val Loss: 0.028925483524799', 'Epoch: 39, Train Loss: 0.034667470362471, Val Loss: 0.029230117946863', 'Epoch: 40, Train Loss: 0.032191348262131, Val Loss: 0.025045999288559', 'Epoch: 41, Train Loss: 0.027937779896135, Val Loss: 0.025752463191748', 'Epoch: 42, Train Loss: 0.030770558430705, Val Loss: 0.027329715341330', 'Epoch: 43, Train Loss: 0.026225406806483, Val Loss: 0.023713975101709', 'Epoch: 44, Train Loss: 0.028864583780253, Val Loss: 0.027779039442539', 'Epoch: 45, Train Loss: 0.027500830569066, Val Loss: 0.029435503371060', 'Epoch: 46, Train Loss: 0.028476082893132, Val Loss: 0.030771837532520', 'Epoch: 47, Train Loss: 0.027607781119471, Val Loss: 0.025619064867496', 'Epoch: 48, Train Loss: 0.028311730362475, Val Loss: 0.046566406413913', 'Epoch: 49, Train Loss: 0.030331509989188, Val Loss: 0.023882865533233', 'Epoch: 50, Train Loss: 0.026053799359604, Val Loss: 0.024742036759853', 'Epoch: 51, Train Loss: 0.026654870747480, Val Loss: 0.028189290910959', 'Epoch: 52, Train Loss: 0.025314487408587, Val Loss: 0.024749045073986', 'Epoch: 53, Train Loss: 0.026296198324755, Val Loss: 0.027215244174004', 'Epoch: 54, Train Loss: 0.025988131934820, Val Loss: 0.024238880723715', 'Epoch: 55, Train Loss: 0.024899363106247, Val Loss: 0.026179782524705', 'Epoch: 56, Train Loss: 0.024258960146717, Val Loss: 0.025781757980585', 'Epoch: 57, Train Loss: 0.025536429786751, Val Loss: 0.023639488108456', 'Epoch: 58, Train Loss: 0.028482679645856, Val Loss: 0.033443323075771', 'Epoch: 59, Train Loss: 0.025696355156427, Val Loss: 0.024434823393822', 'Epoch: 60, Train Loss: 0.025244673800676, Val Loss: 0.025564797222614', 'Epoch: 61, Train Loss: 0.023608917175511, Val Loss: 0.022971439957619', 'Epoch: 62, Train Loss: 0.024903418539568, Val Loss: 0.026868027448654', 'Epoch: 63, Train Loss: 0.024999397481943, Val Loss: 0.023459465280175', 'Epoch: 64, Train Loss: 0.023377590812743, Val Loss: 0.022046245932579', 'Epoch: 65, Train Loss: 0.024739346856814, Val Loss: 0.023955394923687', 'Epoch: 66, Train Loss: 0.025546636150847, Val Loss: 0.024370210766792', 'Epoch: 67, Train Loss: 0.024537633909562, Val Loss: 0.023830361664295', 'Epoch: 68, Train Loss: 0.024686685698323, Val Loss: 0.029774347394705', 'Epoch: 69, Train Loss: 0.024649583864524, Val Loss: 0.022993457615376', 'Epoch: 70, Train Loss: 0.023528448132755, Val Loss: 0.024050642102957', 'Epoch: 71, Train Loss: 0.023845868445067, Val Loss: 0.026091981232166', 'Epoch: 72, Train Loss: 0.023074864366547, Val Loss: 0.022499941289425', 'Epoch: 73, Train Loss: 0.022287385429927, Val Loss: 0.024012750387192', 'Epoch: 74, Train Loss: 0.022985405115367, Val Loss: 0.024266036823392', 'Epoch: 75, Train Loss: 0.021568433078396, Val Loss: 0.024254872202873', 'Epoch: 76, Train Loss: 0.023309857822781, Val Loss: 0.025995678901672', 'Epoch: 77, Train Loss: 0.022560002758752, Val Loss: 0.024512999951839', 'Epoch: 78, Train Loss: 0.021325474583306, Val Loss: 0.032122611105442', 'Epoch: 79, Train Loss: 0.026792765508384, Val Loss: 0.023307474553585', 'Epoch: 80, Train Loss: 0.020553806081934, Val Loss: 0.027613445967436', 'Epoch: 81, Train Loss: 0.022392501274860, Val Loss: 0.021992344111204', 'Epoch: 82, Train Loss: 0.020864543678282, Val Loss: 0.022585383951664', 'Epoch: 83, Train Loss: 0.021327230126359, Val Loss: 0.024689099043608', 'Epoch: 84, Train Loss: 0.022929964002308, Val Loss: 0.026016665399075', 'Epoch: 85, Train Loss: 0.022153807652378, Val Loss: 0.023111211359501', 'Epoch: 86, Train Loss: 0.020336656766229, Val Loss: 0.024110215157270', 'Epoch: 87, Train Loss: 0.022575256046514, Val Loss: 0.024066207557917', 'Epoch: 88, Train Loss: 0.020977367083867, Val Loss: 0.026665533035994', 'Epoch: 89, Train Loss: 0.021756286646218, Val Loss: 0.026125444099307', 'Epoch: 90, Train Loss: 0.022403200037864, Val Loss: 0.026142737567425', 'Epoch: 91, Train Loss: 0.022779878553783, Val Loss: 0.024215694963932', 'Epoch: 92, Train Loss: 0.021864732727408, Val Loss: 0.022981265783310', 'Epoch: 93, Train Loss: 0.020217537360136, Val Loss: 0.023078538179398', 'Epoch: 94, Train Loss: 0.021305198672899, Val Loss: 0.025910049676895', 'Epoch: 95, Train Loss: 0.021381233082434, Val Loss: 0.027132913470268', 'Epoch: 96, Train Loss: 0.021269179599056, Val Loss: 0.022221709340811', 'Epoch: 97, Train Loss: 0.020318517937910, Val Loss: 0.022675198763609', 'Epoch: 98, Train Loss: 0.019334280170327, Val Loss: 0.023943425714970', 'Epoch: 99, Train Loss: 0.020219109172738, Val Loss: 0.022970677465200', 'Epoch: 100, Train Loss: 0.020058670449396, Val Loss: 0.024128325283527', 'Epoch: 101, Train Loss: 0.018901576526290, Val Loss: 0.023454009741545', 'Epoch: 102, Train Loss: 0.019367601917407, Val Loss: 0.021799265146255', 'Epoch: 103, Train Loss: 0.021483307531060, Val Loss: 0.026445674225688', 'Epoch: 104, Train Loss: 0.019550590559320, Val Loss: 0.026262834966183', 'Epoch: 105, Train Loss: 0.020069506571650, Val Loss: 0.023721610754728', 'Epoch: 106, Train Loss: 0.018908540415036, Val Loss: 0.025153900831938', 'Epoch: 107, Train Loss: 0.019992247310489, Val Loss: 0.022946584075689', 'Epoch: 108, Train Loss: 0.018821641456249, Val Loss: 0.025612219572067', 'Epoch: 109, Train Loss: 0.021509947818379, Val Loss: 0.026464545130730', 'Epoch: 110, Train Loss: 0.020898036767057, Val Loss: 0.025812381505966', 'Epoch: 111, Train Loss: 0.020311656819527, Val Loss: 0.021848798617721', 'Epoch: 112, Train Loss: 0.018900523092165, Val Loss: 0.022676533907652', 'Epoch: 113, Train Loss: 0.020081700692170, Val Loss: 0.023313402682543', 'Epoch: 114, Train Loss: 0.019693702286066, Val Loss: 0.023186995014548', 'Epoch: 115, Train Loss: 0.018740165090665, Val Loss: 0.027385393679142', 'Epoch: 116, Train Loss: 0.017744499746017, Val Loss: 0.023010576516390', 'Epoch: 117, Train Loss: 0.018679218724110, Val Loss: 0.025408119335771', 'Epoch: 118, Train Loss: 0.019452974211078, Val Loss: 0.023947137445211', 'Epoch: 119, Train Loss: 0.018539125554610, Val Loss: 0.022463931739330', 'Epoch: 120, Train Loss: 0.018787313122735, Val Loss: 0.024343605339527', 'Epoch: 121, Train Loss: 0.018698969184486, Val Loss: 0.023438112586737', 'Epoch: 122, Train Loss: 0.018988428853972, Val Loss: 0.023254791125655', 'Epoch: 123, Train Loss: 0.018799039600200, Val Loss: 0.025374590307474', 'Epoch: 124, Train Loss: 0.017021487207087, Val Loss: 0.023612295240164', 'Epoch: 125, Train Loss: 0.018105755820004, Val Loss: 0.027655194103718', 'Epoch: 126, Train Loss: 0.016454665076941, Val Loss: 0.023288627266884', 'Epoch: 127, Train Loss: 0.017464783735747, Val Loss: 0.022767714485526', 'Epoch: 128, Train Loss: 0.017970869566725, Val Loss: 0.024083888605237', 'Epoch: 129, Train Loss: 0.017583780033990, Val Loss: 0.024520178735256', 'Epoch: 130, Train Loss: 0.018105824477971, Val Loss: 0.024735305383801', 'Epoch: 131, Train Loss: 0.017970614221900, Val Loss: 0.023472111821175', 'Epoch: 132, Train Loss: 0.017115480223194, Val Loss: 0.023314723297954', 'Epoch: 133, Train Loss: 0.017733162355631, Val Loss: 0.022741483524442', 'Epoch: 134, Train Loss: 0.017807525810028, Val Loss: 0.027463340759277', 'Epoch: 135, Train Loss: 0.017727074018398, Val Loss: 0.022901222556829', 'Epoch: 136, Train Loss: 0.016708906198484, Val Loss: 0.026048001497984', 'Epoch: 137, Train Loss: 0.017734484757882, Val Loss: 0.023947809189558', 'Epoch: 138, Train Loss: 0.017466262611019, Val Loss: 0.025943669453263', 'Epoch: 139, Train Loss: 0.017946201311641, Val Loss: 0.026148439645767', 'Epoch: 140, Train Loss: 0.017496016309705, Val Loss: 0.025022333562374', 'Epoch: 141, Train Loss: 0.016687064691512, Val Loss: 0.023731587231159', 'Epoch: 142, Train Loss: 0.017874899894259, Val Loss: 0.024126858413219', 'Epoch: 143, Train Loss: 0.017063610558940, Val Loss: 0.022915662080050', 'Epoch: 144, Train Loss: 0.017204858427651, Val Loss: 0.024558109939098', 'Epoch: 145, Train Loss: 0.015438943624843, Val Loss: 0.023742155432701', 'Epoch: 146, Train Loss: 0.016484557845911, Val Loss: 0.023197670727968', 'Epoch: 147, Train Loss: 0.016246370624664, Val Loss: 0.023447142168880', 'Epoch: 148, Train Loss: 0.016457701816635, Val Loss: 0.023166236877441', 'Epoch: 149, Train Loss: 0.016895239761229, Val Loss: 0.022878232970834', 'Epoch: 150, Train Loss: 0.016108227839563, Val Loss: 0.023643177747726', 'Epoch: 151, Train Loss: 0.016508425867488, Val Loss: 0.024366153851151', 'Epoch: 152, Train Loss: 0.014963071999075, Val Loss: 0.022670949101448', 'Epoch: 153, Train Loss: 0.015094254155059, Val Loss: 0.024239840805531', 'Epoch: 154, Train Loss: 0.015389318188089, Val Loss: 0.025136087983847', 'Epoch: 155, Train Loss: 0.014524641056913, Val Loss: 0.024546581953764', 'Epoch: 156, Train Loss: 0.015937999042487, Val Loss: 0.024462689012289', 'Epoch: 157, Train Loss: 0.015355267800217, Val Loss: 0.022822574898601', 'Epoch: 158, Train Loss: 0.015068139924213, Val Loss: 0.024554356932640', 'Epoch: 159, Train Loss: 0.014464162918198, Val Loss: 0.023750794008374', 'Epoch: 160, Train Loss: 0.014898145506375, Val Loss: 0.023456505686045', 'Epoch: 161, Train Loss: 0.015276163123375, Val Loss: 0.023642616793513', 'Epoch: 162, Train Loss: 0.014813173692240, Val Loss: 0.024683430790901', 'Epoch: 163, Train Loss: 0.014339226980282, Val Loss: 0.024096131846309', 'Epoch: 164, Train Loss: 0.014863114728224, Val Loss: 0.024415005743504', 'Epoch: 165, Train Loss: 0.014070628395001, Val Loss: 0.024235708713531', 'Epoch: 166, Train Loss: 0.014621897979618, Val Loss: 0.025787656828761', 'Epoch: 167, Train Loss: 0.014955330726712, Val Loss: 0.025003927052021', 'Epoch: 168, Train Loss: 0.014539329053531, Val Loss: 0.024520354270935', 'Epoch: 169, Train Loss: 0.013072222601189, Val Loss: 0.024330676645041', 'Epoch: 170, Train Loss: 0.013624033446662, Val Loss: 0.024898638427258', 'Epoch: 171, Train Loss: 0.014351018011397, Val Loss: 0.023930619359016', 'Epoch: 172, Train Loss: 0.014674726299682, Val Loss: 0.025961290225387', 'Epoch: 173, Train Loss: 0.012452129058020, Val Loss: 0.024033574908972', 'Epoch: 174, Train Loss: 0.013259417366583, Val Loss: 0.024123164266348', 'Epoch: 175, Train Loss: 0.013836502000083, Val Loss: 0.024659730643034', 'Epoch: 176, Train Loss: 0.013970044809718, Val Loss: 0.024696861803532', 'Epoch: 177, Train Loss: 0.013015463201026, Val Loss: 0.024710655957460', 'Epoch: 178, Train Loss: 0.013705648384382, Val Loss: 0.024310127794743', 'Epoch: 179, Train Loss: 0.012902185234220, Val Loss: 0.024822305440903', 'Epoch: 180, Train Loss: 0.013077660398774, Val Loss: 0.024259888678789', 'Epoch: 181, Train Loss: 0.013248150843347, Val Loss: 0.023800241574645', 'Epoch: 182, Train Loss: 0.013701169979001, Val Loss: 0.024930341541767', 'Epoch: 183, Train Loss: 0.013570786843639, Val Loss: 0.024209057837725', 'Epoch: 184, Train Loss: 0.013374283173403, Val Loss: 0.024016622826457', 'Epoch: 185, Train Loss: 0.013631608163895, Val Loss: 0.024101676046848', 'Epoch: 186, Train Loss: 0.012948618606166, Val Loss: 0.023938875496387', 'Epoch: 187, Train Loss: 0.012877843537649, Val Loss: 0.024551213309169', 'Epoch: 188, Train Loss: 0.013385552328167, Val Loss: 0.024598151743412', 'Epoch: 189, Train Loss: 0.012825414067308, Val Loss: 0.024118996411562', 'Epoch: 190, Train Loss: 0.012835396345445, Val Loss: 0.024358742237091', 'Epoch: 191, Train Loss: 0.012600349413967, Val Loss: 0.024122313559055', 'Epoch: 192, Train Loss: 0.012734477234961, Val Loss: 0.024055580943823', 'Epoch: 193, Train Loss: 0.012105965542845, Val Loss: 0.023881231397390', 'Epoch: 194, Train Loss: 0.014120270866294, Val Loss: 0.023967541903257', 'Epoch: 195, Train Loss: 0.012403842484102, Val Loss: 0.023937099352479', 'Epoch: 196, Train Loss: 0.012540956168587, Val Loss: 0.024003921896219', 'Epoch: 197, Train Loss: 0.012464987991248, Val Loss: 0.023820022195578', 'Epoch: 198, Train Loss: 0.012991061293368, Val Loss: 0.023820835426450', 'Epoch: 199, Train Loss: 0.012699722864687, Val Loss: 0.023923189565539']","[ 754.61475     97.42377    158.14053   1186.0092    1100.176
  104.27222    310.00125    391.33197    894.4432     591.16583
  173.13165     19.727844   780.9375     169.95193     70.40051
  153.59015    456.17374    652.65466      2.2502747  269.1156
  734.9617    1183.5093      48.104126   920.30786    666.303
 1121.5784      46.450974   382.49048    951.378      563.8589
  120.861694   554.2423     565.4727      36.581665   345.38657
  547.24445   1230.6567     307.52368   1406.9412     513.1842
  373.10187   1118.6813      39.0036    1040.5222     389.26315
 1074.6207     871.55237   1087.1145     946.89874    548.2731
   46.20291   1045.3413     462.3793      60.77997   1186.1846
 1237.3528     442.60812     44.225647   713.5736      75.3656
 1023.0827    1101.0829    1186.4725     731.03864    977.2838
  671.51166    637.73267    563.4795     564.8236    1252.8528
   38.821747   306.98596    394.9646     730.3208     400.33142
  120.64932    853.73914    451.35275   1067.0028     705.13257
  526.56433    657.75366    373.27112    746.8778     273.26614
  572.0071      63.516052  1023.2105     197.81555    975.8574
  160.88342    217.36932    224.74188    569.8727      68.83832
  540.7717     380.32172    269.644      178.77675    641.5297
   79.65781    587.62317    459.58054     65.43732    374.8637
 1088.0458     486.92947    524.8185     693.50543    655.49786
  163.91357    705.058     1041.0581     323.7646     140.32587
  355.80075     88.39078    549.1387     345.7357    1118.8352
   83.2384     675.36914    827.11676   1021.7004     859.9035
  430.95157    944.0414      44.65631    465.11234    535.85657
  432.15707    973.40826      4.117157   513.5219    1361.6686
  125.29822   1102.2449     848.35657    321.45984    165.14624
  176.54437    551.1207      59.968887    41.724533   566.1559
 1299.769      975.8636     685.29205   1015.2034     951.0977
   53.853912    78.60184     67.29549     48.592316   639.15814
   24.012573   937.9747     279.43814    351.21973    379.23608
   62.762497   349.43884    714.9059     643.7886    1053.8757
  428.55356    180.6836     770.1936     372.1075     376.14294
    1.6113586  551.7114     377.8321     417.99625    235.05647
   60.358032   669.9981     202.03546   1234.3539     445.3216
  710.324      162.27118    282.4538     160.22673    667.56714
  325.1936     580.4871     932.5768      36.7771       4.3454895
  135.52171    201.62183      3.916565   900.203     1072.9689
  370.5279     111.855194   140.83392    418.43655     97.21088
  450.44705   1385.708      341.22778    545.7722     566.48627
  530.03235    838.7342     649.276     1033.2789      58.282043
  157.53317    427.20206     39.75934    713.0162    1429.1215
 1320.806      783.381      570.1168    1351.4679     964.23517
  379.3313     671.0469     237.32996      5.294098   650.5582
  734.07043    351.54538    545.83606    612.058      471.77994
  944.3368     110.68292    263.01477    576.7248      44.00284
  390.74808    953.9908     256.64743    903.4203      37.25699
  880.0132     273.41028    315.9381    1052.9164     863.71436
  884.44147    673.53345     26.792542    70.4389    1028.1637
   81.14157    486.08307    260.16946    628.3123     894.7617
  277.73654    369.091      556.3142    1259.7731     843.9381
  252.1992     664.1553     842.00037    687.0227    1034.9741
  692.4924    1160.4696      38.177185   670.17664    842.2284
  243.12071    525.1533     368.09662    417.59708    588.10266
  104.5094     321.7729     123.35571     83.99245    299.1981
  535.83154    169.54077    795.42523    326.70697    373.8099
  649.5505     368.16507    174.4997     194.2343     280.80118
   59.065002   950.72363    480.52438    312.0552     292.03036
  130.7554     115.03247    549.97217     86.54547   1192.1072
   19.060913  1040.2966      87.20868     63.780243   474.38312
  370.18323     66.016815    54.467316    65.13632    320.9296
  992.29224    349.66843    142.96838    608.20123    295.42715
  810.3058     107.76669    223.33801    748.79156    664.28094
 1087.1013     887.66534    136.19025    730.8425     127.65503
 1405.9531     586.7429     253.09467   1269.8574    1067.8019
  135.53015    828.756      765.11066    600.86536   1024.2732
  648.44336    578.2914      60.312912   970.2869    1263.8267
  840.8305    1058.7883     296.97302    693.8479    1297.6204
   64.89026    754.53125    791.94336    494.238     1233.5281
  225.81189   1225.8948     600.74634    108.01166     49.797974
  535.1049     797.64386    868.2418     889.50964    346.96674
  856.5029     373.35306    536.3993     169.65112    921.84656
 1083.5918    1002.8652     481.83667    604.0878     256.40222
 1031.4175     127.7457     197.35635    668.0109     209.33005
   83.73291    127.23183    397.53262    111.405334   989.9154
    8.580841   155.45877    771.08875    680.7239     202.36829
    4.9738464  717.927      692.8268     215.85161     15.129181
  268.8397    1165.1152     597.57166    244.3035     715.0655
 1137.3623     775.3104     769.4473     701.1074     569.9599   ]","[ 721.11896   159.7142    252.78464  1054.904    1048.9097    259.40283
  387.51154   386.94742   977.6599    654.7735    213.4811     45.139038
  741.92053   214.2417     44.18849   140.6381    349.8083    523.45703
   53.95404   267.48645   717.3249   1148.8391     34.746277  899.75525
  656.52496  1153.0027     72.41281   396.2725    952.1279    543.2663
  127.92285   602.2719    629.802     181.33008   429.54266   552.01666
 1230.3665    270.74915  1427.0667    443.185     431.7936   1034.3842
  193.2688    873.6592    398.93994  1044.6414    863.3212   1029.1565
  921.5881    553.63855   229.72778   824.97815   452.15622    65.70477
 1168.2489   1180.0377    440.27258    55.168213  729.8387    213.72363
  992.37726  1099.0504   1156.0033    744.8985   1048.3793    687.10034
  608.67053   538.06555   659.9283   1315.9542     41.95517   298.29944
  399.99396   711.55237   475.36325    91.89905   878.1326    434.71243
 1234.5425    736.2109    381.87628   569.53174   393.3809    771.0134
  321.7991    583.1121    106.390076 1033.0076    129.79517   939.00507
   74.272736  214.97148   260.0098    516.6203    138.88994   429.69308
  254.85788   130.8258    180.92847   656.4161    112.5499    606.067
  449.8157    127.20636   361.64883  1154.888     542.8087    547.1918
  690.3717    717.398     168.80722   810.86304   997.80145   298.82172
  177.37682   355.76978    37.259552  682.6383    269.71875  1208.7786
  291.85214   564.4465    854.2187   1061.2065    870.9509    486.39893
  859.9287    209.05295   409.71216   578.6255    459.63574   955.7484
   52.46544   492.73047  1221.0234    201.21158  1035.7574    838.85376
  264.1319    153.51727   225.59872   484.95795    73.28035    27.219086
  611.0763   1303.2142   1190.0358    640.7753   1107.429    1037.7094
  105.7948    126.83734   103.26529    54.477173  666.5006    122.691284
 1027.1144    329.79138   336.0051    449.53607   120.7206    331.60098
  570.00867   586.9187   1059.7024    377.37143   227.23267   774.2623
  360.3931    360.93558    90.235596  498.72177   395.0122    455.76746
  278.4694     55.213654  677.376     197.46951  1270.5912    407.0375
  648.7793    348.07397   276.0535    124.62048   709.65466   300.5108
  641.8967    909.7929    130.74207    39.283096   59.185364  195.25534
  173.60767   760.7785   1083.5647    365.09207   179.30746   133.05792
  411.01514    89.78296   471.0261   1434.9304    172.8042    541.6443
  468.80194   603.97974   832.2802    666.8733    964.0171    147.5946
  130.79846   588.7648     30.298096  743.8605   1269.1112   1124.984
  779.7035    599.63745  1185.4266    996.10504   403.9854    674.8081
  208.05461    27.899445  713.07263   754.6128    292.51022   445.5279
  561.4773    438.8672    934.6009     80.061035  238.24823   598.4541
   92.39584   390.51926   950.0785    310.24344   813.92206    95.01404
  704.19775   385.0577    328.8441   1081.0073    929.562     979.15686
  629.0312     62.633606  109.53839  1008.65186   137.79391   501.24362
  286.96652   569.9659    844.2793    341.3025    371.5248    481.57547
 1265.8772    761.9236    255.71573   677.2543    957.0309    646.694
  934.89154   721.9965   1106.8959     98.0553    663.50446   937.7691
  213.80273   554.82043   330.98563   402.7903    589.65076   186.74005
  344.61826   117.14899    51.145233  239.04593   585.3485    112.849976
  825.1476    217.87854   437.26575   694.38403   330.04633   148.75473
  152.0104    269.95493    58.55652   960.798     511.0748    350.67297
  302.76114    61.940796   66.04645   613.2008    108.95807  1134.3667
  246.66583   908.3463     79.170044   37.716736  531.8339    450.1778
   71.7204     59.88922   125.720276  317.0808   1010.7889    390.39914
  225.00793   528.073     247.57967   839.9843     94.567505  195.75122
  677.23914   596.9645    924.8002    840.4683    104.26651   728.7268
  213.9635   1285.6117    615.9636    239.20294  1115.1775   1016.62634
  204.03519   757.42804   970.56104   604.2177    985.7312    611.0838
  513.42316    93.54637  1046.8866   1309.9392    915.9518   1107.8049
  324.29376   625.30066  1126.0388    141.03442   732.7435    753.5011
  498.5727   1190.3712    206.82202  1194.6208    659.6029    168.7528
   59.92119   509.90167   818.732     947.26715   883.29626   317.79095
  811.102     400.543     594.8854    221.73401   983.65704  1201.8828
 1075.742     486.32437   581.2756    299.68472   963.1144    139.39197
  123.90289   634.2381    181.78204    44.89096   111.22191   376.3609
   83.050964  983.20685    58.862793  202.89908   842.59247   718.09357
  231.04813   142.31169   808.94275   809.87854   230.30153    39.981598
  292.04904  1205.0677    648.26624   281.68182   654.9123   1188.9568
  844.24066   825.25275   711.6618    560.07574 ]",50.652344,4592.6924,67.76940594997495
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 0.500680990690409, Val Loss: 0.474302296638489', 'Epoch: 1, Train Loss: 0.464948760908703, Val Loss: 0.422600617408752', 'Epoch: 2, Train Loss: 0.408648859622867, Val Loss: 0.315970407724381', 'Epoch: 3, Train Loss: 0.275995030306106, Val Loss: 0.137427810430527', 'Epoch: 4, Train Loss: 0.154737872959569, Val Loss: 0.090804901719093', 'Epoch: 5, Train Loss: 0.126889889929877, Val Loss: 0.094507031440735', 'Epoch: 6, Train Loss: 0.120607638948186, Val Loss: 0.075418625473976', 'Epoch: 7, Train Loss: 0.106377027668925, Val Loss: 0.082948827743530', 'Epoch: 8, Train Loss: 0.102309990327719, Val Loss: 0.102289185523987', 'Epoch: 9, Train Loss: 0.105197042919869, Val Loss: 0.089504907727242', 'Epoch: 10, Train Loss: 0.096801222063774, Val Loss: 0.065529927015305', 'Epoch: 11, Train Loss: 0.098956903052884, Val Loss: 0.062779116034508', 'Epoch: 12, Train Loss: 0.102833587243113, Val Loss: 0.063538455963135', 'Epoch: 13, Train Loss: 0.090022722822289, Val Loss: 0.066326121687889', 'Epoch: 14, Train Loss: 0.089357680792725, Val Loss: 0.074916708469391', 'Epoch: 15, Train Loss: 0.085162009783956, Val Loss: 0.073474867939949', 'Epoch: 16, Train Loss: 0.093818179310061, Val Loss: 0.068029804229736', 'Epoch: 17, Train Loss: 0.087900576809811, Val Loss: 0.066171249747276', 'Epoch: 18, Train Loss: 0.082015434150086, Val Loss: 0.066885704398155', 'Epoch: 19, Train Loss: 0.078102593938279, Val Loss: 0.069892203807831', 'Epoch: 20, Train Loss: 0.088812820180211, Val Loss: 0.057082452774048', 'Epoch: 21, Train Loss: 0.083952129926792, Val Loss: 0.083743652701378', 'Epoch: 22, Train Loss: 0.084166682303645, Val Loss: 0.060808736085892', 'Epoch: 23, Train Loss: 0.084362959879082, Val Loss: 0.067303314208984', 'Epoch: 24, Train Loss: 0.077515043924714, Val Loss: 0.061002857387066', 'Epoch: 25, Train Loss: 0.077768665066985, Val Loss: 0.062037566304207', 'Epoch: 26, Train Loss: 0.075793534344019, Val Loss: 0.056106086969376', 'Epoch: 27, Train Loss: 0.075030533293652, Val Loss: 0.060038579106331', 'Epoch: 28, Train Loss: 0.079014232165592, Val Loss: 0.056749017238617', 'Epoch: 29, Train Loss: 0.070586860006632, Val Loss: 0.065207340717316', 'Epoch: 30, Train Loss: 0.071815605686848, Val Loss: 0.051518310904503', 'Epoch: 31, Train Loss: 0.075406359292047, Val Loss: 0.094613186120987', 'Epoch: 32, Train Loss: 0.074247403720091, Val Loss: 0.059746298193932', 'Epoch: 33, Train Loss: 0.069888492049866, Val Loss: 0.067424199581146', 'Epoch: 34, Train Loss: 0.073113452643156, Val Loss: 0.073605176210403', 'Epoch: 35, Train Loss: 0.068949228109315, Val Loss: 0.055584062039852', 'Epoch: 36, Train Loss: 0.077516193653262, Val Loss: 0.084161754250526', 'Epoch: 37, Train Loss: 0.078958396864838, Val Loss: 0.056394038200378', 'Epoch: 38, Train Loss: 0.069099614526643, Val Loss: 0.071167013645172', 'Epoch: 39, Train Loss: 0.068574610707718, Val Loss: 0.078349883556366', 'Epoch: 40, Train Loss: 0.070978648094244, Val Loss: 0.055157164335251', 'Epoch: 41, Train Loss: 0.063946915833756, Val Loss: 0.074820384979248', 'Epoch: 42, Train Loss: 0.064596760541547, Val Loss: 0.051835489571095', 'Epoch: 43, Train Loss: 0.065367300929718, Val Loss: 0.049862020611763', 'Epoch: 44, Train Loss: 0.066987866492465, Val Loss: 0.057458478510380', 'Epoch: 45, Train Loss: 0.065959407146587, Val Loss: 0.055164013504982', 'Epoch: 46, Train Loss: 0.059684706158763, Val Loss: 0.062451490163803', 'Epoch: 47, Train Loss: 0.056191413598352, Val Loss: 0.056507413089275', 'Epoch: 48, Train Loss: 0.057686672827532, Val Loss: 0.047695530653000', 'Epoch: 49, Train Loss: 0.056086736103130, Val Loss: 0.051044173240662', 'Epoch: 50, Train Loss: 0.061056132839863, Val Loss: 0.049782837927341', 'Epoch: 51, Train Loss: 0.057989177575638, Val Loss: 0.053044283986092', 'Epoch: 52, Train Loss: 0.054962907203062, Val Loss: 0.051052704751492', 'Epoch: 53, Train Loss: 0.054606846165518, Val Loss: 0.048480330407619', 'Epoch: 54, Train Loss: 0.055703095182083, Val Loss: 0.061008692979813', 'Epoch: 55, Train Loss: 0.060815313181212, Val Loss: 0.062344958186150', 'Epoch: 56, Train Loss: 0.053886867366558, Val Loss: 0.057679340839386', 'Epoch: 57, Train Loss: 0.057255901699496, Val Loss: 0.050103246867657', 'Epoch: 58, Train Loss: 0.052638438855146, Val Loss: 0.046884208023548', 'Epoch: 59, Train Loss: 0.052392333919226, Val Loss: 0.043161305636168', 'Epoch: 60, Train Loss: 0.051604903238111, Val Loss: 0.061463443636894', 'Epoch: 61, Train Loss: 0.054265271135887, Val Loss: 0.042420782148838', 'Epoch: 62, Train Loss: 0.051150061969840, Val Loss: 0.047967519462109', 'Epoch: 63, Train Loss: 0.051124533161867, Val Loss: 0.042732186317444', 'Epoch: 64, Train Loss: 0.049832132709927, Val Loss: 0.046772040426731', 'Epoch: 65, Train Loss: 0.052343680631629, Val Loss: 0.046256439387798', 'Epoch: 66, Train Loss: 0.051654001697898, Val Loss: 0.044596230685711', 'Epoch: 67, Train Loss: 0.052154088739392, Val Loss: 0.050752436816692', 'Epoch: 68, Train Loss: 0.054042693465775, Val Loss: 0.046591044664383', 'Epoch: 69, Train Loss: 0.050230726209837, Val Loss: 0.043793234825134', 'Epoch: 70, Train Loss: 0.049418654552726, Val Loss: 0.042359604537487', 'Epoch: 71, Train Loss: 0.044994409001151, Val Loss: 0.047679658532143', 'Epoch: 72, Train Loss: 0.049739549369660, Val Loss: 0.041979346871376', 'Epoch: 73, Train Loss: 0.050713347401037, Val Loss: 0.046651150584221', 'Epoch: 74, Train Loss: 0.047368874643431, Val Loss: 0.046996720135212', 'Epoch: 75, Train Loss: 0.050512888230557, Val Loss: 0.050465950965881', 'Epoch: 76, Train Loss: 0.045003955230810, Val Loss: 0.048953597843647', 'Epoch: 77, Train Loss: 0.048763121456601, Val Loss: 0.040526047945023', 'Epoch: 78, Train Loss: 0.047169199126751, Val Loss: 0.052185074090958', 'Epoch: 79, Train Loss: 0.049011263953045, Val Loss: 0.045714928507805', 'Epoch: 80, Train Loss: 0.041376605153430, Val Loss: 0.045582472980022', 'Epoch: 81, Train Loss: 0.046088438784314, Val Loss: 0.052604906260967', 'Epoch: 82, Train Loss: 0.046770621091127, Val Loss: 0.048172579705715', 'Epoch: 83, Train Loss: 0.045401830399452, Val Loss: 0.046053219735622', 'Epoch: 84, Train Loss: 0.040022251780990, Val Loss: 0.044219914078712', 'Epoch: 85, Train Loss: 0.041427660690144, Val Loss: 0.044674726128578', 'Epoch: 86, Train Loss: 0.041776370603678, Val Loss: 0.052711944282055', 'Epoch: 87, Train Loss: 0.042930345245919, Val Loss: 0.042757131755352', 'Epoch: 88, Train Loss: 0.042280499238607, Val Loss: 0.045186284184456', 'Epoch: 89, Train Loss: 0.040849828096323, Val Loss: 0.044538437128067', 'Epoch: 90, Train Loss: 0.041253996449848, Val Loss: 0.053004407286644', 'Epoch: 91, Train Loss: 0.041112420863883, Val Loss: 0.041458259522915', 'Epoch: 92, Train Loss: 0.041054368712181, Val Loss: 0.051838350892067', 'Epoch: 93, Train Loss: 0.041236343771912, Val Loss: 0.047240162491798', 'Epoch: 94, Train Loss: 0.041244565660870, Val Loss: 0.043082239031792', 'Epoch: 95, Train Loss: 0.035875766299838, Val Loss: 0.039804787784815', 'Epoch: 96, Train Loss: 0.037243087017952, Val Loss: 0.044598996937275', 'Epoch: 97, Train Loss: 0.038004230144759, Val Loss: 0.049268717765808', 'Epoch: 98, Train Loss: 0.035917690673540, Val Loss: 0.042357055544853', 'Epoch: 99, Train Loss: 0.037605729777106, Val Loss: 0.046048538684845', 'Epoch: 100, Train Loss: 0.035567650506489, Val Loss: 0.042213231623173', 'Epoch: 101, Train Loss: 0.036180033803333, Val Loss: 0.046661732196808', 'Epoch: 102, Train Loss: 0.034857107066484, Val Loss: 0.044699773788452', 'Epoch: 103, Train Loss: 0.033689704203848, Val Loss: 0.040146542787552', 'Epoch: 104, Train Loss: 0.034148445569499, Val Loss: 0.043809202611446', 'Epoch: 105, Train Loss: 0.035127124814100, Val Loss: 0.047414260208607', 'Epoch: 106, Train Loss: 0.037413026141219, Val Loss: 0.054049325883389', 'Epoch: 107, Train Loss: 0.032697273808163, Val Loss: 0.048948000073433', 'Epoch: 108, Train Loss: 0.035608497513242, Val Loss: 0.044349175393581', 'Epoch: 109, Train Loss: 0.032788344897157, Val Loss: 0.042824140191078', 'Epoch: 110, Train Loss: 0.034716470426945, Val Loss: 0.046203913092613', 'Epoch: 111, Train Loss: 0.034261172074218, Val Loss: 0.043718468248844', 'Epoch: 112, Train Loss: 0.030111308274574, Val Loss: 0.039082907438278', 'Epoch: 113, Train Loss: 0.031353210510556, Val Loss: 0.040449090600014', 'Epoch: 114, Train Loss: 0.032781486616058, Val Loss: 0.040205287337303', 'Epoch: 115, Train Loss: 0.031563128539643, Val Loss: 0.041123683154583', 'Epoch: 116, Train Loss: 0.029441544309605, Val Loss: 0.046467985212803', 'Epoch: 117, Train Loss: 0.030076386103796, Val Loss: 0.043566178083420', 'Epoch: 118, Train Loss: 0.028612623511012, Val Loss: 0.046037675142288', 'Epoch: 119, Train Loss: 0.029058307755825, Val Loss: 0.044508659839630', 'Epoch: 120, Train Loss: 0.029945452849186, Val Loss: 0.039853612780571', 'Epoch: 121, Train Loss: 0.028838590393926, Val Loss: 0.038982598185539', 'Epoch: 122, Train Loss: 0.028280485746299, Val Loss: 0.042870666682720', 'Epoch: 123, Train Loss: 0.027869426991877, Val Loss: 0.043238647878170', 'Epoch: 124, Train Loss: 0.028719544237436, Val Loss: 0.044594549685717', 'Epoch: 125, Train Loss: 0.030295412424345, Val Loss: 0.036688769459724', 'Epoch: 126, Train Loss: 0.027046527496951, Val Loss: 0.043158212602139', 'Epoch: 127, Train Loss: 0.027600326250459, Val Loss: 0.037913474440575', 'Epoch: 128, Train Loss: 0.025153286581816, Val Loss: 0.042091084718704', 'Epoch: 129, Train Loss: 0.025508738686006, Val Loss: 0.040184998810291', 'Epoch: 130, Train Loss: 0.028325405426670, Val Loss: 0.043443221300840', 'Epoch: 131, Train Loss: 0.027239399918810, Val Loss: 0.044643966853619', 'Epoch: 132, Train Loss: 0.025061106114367, Val Loss: 0.043733337223530', 'Epoch: 133, Train Loss: 0.026797362018463, Val Loss: 0.045765251219273', 'Epoch: 134, Train Loss: 0.026829550670850, Val Loss: 0.039631068110466', 'Epoch: 135, Train Loss: 0.024724153628530, Val Loss: 0.043605334162712', 'Epoch: 136, Train Loss: 0.023248166192410, Val Loss: 0.043451164811850', 'Epoch: 137, Train Loss: 0.024169220913981, Val Loss: 0.044220215678215', 'Epoch: 138, Train Loss: 0.025145935241220, Val Loss: 0.039173682630062', 'Epoch: 139, Train Loss: 0.023528022994829, Val Loss: 0.041646517515182', 'Epoch: 140, Train Loss: 0.023574649637868, Val Loss: 0.040109828412533', 'Epoch: 141, Train Loss: 0.024262497634735, Val Loss: 0.041599518358707', 'Epoch: 142, Train Loss: 0.022594732015805, Val Loss: 0.039673896580935', 'Epoch: 143, Train Loss: 0.023484755459047, Val Loss: 0.037332438081503', 'Epoch: 144, Train Loss: 0.020799337279831, Val Loss: 0.039179513156414', 'Epoch: 145, Train Loss: 0.021971771385261, Val Loss: 0.040558921843767', 'Epoch: 146, Train Loss: 0.021552576336923, Val Loss: 0.042601229846478', 'Epoch: 147, Train Loss: 0.021387356614997, Val Loss: 0.040033348798752', 'Epoch: 148, Train Loss: 0.021231222746157, Val Loss: 0.038958082497120', 'Epoch: 149, Train Loss: 0.019928957010771, Val Loss: 0.038028106093407', 'Epoch: 150, Train Loss: 0.021267824481393, Val Loss: 0.039262515902519', 'Epoch: 151, Train Loss: 0.021864347441425, Val Loss: 0.040363942980766', 'Epoch: 152, Train Loss: 0.019066036462264, Val Loss: 0.040676788091660', 'Epoch: 153, Train Loss: 0.019024214100872, Val Loss: 0.041980899423361', 'Epoch: 154, Train Loss: 0.018932204217065, Val Loss: 0.040708664208651', 'Epoch: 155, Train Loss: 0.020906063728034, Val Loss: 0.040425551235676', 'Epoch: 156, Train Loss: 0.020146081982137, Val Loss: 0.042068608850241', 'Epoch: 157, Train Loss: 0.019469654035949, Val Loss: 0.040947058200836', 'Epoch: 158, Train Loss: 0.020161494720987, Val Loss: 0.043842360973358', 'Epoch: 159, Train Loss: 0.018462305845216, Val Loss: 0.044067766070366', 'Epoch: 160, Train Loss: 0.020737976550536, Val Loss: 0.041387777030468', 'Epoch: 161, Train Loss: 0.018805517446856, Val Loss: 0.044398006796837', 'Epoch: 162, Train Loss: 0.020092953862839, Val Loss: 0.041100321263075', 'Epoch: 163, Train Loss: 0.019105728347461, Val Loss: 0.041632602512836', 'Epoch: 164, Train Loss: 0.019402687221246, Val Loss: 0.042592619508505', 'Epoch: 165, Train Loss: 0.018816349703039, Val Loss: 0.045816076695919', 'Epoch: 166, Train Loss: 0.020090864299861, Val Loss: 0.043704034835100', 'Epoch: 167, Train Loss: 0.019707331975359, Val Loss: 0.041590711325407', 'Epoch: 168, Train Loss: 0.018093334879120, Val Loss: 0.043062946647406', 'Epoch: 169, Train Loss: 0.018785093066304, Val Loss: 0.040582443475723', 'Epoch: 170, Train Loss: 0.018219911233457, Val Loss: 0.040545638501644', 'Epoch: 171, Train Loss: 0.017795463179260, Val Loss: 0.041966793835163', 'Epoch: 172, Train Loss: 0.017390220512658, Val Loss: 0.040831700265408', 'Epoch: 173, Train Loss: 0.017941743492820, Val Loss: 0.038600520938635', 'Epoch: 174, Train Loss: 0.017115188351031, Val Loss: 0.038549705147743', 'Epoch: 175, Train Loss: 0.016693255799108, Val Loss: 0.041798048019409', 'Epoch: 176, Train Loss: 0.017650969608059, Val Loss: 0.042018864005804', 'Epoch: 177, Train Loss: 0.017290633388383, Val Loss: 0.040044687092304', 'Epoch: 178, Train Loss: 0.016925222738538, Val Loss: 0.040859335362911', 'Epoch: 179, Train Loss: 0.018557259303972, Val Loss: 0.040539410561323', 'Epoch: 180, Train Loss: 0.015857563917200, Val Loss: 0.040632340013981', 'Epoch: 181, Train Loss: 0.017258805287785, Val Loss: 0.040333126932383', 'Epoch: 182, Train Loss: 0.016503589162820, Val Loss: 0.039053031951189', 'Epoch: 183, Train Loss: 0.015617152697645, Val Loss: 0.039463974386454', 'Epoch: 184, Train Loss: 0.016364886815292, Val Loss: 0.039965538978577', 'Epoch: 185, Train Loss: 0.016267854677037, Val Loss: 0.039916765093803', 'Epoch: 186, Train Loss: 0.016287805642499, Val Loss: 0.040796586722136', 'Epoch: 187, Train Loss: 0.016752877229348, Val Loss: 0.040184852033854', 'Epoch: 188, Train Loss: 0.016803125742563, Val Loss: 0.040515054464340', 'Epoch: 189, Train Loss: 0.015835586415474, Val Loss: 0.040733567774296', 'Epoch: 190, Train Loss: 0.014835897540717, Val Loss: 0.039933120310307', 'Epoch: 191, Train Loss: 0.015278382053555, Val Loss: 0.039741111099720', 'Epoch: 192, Train Loss: 0.014471134701527, Val Loss: 0.040254354178905', 'Epoch: 193, Train Loss: 0.015339120919275, Val Loss: 0.039521768987179', 'Epoch: 194, Train Loss: 0.014717830117619, Val Loss: 0.039439435899258', 'Epoch: 195, Train Loss: 0.015285214539184, Val Loss: 0.039787284433842', 'Epoch: 196, Train Loss: 0.013990649303725, Val Loss: 0.039255528748035', 'Epoch: 197, Train Loss: 0.015106295798580, Val Loss: 0.039381029754877', 'Epoch: 198, Train Loss: 0.013789883403237, Val Loss: 0.039658235609531', 'Epoch: 199, Train Loss: 0.014868589248075, Val Loss: 0.039612972736359']","[ 654.8878     858.9408     605.62524    823.4177     242.27808
  226.74203    917.0897     420.75623    802.193      270.67612
  589.895      114.392426   108.31038    475.46124    701.3312
  283.17047     30.477722   373.7079     270.6423     183.52786
  305.33618    568.80365     58.10005    361.6359      61.567993
  454.26773    308.22546     69.763916   183.90654    212.50854
   40.234406   620.99854    814.639      510.12308    531.67065
  487.08307    635.54205     39.299835   819.2933     436.85977
   32.10199     12.737305   917.3487     705.1004    1304.426
   68.15735    261.748      527.5565     264.05396     42.894867
  553.5415      97.17648    226.36008    431.72595    758.5828
  754.55194     15.328674   343.79028    356.12573    122.3858
  277.3116     595.1436     379.22644    401.2742     300.07178
  625.33923    572.72656    790.3269    1011.9909     602.06335
  203.4389     289.91208    343.72363      5.776703   466.1126
  759.3667     465.3123    1216.9402      30.441345   115.942535
  193.90115     77.62163     38.13925     81.318756   851.2733
  735.58057   1116.7454     668.78516   1098.9905     846.20404
  908.8528     559.20264    387.01514    578.9451     450.63168
 1216.2407     425.49884     34.297546   261.2008      33.871704
  322.72787    912.1011    1121.5552     179.18167      7.5022583
  194.73083    617.52527    480.5709     142.58606    725.30066
   46.155334    91.34143    354.06763    370.0709     981.4962
 1336.079       69.434235   537.00867    180.86958    418.97964
  710.4889     260.3442      12.303162   187.74892    298.54327
  803.4951      46.482483   858.71857    219.03978    107.76697
  551.4474     545.66925    443.00385     25.466217   433.80112
  251.94963    800.4219     410.4281    1138.5406    1118.0664
  190.98244    158.13097    518.3438     644.11694   1418.8811
  688.76044    981.79474    301.1149     212.61569    417.56952
  491.81717    421.86273     74.70093    728.85095    283.2077
  696.245      145.2526    1067.0781    1264.9797     617.0177
  582.0005     852.8277     987.7833     898.12915    458.07535
  923.48206    199.7443     725.53906    173.27808    791.0471
  477.16177    565.2103     820.3782     322.36844    282.6477
  149.78822    163.725      488.9561     574.168      803.22064
 1050.0377     481.8217    1007.05554    697.4676     203.94867
  922.51196    687.5653     314.99268    813.1365     538.32446
  761.8296     345.20123    936.8981     115.85745    257.72635
  324.40198    399.0803     327.13446   1037.9456     819.92365
 1051.1375      26.996155   398.21747    316.95782    496.91003
  386.84436    671.03345    877.35345    162.6325       9.513733
  308.87494    439.3988     362.44995    402.552      196.25925
  166.34024    407.19095    153.45319    912.1277     729.66125
  286.10147    696.10693    141.52783    257.21802    535.18024
  111.27716   1085.7736     585.11993    165.30775    177.23946
  165.6166     237.75441   1022.74536    522.59485    481.69104
   79.306885   241.17947    792.0262     223.10826    641.3335
  811.7124     506.19135    142.5553      64.03064    648.6159
   63.382294   415.2347     501.7229    1229.338     1111.8049
  542.6698     483.33694    240.7266      45.139435  1373.4327
  640.0082      62.755096    53.227966   539.66223    930.95605
  472.02747    531.68274    940.1595     569.2471    1235.1926
  857.57104   1113.6592     764.0492     534.20123    426.0774
   42.318085   949.4911     713.8461     205.00055    826.73346
   77.16815    131.76715    377.8271     344.79715    678.5821
  430.52957    137.32486   1435.5125     897.1657     225.69849
  414.05457   1097.7946    1086.8049     935.15063    607.05676
 1008.82983    618.74554    690.80347   1188.7153      58.015076
 1028.4375     381.07742    235.9519     431.94696    737.0876
  292.09497    590.77527    682.3959     866.5042     190.246
  639.00104    446.5121     645.1103    1011.2304     986.7119
  488.81894   1168.2249     524.67065    271.4146     373.0884
  575.8357     172.81967    682.8658     164.63852    102.00479
  835.3355     502.10764   1236.6492    1132.6476     257.4434
  571.64325    478.9785     275.42337    563.32935    403.2876
  675.0062     849.57477    341.82306    277.66916    286.15344
  200.9878     149.56458    125.95441    766.14185    768.23303
   31.58957    802.94574    531.9065    1002.379      114.17993
  445.30933    774.8724     204.37741    693.9823     195.18573
  631.74976    684.7658     410.7372     151.08672    298.65332
  390.7622     875.8579     591.0382     441.93622    898.2204
   97.75177    411.68484    588.56616   1279.7058     404.93524
  114.538284   164.05548    613.60205    788.578      645.23157
  229.17506    230.01384    652.66327    259.74988    421.67123
  860.66016    588.063      927.615      250.1188     333.07758
  786.90393    314.41608    708.38855    173.62585    299.57147
  801.8904     293.27518    241.71696   1148.9604      68.22925
  635.87286    429.1941     285.88324    653.09375    380.31708
  571.9962     789.92004    995.17896    112.02902    760.40076  ]","[ 506.6071   1138.7554    605.8976    727.1607    168.15588   154.82013
  917.3258    395.1007    804.56165   331.17337   609.77905   125.07541
  108.49899   467.2434    697.52496   113.644165  148.08902   260.19562
  173.36707   178.18906   345.16498   517.8993    150.753     360.5513
  120.34857   448.04153   443.46112     7.219208  120.295456   74.1109
   71.79501   639.4336    866.2021    277.56976   537.39526   531.3286
  617.9949    108.610016  810.52466   414.44397   137.04779   332.67627
  875.3627    736.14746  1231.3921    125.38483   203.24083   497.5589
  252.67697   200.44363   519.6238    169.31313   196.49773   421.9085
  893.17535   863.93976   185.33447   381.6852    310.23193    30.712708
  243.373     688.55963   387.39825   352.16388   209.77423   638.1602
  610.0725    968.40686  1029.5642    468.07516   139.00624   291.9407
  419.57178    40.481323  454.63617   777.72485   465.7322   1180.9094
  125.10184   148.16177   199.10931    70.373825   33.866455  201.41743
  854.2825    794.0427   1056.008     654.8482   1134.3892    852.9403
  910.8539    489.636     320.6759    614.2086    517.30896  1153.8845
  447.19403    27.528809  256.3892    142.77637   324.31265   943.155
 1113.4392    329.59656    89.59241   202.18713   661.78534   395.6368
  290.0167    676.9217    167.48096   193.02722   291.5915    332.93665
 1011.5826   1244.8497     24.78534   466.32965    73.53354   485.9395
  671.7298    260.7621     97.52553   305.4795    208.45483   861.80334
  167.66876   868.73047   234.99477   119.85104   475.50818   573.02277
  438.87314    62.068542  440.1119    237.98068   816.9179    235.71463
 1081.5623   1107.2275    195.1799    119.829285  639.6142    724.5224
 1362.5117    722.93616   963.504     254.35916   249.90302   380.53094
  424.9193    437.13513    68.60248   483.69055   296.7165    656.83154
  178.86334   843.16327  1083.3398    567.3214    768.8053    813.4282
 1073.1313    964.11847   409.8537    932.3052    233.36621   771.1405
  143.2915    701.328     277.315     578.2825    839.5415    299.93155
  234.92441   136.22049   104.591034  474.49323   546.6896    815.45605
 1040.5671    492.36768  1059.592     754.52405   297.57834   828.5163
  712.551     316.34518   817.5596    542.5447    705.20703   324.01718
  809.80853   102.29324   274.21573   295.2346    442.4149    366.49368
  995.51135   752.7986   1042.8113    185.6117    403.93057   233.58015
  408.57086   379.08563   650.47546   829.7278    532.6559    390.79318
  387.9558    471.41016   319.17273   583.66003   268.10083   284.08276
  385.9912    201.324     968.95544   693.9676    271.53845   611.56793
  199.38754   186.74066   381.12473   195.32956  1111.6035    586.6864
  135.54347   134.40755   105.68024   200.3063   1040.7301    520.23615
  461.50262    52.007324  162.45453   624.8083    297.60715   583.1266
  836.5858    602.4846    439.66562   345.59903   677.03125   115.112335
  343.8714    485.47217  1072.6354   1047.47      602.3158    497.90237
  197.07643   107.93907  1227.1044    904.71185   332.83084   148.41856
  468.94424   688.4497    511.21198   516.5187    892.5061    770.01654
 1140.5874    880.02734  1135.0806    828.4716    450.45447   374.36005
  149.32578   764.8957    580.3354     79.91736   741.1782    209.45175
   72.28229   415.00604   302.75958   673.0546    579.9834    -69.17108
 1461.6389    778.9182    254.07239   418.27744   863.1911    850.76807
  950.1925    592.56775  1128.4573    577.1847    699.23267  1116.3938
   56.272583 1231.9534    418.59293   197.57782   224.945     743.36755
  315.58087   625.5887    704.7744    991.382     171.12158   586.5109
  318.80072   722.39825   957.6521    969.46533   403.6885   1189.0432
  499.63052   279.78568   377.10013   546.4409    123.96066   631.3584
  257.1867    256.01236   885.4935    539.94934  1059.2915   1353.1202
  286.2821    586.7401    532.20654   227.29358   665.20776   388.89728
  750.9862    893.1837    239.05893   235.1426    227.12465    53.768433
   44.240936  181.43391   530.4461    758.73254    63.190216  738.71643
  561.8814    955.7256     90.84267   457.91663   761.01355   187.65094
  625.75244   148.99414   597.31885   553.1242    357.90265   196.5094
  185.19781   372.87418   941.10925   599.384     340.74756   780.60016
   92.00906   415.0404    681.2005   1163.2034    421.27213    80.22609
  178.76227   576.8325    731.2975    582.83655   202.6767    183.32487
  656.46106   349.06573   442.72067   692.371     487.44568   950.0375
  232.47275   286.17548   852.2172    268.80212   707.779     131.34021
  319.50446   764.3806    269.26556   165.4616   1006.3029    225.58115
  549.22906   500.12112   295.71783   635.3517    345.0719    584.8282
  823.7188    942.13257    36.974335  768.3972  ]",64.452385,8156.279,90.31211883570084
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 0.389131739042526, Val Loss: 0.364789309501648', 'Epoch: 1, Train Loss: 0.364228870979575, Val Loss: 0.333778719902039', 'Epoch: 2, Train Loss: 0.307004141599633, Val Loss: 0.256629812717438', 'Epoch: 3, Train Loss: 0.211399736965812, Val Loss: 0.135772192478180', 'Epoch: 4, Train Loss: 0.124468772390554, Val Loss: 0.093146072030067', 'Epoch: 5, Train Loss: 0.082510042242533, Val Loss: 0.060289616286755', 'Epoch: 6, Train Loss: 0.071765613070754, Val Loss: 0.066432363390923', 'Epoch: 7, Train Loss: 0.073491284667059, Val Loss: 0.054526546299458', 'Epoch: 8, Train Loss: 0.064044890448798, Val Loss: 0.051590393185616', 'Epoch: 9, Train Loss: 0.065593133745498, Val Loss: 0.067483839988708', 'Epoch: 10, Train Loss: 0.062114990684529, Val Loss: 0.053657221198082', 'Epoch: 11, Train Loss: 0.062279506824737, Val Loss: 0.048131043016911', 'Epoch: 12, Train Loss: 0.057817771034532, Val Loss: 0.050340751707554', 'Epoch: 13, Train Loss: 0.054348639364159, Val Loss: 0.057893588244915', 'Epoch: 14, Train Loss: 0.054949731111180, Val Loss: 0.057979600429535', 'Epoch: 15, Train Loss: 0.053842769719140, Val Loss: 0.047759106755257', 'Epoch: 16, Train Loss: 0.045219585646031, Val Loss: 0.044451211392879', 'Epoch: 17, Train Loss: 0.050111160245399, Val Loss: 0.038562130928040', 'Epoch: 18, Train Loss: 0.049443766518041, Val Loss: 0.043802164196968', 'Epoch: 19, Train Loss: 0.044745669028787, Val Loss: 0.039342387020588', 'Epoch: 20, Train Loss: 0.042217884126098, Val Loss: 0.043284995555878', 'Epoch: 21, Train Loss: 0.040406606961475, Val Loss: 0.034605680406094', 'Epoch: 22, Train Loss: 0.035530273261112, Val Loss: 0.031415332257748', 'Epoch: 23, Train Loss: 0.042644738717828, Val Loss: 0.041182610094547', 'Epoch: 24, Train Loss: 0.037320976946936, Val Loss: 0.033021492958069', 'Epoch: 25, Train Loss: 0.043659642641974, Val Loss: 0.039091623425484', 'Epoch: 26, Train Loss: 0.037255490372001, Val Loss: 0.031912743449211', 'Epoch: 27, Train Loss: 0.035907205497456, Val Loss: 0.033887072503567', 'Epoch: 28, Train Loss: 0.033407669297831, Val Loss: 0.033291199058294', 'Epoch: 29, Train Loss: 0.034646283705221, Val Loss: 0.029955387115479', 'Epoch: 30, Train Loss: 0.034748379964122, Val Loss: 0.041113068759441', 'Epoch: 31, Train Loss: 0.033190161422935, Val Loss: 0.030859953165054', 'Epoch: 32, Train Loss: 0.035042048930082, Val Loss: 0.027529543638229', 'Epoch: 33, Train Loss: 0.029661112464964, Val Loss: 0.030272017419338', 'Epoch: 34, Train Loss: 0.034784793204000, Val Loss: 0.026775726974010', 'Epoch: 35, Train Loss: 0.035795250690954, Val Loss: 0.028418298065662', 'Epoch: 36, Train Loss: 0.034868812318458, Val Loss: 0.041335629522800', 'Epoch: 37, Train Loss: 0.034752796512357, Val Loss: 0.029244646430016', 'Epoch: 38, Train Loss: 0.031128415642956, Val Loss: 0.035963877588511', 'Epoch: 39, Train Loss: 0.027180873377379, Val Loss: 0.024114021956921', 'Epoch: 40, Train Loss: 0.023610960800461, Val Loss: 0.028630084693432', 'Epoch: 41, Train Loss: 0.026979162227796, Val Loss: 0.027294464111328', 'Epoch: 42, Train Loss: 0.026885000534009, Val Loss: 0.021632253825665', 'Epoch: 43, Train Loss: 0.029959359184601, Val Loss: 0.034048223942518', 'Epoch: 44, Train Loss: 0.031111446209252, Val Loss: 0.027255233079195', 'Epoch: 45, Train Loss: 0.028643387001614, Val Loss: 0.024191644787788', 'Epoch: 46, Train Loss: 0.026135420686630, Val Loss: 0.031408306658268', 'Epoch: 47, Train Loss: 0.025226160450730, Val Loss: 0.024806167483330', 'Epoch: 48, Train Loss: 0.027920257625018, Val Loss: 0.032136764526367', 'Epoch: 49, Train Loss: 0.026048521294670, Val Loss: 0.025082403421402', 'Epoch: 50, Train Loss: 0.025662004666100, Val Loss: 0.023966560959816', 'Epoch: 51, Train Loss: 0.021850529321751, Val Loss: 0.025100371241570', 'Epoch: 52, Train Loss: 0.023000260208582, Val Loss: 0.023661786168814', 'Epoch: 53, Train Loss: 0.022048309293771, Val Loss: 0.032621771991253', 'Epoch: 54, Train Loss: 0.023752049239742, Val Loss: 0.029588323384523', 'Epoch: 55, Train Loss: 0.022384248998796, Val Loss: 0.028383736312389', 'Epoch: 56, Train Loss: 0.023524402684077, Val Loss: 0.025749964863062', 'Epoch: 57, Train Loss: 0.024026893923969, Val Loss: 0.027568497657776', 'Epoch: 58, Train Loss: 0.022092949404100, Val Loss: 0.027181646376848', 'Epoch: 59, Train Loss: 0.021139368479855, Val Loss: 0.023631922304630', 'Epoch: 60, Train Loss: 0.022628795615462, Val Loss: 0.023569703698158', 'Epoch: 61, Train Loss: 0.020986659820516, Val Loss: 0.024668903052807', 'Epoch: 62, Train Loss: 0.023128763393521, Val Loss: 0.027076745182276', 'Epoch: 63, Train Loss: 0.023057321021550, Val Loss: 0.028443133011460', 'Epoch: 64, Train Loss: 0.021342127562262, Val Loss: 0.030686597079039', 'Epoch: 65, Train Loss: 0.020310838316935, Val Loss: 0.024829047769308', 'Epoch: 66, Train Loss: 0.020987371026083, Val Loss: 0.022951374873519', 'Epoch: 67, Train Loss: 0.021138139242350, Val Loss: 0.024737973958254', 'Epoch: 68, Train Loss: 0.019452854839349, Val Loss: 0.022592734619975', 'Epoch: 69, Train Loss: 0.022202365923413, Val Loss: 0.021756033673882', 'Epoch: 70, Train Loss: 0.019701150419234, Val Loss: 0.027141464352608', 'Epoch: 71, Train Loss: 0.021311587740689, Val Loss: 0.022468168288469', 'Epoch: 72, Train Loss: 0.020702852369394, Val Loss: 0.026004288196564', 'Epoch: 73, Train Loss: 0.021124193650605, Val Loss: 0.024644934386015', 'Epoch: 74, Train Loss: 0.019521574294844, Val Loss: 0.026773569807410', 'Epoch: 75, Train Loss: 0.019045635667998, Val Loss: 0.023025503084064', 'Epoch: 76, Train Loss: 0.019206290642276, Val Loss: 0.026262374892831', 'Epoch: 77, Train Loss: 0.020209868763422, Val Loss: 0.021908743679523', 'Epoch: 78, Train Loss: 0.018134768619094, Val Loss: 0.023738292753696', 'Epoch: 79, Train Loss: 0.019887613360012, Val Loss: 0.027337068319321', 'Epoch: 80, Train Loss: 0.019284005753349, Val Loss: 0.024700466766953', 'Epoch: 81, Train Loss: 0.019637984483568, Val Loss: 0.023967382013798', 'Epoch: 82, Train Loss: 0.017907060141307, Val Loss: 0.025217181742191', 'Epoch: 83, Train Loss: 0.018463518481355, Val Loss: 0.022861700803041', 'Epoch: 84, Train Loss: 0.018020134419203, Val Loss: 0.021206835359335', 'Epoch: 85, Train Loss: 0.018227824204883, Val Loss: 0.024524549096823', 'Epoch: 86, Train Loss: 0.020304593441705, Val Loss: 0.028584540784359', 'Epoch: 87, Train Loss: 0.017284030008108, Val Loss: 0.026852205544710', 'Epoch: 88, Train Loss: 0.018481900514818, Val Loss: 0.027056234627962', 'Epoch: 89, Train Loss: 0.020233287367710, Val Loss: 0.021623716503382', 'Epoch: 90, Train Loss: 0.016746194123529, Val Loss: 0.025499569475651', 'Epoch: 91, Train Loss: 0.018858256446587, Val Loss: 0.027864720672369', 'Epoch: 92, Train Loss: 0.016877147109183, Val Loss: 0.023197524324059', 'Epoch: 93, Train Loss: 0.017200887268193, Val Loss: 0.027603974044323', 'Epoch: 94, Train Loss: 0.020270731300116, Val Loss: 0.024453735426068', 'Epoch: 95, Train Loss: 0.017893446176205, Val Loss: 0.025499640554190', 'Epoch: 96, Train Loss: 0.017782799747967, Val Loss: 0.026212609708309', 'Epoch: 97, Train Loss: 0.016590842056673, Val Loss: 0.026205608472228', 'Epoch: 98, Train Loss: 0.016785287471531, Val Loss: 0.023947878181934', 'Epoch: 99, Train Loss: 0.020614476354663, Val Loss: 0.024012589305639', 'Epoch: 100, Train Loss: 0.016256522582194, Val Loss: 0.024316245913506', 'Epoch: 101, Train Loss: 0.017924926265381, Val Loss: 0.028078096434474', 'Epoch: 102, Train Loss: 0.016246514557319, Val Loss: 0.025843607038260', 'Epoch: 103, Train Loss: 0.015779945436259, Val Loss: 0.021508221775293', 'Epoch: 104, Train Loss: 0.017124592673120, Val Loss: 0.025094658955932', 'Epoch: 105, Train Loss: 0.017910292632011, Val Loss: 0.024890404716134', 'Epoch: 106, Train Loss: 0.017152347883513, Val Loss: 0.023430395424366', 'Epoch: 107, Train Loss: 0.017771879622583, Val Loss: 0.027146242111921', 'Epoch: 108, Train Loss: 0.017944585358681, Val Loss: 0.024839122891426', 'Epoch: 109, Train Loss: 0.016620984495899, Val Loss: 0.020948955193162', 'Epoch: 110, Train Loss: 0.017288844523475, Val Loss: 0.022000474035740', 'Epoch: 111, Train Loss: 0.017220491305167, Val Loss: 0.024351616352797', 'Epoch: 112, Train Loss: 0.016741249482905, Val Loss: 0.023130777850747', 'Epoch: 113, Train Loss: 0.014649947791165, Val Loss: 0.022839829325676', 'Epoch: 114, Train Loss: 0.014803696759478, Val Loss: 0.026291879415512', 'Epoch: 115, Train Loss: 0.015854755427342, Val Loss: 0.023523696511984', 'Epoch: 116, Train Loss: 0.016195863333726, Val Loss: 0.027594723850489', 'Epoch: 117, Train Loss: 0.016668511424647, Val Loss: 0.025823664367199', 'Epoch: 118, Train Loss: 0.015331380004280, Val Loss: 0.022627035900950', 'Epoch: 119, Train Loss: 0.015752471257868, Val Loss: 0.026921051815152', 'Epoch: 120, Train Loss: 0.015940112180921, Val Loss: 0.022613523453474', 'Epoch: 121, Train Loss: 0.016376533469748, Val Loss: 0.021884650737047', 'Epoch: 122, Train Loss: 0.015480884361666, Val Loss: 0.021254918873310', 'Epoch: 123, Train Loss: 0.014216923165720, Val Loss: 0.022157439589500', 'Epoch: 124, Train Loss: 0.014899237492923, Val Loss: 0.022328062430024', 'Epoch: 125, Train Loss: 0.014943565036235, Val Loss: 0.023795018047094', 'Epoch: 126, Train Loss: 0.013702267921681, Val Loss: 0.022718884125352', 'Epoch: 127, Train Loss: 0.014716615293955, Val Loss: 0.025410965681076', 'Epoch: 128, Train Loss: 0.014499328543194, Val Loss: 0.024575346633792', 'Epoch: 129, Train Loss: 0.014369715882335, Val Loss: 0.023037926703691', 'Epoch: 130, Train Loss: 0.013340649519895, Val Loss: 0.021026166975498', 'Epoch: 131, Train Loss: 0.013386796358540, Val Loss: 0.023264896273613', 'Epoch: 132, Train Loss: 0.013755265471720, Val Loss: 0.022892118245363', 'Epoch: 133, Train Loss: 0.015239469349644, Val Loss: 0.023089617192745', 'Epoch: 134, Train Loss: 0.012875938441518, Val Loss: 0.024597853124142', 'Epoch: 135, Train Loss: 0.013409391630354, Val Loss: 0.023441779688001', 'Epoch: 136, Train Loss: 0.013530222070945, Val Loss: 0.022227246910334', 'Epoch: 137, Train Loss: 0.014296161021691, Val Loss: 0.023771640360355', 'Epoch: 138, Train Loss: 0.014010743194715, Val Loss: 0.022178651094437', 'Epoch: 139, Train Loss: 0.013927022883192, Val Loss: 0.025346071273088', 'Epoch: 140, Train Loss: 0.012625766636501, Val Loss: 0.025492400676012', 'Epoch: 141, Train Loss: 0.013895303768994, Val Loss: 0.023317693620920', 'Epoch: 142, Train Loss: 0.013843601244653, Val Loss: 0.022357152625918', 'Epoch: 143, Train Loss: 0.012991938209378, Val Loss: 0.025542609244585', 'Epoch: 144, Train Loss: 0.013260160789414, Val Loss: 0.024636153280735', 'Epoch: 145, Train Loss: 0.014000347111547, Val Loss: 0.028406762480736', 'Epoch: 146, Train Loss: 0.013492492254997, Val Loss: 0.022959318161011', 'Epoch: 147, Train Loss: 0.013153238092051, Val Loss: 0.023726067841053', 'Epoch: 148, Train Loss: 0.012743812974889, Val Loss: 0.022924653738737', 'Epoch: 149, Train Loss: 0.011564370482987, Val Loss: 0.022322111278772', 'Epoch: 150, Train Loss: 0.012059795215379, Val Loss: 0.023018091171980', 'Epoch: 151, Train Loss: 0.013095636029056, Val Loss: 0.023298900872469', 'Epoch: 152, Train Loss: 0.011937300068175, Val Loss: 0.021517749056220', 'Epoch: 153, Train Loss: 0.013207484881372, Val Loss: 0.022762373536825', 'Epoch: 154, Train Loss: 0.012424628878402, Val Loss: 0.025365318655968', 'Epoch: 155, Train Loss: 0.012516400581876, Val Loss: 0.021568113118410', 'Epoch: 156, Train Loss: 0.012778662643287, Val Loss: 0.024689872413874', 'Epoch: 157, Train Loss: 0.012091787217921, Val Loss: 0.023614968806505', 'Epoch: 158, Train Loss: 0.013014580534641, Val Loss: 0.022200039923191', 'Epoch: 159, Train Loss: 0.012123103751693, Val Loss: 0.023001349642873', 'Epoch: 160, Train Loss: 0.011862226480315, Val Loss: 0.023159064352512', 'Epoch: 161, Train Loss: 0.012464416202504, Val Loss: 0.023133908063173', 'Epoch: 162, Train Loss: 0.011521160835400, Val Loss: 0.023708930909634', 'Epoch: 163, Train Loss: 0.012008307750748, Val Loss: 0.023548374176025', 'Epoch: 164, Train Loss: 0.012319282612352, Val Loss: 0.022971294820309', 'Epoch: 165, Train Loss: 0.011456659161161, Val Loss: 0.023332787901163', 'Epoch: 166, Train Loss: 0.011806475215180, Val Loss: 0.023529841303825', 'Epoch: 167, Train Loss: 0.011733938485037, Val Loss: 0.023760308176279', 'Epoch: 168, Train Loss: 0.012120436887842, Val Loss: 0.022593010962009', 'Epoch: 169, Train Loss: 0.011959488709392, Val Loss: 0.023346018046141', 'Epoch: 170, Train Loss: 0.012037513550198, Val Loss: 0.022272623032331', 'Epoch: 171, Train Loss: 0.011668786406517, Val Loss: 0.024115946739912', 'Epoch: 172, Train Loss: 0.012131241496739, Val Loss: 0.023500819057226', 'Epoch: 173, Train Loss: 0.011901319752512, Val Loss: 0.023569275587797', 'Epoch: 174, Train Loss: 0.011821210081148, Val Loss: 0.024145747870207', 'Epoch: 175, Train Loss: 0.011917858427867, Val Loss: 0.022988405525684', 'Epoch: 176, Train Loss: 0.010693375281123, Val Loss: 0.022321158796549', 'Epoch: 177, Train Loss: 0.011457429798103, Val Loss: 0.024774642437696', 'Epoch: 178, Train Loss: 0.010172246110647, Val Loss: 0.022751659154892', 'Epoch: 179, Train Loss: 0.011104530189186, Val Loss: 0.023051063865423', 'Epoch: 180, Train Loss: 0.010650293186827, Val Loss: 0.021952140331268', 'Epoch: 181, Train Loss: 0.010969382190947, Val Loss: 0.022691745012999', 'Epoch: 182, Train Loss: 0.011063634526244, Val Loss: 0.022314301580191', 'Epoch: 183, Train Loss: 0.010593295671306, Val Loss: 0.023171303570271', 'Epoch: 184, Train Loss: 0.010525487731536, Val Loss: 0.023776356428862', 'Epoch: 185, Train Loss: 0.011104312920293, Val Loss: 0.022607618123293', 'Epoch: 186, Train Loss: 0.010004938081946, Val Loss: 0.023413566350937', 'Epoch: 187, Train Loss: 0.010017865543189, Val Loss: 0.022727890908718', 'Epoch: 188, Train Loss: 0.011011891326932, Val Loss: 0.023028970956802', 'Epoch: 189, Train Loss: 0.010622951602780, Val Loss: 0.022469422221184', 'Epoch: 190, Train Loss: 0.011207194489882, Val Loss: 0.022295809835196', 'Epoch: 191, Train Loss: 0.010610959579258, Val Loss: 0.022337324768305', 'Epoch: 192, Train Loss: 0.010336206186303, Val Loss: 0.023206560015678', 'Epoch: 193, Train Loss: 0.009945623544153, Val Loss: 0.022947025150061', 'Epoch: 194, Train Loss: 0.010503934891245, Val Loss: 0.022395372837782', 'Epoch: 195, Train Loss: 0.010117980933120, Val Loss: 0.022554533332586', 'Epoch: 196, Train Loss: 0.010914086071818, Val Loss: 0.022690496742725', 'Epoch: 197, Train Loss: 0.010177020709095, Val Loss: 0.022648192197084', 'Epoch: 198, Train Loss: 0.009699967419079, Val Loss: 0.022697782665491', 'Epoch: 199, Train Loss: 0.009958855228412, Val Loss: 0.022629661113024']","[1.14568848e+03 6.10946045e+02 3.78342438e+02 1.68954025e+02
 7.54880737e+02 1.91319061e+02 7.96743835e+02 7.08230164e+02
 3.59914764e+02 1.53289383e+02 6.54522095e+02 3.45452423e+02
 7.94332458e+02 5.36096924e+02 1.29317810e+02 7.24320251e+02
 4.44464386e+02 6.15911560e+02 2.60964600e+02 3.89137878e+02
 6.02567688e+02 5.48624023e+02 1.33540955e+01 7.75947937e+02
 8.98366089e+02 3.40736877e+02 3.23883057e-01 4.12170898e+02
 2.96619476e+02 9.96644165e+02 6.94600464e+02 1.17757178e+03
 2.12876373e+02 1.33048737e+02 9.83299683e+02 6.99610291e+02
 6.67430420e+02 4.30979919e+01 4.43687744e+01 1.93135681e+01
 4.27755371e+02 4.82120270e+02 1.03139111e+03 2.29990662e+02
 1.11468567e+02 2.43760345e+02 3.31581116e+01 5.73776184e+02
 7.81199341e+02 8.40061035e+02 6.27402344e+02 3.67147827e+02
 8.74550171e+01 5.09033508e+02 5.02407684e+02 1.02146399e+03
 3.10322632e+02 2.90642242e+02 1.75612885e+02 3.01952515e+02
 6.01790649e+02 2.53884750e+02 4.80116791e+02 5.34177612e+02
 9.59171875e+02 9.71587708e+02 4.30435852e+02 4.30994720e+02
 5.84627014e+02 3.37953827e+02 1.54960739e+02 2.78524353e+02
 3.94968933e+02 5.27536743e+02 3.98767670e+02 7.51596802e+02
 3.96071838e+02 5.16609924e+02 8.01454773e+01 2.24381714e+02
 1.90466614e+01 1.39530182e+02 6.82239990e+01 3.02293030e+02
 2.16143082e+02 1.00028662e+03 5.09100494e+02 4.87687408e+02
 1.14586145e+03 1.09036707e+03 2.72139313e+02 3.51056671e+02
 3.50885590e+02 1.51952423e+02 4.31590210e+02 4.81409790e+02
 7.69524597e+02 3.01323242e+02 6.17026428e+02 1.12998993e+02
 9.88310852e+02 1.47624121e+03 1.31685876e+03 4.24889282e+02
 2.26990234e+02 5.01640930e+02 4.23015808e+02 3.79351807e+02
 9.85479736e+00 1.86629639e+01 6.15427368e+02 8.10983643e+02
 2.73976685e+02 2.17242111e+02 4.75294159e+02 8.07799377e+02
 4.19469025e+02 6.45816956e+01 5.09211060e+02 5.46902710e+02
 9.26665649e+01 6.83426208e+02 5.50138397e+01 4.55967407e+02
 2.22246552e+02 4.24873871e+02 4.61210541e+02 6.11643311e+02
 2.48127609e+02 2.16114655e+02 2.94728333e+02 3.23484619e+02
 4.42380066e+02 1.24866951e+02 5.57459229e+02 4.89709351e+02
 1.11251923e+02 5.47645142e+02 4.34669006e+02 5.26158508e+02
 1.10367249e+02 1.13819702e+03 1.48106421e+03 4.69015656e+02
 1.02596948e+03 6.85988159e+01 5.57875519e+01 5.70584412e+02
 3.49646576e+02 6.80213318e+02 3.09824310e+02 4.65796478e+02
 1.60155457e+02 5.35607361e+02 1.08391296e+02 3.46457520e+01
 2.46389999e+02 3.51947021e+02 1.17053430e+03 2.64257660e+02
 3.51185303e+01 5.26621033e+02 5.87983948e+02 8.53609619e+02
 4.59634857e+02 1.96030045e+02 1.11004929e+02 3.67926788e+02
 3.43309814e+02 6.11034180e+02 2.13107666e+02 5.31663513e+01
 1.22122632e+03 8.10149231e+01 4.36904816e+02 4.01920868e+02
 3.87786865e+01 4.30526825e+02 3.20137085e+02 7.56370544e+01
 7.70210632e+02 8.58886719e+02 9.85680908e+02 7.42747559e+02
 4.48549469e+02 2.51337585e+01 6.67393921e+02 7.46128967e+02
 5.45224854e+02 5.88070435e+02 6.42626282e+02 4.75527740e+02
 5.81808105e+02 4.54112640e+02 9.41193054e+02 7.33213440e+02
 2.16802475e+02 2.40246033e+02 8.54642639e+02 3.94033203e+02
 2.35464920e+02 8.40889038e+02 7.44874023e+02 2.60721222e+02
 6.07410645e+02 7.90466187e+02 6.77007507e+02 6.60000610e+00
 5.74711365e+02 3.79151611e+01 1.73738602e+02 3.94844513e+02
 3.65238647e+02 7.87309204e+02 4.81975677e+02 2.82577087e+02
 4.13062866e+02 3.65283691e+02 3.56185608e+02 1.47100555e+02
 6.02319519e+02 9.23918457e+01 9.34136536e+02 1.42405884e+02
 5.53421082e+02 3.53795197e+02 5.46423523e+02 2.82973297e+02
 5.76923584e+02 7.84624817e+02 2.79401886e+02 4.72292908e+02
 1.21768402e+02 3.86766571e+02 4.40116516e+02 1.02752594e+02
 5.36494385e+02 7.01583252e+01 6.62462036e+02 2.03762329e+02
 5.12433777e+02 3.08570312e+02 9.78428894e+02 9.07292236e+02
 3.58535095e+02 7.69567383e+02 8.84756897e+02 8.54946594e+01
 8.79333496e+00 3.32860138e+02 1.00396771e+03 5.71718689e+02
 4.36951935e+02 3.13426239e+02 4.34935852e+02 4.46609100e+02
 8.35464233e+02 8.60828857e+02 4.63502075e+02 1.18389355e+03
 3.09129669e+02 5.80383240e+02 3.90994720e+02 4.00883850e+02
 6.72852783e+02 9.72447083e+02 2.89139893e+02 3.92491333e+02
 5.62752930e+02 2.79192200e+01 1.01783228e+03 1.17448840e+03
 1.16198730e+00 1.02143848e+03 1.31926651e+02 2.81835663e+02
 1.32540390e+02 2.34996323e+02 6.05457275e+02 1.75756912e+02
 7.71168030e+02 4.28270233e+02 1.83063019e+02 5.40941040e+02
 3.04343597e+02 1.77509155e+01 6.93650696e+02 7.07067383e+02
 3.31293823e+02 2.39898285e+02 1.32643811e+03 6.35409302e+02
 6.46478333e+02 7.18050232e+02 4.51572693e+02 5.82230347e+02
 1.13567932e+02 3.44240265e+02 7.86962341e+02 7.71087036e+01
 4.52554047e+02 3.72523254e+02 8.52013000e+02 9.10418701e+01
 2.71225586e+02 4.59606628e+02 7.75112488e+02 3.62949921e+02
 6.65410950e+02 5.66855835e+02 8.21821594e+02 8.82283936e+01
 5.42946594e+02 7.58995605e+02 6.24377075e+02 1.47159424e+02
 1.17479517e+03 8.44778809e+02 4.91555756e+02 6.83921204e+01
 2.45994659e+02 4.59473236e+02 8.32657166e+01 8.04151672e+02
 1.93469193e+02 3.41248657e+02 5.74513367e+02 1.00492932e+03
 4.26404236e+02 3.55764771e+00 5.69704163e+02 9.63125122e+02
 3.44461121e+02 4.72726746e+01 3.94876129e+02 5.04162140e+02
 1.18071289e+01 1.13756018e+03 5.86358643e+01 2.71182770e+02
 2.27140030e+02 5.14123413e+02 8.72013062e+02 5.79910156e+02
 5.80573059e+02 4.09669525e+02 6.54516113e+02 3.52054169e+02
 6.71016602e+02 6.45537415e+01 9.60313721e+02 3.14485413e+02
 8.66568298e+01 9.44947998e+02 3.15855316e+02 5.64192139e+02
 1.24954468e+02 4.18124573e+02 7.53923462e+02 5.76599243e+02
 6.33248840e+02 7.11806824e+02 1.13290375e+02 8.28942322e+02
 1.79855225e+02 1.79430267e+02 6.70669373e+02 1.70873413e+01
 1.53823486e+02 1.86999908e+02 2.00541519e+02 1.73461853e+02
 4.29928619e+02 1.26393494e+02 6.45956421e+02 5.22221863e+02
 1.18641815e+02 2.52186417e+02 1.00527466e+03 7.51806091e+02
 3.43007599e+02 2.35465637e+02 8.70820007e+01 5.92554016e+02
 5.10015259e+02 1.12901013e+03 5.29715942e+02 4.30694580e+00
 4.07793854e+02 7.57631592e+02 7.25960327e+02 5.82625305e+02
 2.15422852e+02 6.29420105e+02 7.53189575e+02 6.58245117e+02
 6.22357422e+02 5.86164856e+01 7.65229187e+02 6.16135254e+01]","[1033.3275    609.5943    364.61224   144.4904    773.4239    208.01251
  708.86664   531.28955   379.60822   137.77197   493.1301    349.61996
  795.183     523.3475    123.93988   697.7508    529.12823   757.1458
  211.92601   348.0404    580.2678    563.2163     12.074554  846.1912
  898.9762    295.44232    37.21913   385.805     312.4008    998.4981
  718.03326  1318.2871    298.78384   149.09698   987.3343    645.4394
  667.32214    52.176285   85.59955    81.50769   434.538     460.81543
 1039.7709    252.36377   105.68831   203.22672    81.34248   557.36566
  772.6238    910.33      635.8348    453.7598    132.57666   430.4829
  509.6863   1011.97546   331.43222   283.92575   140.99532   299.2656
  603.6735    218.26704   505.19965   574.2145   1035.414    1097.3982
  398.37558   448.12616   619.48364   359.1913    104.59912   287.4225
  421.02115   530.01715   380.22946   768.2792    360.67606   498.21848
  129.24022   160.90414    28.049988  166.95973   123.463104  285.5549
  123.7514    861.14185   493.79916   394.6917   1112.369    1055.6833
  291.55566   390.01184   330.94922   158.09926   456.2527    519.2028
  776.8768    285.42908   636.368     121.32083   959.65796  1611.8792
 1176.1835    383.34607   199.11693   440.59988   391.2753    395.8056
   34.58252    20.003418  623.0158    787.89594   282.17712   221.51997
  486.96124   850.90674   400.5752     60.347992  431.1283    580.5339
   94.459076  675.1845     91.14542   463.6946    250.5285    496.79984
  462.2604    572.39197   268.97452   290.6693    276.2488    341.00226
  431.99234   194.56346   539.6213    534.33984   221.22879   593.4044
  452.40466   516.65173   176.22937  1135.8682   1381.0209    371.53864
  964.9827    158.44775   167.9699    386.4442    184.914     529.6757
  383.87357   471.5603    121.50473   514.70593   115.855255   24.712189
  260.86267   380.8094   1086.1987    186.32422    95.81232   496.3539
  680.51294   836.0899    490.49545   238.8569    139.44852   385.12897
  368.15836   648.4005    233.51697    69.1073   1219.6094     30.509521
  402.22476   388.83304    79.781494  426.313     278.1427     74.788574
  771.1835    788.90283   970.04376   759.26196   530.7881     19.641266
  606.0725    690.7045    562.1975    560.1752    647.1467    507.1655
  635.2568    445.96814   956.8152    721.9527    222.01848   267.36334
  844.92017   288.19455   142.05048   722.0402    724.44464   250.647
  595.7398    801.24646   669.7242     31.31845   577.34924    67.1048
  190.53522   413.74402   347.0082    813.3072    475.4962    240.62822
  437.70035   359.94382   375.6216    135.55026   656.69635    68.272675
  947.4251    164.96082   536.96594   331.9316    574.4318     43.30786
  573.46497   835.39404   250.54976   364.67267    84.99899   429.16846
  403.81543   107.99097   533.3203    144.47769   638.2104    154.73851
  497.54132   337.54672   931.20624   881.1381    304.60062   784.1953
  898.57635    30.183746   56.4292    355.58533   978.1216    723.8482
  464.52185   327.0507    345.5324    495.92584   795.51556   763.74164
  476.21954  1224.0311    304.9305    474.26062   426.15176   390.14703
  688.31604   999.8906    333.21423   280.71426   594.73706    46.610397
 1066.2981   1188.7842     24.119568 1036.5449    121.82837   258.5423
  142.19879   270.1008    565.9282    153.70023   813.5947    475.8667
  214.56987   576.0154    268.1386     39.130585  727.1266    711.2595
  296.5594    237.80986  1359.0411    642.48065   554.79565   712.52295
  530.5848    498.83746    62.832138  487.47003   810.49567   111.93678
  609.79596   544.6914    833.2198    139.38489   275.96796   493.49954
  751.0127    371.8229    756.88324   650.4117    759.5865     79.006775
  574.4193    825.0755    657.15076   152.1561   1263.4241    971.81165
  483.23938    65.226166  204.56024   416.5531     96.739105  653.2356
  207.95827   335.68167   555.2539   1058.7927    446.66187    26.50467
  579.3766   1005.45374   392.16486    72.18005   388.1719    492.46414
   45.9245   1181.2416    147.71759   235.25876   263.6833    485.72147
  723.0891    445.45645   650.17883   496.03406   641.6601    342.29242
  666.73486   115.77588   920.6842    268.60422   131.22815   880.5314
  271.9867    555.036     156.04419   486.2199    784.5564    563.36206
  662.9666    674.5626     26.721313  632.17523   156.40616   152.85632
  767.2278     44.294464  189.65768   210.69887   207.16142   167.33643
  479.42334   130.79312   701.8583    531.1558    111.141235  278.91138
  887.8479    779.36755   254.00983   229.68279    81.447815  576.33417
  559.87427   774.29425   530.1702     20.608276  396.0617    704.73975
  730.21655   483.59097   267.80646   667.7354    722.59155   662.7813
  635.3866     74.11401   790.1663     66.742615]",39.97873,3339.7905,57.79092080373655
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 0.371006786823273, Val Loss: 0.312870862483978', 'Epoch: 1, Train Loss: 0.355936307893243, Val Loss: 0.291195963621140', 'Epoch: 2, Train Loss: 0.312128232662068, Val Loss: 0.261567458808422', 'Epoch: 3, Train Loss: 0.229631861455219, Val Loss: 0.129946526587009', 'Epoch: 4, Train Loss: 0.137298031775064, Val Loss: 0.116241596937180', 'Epoch: 5, Train Loss: 0.106129711277263, Val Loss: 0.067414256334305', 'Epoch: 6, Train Loss: 0.091320504889239, Val Loss: 0.073927401006222', 'Epoch: 7, Train Loss: 0.083873054575781, Val Loss: 0.059485922455788', 'Epoch: 8, Train Loss: 0.082347026224746, Val Loss: 0.061385153234005', 'Epoch: 9, Train Loss: 0.080981447513020, Val Loss: 0.065709859132767', 'Epoch: 10, Train Loss: 0.081012392286644, Val Loss: 0.054279103577137', 'Epoch: 11, Train Loss: 0.075946805782096, Val Loss: 0.064702033996582', 'Epoch: 12, Train Loss: 0.069671784895797, Val Loss: 0.049034651219845', 'Epoch: 13, Train Loss: 0.069190454344417, Val Loss: 0.057582118511200', 'Epoch: 14, Train Loss: 0.065010587359930, Val Loss: 0.047796313166618', 'Epoch: 15, Train Loss: 0.058704319648271, Val Loss: 0.041855430603027', 'Epoch: 16, Train Loss: 0.055006200101140, Val Loss: 0.041920134723186', 'Epoch: 17, Train Loss: 0.048428354113428, Val Loss: 0.037054039686918', 'Epoch: 18, Train Loss: 0.043208538554609, Val Loss: 0.035484965443611', 'Epoch: 19, Train Loss: 0.040112646816428, Val Loss: 0.037274869978428', 'Epoch: 20, Train Loss: 0.043574192301305, Val Loss: 0.033248668015003', 'Epoch: 21, Train Loss: 0.036331983759653, Val Loss: 0.033396461158991', 'Epoch: 22, Train Loss: 0.036674956249636, Val Loss: 0.029557615965605', 'Epoch: 23, Train Loss: 0.040022301985774, Val Loss: 0.028346733525395', 'Epoch: 24, Train Loss: 0.034869673380325, Val Loss: 0.037605780661106', 'Epoch: 25, Train Loss: 0.037315069676139, Val Loss: 0.046216326951981', 'Epoch: 26, Train Loss: 0.038958875419096, Val Loss: 0.033315003067255', 'Epoch: 27, Train Loss: 0.032298851541655, Val Loss: 0.029817126691341', 'Epoch: 28, Train Loss: 0.032230481678663, Val Loss: 0.041544767320156', 'Epoch: 29, Train Loss: 0.034186860351542, Val Loss: 0.042270684540272', 'Epoch: 30, Train Loss: 0.033451772879723, Val Loss: 0.033860683739185', 'Epoch: 31, Train Loss: 0.032605521077680, Val Loss: 0.041492471992970', 'Epoch: 32, Train Loss: 0.032833549410625, Val Loss: 0.029419618844986', 'Epoch: 33, Train Loss: 0.031116016165808, Val Loss: 0.029284987747669', 'Epoch: 34, Train Loss: 0.032334671507395, Val Loss: 0.031834379434586', 'Epoch: 35, Train Loss: 0.032773005906059, Val Loss: 0.029399507343769', 'Epoch: 36, Train Loss: 0.029612028841362, Val Loss: 0.028089673519135', 'Epoch: 37, Train Loss: 0.034562410656796, Val Loss: 0.036140058189631', 'Epoch: 38, Train Loss: 0.030103779224636, Val Loss: 0.031463149189949', 'Epoch: 39, Train Loss: 0.028735468553942, Val Loss: 0.028532848209143', 'Epoch: 40, Train Loss: 0.029585140259113, Val Loss: 0.031091141700745', 'Epoch: 41, Train Loss: 0.032181883512368, Val Loss: 0.032064574062824', 'Epoch: 42, Train Loss: 0.031513750639766, Val Loss: 0.028078880459070', 'Epoch: 43, Train Loss: 0.027985893796350, Val Loss: 0.033184305876493', 'Epoch: 44, Train Loss: 0.029384111119218, Val Loss: 0.032254508435726', 'Epoch: 45, Train Loss: 0.030703572253155, Val Loss: 0.031534854918718', 'Epoch: 46, Train Loss: 0.030437461252129, Val Loss: 0.035872365683317', 'Epoch: 47, Train Loss: 0.027637956750601, Val Loss: 0.028935357630253', 'Epoch: 48, Train Loss: 0.025973978972192, Val Loss: 0.029449251443148', 'Epoch: 49, Train Loss: 0.030838525139315, Val Loss: 0.031191056072712', 'Epoch: 50, Train Loss: 0.026301219171390, Val Loss: 0.030820601284504', 'Epoch: 51, Train Loss: 0.028315581771177, Val Loss: 0.030098188370466', 'Epoch: 52, Train Loss: 0.025777180419239, Val Loss: 0.029782807826996', 'Epoch: 53, Train Loss: 0.023630255919903, Val Loss: 0.029446039348841', 'Epoch: 54, Train Loss: 0.024528563499104, Val Loss: 0.028713733255863', 'Epoch: 55, Train Loss: 0.023798422519724, Val Loss: 0.030878238677979', 'Epoch: 56, Train Loss: 0.025020066497111, Val Loss: 0.034986709654331', 'Epoch: 57, Train Loss: 0.023999681089853, Val Loss: 0.029550565481186', 'Epoch: 58, Train Loss: 0.023466208949685, Val Loss: 0.031820996254683', 'Epoch: 59, Train Loss: 0.023896612140328, Val Loss: 0.037027589380741', 'Epoch: 60, Train Loss: 0.023769174312610, Val Loss: 0.029244777932763', 'Epoch: 61, Train Loss: 0.022186464370163, Val Loss: 0.035737448930740', 'Epoch: 62, Train Loss: 0.024529920002922, Val Loss: 0.030653710663319', 'Epoch: 63, Train Loss: 0.024643275280331, Val Loss: 0.034375459402800', 'Epoch: 64, Train Loss: 0.022531553409820, Val Loss: 0.030486848056316', 'Epoch: 65, Train Loss: 0.023590280371177, Val Loss: 0.035583927035332', 'Epoch: 66, Train Loss: 0.021345350349885, Val Loss: 0.031159094572067', 'Epoch: 67, Train Loss: 0.020739120626172, Val Loss: 0.038010849952698', 'Epoch: 68, Train Loss: 0.024265723043056, Val Loss: 0.034532991200686', 'Epoch: 69, Train Loss: 0.020799367645279, Val Loss: 0.029526649862528', 'Epoch: 70, Train Loss: 0.020960203415259, Val Loss: 0.028269895464182', 'Epoch: 71, Train Loss: 0.020511059523668, Val Loss: 0.031986629962921', 'Epoch: 72, Train Loss: 0.022297161544651, Val Loss: 0.028488737791777', 'Epoch: 73, Train Loss: 0.020262958373615, Val Loss: 0.029163754284382', 'Epoch: 74, Train Loss: 0.020171549777652, Val Loss: 0.029204341173172', 'Epoch: 75, Train Loss: 0.020053297562828, Val Loss: 0.029429603591561', 'Epoch: 76, Train Loss: 0.021705017663365, Val Loss: 0.034843517094851', 'Epoch: 77, Train Loss: 0.022928608343178, Val Loss: 0.029178044348955', 'Epoch: 78, Train Loss: 0.018516207200497, Val Loss: 0.028140850961208', 'Epoch: 79, Train Loss: 0.018949720575366, Val Loss: 0.032100818753242', 'Epoch: 80, Train Loss: 0.021614737462166, Val Loss: 0.038699846267700', 'Epoch: 81, Train Loss: 0.020480321092141, Val Loss: 0.030917109102011', 'Epoch: 82, Train Loss: 0.018511534365284, Val Loss: 0.031802238672972', 'Epoch: 83, Train Loss: 0.018366241069554, Val Loss: 0.029755191802979', 'Epoch: 84, Train Loss: 0.019001675358172, Val Loss: 0.027537564337254', 'Epoch: 85, Train Loss: 0.017114326379500, Val Loss: 0.033358660936356', 'Epoch: 86, Train Loss: 0.019422067350946, Val Loss: 0.031424163430929', 'Epoch: 87, Train Loss: 0.016935500749495, Val Loss: 0.027891866192222', 'Epoch: 88, Train Loss: 0.016419305920947, Val Loss: 0.028684775829315', 'Epoch: 89, Train Loss: 0.017189401158586, Val Loss: 0.030759035050869', 'Epoch: 90, Train Loss: 0.016844042641825, Val Loss: 0.032620872855186', 'Epoch: 91, Train Loss: 0.016582609522481, Val Loss: 0.031271919012070', 'Epoch: 92, Train Loss: 0.017062331506506, Val Loss: 0.029912447184324', 'Epoch: 93, Train Loss: 0.017569600063008, Val Loss: 0.031641796827316', 'Epoch: 94, Train Loss: 0.015924739716358, Val Loss: 0.029847314059734', 'Epoch: 95, Train Loss: 0.014638213679021, Val Loss: 0.030144172757864', 'Epoch: 96, Train Loss: 0.015317639682529, Val Loss: 0.028814306333661', 'Epoch: 97, Train Loss: 0.016060741650764, Val Loss: 0.031141504943371', 'Epoch: 98, Train Loss: 0.015671269556637, Val Loss: 0.029121458381414', 'Epoch: 99, Train Loss: 0.015665178663682, Val Loss: 0.032936018258333', 'Epoch: 100, Train Loss: 0.014970261809351, Val Loss: 0.032070869207382', 'Epoch: 101, Train Loss: 0.016750094459154, Val Loss: 0.029516295492649', 'Epoch: 102, Train Loss: 0.014491231072434, Val Loss: 0.030589579492807', 'Epoch: 103, Train Loss: 0.014328776544696, Val Loss: 0.031591856926680', 'Epoch: 104, Train Loss: 0.014867245176331, Val Loss: 0.033408136218786', 'Epoch: 105, Train Loss: 0.017398771483364, Val Loss: 0.030640622079372', 'Epoch: 106, Train Loss: 0.015445285119376, Val Loss: 0.031016451418400', 'Epoch: 107, Train Loss: 0.014993880344771, Val Loss: 0.027349764853716', 'Epoch: 108, Train Loss: 0.014582754935809, Val Loss: 0.030674403607845', 'Epoch: 109, Train Loss: 0.015380838322778, Val Loss: 0.030700142234564', 'Epoch: 110, Train Loss: 0.013089835308059, Val Loss: 0.030665394663811', 'Epoch: 111, Train Loss: 0.014301805134300, Val Loss: 0.034926438480616', 'Epoch: 112, Train Loss: 0.014383066651346, Val Loss: 0.027772685736418', 'Epoch: 113, Train Loss: 0.014260306098867, Val Loss: 0.035359288305044', 'Epoch: 114, Train Loss: 0.015320295099775, Val Loss: 0.029464833140373', 'Epoch: 115, Train Loss: 0.013259099027532, Val Loss: 0.031713688075542', 'Epoch: 116, Train Loss: 0.013180779932110, Val Loss: 0.031515237092972', 'Epoch: 117, Train Loss: 0.013402396054982, Val Loss: 0.028515058308840', 'Epoch: 118, Train Loss: 0.012685485574049, Val Loss: 0.033230939060450', 'Epoch: 119, Train Loss: 0.012906938747958, Val Loss: 0.034551021009684', 'Epoch: 120, Train Loss: 0.013311281367097, Val Loss: 0.034071610271931', 'Epoch: 121, Train Loss: 0.014942273324312, Val Loss: 0.032374432086945', 'Epoch: 122, Train Loss: 0.014266626043029, Val Loss: 0.033945341110229', 'Epoch: 123, Train Loss: 0.013097701410135, Val Loss: 0.034390970468521', 'Epoch: 124, Train Loss: 0.013229897473181, Val Loss: 0.040142345130444', 'Epoch: 125, Train Loss: 0.012563070293169, Val Loss: 0.029785819575191', 'Epoch: 126, Train Loss: 0.012175325845736, Val Loss: 0.031261589825153', 'Epoch: 127, Train Loss: 0.011586619367780, Val Loss: 0.030283469408751', 'Epoch: 128, Train Loss: 0.011451557137852, Val Loss: 0.035137886703014', 'Epoch: 129, Train Loss: 0.011375640800526, Val Loss: 0.028754171431065', 'Epoch: 130, Train Loss: 0.012093239615476, Val Loss: 0.028770769387484', 'Epoch: 131, Train Loss: 0.012300717774345, Val Loss: 0.031484147757292', 'Epoch: 132, Train Loss: 0.011315468536300, Val Loss: 0.028704004436731', 'Epoch: 133, Train Loss: 0.011685293860907, Val Loss: 0.031134313866496', 'Epoch: 134, Train Loss: 0.010977683112372, Val Loss: 0.031555397957563', 'Epoch: 135, Train Loss: 0.010829481404535, Val Loss: 0.032199612110853', 'Epoch: 136, Train Loss: 0.011469086263935, Val Loss: 0.033455713838339', 'Epoch: 137, Train Loss: 0.010493037269212, Val Loss: 0.031597980111837', 'Epoch: 138, Train Loss: 0.010500615982469, Val Loss: 0.035580098927021', 'Epoch: 139, Train Loss: 0.010998630766259, Val Loss: 0.029777915105224', 'Epoch: 140, Train Loss: 0.010658482057151, Val Loss: 0.030846399217844', 'Epoch: 141, Train Loss: 0.010272465613779, Val Loss: 0.031509281992912', 'Epoch: 142, Train Loss: 0.010319442618205, Val Loss: 0.034411038979888', 'Epoch: 143, Train Loss: 0.010551375347774, Val Loss: 0.032193646579981', 'Epoch: 144, Train Loss: 0.010046654770714, Val Loss: 0.030524141564965', 'Epoch: 145, Train Loss: 0.009551327502312, Val Loss: 0.031175921112299', 'Epoch: 146, Train Loss: 0.011145606398756, Val Loss: 0.032861132770777', 'Epoch: 147, Train Loss: 0.010444373747897, Val Loss: 0.028658936768770', 'Epoch: 148, Train Loss: 0.011764529659305, Val Loss: 0.031790886744857', 'Epoch: 149, Train Loss: 0.010405441442894, Val Loss: 0.031797572970390', 'Epoch: 150, Train Loss: 0.012252891371243, Val Loss: 0.033605611026287', 'Epoch: 151, Train Loss: 0.012662500413784, Val Loss: 0.028179421722889', 'Epoch: 152, Train Loss: 0.009977958073060, Val Loss: 0.033120114356279', 'Epoch: 153, Train Loss: 0.010109909701833, Val Loss: 0.029626741707325', 'Epoch: 154, Train Loss: 0.009916774787788, Val Loss: 0.029109566807747', 'Epoch: 155, Train Loss: 0.009369994697789, Val Loss: 0.029947140365839', 'Epoch: 156, Train Loss: 0.010848707692741, Val Loss: 0.034205615818501', 'Epoch: 157, Train Loss: 0.009937376650267, Val Loss: 0.030188768506050', 'Epoch: 158, Train Loss: 0.009617892981962, Val Loss: 0.028832031786442', 'Epoch: 159, Train Loss: 0.008225148197177, Val Loss: 0.030694594234228', 'Epoch: 160, Train Loss: 0.009306197412052, Val Loss: 0.032685386687517', 'Epoch: 161, Train Loss: 0.010188553547270, Val Loss: 0.029184087514877', 'Epoch: 162, Train Loss: 0.009134565360931, Val Loss: 0.030551809519529', 'Epoch: 163, Train Loss: 0.009776712211152, Val Loss: 0.030115298330784', 'Epoch: 164, Train Loss: 0.009523613898214, Val Loss: 0.029318460971117', 'Epoch: 165, Train Loss: 0.009348467111501, Val Loss: 0.031133949458599', 'Epoch: 166, Train Loss: 0.009006821431306, Val Loss: 0.030977667272091', 'Epoch: 167, Train Loss: 0.008575298780099, Val Loss: 0.030566589012742', 'Epoch: 168, Train Loss: 0.008361076167243, Val Loss: 0.031131963878870', 'Epoch: 169, Train Loss: 0.008283663920105, Val Loss: 0.028920451551676', 'Epoch: 170, Train Loss: 0.008264228214272, Val Loss: 0.030467670410872', 'Epoch: 171, Train Loss: 0.009004474541736, Val Loss: 0.029889512807131', 'Epoch: 172, Train Loss: 0.008820312325085, Val Loss: 0.032006328627467', 'Epoch: 173, Train Loss: 0.007815403365638, Val Loss: 0.030083499699831', 'Epoch: 174, Train Loss: 0.008758418868447, Val Loss: 0.029437105059624', 'Epoch: 175, Train Loss: 0.008552098933737, Val Loss: 0.030153038352728', 'Epoch: 176, Train Loss: 0.008503252174705, Val Loss: 0.032202652692795', 'Epoch: 177, Train Loss: 0.008318853369632, Val Loss: 0.030810547024012', 'Epoch: 178, Train Loss: 0.008100134423436, Val Loss: 0.030871643126011', 'Epoch: 179, Train Loss: 0.007872612285969, Val Loss: 0.032179499864578', 'Epoch: 180, Train Loss: 0.007715254047409, Val Loss: 0.030329943448305', 'Epoch: 181, Train Loss: 0.008003475713045, Val Loss: 0.029379635378718', 'Epoch: 182, Train Loss: 0.007475342244170, Val Loss: 0.030516569912434', 'Epoch: 183, Train Loss: 0.007279047228093, Val Loss: 0.029909802079201', 'Epoch: 184, Train Loss: 0.007357499275227, Val Loss: 0.029249136149883', 'Epoch: 185, Train Loss: 0.007599233216498, Val Loss: 0.030566193759441', 'Epoch: 186, Train Loss: 0.008146363700372, Val Loss: 0.030047889351845', 'Epoch: 187, Train Loss: 0.007828954970031, Val Loss: 0.030955555438995', 'Epoch: 188, Train Loss: 0.007442734859407, Val Loss: 0.030221871286631', 'Epoch: 189, Train Loss: 0.007734138188277, Val Loss: 0.029216761589050', 'Epoch: 190, Train Loss: 0.007896870807853, Val Loss: 0.031012468934059', 'Epoch: 191, Train Loss: 0.007480535515432, Val Loss: 0.029393450170755', 'Epoch: 192, Train Loss: 0.008049673000134, Val Loss: 0.029915178865194', 'Epoch: 193, Train Loss: 0.007106376178346, Val Loss: 0.029774461537600', 'Epoch: 194, Train Loss: 0.007829992631234, Val Loss: 0.029433567374945', 'Epoch: 195, Train Loss: 0.007513137138990, Val Loss: 0.030056281983852', 'Epoch: 196, Train Loss: 0.007168206694904, Val Loss: 0.029420487731695', 'Epoch: 197, Train Loss: 0.007191142278485, Val Loss: 0.029589833021164', 'Epoch: 198, Train Loss: 0.006966536745516, Val Loss: 0.029758480787277', 'Epoch: 199, Train Loss: 0.007776720487231, Val Loss: 0.029940868765116']","[ 624.02423    645.22284    746.4755     684.69116    659.68634
  297.72116    593.87134    111.07825   1261.771      536.84625
  128.1105     615.09296    516.2195     695.48834   1138.6683
  508.31668    173.17972    574.4999     344.70023     21.838867
  401.91763     41.302856   160.47559    146.70143    171.80981
  303.82382    163.263      565.14087    200.25073    596.5774
    9.660614   117.02179    170.30614      9.379242   451.05627
  892.97       913.05035   1409.7766     514.8704     402.12872
  884.3485     522.9502     738.5331     277.00208    179.30917
  231.20673      6.1844177  244.78226    856.8629     893.92615
  582.7081     235.53076    932.72034    416.60284    158.94452
  600.1701     942.3081     981.06396    635.70245    263.9358
  776.09766    143.88654    527.8695     744.4396     224.2785
  660.6988     611.6223     339.60056    392.62112     19.87207
   39.351868   184.02052    919.5456    1011.18884    307.15353
  889.46277    999.2449     248.04755   1422.1765    1005.8761
   38.953415     7.6737366  810.1791     219.61716    237.58682
  813.3174     571.88586    269.8507      28.518005   469.19547
   54.248596   330.71603    211.70541     88.46774    685.834
  184.91046    305.403      309.46625    372.3308    1011.7884
  993.9281     686.0082     184.63214    227.4848     260.69598
  717.9086     111.03186    445.4638     118.21863     44.976654
  712.32446    572.28467    360.70258    157.76157    763.7543
  564.7911     124.5798     463.21924    539.4207     487.36877
  470.73367    719.50977    283.73187     69.48239   1058.1924
  225.07822    419.72165    240.44096    740.28485   1093.1655
  217.17557     85.664276    39.739532   310.94608   1011.1178
  908.8791     740.9675     773.94086    423.86465     48.437714
  175.06656    713.85187    359.84198    711.34094    609.4333
  871.2607      27.25412    691.4109    1105.2764    1246.6116
  917.9816     288.48026    840.0362     595.741      165.74274
  728.56934    341.52252     65.071045   610.4049    1228.2405
  595.33966     23.388062   658.8761     145.84596    472.06393
  225.4602     197.22849     47.075256   897.9614     464.12958
  304.35706     45.815063   748.0794     427.50723    113.147
  534.32294    459.25012    489.07385    196.20435    591.2241
  624.0758     353.31107    398.60245    396.49094    474.92462
  100.48388   1033.7       1353.2733      48.55887    562.38544
  331.48206    182.27954   1105.6497     865.70435    859.7092
  466.33154    259.0413     231.57765    241.41664    290.66708
  560.428      571.34503    244.15703    691.4933     187.43205
  363.58514    672.307      946.86993    933.20355    207.32364
  366.01035    407.49594    439.71964    284.54474    137.70715
  766.4275     101.96384    267.698      409.9464     379.43954
   64.54828    595.0394     264.834      203.22916   1299.6917
  821.1656     295.73383    549.6151     350.65314     64.967865
   52.679047   480.1442    1133.6475    1102.223       77.717224
  940.6878     385.25214    810.7108     294.76218    620.56177
  129.12875    356.6612     361.50253    152.58195    521.36414
  951.68286    202.26707    289.61685    602.7756      13.648193
  604.0413     284.6363    1091.1932    1161.291      486.4137
  194.22948    426.84338    488.50632    738.68604     69.85162
   90.20529     79.789276   499.906       81.08188    723.39465
  636.94977    722.7733      27.402954   443.3636     545.8211
  229.53534    572.48785    237.97646    378.13324    438.31818
  508.96677    473.31223    191.54396    443.01907    659.1204
  880.9065     500.47745    327.04144    246.45148    676.4028
  645.1134     453.4824     272.0517     218.2027     504.19498
 1000.5973      85.19345    845.37524    883.63934    403.95328
  112.21698     76.41208    886.8687     675.5602     529.92615
  923.3754     653.12555    161.99213    608.0746     529.5851
  168.336      210.31552   1235.7043     279.3806     167.84628
  781.8174     606.9031    1224.6216     968.7288     343.60522
  156.0503     243.26062    371.67648    719.9202     111.84955
  106.14171    116.9536     975.1446    1052.4219     452.19666
  143.53156    998.17163     23.809631   135.72513    332.34537
  362.4828     311.42163    909.4208     201.36697    256.53925
  671.4996     829.6905     245.83539    726.22815    533.0665
  133.93402    394.61417    985.78784    802.1061     217.0376
   68.00183    426.26257    473.05573    525.6645     207.20256
  540.611       57.29358    419.90314     47.368347   754.59454
  328.4369     874.9733     858.1052     255.33435   1044.6222
  259.39703     66.54761     99.9057     175.69392   1054.2133
  973.5172    1365.6628    1328.2307     241.88907    142.78665
   35.582092   327.1531     194.2558     222.26614    112.27759
  322.95306    490.5563      20.477081   277.38263    105.16678
  986.7056     384.15228    159.39735    134.01254    452.61606
  521.4828     180.71217    218.14844      7.081909   268.75165
 1060.9255     590.03436    951.12054    407.43362    629.1599
   91.15842    122.50571    324.32343    152.42422    198.48582  ]","[ 612.48145    590.46063    615.0519     495.66968    703.3423
  275.3341     682.8594      29.379425  1169.0479     556.4763
  203.6177     600.00934    539.9771     734.07294   1021.4891
  289.65903    142.8771     600.7599     354.1775     217.03937
  403.74136    266.95224    249.60588    155.69069    182.30219
  247.68518    155.82556    602.93115    226.18854    690.3364
   30.284424   152.87633    116.26349     50.83641    492.46494
  878.38135    943.7248    1328.6729     476.7541     404.9642
  826.0668     477.92484    726.6585     341.89114    115.9758
  178.9815     111.26555    201.6931     912.3714     925.61615
  610.2776     216.15134    933.7328     360.07736    179.1885
  631.0846     857.97485    834.7076     654.9548     275.20444
  783.9629     154.29984    409.58496    784.86804    303.33276
  592.7042     726.5161     352.66232    336.64978     99.80812
   46.872314    94.86572   1064.2389    1256.6396     311.9843
  857.43066   1005.8805     305.0495    1252.4072     987.75684
  175.40866     64.176254   882.21765    187.24411    168.90033
  783.69147    607.341      394.62817    200.23433    461.09915
   57.12285    339.0846     176.94626    130.15405    754.8883
  100.15582    474.86615    264.35803    485.48828    792.46643
  975.4029     757.3429     103.4646     217.08331    426.32288
  704.2467     204.0105     476.78912    121.36597     70.99216
  549.2356     628.28845    366.0544     177.38185    673.7793
  556.58575    135.65216    418.73712    639.4741     500.96655
  446.24542    673.80096    255.80798    118.01364    963.65717
  171.84946    411.95166    268.92767    659.15375   1039.7622
  221.35774    109.16821     63.545425   301.77396    918.6204
 1155.1334     811.9362     874.98676    446.49402     83.5188
  170.37692    713.1724     408.2859     728.70886    543.28754
  809.4897     394.85077    616.8462    1054.8217    1243.0839
  936.49097    258.081      904.3347     527.23975    164.07062
  687.0273     358.2378      62.340454   609.53564   1090.353
  523.19574    -31.638245   684.35205    141.90219    574.4855
  196.76813    163.14398    107.88629    945.2972     310.47092
  316.5337      98.428925   818.0116     350.84207     76.01398
  542.094      587.456      567.78186    202.40521    516.8146
  659.88513    158.43205    418.49762    484.70438    573.57385
  -14.483719   957.2453    1253.5137      45.73001    591.39185
  409.80215    268.3492    1089.4341     956.152      853.1456
  400.61435    249.23703    181.47093    250.77318    313.6402
  578.79626    543.6724     265.8604     687.6212      55.367126
  372.09726    716.29834    938.54       977.405      299.29648
  329.94318    370.1321     418.02582    282.32092    132.54309
  644.34235    108.35858    279.87653    380.98505    416.245
   19.059235   569.3439     287.42343    196.74118   1272.5547
  768.83984    173.98254    408.5161     310.1908       6.9629517
  147.1817     217.21938   1220.9939    1000.77466     49.990967
  922.9711     386.73013    800.19214    258.85205    565.6199
  170.56143    307.3257     373.93457    140.32587    390.89822
  936.2221     132.73575    260.8888     678.7184     153.17896
  614.946      277.35507   1012.74304   1258.4668     466.65588
   46.473633   370.12833    522.2247     743.12024     52.66687
  116.83711    154.43805    532.4105      33.74176    557.28015
  645.2028     612.9761      85.72943    478.98685    523.3536
  252.01971    613.19617    253.3888     393.07718    353.86188
  627.1467     457.49225    171.10353    383.71988    672.2982
  949.37805    435.15796    418.94308    207.58484    797.8667
  620.1976     562.92505    348.5005     137.00864    411.29495
  961.141      190.85117   1007.4679     985.89764    351.9781
  198.25726     23.393677   938.5587     651.82587    539.19714
 1032.5687     672.2375     174.8562     586.4219     499.96707
  210.88321    -58.95465   1120.9498     301.6856     165.8802
  703.422      726.02875   1225.0989    1039.2747     364.8304
  129.90471    236.00821    330.35712    799.8383     100.028076
   93.30373     84.08348   1004.57404   1023.5904     480.73337
  220.11264   1033.2169     -66.70886    114.49954    329.26486
  384.22107    334.0219     890.6433     352.10614    254.3023
  714.0398     795.4258     369.155      693.91406    499.11627
  162.51263    352.5032    1021.1799     795.61707    158.32095
  119.770966   355.82498    386.70135    520.5779     243.40236
  507.23312    112.93103    391.2579     171.58313    796.19696
  384.49915    960.0537     943.71436    229.99545    953.51263
  274.87094     69.20947     78.08124    229.91309    941.8146
  895.29474   1251.5525    1222.4183     285.36945    190.70073
  177.13745    309.67096    199.47011    198.25883    143.68536
  227.03876    362.37317     83.52432    285.70404     91.621
  918.24786    347.83542    300.97943    -11.718094   510.40692
  534.87585    209.38135    251.58682     41.519623   301.84772
 1118.5144     709.46155    956.9533     426.44556    493.825
   73.38141    132.03746    309.25446    121.93007    137.56169  ]",55.936558,5760.4014,75.89730803650087
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 1.523361886656561, Val Loss: 1.134336872100830', 'Epoch: 1, Train Loss: 1.293716297593228, Val Loss: 1.104723548889160', 'Epoch: 2, Train Loss: 1.268346057381741, Val Loss: 1.069924006462097', 'Epoch: 3, Train Loss: 1.185513267683428, Val Loss: 1.020835566520691', 'Epoch: 4, Train Loss: 1.088280892649362, Val Loss: 0.882373800277710', 'Epoch: 5, Train Loss: 0.874179446073466, Val Loss: 0.709629168510437', 'Epoch: 6, Train Loss: 0.685462322692538, Val Loss: 0.683607034683228', 'Epoch: 7, Train Loss: 0.661750562662302, Val Loss: 0.610067982673645', 'Epoch: 8, Train Loss: 0.634465730120969, Val Loss: 0.596620850563049', 'Epoch: 9, Train Loss: 0.652775695157606, Val Loss: 0.720053033828735', 'Epoch: 10, Train Loss: 0.634158007627310, Val Loss: 0.627530536651611', 'Epoch: 11, Train Loss: 0.576131462704304, Val Loss: 0.626548970937729', 'Epoch: 12, Train Loss: 0.573527040869691, Val Loss: 0.646802635192871', 'Epoch: 13, Train Loss: 0.552983169292295, Val Loss: 0.658312473297119', 'Epoch: 14, Train Loss: 0.553333232569140, Val Loss: 0.685734434127808', 'Epoch: 15, Train Loss: 0.565706209387890, Val Loss: 0.594939591884613', 'Epoch: 16, Train Loss: 0.513913617577664, Val Loss: 0.563358410596848', 'Epoch: 17, Train Loss: 0.535141814240189, Val Loss: 0.624828234910965', 'Epoch: 18, Train Loss: 0.514666421122329, Val Loss: 0.592446867227554', 'Epoch: 19, Train Loss: 0.500194666344066, Val Loss: 0.625146954059601', 'Epoch: 20, Train Loss: 0.525592966481697, Val Loss: 0.602134239673614', 'Epoch: 21, Train Loss: 0.496401292640109, Val Loss: 0.658588399887085', 'Epoch: 22, Train Loss: 0.485632577607798, Val Loss: 0.609886302947998', 'Epoch: 23, Train Loss: 0.484280923424765, Val Loss: 0.575921540260315', 'Epoch: 24, Train Loss: 0.454737828221432, Val Loss: 0.576688824892044', 'Epoch: 25, Train Loss: 0.480820416711098, Val Loss: 0.593120630979538', 'Epoch: 26, Train Loss: 0.465256207904150, Val Loss: 0.607147655487061', 'Epoch: 27, Train Loss: 0.450355623004048, Val Loss: 0.614226765632629', 'Epoch: 28, Train Loss: 0.462038498631744, Val Loss: 0.674135341644287', 'Epoch: 29, Train Loss: 0.443787989055001, Val Loss: 0.650214393138886', 'Epoch: 30, Train Loss: 0.459778745160546, Val Loss: 0.581255559921265', 'Epoch: 31, Train Loss: 0.439097636314326, Val Loss: 0.637369763255119', 'Epoch: 32, Train Loss: 0.407892038309297, Val Loss: 0.612926779985428', 'Epoch: 33, Train Loss: 0.439257690033247, Val Loss: 0.570577082633972', 'Epoch: 34, Train Loss: 0.414566674204760, Val Loss: 0.639692863225937', 'Epoch: 35, Train Loss: 0.460027653464051, Val Loss: 0.681816838979721', 'Epoch: 36, Train Loss: 0.436662285480388, Val Loss: 0.673683047294617', 'Epoch: 37, Train Loss: 0.408412126607673, Val Loss: 0.595722364187241', 'Epoch: 38, Train Loss: 0.414570774796397, Val Loss: 0.619760472774506', 'Epoch: 39, Train Loss: 0.420014843344688, Val Loss: 0.603632847070694', 'Epoch: 40, Train Loss: 0.415998196186021, Val Loss: 0.644406299591064', 'Epoch: 41, Train Loss: 0.408979544112849, Val Loss: 0.599372497797012', 'Epoch: 42, Train Loss: 0.396148276190425, Val Loss: 0.673215198516846', 'Epoch: 43, Train Loss: 0.386263061401456, Val Loss: 0.556084276437759', 'Epoch: 44, Train Loss: 0.359765860923501, Val Loss: 0.680619071722031', 'Epoch: 45, Train Loss: 0.366261858579724, Val Loss: 0.552323346138000', 'Epoch: 46, Train Loss: 0.378141959046209, Val Loss: 0.638669947385788', 'Epoch: 47, Train Loss: 0.335462748657825, Val Loss: 0.719457536935806', 'Epoch: 48, Train Loss: 0.361160018416338, Val Loss: 0.662286669015884', 'Epoch: 49, Train Loss: 0.376192317799080, Val Loss: 0.653343602418900', 'Epoch: 50, Train Loss: 0.355197691640189, Val Loss: 0.572566999197006', 'Epoch: 51, Train Loss: 0.340481254597043, Val Loss: 0.581864480972290', 'Epoch: 52, Train Loss: 0.336488847815713, Val Loss: 0.666098765134811', 'Epoch: 53, Train Loss: 0.323895344553992, Val Loss: 0.654085749387741', 'Epoch: 54, Train Loss: 0.308702701572762, Val Loss: 0.639112658500671', 'Epoch: 55, Train Loss: 0.301338635211767, Val Loss: 0.664350535869598', 'Epoch: 56, Train Loss: 0.292803630925888, Val Loss: 0.644117245674133', 'Epoch: 57, Train Loss: 0.289342975027339, Val Loss: 0.604133204221725', 'Epoch: 58, Train Loss: 0.290172620048357, Val Loss: 0.652131519317627', 'Epoch: 59, Train Loss: 0.296615411029306, Val Loss: 0.605592179298401', 'Epoch: 60, Train Loss: 0.282913392019826, Val Loss: 0.638789660930633', 'Epoch: 61, Train Loss: 0.278640644148339, Val Loss: 0.732562685012817', 'Epoch: 62, Train Loss: 0.281023380194986, Val Loss: 0.741131799221039', 'Epoch: 63, Train Loss: 0.260235202693662, Val Loss: 0.647983663082123', 'Epoch: 64, Train Loss: 0.241093544072883, Val Loss: 0.675500423312187', 'Epoch: 65, Train Loss: 0.242210239691790, Val Loss: 0.646605477333069', 'Epoch: 66, Train Loss: 0.255488522524057, Val Loss: 0.633176915645599', 'Epoch: 67, Train Loss: 0.236532930891181, Val Loss: 0.601726794242859', 'Epoch: 68, Train Loss: 0.224273009009139, Val Loss: 0.578847620487213', 'Epoch: 69, Train Loss: 0.238206333892290, Val Loss: 0.549809572696686', 'Epoch: 70, Train Loss: 0.207440010596846, Val Loss: 0.591680098772049', 'Epoch: 71, Train Loss: 0.211765471585961, Val Loss: 0.651040067672729', 'Epoch: 72, Train Loss: 0.202819638993851, Val Loss: 0.615127956867218', 'Epoch: 73, Train Loss: 0.201870138475368, Val Loss: 0.685825284719467', 'Epoch: 74, Train Loss: 0.221098312285057, Val Loss: 0.659248667955399', 'Epoch: 75, Train Loss: 0.223057925527872, Val Loss: 0.641415359973907', 'Epoch: 76, Train Loss: 0.180164586666018, Val Loss: 0.681934311389923', 'Epoch: 77, Train Loss: 0.172832629361818, Val Loss: 0.618568177223206', 'Epoch: 78, Train Loss: 0.177865090585032, Val Loss: 0.742225106954575', 'Epoch: 79, Train Loss: 0.168550547645536, Val Loss: 0.780631446838379', 'Epoch: 80, Train Loss: 0.181521703684053, Val Loss: 0.660628089904785', 'Epoch: 81, Train Loss: 0.173005610011345, Val Loss: 0.647887887954712', 'Epoch: 82, Train Loss: 0.166687007387017, Val Loss: 0.795820415019989', 'Epoch: 83, Train Loss: 0.156577556805555, Val Loss: 0.586269209384918', 'Epoch: 84, Train Loss: 0.161546793614709, Val Loss: 0.663815934658051', 'Epoch: 85, Train Loss: 0.162683196192564, Val Loss: 0.643082405328751', 'Epoch: 86, Train Loss: 0.160175222123778, Val Loss: 0.681588230133057', 'Epoch: 87, Train Loss: 0.149403740240391, Val Loss: 0.724517564773560', 'Epoch: 88, Train Loss: 0.139011390333952, Val Loss: 0.696881573200226', 'Epoch: 89, Train Loss: 0.149474740374920, Val Loss: 0.637993535995483', 'Epoch: 90, Train Loss: 0.142251200454180, Val Loss: 0.721751487255096', 'Epoch: 91, Train Loss: 0.134685468621725, Val Loss: 0.700602023601532', 'Epoch: 92, Train Loss: 0.126468915578931, Val Loss: 0.725796990394592', 'Epoch: 93, Train Loss: 0.134327740256870, Val Loss: 0.682052755355835', 'Epoch: 94, Train Loss: 0.124686181545258, Val Loss: 0.656023492813110', 'Epoch: 95, Train Loss: 0.127665492770977, Val Loss: 0.704953646659851', 'Epoch: 96, Train Loss: 0.124452547018611, Val Loss: 0.679516236782074', 'Epoch: 97, Train Loss: 0.115845899769040, Val Loss: 0.690740468502045', 'Epoch: 98, Train Loss: 0.119047198791144, Val Loss: 0.706774488687515', 'Epoch: 99, Train Loss: 0.109312063039735, Val Loss: 0.716271637678146', 'Epoch: 100, Train Loss: 0.105347302937230, Val Loss: 0.697778124809265', 'Epoch: 101, Train Loss: 0.122880622051483, Val Loss: 0.762920446395874', 'Epoch: 102, Train Loss: 0.113353019450293, Val Loss: 0.789946901798248', 'Epoch: 103, Train Loss: 0.118594645587511, Val Loss: 0.751233816146851', 'Epoch: 104, Train Loss: 0.111064788040727, Val Loss: 0.717718877792358', 'Epoch: 105, Train Loss: 0.093876430634842, Val Loss: 0.769512902498245', 'Epoch: 106, Train Loss: 0.093627252291108, Val Loss: 0.732685856819153', 'Epoch: 107, Train Loss: 0.090099234567132, Val Loss: 0.703223702907562', 'Epoch: 108, Train Loss: 0.096513668551695, Val Loss: 0.785190478563309', 'Epoch: 109, Train Loss: 0.087451138815214, Val Loss: 0.739568120241165', 'Epoch: 110, Train Loss: 0.094061062606268, Val Loss: 0.674768589735031', 'Epoch: 111, Train Loss: 0.086346909230532, Val Loss: 0.713600397109985', 'Epoch: 112, Train Loss: 0.076692464393239, Val Loss: 0.697079119682312', 'Epoch: 113, Train Loss: 0.081825142423081, Val Loss: 0.702157829999924', 'Epoch: 114, Train Loss: 0.080036539194542, Val Loss: 0.734322389364243', 'Epoch: 115, Train Loss: 0.089916084048360, Val Loss: 0.695006418228149', 'Epoch: 116, Train Loss: 0.100010383094466, Val Loss: 0.676852779388428', 'Epoch: 117, Train Loss: 0.088700935764368, Val Loss: 0.670361816883087', 'Epoch: 118, Train Loss: 0.079909671097994, Val Loss: 0.727389183044434', 'Epoch: 119, Train Loss: 0.083592571404784, Val Loss: 0.800614656209946', 'Epoch: 120, Train Loss: 0.083139677986849, Val Loss: 0.723691029548645', 'Epoch: 121, Train Loss: 0.075816355125849, Val Loss: 0.718885941505432', 'Epoch: 122, Train Loss: 0.074516692133837, Val Loss: 0.677721939086914', 'Epoch: 123, Train Loss: 0.070452117469422, Val Loss: 0.695539195537567', 'Epoch: 124, Train Loss: 0.074804081819778, Val Loss: 0.722651556730270', 'Epoch: 125, Train Loss: 0.072088980484147, Val Loss: 0.791185959577560', 'Epoch: 126, Train Loss: 0.080374816042739, Val Loss: 0.766808633804321', 'Epoch: 127, Train Loss: 0.073788731423921, Val Loss: 0.707996219396591', 'Epoch: 128, Train Loss: 0.064409465767270, Val Loss: 0.748651995658875', 'Epoch: 129, Train Loss: 0.066834833472967, Val Loss: 0.766245268583298', 'Epoch: 130, Train Loss: 0.055694285996778, Val Loss: 0.759376125335693', 'Epoch: 131, Train Loss: 0.060408327641875, Val Loss: 0.727720376253128', 'Epoch: 132, Train Loss: 0.062587105690740, Val Loss: 0.764929140806198', 'Epoch: 133, Train Loss: 0.069344864941614, Val Loss: 0.734906799793243', 'Epoch: 134, Train Loss: 0.065136536565977, Val Loss: 0.774625359773636', 'Epoch: 135, Train Loss: 0.063035087963176, Val Loss: 0.757807055711746', 'Epoch: 136, Train Loss: 0.060183744097865, Val Loss: 0.705564434528351', 'Epoch: 137, Train Loss: 0.061404027239701, Val Loss: 0.826571339368820', 'Epoch: 138, Train Loss: 0.059490191728570, Val Loss: 0.683188376426697', 'Epoch: 139, Train Loss: 0.063664285032902, Val Loss: 0.753201656341553', 'Epoch: 140, Train Loss: 0.063485428604276, Val Loss: 0.749673366546631', 'Epoch: 141, Train Loss: 0.060406683316064, Val Loss: 0.756829516887665', 'Epoch: 142, Train Loss: 0.061551813815915, Val Loss: 0.786505105495453', 'Epoch: 143, Train Loss: 0.052575694050553, Val Loss: 0.725820734500885', 'Epoch: 144, Train Loss: 0.059405657094578, Val Loss: 0.698492208719254', 'Epoch: 145, Train Loss: 0.055915338528711, Val Loss: 0.750762770175934', 'Epoch: 146, Train Loss: 0.056920632113551, Val Loss: 0.728524446487427', 'Epoch: 147, Train Loss: 0.052765310070542, Val Loss: 0.717738919258118', 'Epoch: 148, Train Loss: 0.056198257736342, Val Loss: 0.707194194793701', 'Epoch: 149, Train Loss: 0.058774179584065, Val Loss: 0.720436615943909', 'Epoch: 150, Train Loss: 0.052187109929185, Val Loss: 0.744495475292206', 'Epoch: 151, Train Loss: 0.052354099748786, Val Loss: 0.760256276130676', 'Epoch: 152, Train Loss: 0.062135831821103, Val Loss: 0.734366945028305', 'Epoch: 153, Train Loss: 0.056959928554851, Val Loss: 0.746008520126343', 'Epoch: 154, Train Loss: 0.047880214010907, Val Loss: 0.688387870788574', 'Epoch: 155, Train Loss: 0.046249604242486, Val Loss: 0.744198713302612', 'Epoch: 156, Train Loss: 0.046227895546445, Val Loss: 0.735454548597336', 'Epoch: 157, Train Loss: 0.051282228685396, Val Loss: 0.724335489273071', 'Epoch: 158, Train Loss: 0.052925945411241, Val Loss: 0.744712083339691', 'Epoch: 159, Train Loss: 0.049237418486628, Val Loss: 0.767490177154541', 'Epoch: 160, Train Loss: 0.048985231970978, Val Loss: 0.706973239183426', 'Epoch: 161, Train Loss: 0.055783473258448, Val Loss: 0.785973918437958', 'Epoch: 162, Train Loss: 0.050796510391804, Val Loss: 0.757510442733765', 'Epoch: 163, Train Loss: 0.052103452341155, Val Loss: 0.737987831830978', 'Epoch: 164, Train Loss: 0.047566505798767, Val Loss: 0.741982192993164', 'Epoch: 165, Train Loss: 0.046824245518723, Val Loss: 0.716731450557709', 'Epoch: 166, Train Loss: 0.050336101200691, Val Loss: 0.743620934486389', 'Epoch: 167, Train Loss: 0.047810423339522, Val Loss: 0.699962568283081', 'Epoch: 168, Train Loss: 0.048279221797752, Val Loss: 0.733449435234070', 'Epoch: 169, Train Loss: 0.039504178128270, Val Loss: 0.717103866338730', 'Epoch: 170, Train Loss: 0.040629610289321, Val Loss: 0.725914405584335', 'Epoch: 171, Train Loss: 0.043058996716904, Val Loss: 0.794815993309021', 'Epoch: 172, Train Loss: 0.043763261721578, Val Loss: 0.755425567626953', 'Epoch: 173, Train Loss: 0.040471650010278, Val Loss: 0.735341548919678', 'Epoch: 174, Train Loss: 0.045364030745140, Val Loss: 0.737740175724030', 'Epoch: 175, Train Loss: 0.045581036918732, Val Loss: 0.769363605976105', 'Epoch: 176, Train Loss: 0.039998901661399, Val Loss: 0.729583131074905', 'Epoch: 177, Train Loss: 0.040530892998673, Val Loss: 0.736748719215393', 'Epoch: 178, Train Loss: 0.037290884788300, Val Loss: 0.718462417125702', 'Epoch: 179, Train Loss: 0.039173102829345, Val Loss: 0.729603385925293', 'Epoch: 180, Train Loss: 0.043471987857375, Val Loss: 0.734262655973434', 'Epoch: 181, Train Loss: 0.037698777825680, Val Loss: 0.714540511369705', 'Epoch: 182, Train Loss: 0.038487487494252, Val Loss: 0.724605525732040', 'Epoch: 183, Train Loss: 0.038330686733473, Val Loss: 0.722495770454407', 'Epoch: 184, Train Loss: 0.042537230045296, Val Loss: 0.716224535703659', 'Epoch: 185, Train Loss: 0.037896645796853, Val Loss: 0.743469853401184', 'Epoch: 186, Train Loss: 0.035578147356593, Val Loss: 0.715608637332916', 'Epoch: 187, Train Loss: 0.040228115394711, Val Loss: 0.726050095558166', 'Epoch: 188, Train Loss: 0.035800786472337, Val Loss: 0.722570559978485', 'Epoch: 189, Train Loss: 0.037108194992639, Val Loss: 0.761347520351410', 'Epoch: 190, Train Loss: 0.038357075563697, Val Loss: 0.752862615585327', 'Epoch: 191, Train Loss: 0.033745174816008, Val Loss: 0.723729085922241', 'Epoch: 192, Train Loss: 0.033548693800735, Val Loss: 0.736601611375809', 'Epoch: 193, Train Loss: 0.039456038930735, Val Loss: 0.747317018508911', 'Epoch: 194, Train Loss: 0.035069003268037, Val Loss: 0.746055729389191', 'Epoch: 195, Train Loss: 0.038497638130604, Val Loss: 0.744364320039749', 'Epoch: 196, Train Loss: 0.034302536961298, Val Loss: 0.743399991989136', 'Epoch: 197, Train Loss: 0.032124618848049, Val Loss: 0.739978108406067', 'Epoch: 198, Train Loss: 0.034365964100458, Val Loss: 0.742095793485641', 'Epoch: 199, Train Loss: 0.036582681415386, Val Loss: 0.739252848625183']","[1104.0347     956.6102    1465.0964     227.5087     363.78357
 1440.9946    1459.585      349.48837    632.5002     497.5551
 1338.7985    1207.8118     993.17896    559.24805   1047.9854
  503.60318   1223.6206     432.59552   1156.3693     486.85242
 1245.4146     465.62204    547.75256   1289.0369     865.21265
 1385.1135     926.0121    1361.782     1070.5461     169.672
  623.7172      43.384216  1091.7954     489.21646    975.5623
  931.8482    1286.9153    1190.2637     664.223      867.416
 1233.6183     691.50555   1372.7042     409.4193     271.5163
  979.0788    1422.6572     718.63983   1272.7759     232.81934
 1260.7455    1367.8187     930.7262    1190.045     1222.4266
 1396.9266    1221.3318     441.4657     635.2173    1471.4781
  864.121     1061.1493     445.1471    1179.3159     350.33255
 1294.7693     212.43585   1395.2587      83.50337    711.62305
  552.31525    908.34454   1037.3513     665.5908     124.58719
 1340.4011     440.3221    1329.7058    1493.05        85.16693
 1268.5962     871.4937     595.50006   1493.5063    1163.4841
  994.9356      40.214203   125.86867    826.6011    1411.0476
 1186.4965     963.75415    927.7973    1456.7       1203.5999
  527.23145     15.532898   924.8995    1442.4077     468.06836
 1308.9666    1014.1895    1007.12445   1476.8341     875.8463
 1305.4644    1476.8328     600.5404    1253.9631     153.2414
 1298.344      275.8094    1294.8867     844.49994   1435.002
   27.901367  1181.4493     455.81287    872.47253   1118.4347
  261.48682    954.3469    1473.3918     454.14655    500.07596
 1433.1667    1104.1013    1451.5286    1461.8528     842.5057
 1420.3796    1439.5986    1224.1089    1487.1624    1486.2208
 1294.761      107.57593   1323.9868    1202.5549    1495.995
 1497.7745     612.0576    1119.1575     156.44095   1417.1246
 1149.5269    1458.0642     711.4471    1200.179     1295.665
  770.31433   1115.2582       9.397827  1437.3352      13.062317
 1133.27       888.3414      21.539276   777.21875   1440.2052
  945.2103     597.631       90.92261   1476.3865    1480.8289
  795.00354    660.16956   1173.0352     117.41754    652.8612
 1144.0917    1110.101      743.95337   1165.6415    1422.3943
  136.4574    1421.7688     310.4762    1355.7125     148.13963
  718.8337     328.94922   1219.8751     378.4339    1251.2267
  392.49448   1457.1497     252.96982   1262.2665     457.38846
 1421.3386     790.06836   1039.846      946.31305    915.5529
  159.28178   1119.3313    1398.8267    1336.0957    1089.8938
 1068.87       817.9888    1118.6423     962.1046    1219.4497
 1174.6592    1388.9272    1219.904      496.68967   1166.7012
 1237.8103    1122.8035     126.15497   1280.2245    1349.2693
  707.74255   1222.8689    1345.3787     642.09705    826.71985
  697.3101    1473.9949    1482.7932     175.33273    759.0161
 1300.4441     114.17255   1209.3457    1468.2565     174.16833
  356.791     1496.78       308.88788     10.570709    95.191956
 1333.6052    1302.2075      58.17572    998.052      688.9762
  383.84506   1480.3801    1044.4346     652.1829     233.4455
  844.9077     577.1073     899.92944    900.9206    1314.7214
 1227.1875     161.18875    729.09766     81.886856  1001.23364
 1458.7513     360.0715      72.60077   1012.4835     213.81645
 1481.0698    1351.4705    1012.46954    648.9986    1164.7163
  634.38586      2.7612915  740.1763    1290.1487     361.9615
 1363.3833     652.6001    1211.1934    1401.1028    1305.6631
  273.35718    743.32416     11.872681   616.363     1427.0776
  748.33417   1426.3435    1473.9944     318.1805     869.26404
 1035.488     1132.475     1125.6979     359.82837      9.762634
 1409.5725     220.0397    1477.4331     613.5451       8.568115
  499.6652    1403.6005    1268.603     1452.3739    1496.9451
 1448.4644     550.1498    1337.8589    1203.0249     126.79651
  898.659      141.90123    573.3219    1154.292      747.3436
 1243.4148    1483.4565     468.61014   1387.7372    1413.5115
  354.12683   1125.1761     838.8264    1348.3948    1160.1279
 1476.9807     531.19714    939.1426      67.068085   166.50684
 1300.6241       3.7573547  519.3954    1321.3188    1489.6377
  355.64142   1413.687      830.8478     636.27026   1490.8573
 1400.3799     271.58813   1313.7845    1206.0107     490.5289
 1285.3145    1387.7922     901.73267   1301.1254     141.23756
  823.99036    296.61755   1204.9082    1422.9078    1289.335
  404.90106   1086.0458     785.9699     434.2728     993.7584
 1379.0283    1332.7463    1052.228      165.45917   1293.5986
 1492.5974     298.06448   1008.7727    1453.0945       4.777588
   68.91144    585.10455   1356.1521     157.36926   1395.4318
 1493.5657     903.17993   1158.2505     663.52515    223.46994
    1.8953857 1425.3394     626.8422    1229.803     1282.4845
 1496.7222     511.82227    178.93985    602.72144      3.2839966
   24.680786  1153.5797     595.0495     736.2927     143.35895
  825.2825      17.275635    33.14972     33.965515  1025.2435
  391.15128   1485.6777     756.3888    1479.4904     904.232    ]","[ 1.20191504e+03  1.09337451e+03  1.24350049e+03  1.78295898e+02
  2.32096985e+02  1.50779858e+03  3.08464429e+03  9.39352905e+02
  6.18022339e+02  6.26426514e+02  6.04816650e+02  6.04933289e+02
  1.61159558e+03  5.47419617e+02  9.21060791e+02  5.06932709e+02
  1.36002124e+03  6.62362000e+02  1.27292725e+03  8.00322021e+02
  1.32864355e+03  5.25335938e+02  4.82835205e+02  9.76548584e+02
  1.08795068e+03  1.40464575e+03  5.66179688e+02  9.78821045e+02
  1.30235156e+03  5.75231079e+02  1.10009814e+03 -4.03037354e+02
  1.22865527e+03  2.26168945e+02  9.64728943e+02  6.86584839e+02
  1.08008472e+03  8.33792847e+02  7.30471069e+02  7.48141113e+02
  1.38256372e+03  5.08412262e+02  1.24346924e+03  3.87740479e+02
  1.93237122e+02  7.57091492e+02  1.43930371e+03  7.25720093e+02
  1.14109521e+03  3.76546692e+02  1.28941663e+03  1.54563940e+03
  1.12562244e+03  1.21015637e+03  7.92596436e+02  1.44391699e+03
  1.14999390e+03  3.93640991e+02  6.20707275e+02  1.00998370e+03
  7.66208130e+02  9.13461731e+02  2.09802460e+02  1.25060889e+03
  7.90222168e+00  1.17942310e+03  1.37717560e+02  1.30905579e+03
  1.17659935e+02  6.49094116e+02  7.77875854e+02  7.81770996e+02
  1.05856104e+03  9.62401855e+02  4.87624512e+02  1.28211340e+03
  6.91657715e+01  1.14604956e+03  1.46416663e+03  1.78807922e+02
  9.56561340e+02  1.15378467e+03  2.74852722e+02  1.22960181e+03
  1.20305029e+03  9.58841736e+02  1.30871735e+02  2.41962173e+02
  4.82785950e+02  1.46298535e+03  1.20507312e+03  1.07240601e+03
  6.91783325e+02  1.31687073e+03  1.23740088e+03  3.91071014e+02
 -1.24312317e+02  8.06610657e+02  1.51030933e+03  2.51677307e+02
  1.36623291e+03  1.07636621e+03  8.86378723e+02  1.34209058e+03
  7.05266907e+02  1.52459839e+03  1.43938855e+03  3.09610870e+02
  1.10857495e+03  2.37753052e+02  1.56016699e+03  4.09225586e+02
  1.01001733e+03  8.56780273e+02  1.18363440e+03  2.75287079e+02
  1.11309863e+03  3.17653015e+02  8.28028076e+02  1.00987793e+03
  1.90607361e+02  9.34837402e+02  7.63411865e+02  7.38513184e+02
  4.19687408e+02  1.56118188e+03  1.41379224e+03  1.42421826e+03
  1.54206152e+03  1.08939856e+03  1.80809668e+03  1.20481921e+03
  1.16062109e+03  1.32635303e+03  1.38350061e+03  1.29644995e+03
  2.14014954e+02  1.16938538e+03  1.22554358e+03  1.23458740e+03
  1.40176465e+03  6.18328613e+02  1.19447705e+03  3.60780762e+02
  1.34043811e+03  9.83090027e+02  1.61362451e+03  8.61949280e+02
  1.26169702e+03  1.05026587e+03  7.92373657e+02  7.48470825e+02
  2.62322449e+02  8.55011230e+02  1.96955566e+01  1.15390649e+03
  8.85338196e+02  2.81895874e+02  5.23358887e+02  1.80587964e+03
  9.93817139e+02  5.31568970e+02  2.38441895e+02  1.55986548e+03
  1.34507971e+03  8.55314819e+02  5.19410889e+02  1.34083228e+03
  1.56320190e+00  8.86463013e+02  9.31500732e+02  6.45374451e+02
  8.72432678e+02  1.49586475e+03  1.11978455e+03  5.11970917e+02
  1.63081812e+03  3.39169922e+02  1.08901001e+03  3.36342285e+02
  9.85146057e+02  8.77449707e+02  1.90897266e+03  6.64665405e+02
  1.31329041e+03  5.70176880e+02  2.04340625e+03  1.09985413e+02
  1.46715918e+03  4.74402466e+02  1.56552954e+03  6.74574646e+02
  9.73661499e+02  9.38813354e+02  9.83271423e+02  3.60630188e+02
  1.21701758e+03  8.38550659e+02  1.31541919e+03  8.15991821e+02
  1.00791516e+03  1.06212842e+03  1.10619922e+03  9.20122009e+02
  1.06595325e+03  1.12582642e+03  1.34075293e+03  1.06824890e+03
  4.43335297e+02  1.39925293e+03  1.17888501e+03  1.09243445e+03
  1.21652313e+02  1.38247424e+03  1.23629077e+03  6.99966003e+02
  1.12062085e+03  1.16547119e+03  7.81669861e+02  1.13554895e+03
  5.72337097e+02  1.74043164e+03  1.17628369e+03  5.33325623e+02
  8.86351318e+02  1.19180444e+03  9.49840393e+01  1.03021326e+03
  1.26766858e+03  3.58765961e+02  4.41416229e+02  1.86491956e+03
  5.24349182e+02  1.03537598e+02  1.00792786e+02  1.13380493e+03
  1.21815454e+03  1.11609436e+02  1.21126648e+03  9.28436707e+02
  3.25822418e+02  1.65683765e+03  1.21193250e+03  1.23830396e+03
  8.06661804e+02  8.56409668e+02  7.82075439e+02  1.16041125e+03
  1.15243140e+03  8.42347473e+02  1.27957104e+03  3.42884583e+02
  5.96724060e+02  1.04172897e+02  8.87552368e+02  1.12113647e+03
  7.84426758e+02  3.30869568e+02  8.62787476e+02  3.19235840e+02
  9.50735107e+02  1.02084814e+03  1.08172290e+03  6.77263916e+02
  1.26506934e+03  5.60019470e+02 -1.37522644e+02  1.00091333e+03
  1.38521997e+03 -1.29875854e+02  1.49301123e+03  9.00991455e+02
  1.15526221e+03  1.32630505e+03  1.19218408e+03  1.65671082e+02
  6.71968323e+02  1.92512695e+02  1.08674744e+03  1.73722021e+03
  6.94359314e+02  1.38992285e+03  1.29506262e+03  4.90539734e+02
  9.73678955e+02  9.53991028e+02  1.86444202e+03  2.18138501e+03
  3.55944946e+02 -2.87280701e+02  1.51102588e+03  6.92232056e+01
  1.55532666e+03  8.00006592e+02  5.89989136e+02  2.53671265e+01
  1.39947156e+03  1.05201599e+03  1.28549805e+03  1.79244360e+03
  1.30083276e+03  6.13153320e+02  1.40678552e+03  8.87162720e+02
  6.81959839e+01  7.30222290e+02  1.35093994e+01  6.33068604e+02
  1.00934503e+03  9.83594604e+02  1.23510669e+03  1.50943140e+03
  4.39963257e+02  1.05733484e+03  1.40621606e+03  2.22749329e+02
  1.01965283e+03  9.44266418e+02  7.55002197e+02  4.51761841e+02
  1.33726440e+03  4.59085205e+02  1.00173816e+03  1.89232498e+02
  4.76770294e+02  1.34681445e+03 -1.46179199e+00  8.15038696e+02
  1.52228979e+03  1.41645862e+03  5.64623657e+02  1.21456665e+03
  8.18123413e+02  5.21382568e+02  6.44844849e+02  1.39122974e+03
  3.46743896e+02  1.25164539e+03  1.42035938e+03  8.80997864e+02
  1.18353369e+03  1.11713708e+03  8.50570129e+02  1.16157080e+03
  1.09636642e+02  8.09839722e+02  6.47728271e+01  1.44027380e+03
  1.00699158e+03  9.99751587e+02  4.75896332e+02  9.45864929e+02
  9.83162476e+02  4.88099548e+02  1.05833081e+03  1.14790247e+03
  2.53387650e+02  4.12549225e+02  2.59498718e+02  1.39198938e+03
  1.50819434e+03  2.54401733e+02  8.95910522e+02  1.35699243e+03
  2.34974976e+01  9.81329346e+00  2.95319672e+02  1.33691992e+03
  4.18827118e+02  1.04539600e+03  1.42819116e+03  8.01673645e+02
  1.51508765e+03  7.86637329e+02  1.25053986e+02 -8.56908569e+01
  1.41451807e+03  4.78422119e+02  7.56373413e+02  6.80354675e+02
  1.25494836e+03  8.37387329e+02  1.13402405e+02  7.41233154e+02
 -7.73685913e+01 -5.96756592e+01  1.19351135e+03  5.82742126e+02
  6.36851135e+02  4.50584564e+01  1.40800305e+03 -2.82940063e+01
  5.84116882e+02  1.52555664e+02  1.42394653e+03  6.09061279e+02
  1.28189746e+03  4.28670776e+02  1.59003821e+03  7.13513123e+02]",186.47948,68124.37,261.0064504710564
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 1.609098783759184, Val Loss: 1.754178338050842', 'Epoch: 1, Train Loss: 1.484612342923187, Val Loss: 1.681422152519226', 'Epoch: 2, Train Loss: 1.393727693446847, Val Loss: 1.562187232971191', 'Epoch: 3, Train Loss: 1.217026932294979, Val Loss: 1.240665426254272', 'Epoch: 4, Train Loss: 0.921412969744483, Val Loss: 0.881443338394165', 'Epoch: 5, Train Loss: 0.766352459441784, Val Loss: 0.810456643104553', 'Epoch: 6, Train Loss: 0.705231956271238, Val Loss: 0.733888609409332', 'Epoch: 7, Train Loss: 0.671972578348115, Val Loss: 0.736746768951416', 'Epoch: 8, Train Loss: 0.609281666750132, Val Loss: 0.763197596073151', 'Epoch: 9, Train Loss: 0.684018806662670, Val Loss: 0.758843109607697', 'Epoch: 10, Train Loss: 0.599261130704436, Val Loss: 0.622038474082947', 'Epoch: 11, Train Loss: 0.582348084033922, Val Loss: 0.589445354938507', 'Epoch: 12, Train Loss: 0.573698215706404, Val Loss: 0.611263785362244', 'Epoch: 13, Train Loss: 0.546839266668918, Val Loss: 0.634164640903473', 'Epoch: 14, Train Loss: 0.541399216582609, Val Loss: 0.554019939899445', 'Epoch: 15, Train Loss: 0.548653041554052, Val Loss: 0.617520122528076', 'Epoch: 16, Train Loss: 0.499143979750400, Val Loss: 0.573204128742218', 'Epoch: 17, Train Loss: 0.471342870662379, Val Loss: 0.691531882286072', 'Epoch: 18, Train Loss: 0.506760570718799, Val Loss: 0.555334622859955', 'Epoch: 19, Train Loss: 0.511380433689716, Val Loss: 0.592258830070496', 'Epoch: 20, Train Loss: 0.487019824427228, Val Loss: 0.581553664207458', 'Epoch: 21, Train Loss: 0.494278399403705, Val Loss: 0.582147383689880', 'Epoch: 22, Train Loss: 0.526959502419760, Val Loss: 0.651795859336853', 'Epoch: 23, Train Loss: 0.540035368398178, Val Loss: 0.576709234714508', 'Epoch: 24, Train Loss: 0.492722058365511, Val Loss: 0.506342604160309', 'Epoch: 25, Train Loss: 0.525657614303190, Val Loss: 0.601038119792938', 'Epoch: 26, Train Loss: 0.475579756983491, Val Loss: 0.549701542854309', 'Epoch: 27, Train Loss: 0.517618223678234, Val Loss: 0.507742214202881', 'Epoch: 28, Train Loss: 0.450966706802679, Val Loss: 0.544211082458496', 'Epoch: 29, Train Loss: 0.433711368850497, Val Loss: 0.460430514812469', 'Epoch: 30, Train Loss: 0.425653422641200, Val Loss: 0.439691193103790', 'Epoch: 31, Train Loss: 0.410085499286652, Val Loss: 0.433276317119598', 'Epoch: 32, Train Loss: 0.464446293060170, Val Loss: 0.612439157962799', 'Epoch: 33, Train Loss: 0.396122644113940, Val Loss: 0.485818681716919', 'Epoch: 34, Train Loss: 0.410897914233596, Val Loss: 0.420718879699707', 'Epoch: 35, Train Loss: 0.447854951370594, Val Loss: 0.518743364810944', 'Epoch: 36, Train Loss: 0.409711742297161, Val Loss: 0.449771120548248', 'Epoch: 37, Train Loss: 0.397905506713446, Val Loss: 0.481974766254425', 'Epoch: 38, Train Loss: 0.417347872673079, Val Loss: 0.508750154972076', 'Epoch: 39, Train Loss: 0.412972912538883, Val Loss: 0.463026328086853', 'Epoch: 40, Train Loss: 0.418241012235020, Val Loss: 0.547302218675613', 'Epoch: 41, Train Loss: 0.420193091381428, Val Loss: 0.452129330635071', 'Epoch: 42, Train Loss: 0.408044540085072, Val Loss: 0.492048401832581', 'Epoch: 43, Train Loss: 0.378345486209836, Val Loss: 0.544323848485947', 'Epoch: 44, Train Loss: 0.374009302362453, Val Loss: 0.531317312717438', 'Epoch: 45, Train Loss: 0.399898873165596, Val Loss: 0.581997885704041', 'Epoch: 46, Train Loss: 0.370442753614381, Val Loss: 0.454703744649887', 'Epoch: 47, Train Loss: 0.365475246379542, Val Loss: 0.445404765605927', 'Epoch: 48, Train Loss: 0.350065662070762, Val Loss: 0.533376188278198', 'Epoch: 49, Train Loss: 0.355433583606121, Val Loss: 0.415784599781036', 'Epoch: 50, Train Loss: 0.352846177511437, Val Loss: 0.445001577138901', 'Epoch: 51, Train Loss: 0.361390615791775, Val Loss: 0.531485872268677', 'Epoch: 52, Train Loss: 0.332250526478124, Val Loss: 0.434329330921173', 'Epoch: 53, Train Loss: 0.326025452031646, Val Loss: 0.487250299453735', 'Epoch: 54, Train Loss: 0.333889215145000, Val Loss: 0.445935429334640', 'Epoch: 55, Train Loss: 0.347703176702178, Val Loss: 0.579823682308197', 'Epoch: 56, Train Loss: 0.336792265953020, Val Loss: 0.504535527229309', 'Epoch: 57, Train Loss: 0.312952464056569, Val Loss: 0.527551190853119', 'Epoch: 58, Train Loss: 0.311477168354877, Val Loss: 0.410012670755386', 'Epoch: 59, Train Loss: 0.288531034318514, Val Loss: 0.550153512954712', 'Epoch: 60, Train Loss: 0.314104130794836, Val Loss: 0.602145450115204', 'Epoch: 61, Train Loss: 0.303091745563718, Val Loss: 0.427119674682617', 'Epoch: 62, Train Loss: 0.308554337468258, Val Loss: 0.441366283893585', 'Epoch: 63, Train Loss: 0.295880655909694, Val Loss: 0.417081103324890', 'Epoch: 64, Train Loss: 0.304968025795249, Val Loss: 0.490598301887512', 'Epoch: 65, Train Loss: 0.299208213250304, Val Loss: 0.463418731689453', 'Epoch: 66, Train Loss: 0.320476046481798, Val Loss: 0.472110354900360', 'Epoch: 67, Train Loss: 0.258604609342509, Val Loss: 0.479998528957367', 'Epoch: 68, Train Loss: 0.261171615574249, Val Loss: 0.491165924072266', 'Epoch: 69, Train Loss: 0.262240229131177, Val Loss: 0.429422602653503', 'Epoch: 70, Train Loss: 0.244496860389793, Val Loss: 0.498457560539246', 'Epoch: 71, Train Loss: 0.257353022521318, Val Loss: 0.608359456062317', 'Epoch: 72, Train Loss: 0.276123335714950, Val Loss: 0.619935791492462', 'Epoch: 73, Train Loss: 0.271126120762770, Val Loss: 0.456569883823395', 'Epoch: 74, Train Loss: 0.269378479310246, Val Loss: 0.530287046432495', 'Epoch: 75, Train Loss: 0.255252611325231, Val Loss: 0.530081336498261', 'Epoch: 76, Train Loss: 0.235451692758605, Val Loss: 0.490340256690979', 'Epoch: 77, Train Loss: 0.246362101026746, Val Loss: 0.608455417156220', 'Epoch: 78, Train Loss: 0.258259638970674, Val Loss: 0.514609854221344', 'Epoch: 79, Train Loss: 0.231807779780654, Val Loss: 0.482808513641357', 'Epoch: 80, Train Loss: 0.228366635566534, Val Loss: 0.543915271759033', 'Epoch: 81, Train Loss: 0.229887688575789, Val Loss: 0.593221898078918', 'Epoch: 82, Train Loss: 0.213312324916208, Val Loss: 0.527534132003784', 'Epoch: 83, Train Loss: 0.230304878118426, Val Loss: 0.481358323097229', 'Epoch: 84, Train Loss: 0.204801593755567, Val Loss: 0.558515250682831', 'Epoch: 85, Train Loss: 0.247544467968996, Val Loss: 0.500654606819153', 'Epoch: 86, Train Loss: 0.215211875563444, Val Loss: 0.564577012062073', 'Epoch: 87, Train Loss: 0.229443442682887, Val Loss: 0.566361587047577', 'Epoch: 88, Train Loss: 0.240360607934553, Val Loss: 0.583208329677582', 'Epoch: 89, Train Loss: 0.192233776370453, Val Loss: 0.548045277595520', 'Epoch: 90, Train Loss: 0.198989524744278, Val Loss: 0.616314077377319', 'Epoch: 91, Train Loss: 0.195182282737521, Val Loss: 0.634213790893555', 'Epoch: 92, Train Loss: 0.201934157589147, Val Loss: 0.502628998756409', 'Epoch: 93, Train Loss: 0.183731232358273, Val Loss: 0.605402057170868', 'Epoch: 94, Train Loss: 0.190905651554119, Val Loss: 0.510527305603027', 'Epoch: 95, Train Loss: 0.194475086102652, Val Loss: 0.495598578453064', 'Epoch: 96, Train Loss: 0.171098685801722, Val Loss: 0.618698384761810', 'Epoch: 97, Train Loss: 0.180516958583233, Val Loss: 0.539651184082031', 'Epoch: 98, Train Loss: 0.176932335939518, Val Loss: 0.548595116138458', 'Epoch: 99, Train Loss: 0.163365925294022, Val Loss: 0.562496933937073', 'Epoch: 100, Train Loss: 0.185023415573808, Val Loss: 0.601041827201843', 'Epoch: 101, Train Loss: 0.161953215162421, Val Loss: 0.538287417888641', 'Epoch: 102, Train Loss: 0.164677025620327, Val Loss: 0.527058939933777', 'Epoch: 103, Train Loss: 0.159320757139561, Val Loss: 0.584002628326416', 'Epoch: 104, Train Loss: 0.161006447187690, Val Loss: 0.617441775798798', 'Epoch: 105, Train Loss: 0.153594983698324, Val Loss: 0.570473811626434', 'Epoch: 106, Train Loss: 0.152675914643116, Val Loss: 0.595451836585999', 'Epoch: 107, Train Loss: 0.150040609372217, Val Loss: 0.629924902915955', 'Epoch: 108, Train Loss: 0.147286803223366, Val Loss: 0.593405690193176', 'Epoch: 109, Train Loss: 0.152218779678955, Val Loss: 0.672746303081512', 'Epoch: 110, Train Loss: 0.147744326743969, Val Loss: 0.487603886127472', 'Epoch: 111, Train Loss: 0.142155755484520, Val Loss: 0.527578277587891', 'Epoch: 112, Train Loss: 0.136364526007065, Val Loss: 0.550989046096802', 'Epoch: 113, Train Loss: 0.140532055133304, Val Loss: 0.656500887870789', 'Epoch: 114, Train Loss: 0.129807651995919, Val Loss: 0.542161552906036', 'Epoch: 115, Train Loss: 0.138918611112722, Val Loss: 0.600302143096924', 'Epoch: 116, Train Loss: 0.128031976001207, Val Loss: 0.607054469585419', 'Epoch: 117, Train Loss: 0.159536437326392, Val Loss: 0.494001995921135', 'Epoch: 118, Train Loss: 0.146129558685907, Val Loss: 0.572426471710205', 'Epoch: 119, Train Loss: 0.130226284352153, Val Loss: 0.614640564918518', 'Epoch: 120, Train Loss: 0.121116319714591, Val Loss: 0.585128912925720', 'Epoch: 121, Train Loss: 0.119427548244942, Val Loss: 0.578352751731873', 'Epoch: 122, Train Loss: 0.122161403125109, Val Loss: 0.509323954582214', 'Epoch: 123, Train Loss: 0.140867910412855, Val Loss: 0.590485591888428', 'Epoch: 124, Train Loss: 0.120785433452490, Val Loss: 0.615303649902344', 'Epoch: 125, Train Loss: 0.120996500690316, Val Loss: 0.654581581354141', 'Epoch: 126, Train Loss: 0.140392290818137, Val Loss: 0.617054924964905', 'Epoch: 127, Train Loss: 0.136922963483389, Val Loss: 0.569924244880676', 'Epoch: 128, Train Loss: 0.124150601757127, Val Loss: 0.642827191352844', 'Epoch: 129, Train Loss: 0.118653408836487, Val Loss: 0.553940627574921', 'Epoch: 130, Train Loss: 0.119545064779908, Val Loss: 0.606511824131012', 'Epoch: 131, Train Loss: 0.112541340204865, Val Loss: 0.594209070205688', 'Epoch: 132, Train Loss: 0.103845300022946, Val Loss: 0.571965429782867', 'Epoch: 133, Train Loss: 0.104053231952495, Val Loss: 0.565014567375183', 'Epoch: 134, Train Loss: 0.110699365391981, Val Loss: 0.549891834259033', 'Epoch: 135, Train Loss: 0.097513976918403, Val Loss: 0.584905781745911', 'Epoch: 136, Train Loss: 0.110574163669764, Val Loss: 0.663915684223175', 'Epoch: 137, Train Loss: 0.111118819218042, Val Loss: 0.574488556385040', 'Epoch: 138, Train Loss: 0.101248459847167, Val Loss: 0.546074810028076', 'Epoch: 139, Train Loss: 0.104294400315645, Val Loss: 0.572220606803894', 'Epoch: 140, Train Loss: 0.100088957957057, Val Loss: 0.563747079372406', 'Epoch: 141, Train Loss: 0.101054746744245, Val Loss: 0.608645305633545', 'Epoch: 142, Train Loss: 0.098912970011317, Val Loss: 0.625168623924255', 'Epoch: 143, Train Loss: 0.100095889769321, Val Loss: 0.606034123897553', 'Epoch: 144, Train Loss: 0.101656472527011, Val Loss: 0.657451748847961', 'Epoch: 145, Train Loss: 0.102898876247711, Val Loss: 0.590530900955200', 'Epoch: 146, Train Loss: 0.092514491791642, Val Loss: 0.630840647220612', 'Epoch: 147, Train Loss: 0.094396630172120, Val Loss: 0.576618888378143', 'Epoch: 148, Train Loss: 0.086967721234920, Val Loss: 0.601775364875793', 'Epoch: 149, Train Loss: 0.086331773289414, Val Loss: 0.619578337669373', 'Epoch: 150, Train Loss: 0.090585387030313, Val Loss: 0.672609276771545', 'Epoch: 151, Train Loss: 0.099950098887432, Val Loss: 0.560192632675171', 'Epoch: 152, Train Loss: 0.097974206732456, Val Loss: 0.572490890026093', 'Epoch: 153, Train Loss: 0.079169211172780, Val Loss: 0.622247953414917', 'Epoch: 154, Train Loss: 0.092241039716227, Val Loss: 0.627396342754364', 'Epoch: 155, Train Loss: 0.087885808459548, Val Loss: 0.643832724094391', 'Epoch: 156, Train Loss: 0.084115439722704, Val Loss: 0.567064614295959', 'Epoch: 157, Train Loss: 0.086690381429223, Val Loss: 0.619810624122620', 'Epoch: 158, Train Loss: 0.082510221489640, Val Loss: 0.570389482975006', 'Epoch: 159, Train Loss: 0.089363169098316, Val Loss: 0.616090533733368', 'Epoch: 160, Train Loss: 0.084733788963667, Val Loss: 0.608079886436462', 'Epoch: 161, Train Loss: 0.081735619538745, Val Loss: 0.597238845825195', 'Epoch: 162, Train Loss: 0.078621867957503, Val Loss: 0.591850309371948', 'Epoch: 163, Train Loss: 0.069515544747890, Val Loss: 0.593940756320953', 'Epoch: 164, Train Loss: 0.072342265440628, Val Loss: 0.589182953834534', 'Epoch: 165, Train Loss: 0.082086394172768, Val Loss: 0.596250581741333', 'Epoch: 166, Train Loss: 0.075659557094061, Val Loss: 0.615712113380432', 'Epoch: 167, Train Loss: 0.073812271013509, Val Loss: 0.625991613864899', 'Epoch: 168, Train Loss: 0.070204672252023, Val Loss: 0.588351156711578', 'Epoch: 169, Train Loss: 0.077014200042847, Val Loss: 0.632469899654388', 'Epoch: 170, Train Loss: 0.073365222662687, Val Loss: 0.617780733108521', 'Epoch: 171, Train Loss: 0.070878467240999, Val Loss: 0.597076630592346', 'Epoch: 172, Train Loss: 0.073034775465034, Val Loss: 0.616526775360107', 'Epoch: 173, Train Loss: 0.074101905056904, Val Loss: 0.630547502040863', 'Epoch: 174, Train Loss: 0.064608439196681, Val Loss: 0.578505671024322', 'Epoch: 175, Train Loss: 0.065171202861292, Val Loss: 0.621854555606842', 'Epoch: 176, Train Loss: 0.063297094040832, Val Loss: 0.584117407798767', 'Epoch: 177, Train Loss: 0.064672655187720, Val Loss: 0.578753814697266', 'Epoch: 178, Train Loss: 0.061779211600159, Val Loss: 0.588963048458099', 'Epoch: 179, Train Loss: 0.068499739606713, Val Loss: 0.616315221786499', 'Epoch: 180, Train Loss: 0.069345670903838, Val Loss: 0.600040836334229', 'Epoch: 181, Train Loss: 0.064129277067476, Val Loss: 0.592803640365601', 'Epoch: 182, Train Loss: 0.066306308778219, Val Loss: 0.586963336467743', 'Epoch: 183, Train Loss: 0.065334550949723, Val Loss: 0.608858699798584', 'Epoch: 184, Train Loss: 0.067530020508309, Val Loss: 0.590938706398010', 'Epoch: 185, Train Loss: 0.060149294519147, Val Loss: 0.589000530242920', 'Epoch: 186, Train Loss: 0.065610429402008, Val Loss: 0.575765643119812', 'Epoch: 187, Train Loss: 0.064000560533862, Val Loss: 0.586909179687500', 'Epoch: 188, Train Loss: 0.059949392236249, Val Loss: 0.604182035923004', 'Epoch: 189, Train Loss: 0.062583247979366, Val Loss: 0.609156451225281', 'Epoch: 190, Train Loss: 0.060591067772272, Val Loss: 0.584696443080902', 'Epoch: 191, Train Loss: 0.059567294148512, Val Loss: 0.599242138862610', 'Epoch: 192, Train Loss: 0.060631668628302, Val Loss: 0.601659250259399', 'Epoch: 193, Train Loss: 0.055568203589944, Val Loss: 0.590582056045532', 'Epoch: 194, Train Loss: 0.058253437627194, Val Loss: 0.574297888278961', 'Epoch: 195, Train Loss: 0.064100387267942, Val Loss: 0.593328294754028', 'Epoch: 196, Train Loss: 0.061328976480074, Val Loss: 0.608126139640808', 'Epoch: 197, Train Loss: 0.056165558394305, Val Loss: 0.615381660461426', 'Epoch: 198, Train Loss: 0.058738492689160, Val Loss: 0.609745252132416', 'Epoch: 199, Train Loss: 0.059319511055946, Val Loss: 0.607794704437256']","[ 603.81116  1025.4102    400.44687   146.73395    48.19803    71.539215
 1308.1624    750.81976   399.96207   840.27246   628.5343    449.7399
 1445.6512   1062.5564    986.2949    113.96916  1051.8334   1125.7832
  914.27814   191.05347  1096.8134    493.8052    302.9405   1094.791
 1081.408     688.00745   506.35236   632.6293    759.67914   560.9587
  451.03464  1397.9644    252.68448  1456.6637    781.4193   1228.5033
  194.24567  1122.4226   1038.7471    102.44324  1069.1594    774.93335
  783.40796  1146.5437    547.7932   1458.0481   1492.7878     45.596252
 1074.5381   1096.5618    252.79767   971.9002    485.62418     8.184479
  984.8141    338.536     825.0599   1214.968     126.27869   821.1318
  652.57306  1255.3174   1432.9548     92.33923    25.70575   583.67285
  495.93832  1388.7261   1404.6582   1176.939    1254.6978   1077.8507
  215.82126   820.63043  1275.5156   1152.9808    654.1723   1361.9639
  929.9484    905.01965  1424.1335   1223.562      98.98532   659.6362
  450.75262   102.38574   624.7719    144.34875  1078.2249    593.65063
 1192.1465   1046.4264   1166.3489    315.11755  1350.0278   1466.0437
  790.0531    379.01974   335.80597   213.53946  1281.0359   1033.3005
 1158.3093   1474.0933    401.83508   899.51227    43.289948  773.9769
  816.59875   104.05261    79.512634 1345.2026    789.626    1162.3594
  590.58295  1477.9539   1362.5414   1113.0941    826.91785   773.4209
 1072.1342   1476.1812    284.5634    653.2462    430.636    1153.8298
 1359.9949    997.51855  1171.87      821.59564   974.02264   205.73492
  173.4975   1178.4727    810.0328   1384.2953     93.463165  237.61899
   71.33136   220.38559   242.97168  1255.673     159.79636   861.52954
 1470.3635   1220.8718   1073.3649    113.13049   855.73596   352.38922
  967.76807   577.6921    700.9823    615.82336  1160.4325    195.5119
 1175.3093     12.243042 1029.478     168.65079   487.38806  1253.6182
 1400.125     368.8791    251.61047   991.36646   704.5285   1353.9905
  814.6306    522.03845  1225.4789    936.225    1096.1571   1220.6646
  992.07556  1374.2637   1395.6417    171.76544  1329.2745    999.7886
  358.21176  1264.0802    239.66882    28.833496 1213.4095    676.9229
 1377.4487    841.34143   671.08386  1033.3154   1367.6588    227.84422
  448.22318  1447.804    1049.4227   1167.6875   1483.5964   1139.9447
 1344.4362    571.29834   809.86053   578.77826  1098.0995    204.3469
 1120.5264    123.895294  744.66895  1260.8707    817.807     239.68253
  420.94437  1193.1487    771.8871   1312.4465    900.04956   745.34534
   20.990845  940.3957   1346.0383    744.9515   1372.4324   1224.2001
   14.968658  715.9188    259.00903  1154.3107    975.1745   1119.7722
 1422.0657    993.3657   1237.287     343.9358    856.4913    897.9865
  186.49933   461.5197    825.01654  1014.7174    168.56006   188.23492
 1433.5018   1222.5093    458.39948  1455.2277   1333.4824    464.24802
  555.5934    829.90063   298.84872  1273.5038   1413.8792    631.056
 1162.5171     24.702759   48.51538   507.20007   392.85687   932.2716
  140.60931  1162.6367     17.694275  459.21442   752.4105   1495.4331
  616.98      257.01242   234.1885    231.65674  1267.7639    127.10205
 1333.9146    645.14124  1181.2324    489.89777  1203.187     852.6765
 1373.463    1273.1599   1011.7521    186.16629   223.75772   192.2362
  973.6278    183.70827  1030.2361   1077.9983   1242.2798   1375.7793
  687.5578   1373.4329   1447.479     215.11359    85.2439    591.84625
   93.31262  1473.21      170.02551  1069.5684   1441.5776    763.6692
  538.17255   332.94824   615.8423   1472.2935   1107.512     214.10675
  688.968       4.306671  123.59912   304.58258   550.9872   1347.264
  851.0835    734.1656    326.07584   717.55005    69.05017    75.40256
   35.733276   68.8656    276.66614    31.659058 1096.1019    498.5007
 1449.2751    578.90753  1040.1414   1434.2297   1172.3269   1161.4918
  809.6902   1186.0153    894.09705  1346.5325    986.3513    458.83472
  489.65588  1399.8901   1437.5146    228.8186    775.1678   1235.0366
 1254.0112   1306.9929   1388.7483   1315.1104    940.8818   1048.0686
 1155.448     750.79443   496.68924  1323.0518    700.5476     84.58115
  893.03467  1055.2664    247.75525  1312.123     557.8556    823.3546
 1225.5315    372.18585   967.84515   109.894135  169.86484  1075.7771
  257.92593  1296.7383    657.07275    15.330444  598.5812   1396.4125
  552.35815  1038.9753   1368.7642   1311.0552    634.55853  1193.8635
  157.83368   954.38324   712.03564   499.8916    176.21738  1036.3425
   39.43817   538.973     852.1682   1042.2499    422.52344   552.6413
  365.73938  1410.445     484.3961   1232.5093   1413.6062    304.54208
 1466.7172    728.5472    489.74155  1369.933   ]","[ 808.50867   1276.9509     361.46863    159.88464    129.89403
   80.04901   1109.6053     684.18304    368.39075    957.54645
  715.3367     423.7964    1228.4329     998.44183    900.5054
  340.8052    1179.8042    1157.5713    1014.08954    -48.269714
 1122.4924     428.11694    861.22095   1490.2932    1009.44977
  754.5155     904.2108     640.35815    846.02295    666.07477
  468.6448    1172.0067     721.2388    1347.3937     698.0237
 1231.4921      66.52899   1082.5758     998.44025    154.50742
  911.0717     642.925      864.4911    1348.21       572.5873
 1577.7139     948.8963     271.94202    483.37323    938.18445
  370.9176    1161.9775     508.86697   -162.21616    377.51227
  731.9962     814.13104   1897.6536     345.01016    901.4093
  735.1396    1387.3801    1232.0149     335.89233    -17.825806
  330.58344    693.3296    1202.4448    2193.8774     549.3209
 1298.4121     914.0964     240.13489    928.6059     967.7893
 1300.6779     636.57684   1402.1619     589.1481     997.3025
 1643.0613    1116.2329      60.980286   703.02136    457.3984
   51.151917   603.62787    176.64374   1204.4268     550.6568
 1086.3352     983.955     1249.5356     282.94495   1228.5941
 1737.4658     679.1112     476.31387    104.71878     84.54062
  576.84094    740.09674    905.1443    1145.1532     446.95667
  982.7326     133.9914     759.8513     785.58203     97.8689
  169.62415   1370.2219     660.33704   1096.0853     643.68726
 1194.9329    1383.6028     867.1936     828.7729     855.15485
  763.86536   1428.6477     429.96204    530.33105    488.9741
  966.24274   1176.3438     888.2594    1072.7655     927.3274
  858.57007    307.25775    619.60956   1892.6702    1232.3691
  371.9942     170.15433    271.19       218.29797    206.01834
  428.5342    1200.6394     167.28342    779.04224   1114.984
 1100.5721    1195.7953     107.11359    896.5033     162.68715
  979.38       603.04834   1302.1578     482.6436    1173.5552
  129.05615   1352.5647     405.9894    1003.5174     237.7124
  633.38477   1267.592     1304.4324     241.24155    250.10751
 1087.3369     738.00244    932.3825     848.41565    511.34708
 1670.3047    1249.157     1345.1493    1273.2549     793.0619
 1133.4102    1298.9045     228.11646   1110.9111    1172.7668
  266.20557   1182.8988     274.40973     54.093445  1577.557
 1056.2391    1214.3029     476.4525     573.57996   1055.9905
 1092.2838     637.37177    845.59143    869.63574   1006.94055
  981.2779     924.157      782.18933   1391.5076     667.9974
  728.1083     558.3255    1208.6807     250.72565   1247.3003
  392.37204    752.9281    1390.5793     763.6289     -14.868103
  367.38077   1223.0225     805.6411    1447.7402    1139.9817
  623.3055      68.70935    946.1844    1246.3599     713.5663
  171.94843    310.37585    176.4065     942.5658     625.31305
 1078.0093    1096.2859    1102.5991    1447.4517    1373.6952
 1173.9469     498.989      939.7078     827.186      198.40143
  444.1076     842.17084   1073.0107     201.7084     113.11026
  945.3557     776.7875     286.3659     993.4275    1156.6039
 1034.3625     576.47754    944.5709     281.24103   1318.982
 1416.5096     688.2792    1043.0208     273.97916    102.66876
  485.0761    1286.7896    1674.1301     224.17645   1217.1333
   88.58142    314.23688    272.21622   1158.2129     532.9093
  143.27925    259.58362    119.55902    635.5437     197.61981
  825.36383    654.29663    605.84436     23.215485   598.1688
  669.67236   1045.9757     163.86957   1017.56726    202.52069
  190.28104    144.19275    801.6139     123.79321   1012.0164
 1379.4377    2418.247     2024.0588    1246.231      915.57385
 2461.4038     489.16266    241.07074    543.21655    109.4693
 1262.6118      86.9299     805.12054   1439.7598     689.48895
  689.43536    355.51822    438.0484     957.5468    1261.1489
  116.57422    653.0364      16.156311   211.92438    348.97232
  450.06952   1419.3525    1030.9103     718.1768     373.37436
  536.0265     111.01056    170.18376    206.19601    226.70175
  352.12372      7.4241333 1339.5791     229.48141   1007.4457
 1311.113      809.94977   1731.2136    1232.2739    1271.6737
  824.964     1369.3561     962.7081    1226.6343    1100.0352
  257.64212    628.4664    1212.1628    1133.4119     547.74756
  585.09485   1158.3916    1055.0758    1261.8535     956.7054
 1133.2712    1317.2766    1360.292     1102.7351     573.2821
  904.1046    1451.7607     624.12024    -82.66547    786.2151
  530.99927    258.83548   1369.5398     688.8032    1334.7775
 1390.2842     287.92828    976.0477     332.80017    131.95734
  958.8599     308.2017    1184.9963     453.9623      58.145264
  540.20374   1495.4121     425.6729    1143.8118    1187.6082
 1411.5823     651.6449     667.08923    199.74261    979.40326
  866.5834     407.49585    188.86438    668.3496      31.713562
  558.60767    796.9054    1015.7374     420.30243    964.47644
  496.9815    1420.5062     611.3291    1505.7043    2398.458
  201.4975    1571.6267     739.6631     484.27307    977.10565  ]",179.98772,73822.77,271.703466002
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 1.361933394919994, Val Loss: 0.718840856552124', 'Epoch: 1, Train Loss: 1.061613915964615, Val Loss: 0.701983284950256', 'Epoch: 2, Train Loss: 1.036170673924823, Val Loss: 0.681705203056335', 'Epoch: 3, Train Loss: 0.973356980917066, Val Loss: 0.627949084043503', 'Epoch: 4, Train Loss: 0.846093358688576, Val Loss: 0.489424948692322', 'Epoch: 5, Train Loss: 0.605825629345206, Val Loss: 0.318517519831657', 'Epoch: 6, Train Loss: 0.556910281957582, Val Loss: 0.264129186868668', 'Epoch: 7, Train Loss: 0.496545555979707, Val Loss: 0.322872321605682', 'Epoch: 8, Train Loss: 0.476907925203789, Val Loss: 0.309866291582584', 'Epoch: 9, Train Loss: 0.467955329390459, Val Loss: 0.233045772910118', 'Epoch: 10, Train Loss: 0.419692873608234, Val Loss: 0.213895455002785', 'Epoch: 11, Train Loss: 0.459052033202593, Val Loss: 0.207254560589790', 'Epoch: 12, Train Loss: 0.418611751046292, Val Loss: 0.219330855607986', 'Epoch: 13, Train Loss: 0.395985316051993, Val Loss: 0.199929574131966', 'Epoch: 14, Train Loss: 0.430991327693296, Val Loss: 0.276637327522039', 'Epoch: 15, Train Loss: 0.411272558015446, Val Loss: 0.205857288539410', 'Epoch: 16, Train Loss: 0.371675033555474, Val Loss: 0.191039805710316', 'Epoch: 17, Train Loss: 0.383678667767103, Val Loss: 0.183328743577003', 'Epoch: 18, Train Loss: 0.378349865938342, Val Loss: 0.205662713348866', 'Epoch: 19, Train Loss: 0.360941731479279, Val Loss: 0.187045368552208', 'Epoch: 20, Train Loss: 0.357510513691015, Val Loss: 0.208593216240406', 'Epoch: 21, Train Loss: 0.346336762918982, Val Loss: 0.243226928859949', 'Epoch: 22, Train Loss: 0.365749351507009, Val Loss: 0.201880806684494', 'Epoch: 23, Train Loss: 0.344733879489954, Val Loss: 0.197516745328903', 'Epoch: 24, Train Loss: 0.379390321671963, Val Loss: 0.172447342276573', 'Epoch: 25, Train Loss: 0.350672036236109, Val Loss: 0.178673708438873', 'Epoch: 26, Train Loss: 0.334655670405820, Val Loss: 0.268001780211925', 'Epoch: 27, Train Loss: 0.328929434682048, Val Loss: 0.234260006546974', 'Epoch: 28, Train Loss: 0.337567005219848, Val Loss: 0.190778271257877', 'Epoch: 29, Train Loss: 0.313670423488284, Val Loss: 0.227273960262537', 'Epoch: 30, Train Loss: 0.305477896055510, Val Loss: 0.176701774597168', 'Epoch: 31, Train Loss: 0.316642920811509, Val Loss: 0.171906345486641', 'Epoch: 32, Train Loss: 0.336759163543235, Val Loss: 0.175506334751844', 'Epoch: 33, Train Loss: 0.312553431752116, Val Loss: 0.172289120554924', 'Epoch: 34, Train Loss: 0.330554465914882, Val Loss: 0.189131752848625', 'Epoch: 35, Train Loss: 0.312376822669839, Val Loss: 0.199814676642418', 'Epoch: 36, Train Loss: 0.300378064776576, Val Loss: 0.220851713120937', 'Epoch: 37, Train Loss: 0.327445372419302, Val Loss: 0.165207215845585', 'Epoch: 38, Train Loss: 0.331907525658607, Val Loss: 0.166761165261269', 'Epoch: 39, Train Loss: 0.309807483540025, Val Loss: 0.152836527079344', 'Epoch: 40, Train Loss: 0.326835204002469, Val Loss: 0.184175994396210', 'Epoch: 41, Train Loss: 0.307697570601175, Val Loss: 0.181227569878101', 'Epoch: 42, Train Loss: 0.361052236757999, Val Loss: 0.156220281571150', 'Epoch: 43, Train Loss: 0.315884346012459, Val Loss: 0.194809687584639', 'Epoch: 44, Train Loss: 0.294541343526785, Val Loss: 0.196044718921185', 'Epoch: 45, Train Loss: 0.279429833556330, Val Loss: 0.144024092555046', 'Epoch: 46, Train Loss: 0.297806019006774, Val Loss: 0.176229124665260', 'Epoch: 47, Train Loss: 0.299502685319546, Val Loss: 0.182868893742561', 'Epoch: 48, Train Loss: 0.313211830376193, Val Loss: 0.139487623572350', 'Epoch: 49, Train Loss: 0.278165354631668, Val Loss: 0.137366118133068', 'Epoch: 50, Train Loss: 0.302478993528111, Val Loss: 0.127078157961369', 'Epoch: 51, Train Loss: 0.271195811241172, Val Loss: 0.226031243652105', 'Epoch: 52, Train Loss: 0.283416347101677, Val Loss: 0.167549703419209', 'Epoch: 53, Train Loss: 0.290112047867719, Val Loss: 0.151467841565609', 'Epoch: 54, Train Loss: 0.273701931328274, Val Loss: 0.187287219017744', 'Epoch: 55, Train Loss: 0.281019382178783, Val Loss: 0.186993696391582', 'Epoch: 56, Train Loss: 0.284119760920835, Val Loss: 0.191172277927399', 'Epoch: 57, Train Loss: 0.263747562849244, Val Loss: 0.147065086662769', 'Epoch: 58, Train Loss: 0.270396609379109, Val Loss: 0.201187039837241', 'Epoch: 59, Train Loss: 0.258407419330852, Val Loss: 0.158810309171677', 'Epoch: 60, Train Loss: 0.252915812786235, Val Loss: 0.141186421811581', 'Epoch: 61, Train Loss: 0.242310672998428, Val Loss: 0.145535811185837', 'Epoch: 62, Train Loss: 0.243737103114294, Val Loss: 0.143814573436975', 'Epoch: 63, Train Loss: 0.230646564257006, Val Loss: 0.190152970254421', 'Epoch: 64, Train Loss: 0.258313303076944, Val Loss: 0.164259604513645', 'Epoch: 65, Train Loss: 0.247953260014223, Val Loss: 0.211613544747233', 'Epoch: 66, Train Loss: 0.246570455300253, Val Loss: 0.168791138455272', 'Epoch: 67, Train Loss: 0.232915934954965, Val Loss: 0.147090570330620', 'Epoch: 68, Train Loss: 0.236930103149525, Val Loss: 0.178856291621923', 'Epoch: 69, Train Loss: 0.255814159505589, Val Loss: 0.171590969562531', 'Epoch: 70, Train Loss: 0.232469270395678, Val Loss: 0.177927197217941', 'Epoch: 71, Train Loss: 0.219049853294395, Val Loss: 0.138304835855961', 'Epoch: 72, Train Loss: 0.232592686317688, Val Loss: 0.155791536271572', 'Epoch: 73, Train Loss: 0.212084791947936, Val Loss: 0.189423275589943', 'Epoch: 74, Train Loss: 0.224178042869235, Val Loss: 0.148048759698868', 'Epoch: 75, Train Loss: 0.213051282735758, Val Loss: 0.147524813413620', 'Epoch: 76, Train Loss: 0.224028537786284, Val Loss: 0.240681369751692', 'Epoch: 77, Train Loss: 0.223979862796706, Val Loss: 0.159856130480766', 'Epoch: 78, Train Loss: 0.220673411218233, Val Loss: 0.171372193321586', 'Epoch: 79, Train Loss: 0.217068060366220, Val Loss: 0.124170432984829', 'Epoch: 80, Train Loss: 0.210897630037263, Val Loss: 0.156348750144243', 'Epoch: 81, Train Loss: 0.205195165477520, Val Loss: 0.193647609055042', 'Epoch: 82, Train Loss: 0.217741834562878, Val Loss: 0.148387169241905', 'Epoch: 83, Train Loss: 0.216332725660745, Val Loss: 0.132890654206276', 'Epoch: 84, Train Loss: 0.209588520748671, Val Loss: 0.197873158901930', 'Epoch: 85, Train Loss: 0.198876958080502, Val Loss: 0.149360530376434', 'Epoch: 86, Train Loss: 0.196713250823492, Val Loss: 0.162357646822929', 'Epoch: 87, Train Loss: 0.191520710843940, Val Loss: 0.216116988211870', 'Epoch: 88, Train Loss: 0.194591217436070, Val Loss: 0.201225126981735', 'Epoch: 89, Train Loss: 0.192818628147591, Val Loss: 0.186132394373417', 'Epoch: 90, Train Loss: 0.200496167464312, Val Loss: 0.158118036091328', 'Epoch: 91, Train Loss: 0.196498789326396, Val Loss: 0.169688332974911', 'Epoch: 92, Train Loss: 0.185600822748140, Val Loss: 0.156277493536472', 'Epoch: 93, Train Loss: 0.188727650098329, Val Loss: 0.156195690631866', 'Epoch: 94, Train Loss: 0.188335934523926, Val Loss: 0.192927628159523', 'Epoch: 95, Train Loss: 0.185754268148611, Val Loss: 0.134595661461353', 'Epoch: 96, Train Loss: 0.182035753200221, Val Loss: 0.148093528151512', 'Epoch: 97, Train Loss: 0.189232715427182, Val Loss: 0.137593890726566', 'Epoch: 98, Train Loss: 0.180013020804455, Val Loss: 0.155895092189312', 'Epoch: 99, Train Loss: 0.183018227476020, Val Loss: 0.203819077908993', 'Epoch: 100, Train Loss: 0.186985745506231, Val Loss: 0.259417802244425', 'Epoch: 101, Train Loss: 0.176313059274540, Val Loss: 0.198245625793934', 'Epoch: 102, Train Loss: 0.181998769731023, Val Loss: 0.208529974371195', 'Epoch: 103, Train Loss: 0.178589042536048, Val Loss: 0.176972712278366', 'Epoch: 104, Train Loss: 0.164025053122016, Val Loss: 0.228436566144228', 'Epoch: 105, Train Loss: 0.163304994445901, Val Loss: 0.215073709040880', 'Epoch: 106, Train Loss: 0.165371788015892, Val Loss: 0.162555330842733', 'Epoch: 107, Train Loss: 0.179487200150656, Val Loss: 0.231807329580188', 'Epoch: 108, Train Loss: 0.189683986091337, Val Loss: 0.212570230662823', 'Epoch: 109, Train Loss: 0.156407592428285, Val Loss: 0.177128922939301', 'Epoch: 110, Train Loss: 0.160024302470130, Val Loss: 0.175618804991245', 'Epoch: 111, Train Loss: 0.152938446506511, Val Loss: 0.212694465816021', 'Epoch: 112, Train Loss: 0.150022333791090, Val Loss: 0.227219038605690', 'Epoch: 113, Train Loss: 0.157250527379125, Val Loss: 0.251987660974264', 'Epoch: 114, Train Loss: 0.158050168132366, Val Loss: 0.177400763183832', 'Epoch: 115, Train Loss: 0.155075168886850, Val Loss: 0.195984360426664', 'Epoch: 116, Train Loss: 0.160468115882818, Val Loss: 0.159881683886051', 'Epoch: 117, Train Loss: 0.152461655264677, Val Loss: 0.150809325575829', 'Epoch: 118, Train Loss: 0.139906674623489, Val Loss: 0.301784388720989', 'Epoch: 119, Train Loss: 0.151407227266666, Val Loss: 0.191504223048687', 'Epoch: 120, Train Loss: 0.140619601101376, Val Loss: 0.175656437277794', 'Epoch: 121, Train Loss: 0.151982676497726, Val Loss: 0.168817242383957', 'Epoch: 122, Train Loss: 0.146768961534944, Val Loss: 0.182838350981474', 'Epoch: 123, Train Loss: 0.143445792413035, Val Loss: 0.253796631097794', 'Epoch: 124, Train Loss: 0.136869751350131, Val Loss: 0.216219663321972', 'Epoch: 125, Train Loss: 0.146779228521641, Val Loss: 0.211606364846230', 'Epoch: 126, Train Loss: 0.124214883807094, Val Loss: 0.188106290996075', 'Epoch: 127, Train Loss: 0.137087606413420, Val Loss: 0.177594250142574', 'Epoch: 128, Train Loss: 0.120563830227353, Val Loss: 0.237134634852409', 'Epoch: 129, Train Loss: 0.128847013552522, Val Loss: 0.178435090184212', 'Epoch: 130, Train Loss: 0.128301370629044, Val Loss: 0.160043497085571', 'Epoch: 131, Train Loss: 0.124289651163096, Val Loss: 0.245457245558500', 'Epoch: 132, Train Loss: 0.134138366077528, Val Loss: 0.246100094914436', 'Epoch: 133, Train Loss: 0.132531627492849, Val Loss: 0.206608725786209', 'Epoch: 134, Train Loss: 0.121690625541432, Val Loss: 0.201837296783924', 'Epoch: 135, Train Loss: 0.121531900624896, Val Loss: 0.173624813556671', 'Epoch: 136, Train Loss: 0.110414284433043, Val Loss: 0.228213596045971', 'Epoch: 137, Train Loss: 0.111853878078766, Val Loss: 0.235174362659454', 'Epoch: 138, Train Loss: 0.116029085981291, Val Loss: 0.196723471581936', 'Epoch: 139, Train Loss: 0.111304130145284, Val Loss: 0.255607452392578', 'Epoch: 140, Train Loss: 0.114915432018596, Val Loss: 0.270007903277874', 'Epoch: 141, Train Loss: 0.110798544575309, Val Loss: 0.202657873630524', 'Epoch: 142, Train Loss: 0.111729908907829, Val Loss: 0.236006100624800', 'Epoch: 143, Train Loss: 0.109897102640812, Val Loss: 0.211587621271610', 'Epoch: 144, Train Loss: 0.121741217929263, Val Loss: 0.216003815680742', 'Epoch: 145, Train Loss: 0.117842382036669, Val Loss: 0.212021345496178', 'Epoch: 146, Train Loss: 0.108738203554652, Val Loss: 0.178142393231392', 'Epoch: 147, Train Loss: 0.105218619368104, Val Loss: 0.209648145735264', 'Epoch: 148, Train Loss: 0.101011664368385, Val Loss: 0.225199829339981', 'Epoch: 149, Train Loss: 0.107597142631231, Val Loss: 0.228151099681854', 'Epoch: 150, Train Loss: 0.107145093901213, Val Loss: 0.251186081469059', 'Epoch: 151, Train Loss: 0.108278410379277, Val Loss: 0.230574122667313', 'Epoch: 152, Train Loss: 0.100458151032758, Val Loss: 0.196932778060436', 'Epoch: 153, Train Loss: 0.095959275657701, Val Loss: 0.292325501590967', 'Epoch: 154, Train Loss: 0.090173350257236, Val Loss: 0.220244978368282', 'Epoch: 155, Train Loss: 0.098616535233897, Val Loss: 0.268154287338257', 'Epoch: 156, Train Loss: 0.099696755409241, Val Loss: 0.175097779631615', 'Epoch: 157, Train Loss: 0.103478708586027, Val Loss: 0.226006062626839', 'Epoch: 158, Train Loss: 0.098934018248042, Val Loss: 0.220789392292500', 'Epoch: 159, Train Loss: 0.091713718030342, Val Loss: 0.278598989397287', 'Epoch: 160, Train Loss: 0.095215807907110, Val Loss: 0.225115064382553', 'Epoch: 161, Train Loss: 0.098225599198147, Val Loss: 0.276200711131096', 'Epoch: 162, Train Loss: 0.095287146263344, Val Loss: 0.246889620423317', 'Epoch: 163, Train Loss: 0.083545205638159, Val Loss: 0.212153834700584', 'Epoch: 164, Train Loss: 0.089759880893452, Val Loss: 0.281607971489429', 'Epoch: 165, Train Loss: 0.084441339813693, Val Loss: 0.229272129237652', 'Epoch: 166, Train Loss: 0.083541390854259, Val Loss: 0.223965648412704', 'Epoch: 167, Train Loss: 0.090406798606002, Val Loss: 0.206111453175545', 'Epoch: 168, Train Loss: 0.086742000611022, Val Loss: 0.286148054599762', 'Epoch: 169, Train Loss: 0.090814432475803, Val Loss: 0.245827583074570', 'Epoch: 170, Train Loss: 0.091831203766687, Val Loss: 0.204528655111790', 'Epoch: 171, Train Loss: 0.088663746797761, Val Loss: 0.230409587323666', 'Epoch: 172, Train Loss: 0.080915015710648, Val Loss: 0.203403710126877', 'Epoch: 173, Train Loss: 0.081641787316564, Val Loss: 0.242669725120068', 'Epoch: 174, Train Loss: 0.081244998979707, Val Loss: 0.231989977061749', 'Epoch: 175, Train Loss: 0.077711042883091, Val Loss: 0.251723886132240', 'Epoch: 176, Train Loss: 0.079977991622548, Val Loss: 0.240744560360909', 'Epoch: 177, Train Loss: 0.078962454875541, Val Loss: 0.226331826448441', 'Epoch: 178, Train Loss: 0.081939198336629, Val Loss: 0.201368283033371', 'Epoch: 179, Train Loss: 0.077506433132776, Val Loss: 0.209252821505070', 'Epoch: 180, Train Loss: 0.080305489516535, Val Loss: 0.223400231897831', 'Epoch: 181, Train Loss: 0.076075199298387, Val Loss: 0.224703379571438', 'Epoch: 182, Train Loss: 0.073363606623092, Val Loss: 0.220041396617889', 'Epoch: 183, Train Loss: 0.077963411721379, Val Loss: 0.234776917397976', 'Epoch: 184, Train Loss: 0.074155930776236, Val Loss: 0.231590049862862', 'Epoch: 185, Train Loss: 0.077658537775278, Val Loss: 0.250838969349861', 'Epoch: 186, Train Loss: 0.077354133562293, Val Loss: 0.235507448315620', 'Epoch: 187, Train Loss: 0.073388295897911, Val Loss: 0.230767641961575', 'Epoch: 188, Train Loss: 0.072279248559891, Val Loss: 0.227044022977352', 'Epoch: 189, Train Loss: 0.075223345222861, Val Loss: 0.240708732604980', 'Epoch: 190, Train Loss: 0.072931946276925, Val Loss: 0.240161175727844', 'Epoch: 191, Train Loss: 0.074935548527296, Val Loss: 0.225289330780506', 'Epoch: 192, Train Loss: 0.070974892048642, Val Loss: 0.231326286792755', 'Epoch: 193, Train Loss: 0.076354469757440, Val Loss: 0.240625680685043', 'Epoch: 194, Train Loss: 0.070123128506333, Val Loss: 0.221888400614262', 'Epoch: 195, Train Loss: 0.071731305789462, Val Loss: 0.243401817679405', 'Epoch: 196, Train Loss: 0.076043061305617, Val Loss: 0.231192529201508', 'Epoch: 197, Train Loss: 0.070015379249357, Val Loss: 0.235562731027603', 'Epoch: 198, Train Loss: 0.074551494922056, Val Loss: 0.228149824142456', 'Epoch: 199, Train Loss: 0.067992624718436, Val Loss: 0.227798366248608']","[3.39608490e+02 1.37308203e+03 1.28649695e+03 4.05811432e+02
 1.41675232e+03 1.37039270e+03 1.00707080e+03 1.13650635e+03
 1.14292505e+03 1.77927063e+02 7.24041931e+02 1.36003906e+03
 1.16499219e+03 9.10217957e+02 3.39271240e+01 7.82701416e+02
 1.18989600e+03 8.28582336e+02 9.57208740e+02 3.35592682e+02
 7.17983948e+02 1.08584204e+03 1.49809143e+03 2.05234985e+02
 1.38119766e+02 1.18347327e+03 1.42599854e+03 5.09419922e+02
 4.25841400e+02 9.42394470e+02 9.13549805e+02 2.45288483e+02
 5.43024536e+02 9.43444702e+02 5.92089417e+02 1.36426990e+03
 8.85378418e+02 8.70314819e+02 1.28494604e+03 1.31575366e+03
 1.38471973e+03 1.05788477e+03 2.72779846e+01 1.11143591e+03
 1.43013818e+03 1.26041394e+03 1.20561047e+03 7.86742554e+02
 1.95610718e+02 8.74764526e+02 1.46549744e+03 6.77434082e+01
 1.43308179e+03 6.22371277e+02 8.79140869e+02 1.08530774e+03
 1.29471570e+03 2.20319046e+02 1.34798669e+03 5.83666992e+00
 9.30210815e+02 1.27603735e+03 1.96757202e+01 6.47470825e+02
 1.11905334e+03 2.01263550e+02 1.45641943e+03 1.29612170e+03
 1.40337085e+03 6.14530823e+02 1.01662140e+03 7.24083435e+02
 2.29118896e+02 1.49638208e+03 1.32797485e+02 1.05919104e+03
 8.83501099e+02 3.81680359e+02 1.37081580e+03 1.28405737e+03
 1.39199353e+03 7.30086792e+02 1.18120203e+03 1.19841467e+03
 1.47691260e+03 4.55373199e+02 5.48679321e+02 1.05214990e+03
 1.87715897e+02 7.54092224e+02 8.89951843e+02 1.18044263e+03
 2.45193588e+02 9.76413574e+02 1.29550916e+03 1.32675171e+01
 4.85671753e+02 1.34704883e+03 1.76812134e+02 1.10218665e+03
 1.39392639e+03 2.81738129e+02 1.41290833e+03 1.48617041e+03
 5.03008362e+02 1.19335791e+03 1.38403650e+03 4.40876160e+01
 1.40857397e+03 3.32817139e+02 1.18530304e+02 8.61900940e+02
 5.57516418e+02 1.18183728e+03 3.11982361e+02 7.89070984e+02
 3.52384583e+02 7.14349121e+02 3.20331177e+02 5.87048767e+02
 1.42552588e+03 3.87028015e+02 4.47581635e+02 8.33643982e+02
 1.13975830e+02 1.49242993e+03 1.19848071e+03 2.18749237e+02
 1.10441772e+03 5.35048828e+01 1.32591821e+03 5.59915833e+02
 1.04948743e+03 1.20421313e+03 5.00486145e+02 7.43328125e+02
 1.39226013e+02 1.41944678e+03 1.17816675e+03 7.72958130e+02
 1.78557068e+02 1.45954504e+03 1.14845715e+03 3.42176788e+02
 9.36221619e+02 1.19546643e+03 3.92186279e+01 7.08145874e+02
 4.27349365e+02 1.01034943e+03 2.04799316e+02 1.11414453e+03
 1.06168591e+03 1.18378967e+03 5.16340881e+02 1.47077490e+03
 6.60979187e+02 9.60366577e+02 1.42557349e+03 1.24444128e+03
 7.68753906e+02 1.43574146e+03 1.33817798e+03 5.21982666e+02
 6.22175537e+02 1.49529138e+03 1.47600757e+03 2.01906982e+02
 8.56016785e+02 1.44595129e+03 1.01873517e+03 9.71925354e+02
 1.04969592e+03 1.42424878e+03 1.14642163e+03 1.49596729e+03
 1.39300537e+03 2.00425812e+02 1.19649866e+03 7.89689392e+02
 7.14182007e+02 9.01952454e+02 5.22772217e+01 1.32447034e+03
 1.35336841e+03 9.58373535e+02 3.30493225e+02 6.58373047e+02
 1.37914941e+03 1.02343097e+03 2.18273743e+02 1.15070642e+03
 9.55266602e+02 1.06633923e+03 8.92448242e+02 7.94669189e+02
 7.07728821e+02 1.45995020e+03 1.18412244e+03 3.98230164e+02
 1.03072095e+03 1.34700586e+03 1.47127405e+03 1.42393530e+03
 3.85711212e+02 6.75724060e+02 1.45380872e+03 6.44786743e+02
 1.38838965e+03 2.54625977e+02 1.47509546e+03 6.99124146e+02
 1.37575964e+03 1.04460229e+03 6.38587097e+02 1.28283960e+03
 1.35774365e+03 1.17788733e+03 9.75866150e+02 6.32650146e+01
 8.60851501e+02 9.67519165e+02 1.46001831e+03 6.75650940e+01
 1.29110657e+02 1.18940198e+03 5.09766327e+02 1.34107397e+03
 1.43124231e+03 1.25079297e+03 3.51697784e+02 1.07981726e+03
 1.14297089e+02 1.37502295e+03 1.18246008e+03 2.77057465e+02
 1.32714648e+03 4.97988831e+02 1.10487793e+03 1.13648840e+03
 2.06502991e+02 1.11364563e+03 8.04971252e+02 3.09242767e+02
 1.03883008e+03 2.35846848e+02 1.09237122e+03 1.28456274e+03
 1.21657019e+03 3.97920746e+02 1.40844922e+03 8.18716614e+02
 1.46630811e+03 4.65949036e+02 1.24539185e+03 3.25818024e+02
 1.33433289e+03 1.25711694e+03 3.21574097e+02 9.02780396e+02
 1.28460889e+03 8.17971252e+02 1.31215552e+03 1.37249780e+03
 1.00055957e+03 1.02876355e+03 5.86791992e-01 1.14890198e+03
 1.30826709e+03 6.16444092e+01 1.29084851e+03 5.71048279e+02
 8.80604797e+02 5.22902588e+02 5.06824799e+02 1.16691870e+03
 1.16719385e+03 1.43768640e+03 6.12941895e+02 6.94497742e+02
 1.48512109e+03 1.03492847e+03 1.94743912e+02 7.45573120e+02
 1.33459366e+02 4.93906921e+02 5.44576721e+02 1.39621313e+03
 1.07266321e+03 1.20154285e+03 1.38166406e+03 1.21728467e+03
 6.58061218e+02 7.74988281e+02 1.43340955e+03 3.99095825e+02
 1.06192358e+03 1.14467957e+03 1.09658423e+03 6.08920288e+02
 1.45817920e+03 2.46835999e+02 1.44810693e+03 6.42472900e+02
 2.14529282e+02 1.18185364e+03 9.75771362e+02 6.17497925e+02
 1.03486450e+02 1.26901404e+03 9.65731079e+02 1.20561121e+03
 1.20241565e+03 5.14292358e+02 1.04076208e+03 1.47728992e+03
 8.42567383e+02 1.11904272e+03 1.42351514e+03 9.04593140e+02
 1.25385791e+03 2.10495331e+02 1.43920923e+03 7.22753601e+01
 1.31983594e+03 8.04284546e+02 1.35659314e+03 5.23723694e+02
 3.02324646e+02 1.37619043e+03 8.33153137e+02 4.97027100e+02
 1.81818848e+01 1.47249097e+03 9.99306763e+02 2.49008484e+01
 1.00358441e+03 6.44230469e+02 1.43466541e+03 5.49912537e+02
 1.41676685e+03 1.01285358e+03 6.11678406e+02 4.96016693e+01
 9.53587585e+02 9.95925720e+02 8.37666260e+02 9.11801331e+02
 1.21329346e+02 7.65791260e+02 1.32238330e+03 2.87069092e+01
 1.26831470e+03 2.57377960e+02 6.60388611e+02 1.31998584e+03
 6.39794922e+02 1.34376721e+03 1.45199670e+03 3.25797607e+02
 1.06061792e+03 2.61133652e+01 1.35844543e+03 9.96257935e+02
 1.21944714e+03 3.18730927e+02 1.43323645e+03 1.33393408e+03
 1.22169788e+03 1.35048083e+03 1.21925427e+03 2.62814240e+02
 2.12809921e+02 1.08312610e+03 2.14569092e+01 1.45405310e+03
 1.44928064e+03 6.87109131e+02 1.01539990e+03 3.64743591e+02
 1.24398987e+03 3.12207275e+02 1.10311938e+03 1.08952954e+03
 1.38134412e+03 3.14526825e+02 1.46308459e+03 4.15356140e+02
 9.90246582e+02 9.62561646e+02 1.37346692e+03 6.75552307e+02
 6.15238586e+02 1.42687891e+03 9.86217407e+02 6.96753723e+02
 2.64339539e+02 1.10432996e+03 8.81155090e+01 1.02419641e+03]","[ 256.12485    822.5077    1273.949      488.72925   1418.5132
 1169.418      689.08124    994.0382    1051.4178     170.67584
  790.91785   1060.0189    1446.1322     849.50446    203.02702
  775.6279    1483.046      915.64496    881.5504     205.25166
 1135.7424    1316.1366    1482.8162     536.04034    145.16214
  964.92456   1258.7825     192.03444    407.9385     976.5753
  800.21454    238.92636    584.59375    953.2366     691.7172
 1406.1361     777.70386   1185.0933     767.537     1079.0745
 1390.684     1189.2814     159.93347    789.8611    1976.0935
  480.6081    1077.7294     865.0036     395.52097    883.1471
 1451.8503      94.74509   1651.1602     228.41183   1076.9573
 1321.8132    1186.6244     239.58865   1345.5306     -28.43097
 1114.7372    1347.1217     136.82024    586.28455   1168.6675
  367.63086   1833.6295     895.77277   1594.5952     730.4058
  870.22894    833.9903     298.21402   1650.0575     -37.041565
  982.73883    875.7621     334.57468   1557.8837    1272.2955
 1545.9514     740.5521    1331.0706    1161.8124    1576.7732
  171.50562    565.6386    1133.5856     295.15274    807.00275
  703.95593   1310.5845     234.70306    951.831     1302.3037
  165.52185    264.15167   1454.9778     215.81346   1022.4269
 1530.7854      74.080505  1370.8756    1480.0369     438.9703
 1188.0529     731.9513     212.22124   1196.6774     361.48563
  414.51642    809.7868     392.72864   1388.9641     406.68793
  548.1044     265.89493    575.3827     231.99371    739.3196
 1537.3436     523.01654    647.3743     903.739      204.75012
 1615.5698     794.77905    361.64618   1184.564      410.09738
 1344.1907     535.1907    1033.9069    1307.5127     676.7676
 1030.7738     256.9945    1167.2274    1257.6987     619.66736
  277.87125   1424.8666    1480.2726     854.10925    820.48956
  991.17285    181.13972    711.58203    438.1623     721.8611
  133.44653    901.09033   1056.87      2009.9612     477.5565
 1516.4012     706.9376    1071.5249    1558.1       1173.4647
  743.8246    1304.3738    1245.9817     468.45245    530.49725
 1185.4558    1476.9508     193.5517    1047.5182    1271.9
 1016.98425    982.17633   1145.1439    1514.3434     -39.724243
 1374.6799    1432.6782     210.1098    1562.6622     798.5813
  927.6833    1170.9003     168.24939   1298.7446    1313.0447
 1087.8069     218.77893    729.9203    1523.1902    1484.6373
  172.56055   1245.4901     103.40793    825.60547    881.02527
  847.1822    1242.3624    1010.06836   1021.26587    538.482
  139.24396    985.6876    1164.5654     705.36926    243.56775
  528.7925    1412.7632     393.04263   1496.9695     290.64847
 1255.0319     635.2357    1636.949     1034.3574     523.97516
 1267.0533    1383.884     1398.3286     789.0391     284.02002
  484.35104   1162.1642    1351.4973     355.39835    303.9344
 1044.7192     562.3021    1352.1721    1403.8849    1018.67126
  328.12747   1085.6838     277.29575   1536.0326    1205.9263
  344.9892    1295.1663     543.5904    1109.1432    1464.8752
  432.65506   1341.6019     791.8234     399.05222   1246.7524
  288.97003   1089.3811    1524.8315    1164.2515     243.48004
 1446.7236     752.4765    1289.1781     438.60806   1164.1654
  270.74103   1589.9163     880.03925    210.57906    866.2323
 1072.8094     622.7386    1777.0111    1928.709      714.6619
  394.36002    151.23834   1161.5558    1326.8497      42.524963
  440.01544    447.40076    687.6274     424.73648    855.581
 1606.8928     346.34784   1651.2341     622.0747     602.5507
 1487.276      944.473      204.44492    551.5298     137.71234
  442.84448    725.7993    1209.6196    1259.9222    1401.2667
  665.84      1572.354      503.30087    693.77826   1523.8118
  742.5775     708.3642     332.76996   1064.8885     574.79956
 1632.5038     138.69122   1376.4885     588.91766    563.5607
 1082.1184     880.6523     602.4638     178.98596   1335.9409
  767.902      465.29947   1362.5137     451.0278    1192.9315
 1359.4889     977.73315   1251.2438    1461.9545    1090.2794
 1308.0947     147.33319   1431.2043     208.94098   1281.8844
  962.0381    1564.842      628.54083    419.2375    1155.7465
  795.2241     420.69666    198.0788    1477.779      856.2646
   29.334778  1448.756      889.7553    1526.8998     677.8457
 1253.4609    1098.6649     828.4402      -7.1242676 1453.5488
  783.6499    1024.5186     957.8817     108.41754    765.7024
 1214.2124     186.19153    685.2239      35.831726   375.08014
 1543.9296     587.69916   1155.6329    1368.0428     159.90692
 1409.2448    -215.96683    765.65674   1526.7301    1252.2448
  164.95935   1261.4349    1309.5521    1474.5798    1509.6704
 1271.641      232.54323    495.03497   1196.8167     368.26923
 1322.1819    1519.6686     590.93945   1508.6887     590.013
 1129.585      201.15839   1091.0374    1020.49524   1585.9457
  166.44427   1269.1984     348.5541     954.0969     737.51746
  926.3871    1085.9172     523.94037   1193.1437    1079.1036
  629.0296     228.89621    706.40405    189.57281   1224.4417   ]",166.75473,57344.94,239.46803838142992
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 1.037776888802994, Val Loss: 0.862210028171539', 'Epoch: 1, Train Loss: 0.875686386296915, Val Loss: 0.799294288158417', 'Epoch: 2, Train Loss: 0.804476640945257, Val Loss: 0.707159640789032', 'Epoch: 3, Train Loss: 0.673809504093126, Val Loss: 0.537296438217163', 'Epoch: 4, Train Loss: 0.463800275741622, Val Loss: 0.360374964475632', 'Epoch: 5, Train Loss: 0.370925637005374, Val Loss: 0.291022298783064', 'Epoch: 6, Train Loss: 0.338871822627478, Val Loss: 0.287894617915154', 'Epoch: 7, Train Loss: 0.332872245027575, Val Loss: 0.271707993149757', 'Epoch: 8, Train Loss: 0.333716257020485, Val Loss: 0.274800450503826', 'Epoch: 9, Train Loss: 0.312245283535747, Val Loss: 0.301374684572220', 'Epoch: 10, Train Loss: 0.312315042282260, Val Loss: 0.246235126852989', 'Epoch: 11, Train Loss: 0.281410132209922, Val Loss: 0.252563819587231', 'Epoch: 12, Train Loss: 0.292900346392809, Val Loss: 0.253032038509846', 'Epoch: 13, Train Loss: 0.272336644315442, Val Loss: 0.238216887712479', 'Epoch: 14, Train Loss: 0.280111866115138, Val Loss: 0.254624925851822', 'Epoch: 15, Train Loss: 0.250907867453819, Val Loss: 0.246364572644234', 'Epoch: 16, Train Loss: 0.252478604399881, Val Loss: 0.251585300564766', 'Epoch: 17, Train Loss: 0.274724350592425, Val Loss: 0.254288911819458', 'Epoch: 18, Train Loss: 0.279522059095460, Val Loss: 0.226206919550896', 'Epoch: 19, Train Loss: 0.274008464847886, Val Loss: 0.227620462477207', 'Epoch: 20, Train Loss: 0.236447779764963, Val Loss: 0.262908643484116', 'Epoch: 21, Train Loss: 0.242067273619563, Val Loss: 0.252474229335785', 'Epoch: 22, Train Loss: 0.283587477061638, Val Loss: 0.294951587617397', 'Epoch: 23, Train Loss: 0.252204120159149, Val Loss: 0.222065591663122', 'Epoch: 24, Train Loss: 0.244783976136945, Val Loss: 0.238812621831894', 'Epoch: 25, Train Loss: 0.264747046800547, Val Loss: 0.263811714947224', 'Epoch: 26, Train Loss: 0.260777621248434, Val Loss: 0.248276620805264', 'Epoch: 27, Train Loss: 0.240876993987449, Val Loss: 0.265153901278973', 'Epoch: 28, Train Loss: 0.235162181909694, Val Loss: 0.271940234601498', 'Epoch: 29, Train Loss: 0.248797035147977, Val Loss: 0.214622450917959', 'Epoch: 30, Train Loss: 0.229796074504076, Val Loss: 0.241720442920923', 'Epoch: 31, Train Loss: 0.241416240934023, Val Loss: 0.272235647737980', 'Epoch: 32, Train Loss: 0.228428578654001, Val Loss: 0.230714322775602', 'Epoch: 33, Train Loss: 0.221518070891846, Val Loss: 0.226925129890442', 'Epoch: 34, Train Loss: 0.210883277619994, Val Loss: 0.254596875607967', 'Epoch: 35, Train Loss: 0.239561393857002, Val Loss: 0.214842057377100', 'Epoch: 36, Train Loss: 0.213133147462856, Val Loss: 0.258403329849243', 'Epoch: 37, Train Loss: 0.224593759795954, Val Loss: 0.241874808371067', 'Epoch: 38, Train Loss: 0.241085237108691, Val Loss: 0.245242688357830', 'Epoch: 39, Train Loss: 0.220993730997623, Val Loss: 0.226838836669922', 'Epoch: 40, Train Loss: 0.249644059774488, Val Loss: 0.231118019521236', 'Epoch: 41, Train Loss: 0.222257227398628, Val Loss: 0.206517187654972', 'Epoch: 42, Train Loss: 0.204081123651460, Val Loss: 0.224467942118645', 'Epoch: 43, Train Loss: 0.224260501563549, Val Loss: 0.220053812265396', 'Epoch: 44, Train Loss: 0.203777384965919, Val Loss: 0.186036928594112', 'Epoch: 45, Train Loss: 0.205875417780738, Val Loss: 0.206656506210566', 'Epoch: 46, Train Loss: 0.193111595112917, Val Loss: 0.190201174914837', 'Epoch: 47, Train Loss: 0.200242232184770, Val Loss: 0.254186855256557', 'Epoch: 48, Train Loss: 0.198927702165620, Val Loss: 0.248089128732681', 'Epoch: 49, Train Loss: 0.198823213404001, Val Loss: 0.202645168900490', 'Epoch: 50, Train Loss: 0.220159478572219, Val Loss: 0.241490830034018', 'Epoch: 51, Train Loss: 0.194090336561203, Val Loss: 0.208982226848602', 'Epoch: 52, Train Loss: 0.204005492114744, Val Loss: 0.233659974038601', 'Epoch: 53, Train Loss: 0.204644716409750, Val Loss: 0.192687091380358', 'Epoch: 54, Train Loss: 0.195210124430961, Val Loss: 0.288897361904383', 'Epoch: 55, Train Loss: 0.190146831059179, Val Loss: 0.197316977083683', 'Epoch: 56, Train Loss: 0.186148681093094, Val Loss: 0.230563570410013', 'Epoch: 57, Train Loss: 0.176778548505417, Val Loss: 0.230578947663307', 'Epoch: 58, Train Loss: 0.159170341439718, Val Loss: 0.232264201641083', 'Epoch: 59, Train Loss: 0.171253255286882, Val Loss: 0.178577118963003', 'Epoch: 60, Train Loss: 0.182332281716341, Val Loss: 0.196722581684589', 'Epoch: 61, Train Loss: 0.160302314474139, Val Loss: 0.216480174660683', 'Epoch: 62, Train Loss: 0.181302933672140, Val Loss: 0.186637926101685', 'Epoch: 63, Train Loss: 0.172842282195424, Val Loss: 0.207215244472027', 'Epoch: 64, Train Loss: 0.171333337072716, Val Loss: 0.204804604947567', 'Epoch: 65, Train Loss: 0.159540531333796, Val Loss: 0.188840956985950', 'Epoch: 66, Train Loss: 0.162330110752305, Val Loss: 0.205646281242371', 'Epoch: 67, Train Loss: 0.171132278043863, Val Loss: 0.198001173436642', 'Epoch: 68, Train Loss: 0.159482267533624, Val Loss: 0.197327150851488', 'Epoch: 69, Train Loss: 0.155753528396058, Val Loss: 0.211983976960182', 'Epoch: 70, Train Loss: 0.148150719182436, Val Loss: 0.184375102967024', 'Epoch: 71, Train Loss: 0.148716340101389, Val Loss: 0.169348804354668', 'Epoch: 72, Train Loss: 0.139371962308191, Val Loss: 0.174810053408146', 'Epoch: 73, Train Loss: 0.148611520438693, Val Loss: 0.208709296435118', 'Epoch: 74, Train Loss: 0.160895692227885, Val Loss: 0.212533055543900', 'Epoch: 75, Train Loss: 0.168076757428258, Val Loss: 0.232435644865036', 'Epoch: 76, Train Loss: 0.141912030575927, Val Loss: 0.189544032216072', 'Epoch: 77, Train Loss: 0.148223244260217, Val Loss: 0.184209489524364', 'Epoch: 78, Train Loss: 0.133161840223989, Val Loss: 0.170265901535749', 'Epoch: 79, Train Loss: 0.142994214542383, Val Loss: 0.194045822322369', 'Epoch: 80, Train Loss: 0.144370049151570, Val Loss: 0.179876420944929', 'Epoch: 81, Train Loss: 0.129841466455959, Val Loss: 0.193371704667807', 'Epoch: 82, Train Loss: 0.139117427256911, Val Loss: 0.204986282736063', 'Epoch: 83, Train Loss: 0.150957456075175, Val Loss: 0.173399732559919', 'Epoch: 84, Train Loss: 0.141292147511660, Val Loss: 0.180722259730101', 'Epoch: 85, Train Loss: 0.132199024911537, Val Loss: 0.180953463912010', 'Epoch: 86, Train Loss: 0.138724298064792, Val Loss: 0.181791486293077', 'Epoch: 87, Train Loss: 0.131316423459455, Val Loss: 0.184000788182020', 'Epoch: 88, Train Loss: 0.127783274667901, Val Loss: 0.181253067553043', 'Epoch: 89, Train Loss: 0.122182552811018, Val Loss: 0.176625320911407', 'Epoch: 90, Train Loss: 0.141118785323099, Val Loss: 0.193850721567869', 'Epoch: 91, Train Loss: 0.135962734215481, Val Loss: 0.176254490613937', 'Epoch: 92, Train Loss: 0.133853164089974, Val Loss: 0.169514675736427', 'Epoch: 93, Train Loss: 0.125562061490708, Val Loss: 0.173708111494780', 'Epoch: 94, Train Loss: 0.115519732886622, Val Loss: 0.173400679677725', 'Epoch: 95, Train Loss: 0.111755680466114, Val Loss: 0.169558972418308', 'Epoch: 96, Train Loss: 0.117419703322095, Val Loss: 0.189262272715569', 'Epoch: 97, Train Loss: 0.120214043401702, Val Loss: 0.195629687011242', 'Epoch: 98, Train Loss: 0.114120574841319, Val Loss: 0.198386223465204', 'Epoch: 99, Train Loss: 0.116523291829020, Val Loss: 0.186286609470844', 'Epoch: 100, Train Loss: 0.126650896919675, Val Loss: 0.176400803625584', 'Epoch: 101, Train Loss: 0.111874039956304, Val Loss: 0.166106445491314', 'Epoch: 102, Train Loss: 0.111415563541096, Val Loss: 0.187061697244644', 'Epoch: 103, Train Loss: 0.124765328023323, Val Loss: 0.207734491527081', 'Epoch: 104, Train Loss: 0.114186795298443, Val Loss: 0.183972306549549', 'Epoch: 105, Train Loss: 0.107728099493786, Val Loss: 0.177503694891930', 'Epoch: 106, Train Loss: 0.111162217203961, Val Loss: 0.197561659812927', 'Epoch: 107, Train Loss: 0.120232369014344, Val Loss: 0.189658506214619', 'Epoch: 108, Train Loss: 0.105566502657048, Val Loss: 0.172210441380739', 'Epoch: 109, Train Loss: 0.101611166845920, Val Loss: 0.194745109230280', 'Epoch: 110, Train Loss: 0.110771314176016, Val Loss: 0.190040805786848', 'Epoch: 111, Train Loss: 0.111799435906632, Val Loss: 0.179620426446199', 'Epoch: 112, Train Loss: 0.106601334241934, Val Loss: 0.189164382815361', 'Epoch: 113, Train Loss: 0.112267136140618, Val Loss: 0.196963082551956', 'Epoch: 114, Train Loss: 0.112963192511437, Val Loss: 0.207559893503785', 'Epoch: 115, Train Loss: 0.105055493324302, Val Loss: 0.186868975162506', 'Epoch: 116, Train Loss: 0.099734548176097, Val Loss: 0.191465435177088', 'Epoch: 117, Train Loss: 0.101716544739036, Val Loss: 0.205531706809998', 'Epoch: 118, Train Loss: 0.103203839124289, Val Loss: 0.178470179736614', 'Epoch: 119, Train Loss: 0.099797429127056, Val Loss: 0.204051723033190', 'Epoch: 120, Train Loss: 0.102162639155637, Val Loss: 0.190249672532082', 'Epoch: 121, Train Loss: 0.094853350329538, Val Loss: 0.176774769127369', 'Epoch: 122, Train Loss: 0.090384634211659, Val Loss: 0.176091646999121', 'Epoch: 123, Train Loss: 0.086108799244082, Val Loss: 0.191258995831013', 'Epoch: 124, Train Loss: 0.087984195368928, Val Loss: 0.187395641878247', 'Epoch: 125, Train Loss: 0.092539360270251, Val Loss: 0.208413966894150', 'Epoch: 126, Train Loss: 0.086760909924673, Val Loss: 0.174254281967878', 'Epoch: 127, Train Loss: 0.082747523131412, Val Loss: 0.207801153659821', 'Epoch: 128, Train Loss: 0.095162381959516, Val Loss: 0.185734203010797', 'Epoch: 129, Train Loss: 0.100731874491240, Val Loss: 0.194383633583784', 'Epoch: 130, Train Loss: 0.087155180961587, Val Loss: 0.179133775159717', 'Epoch: 131, Train Loss: 0.084437856580629, Val Loss: 0.194447582066059', 'Epoch: 132, Train Loss: 0.088338165738901, Val Loss: 0.196688778102398', 'Epoch: 133, Train Loss: 0.086122946683751, Val Loss: 0.195102925673127', 'Epoch: 134, Train Loss: 0.076064963933340, Val Loss: 0.185016697049141', 'Epoch: 135, Train Loss: 0.079441363901593, Val Loss: 0.190849707722664', 'Epoch: 136, Train Loss: 0.074948605193302, Val Loss: 0.183375676199794', 'Epoch: 137, Train Loss: 0.082970522907238, Val Loss: 0.184905044287443', 'Epoch: 138, Train Loss: 0.076721124134438, Val Loss: 0.188694253936410', 'Epoch: 139, Train Loss: 0.075020898480055, Val Loss: 0.181767529249191', 'Epoch: 140, Train Loss: 0.075022590758149, Val Loss: 0.180445150882006', 'Epoch: 141, Train Loss: 0.070922764234765, Val Loss: 0.199136776104569', 'Epoch: 142, Train Loss: 0.078916415875388, Val Loss: 0.186143706589937', 'Epoch: 143, Train Loss: 0.069579893246640, Val Loss: 0.194016793370247', 'Epoch: 144, Train Loss: 0.069353059280750, Val Loss: 0.189101334735751', 'Epoch: 145, Train Loss: 0.067094817194481, Val Loss: 0.183274513930082', 'Epoch: 146, Train Loss: 0.073889420129532, Val Loss: 0.201991768181324', 'Epoch: 147, Train Loss: 0.069474552563110, Val Loss: 0.188070462942123', 'Epoch: 148, Train Loss: 0.070028489282311, Val Loss: 0.177770900800824', 'Epoch: 149, Train Loss: 0.061695348991211, Val Loss: 0.186602248251438', 'Epoch: 150, Train Loss: 0.071019284557118, Val Loss: 0.190579883605242', 'Epoch: 151, Train Loss: 0.067556501171270, Val Loss: 0.196242077201605', 'Epoch: 152, Train Loss: 0.068667716974782, Val Loss: 0.189497993364930', 'Epoch: 153, Train Loss: 0.063667001159385, Val Loss: 0.187483999729156', 'Epoch: 154, Train Loss: 0.066591307694136, Val Loss: 0.194551685526967', 'Epoch: 155, Train Loss: 0.062271767490825, Val Loss: 0.184373731911182', 'Epoch: 156, Train Loss: 0.067136500377295, Val Loss: 0.205940874516964', 'Epoch: 157, Train Loss: 0.060337475436025, Val Loss: 0.214081716984510', 'Epoch: 158, Train Loss: 0.058791356594410, Val Loss: 0.191560275405645', 'Epoch: 159, Train Loss: 0.062579095818449, Val Loss: 0.209605629742146', 'Epoch: 160, Train Loss: 0.062364791974772, Val Loss: 0.197270433306694', 'Epoch: 161, Train Loss: 0.061152413357482, Val Loss: 0.221126636862755', 'Epoch: 162, Train Loss: 0.059051863242720, Val Loss: 0.188809773027897', 'Epoch: 163, Train Loss: 0.064043451707030, Val Loss: 0.209889869838953', 'Epoch: 164, Train Loss: 0.059448797342389, Val Loss: 0.199693993031979', 'Epoch: 165, Train Loss: 0.057247657588748, Val Loss: 0.208149064332247', 'Epoch: 166, Train Loss: 0.051734603551585, Val Loss: 0.210380963310599', 'Epoch: 167, Train Loss: 0.056587050820506, Val Loss: 0.195501403734088', 'Epoch: 168, Train Loss: 0.058265308676244, Val Loss: 0.212363430932164', 'Epoch: 169, Train Loss: 0.051142180425137, Val Loss: 0.201429575234652', 'Epoch: 170, Train Loss: 0.050232634078278, Val Loss: 0.198815541788936', 'Epoch: 171, Train Loss: 0.056100890343619, Val Loss: 0.205495657995343', 'Epoch: 172, Train Loss: 0.054267347790301, Val Loss: 0.196359421536326', 'Epoch: 173, Train Loss: 0.053076757161423, Val Loss: 0.210496182590723', 'Epoch: 174, Train Loss: 0.051510417703972, Val Loss: 0.193106891736388', 'Epoch: 175, Train Loss: 0.051739139482379, Val Loss: 0.205430590063334', 'Epoch: 176, Train Loss: 0.051273800995807, Val Loss: 0.192063584104180', 'Epoch: 177, Train Loss: 0.051678431112059, Val Loss: 0.197688805460930', 'Epoch: 178, Train Loss: 0.051458268642945, Val Loss: 0.200670583993196', 'Epoch: 179, Train Loss: 0.053284494076357, Val Loss: 0.207661301419139', 'Epoch: 180, Train Loss: 0.052591133256291, Val Loss: 0.200490356311202', 'Epoch: 181, Train Loss: 0.045632982366653, Val Loss: 0.201035634204745', 'Epoch: 182, Train Loss: 0.050513553108240, Val Loss: 0.203994672745466', 'Epoch: 183, Train Loss: 0.049745120822864, Val Loss: 0.211151386350393', 'Epoch: 184, Train Loss: 0.050665688289459, Val Loss: 0.201146070212126', 'Epoch: 185, Train Loss: 0.044115016280219, Val Loss: 0.206707129701972', 'Epoch: 186, Train Loss: 0.046314844623381, Val Loss: 0.206616164073348', 'Epoch: 187, Train Loss: 0.048154982803173, Val Loss: 0.200706917718053', 'Epoch: 188, Train Loss: 0.049663052092804, Val Loss: 0.202463131546974', 'Epoch: 189, Train Loss: 0.046357039795365, Val Loss: 0.202428604960442', 'Epoch: 190, Train Loss: 0.048946620679872, Val Loss: 0.202146831154823', 'Epoch: 191, Train Loss: 0.045274144904905, Val Loss: 0.204820361584425', 'Epoch: 192, Train Loss: 0.044164120544528, Val Loss: 0.198169556856155', 'Epoch: 193, Train Loss: 0.045094402918462, Val Loss: 0.200748279839754', 'Epoch: 194, Train Loss: 0.045712321346929, Val Loss: 0.199495266899467', 'Epoch: 195, Train Loss: 0.044663392743746, Val Loss: 0.200004225075245', 'Epoch: 196, Train Loss: 0.045190672671726, Val Loss: 0.198566545024514', 'Epoch: 197, Train Loss: 0.046577677433920, Val Loss: 0.198524275720119', 'Epoch: 198, Train Loss: 0.043862800785275, Val Loss: 0.198742420524359', 'Epoch: 199, Train Loss: 0.047393934627952, Val Loss: 0.198846378549933']","[1.35810327e+03 1.44083557e+02 1.31191650e+03 1.38013110e+03
 1.01256976e+03 1.48239941e+03 1.70598618e+02 1.30103711e+03
 1.46176392e+03 1.33664502e+03 1.09700671e+03 1.09962036e+02
 6.70501221e+02 1.46448938e+03 1.35518616e+03 2.42586960e+02
 9.37257996e+02 3.39246735e+02 8.83877075e+02 1.19212817e+03
 1.31304077e+03 2.57316284e+01 1.14807019e+03 1.12065149e+03
 1.32000195e+03 1.48121082e+03 9.69841980e+02 3.16613647e+02
 5.64130920e+02 9.69523438e+02 1.27497192e+02 1.00715723e+03
 8.18295105e+02 7.08294067e+01 8.68494446e+02 2.13237915e+01
 1.46547693e+03 7.32026245e+02 1.87978394e+02 1.49634155e+03
 1.05061914e+03 6.60351440e+02 4.05384583e+02 1.10478601e+03
 9.28976074e+02 1.39608765e+03 1.86789871e+02 1.37755823e+03
 6.37078491e+02 1.31178723e+03 6.39463013e+02 1.24362305e+03
 5.61904907e+02 1.14591504e+03 4.70395203e+01 9.16060547e+02
 7.28132935e+01 1.26925208e+03 1.15346533e+03 1.49456384e+03
 5.82413757e+02 1.46525562e+03 1.23392896e+03 1.98272827e+02
 1.11967810e+03 3.47295837e+02 1.67995911e+02 1.42327783e+03
 1.33368298e+03 8.70692932e+02 5.67513672e+02 1.48283057e+03
 2.50780640e+02 1.18039453e+03 1.48053174e+03 6.72494568e+02
 1.00932910e+03 1.41036206e+03 9.72192261e+02 1.42789563e+03
 9.11117615e+02 1.18751013e+03 1.33504053e+03 4.12653137e+02
 1.46063354e+03 4.94067719e+02 9.27596985e+02 1.46192578e+03
 2.04335251e+02 9.38341736e+02 9.63742798e+02 1.55737671e+02
 1.49376868e+03 9.69340027e+02 1.41086365e+03 5.87777649e+02
 1.49691382e+03 1.28665735e+03 1.38653027e+03 1.11932410e+03
 1.37066687e+03 3.45969055e+02 1.15423816e+03 1.15506750e+03
 6.54085205e+02 1.04265820e+03 1.28592419e+03 1.23287134e+03
 1.05464343e+03 1.46163843e+03 7.32741394e+02 1.49599915e+03
 1.07101184e+03 1.49451465e+03 1.63263000e+02 9.02853027e+02
 1.43761426e+03 8.00416870e+01 1.00478357e+03 1.43105200e+03
 1.42766309e+03 4.45967285e+02 1.07378333e+03 1.49725293e+03
 9.15096436e+02 2.75801636e+02 1.05290857e+03 1.28979980e+03
 1.49286316e+03 1.33798996e+02 5.93304932e+02 1.03410413e+03
 1.95761047e+02 8.24261536e+02 1.47969714e+03 9.08113220e+02
 1.14377417e+03 1.59074783e+02 7.84873718e+02 6.02182434e+02
 3.63402405e+02 1.48880188e+03 4.57710236e+02 8.13727417e+02
 2.16049194e+01 1.23379199e+03 2.50861786e+02 8.56870789e+02
 2.61061615e+02 1.40009619e+03 1.33824707e+03 5.95055176e+02
 6.10565674e+02 1.45068652e+03 5.17529114e+02 1.06821411e+03
 1.48576636e+03 5.47705017e+02 1.11459692e+03 1.11358130e+03
 1.47522876e+03 6.22712402e+01 1.44864099e+03 9.37405945e+02
 8.47903870e+02 1.44668835e+03 1.36798340e+03 6.36008240e+02
 1.39848657e+03 4.83920593e+02 8.96578369e+02 3.50959595e+02
 2.83499756e+01 1.31832849e+03 5.99794250e+02 1.42882422e+03
 9.52106323e+01 1.49255884e+03 1.41547913e+03 1.06692371e+03
 1.39470996e+03 1.37576855e+03 1.34517432e+03 4.49968597e+02
 4.15535248e+02 1.46167139e+03 1.43673022e+03 7.72204102e+02
 1.36073804e+03 1.01216852e+03 2.79254974e+02 1.48244763e+03
 1.21522412e+03 4.28252350e+02 8.91527222e+02 1.26098901e+03
 1.12650891e+03 6.81569092e+02 5.61910034e+02 1.40529590e+03
 3.22026794e+02 1.46271973e+03 1.37842383e+03 1.40132507e+03
 1.31462683e+03 2.97046631e+02 1.41891077e+03 1.32829578e+03
 7.86674194e+01 1.32788892e+03 9.31093018e+02 6.07347412e+01
 1.46959302e+03 1.29950562e+02 7.84041992e+02 1.14416162e+03
 1.42040088e+03 6.07164429e+02 1.28868555e+03 5.94424194e+02
 4.40244965e+02 7.58248657e+02 5.29995483e+02 6.26829163e+02
 1.03803149e+03 7.70338379e+02 1.13190271e+03 1.26545215e+03
 7.89656677e+02 4.00971252e+02 1.42006934e+03 1.21847839e+02
 4.75616241e+02 1.30095386e+03 1.11033545e+03 1.86996460e+01
 1.33655566e+03 8.18586731e+02 1.37512744e+03 8.99312622e+02
 1.15046936e+03 8.81454285e+02 5.87909546e+02 1.14930872e+03
 1.12444153e+03 1.14220142e+03 1.43055139e+03 1.18256970e+03
 1.41664233e+03 5.45563904e+02 2.60715179e+02 1.18561768e+03
 9.16415283e+02 8.82751221e+02 1.41007825e+03 1.18979883e+03
 6.98214355e+02 1.15006506e+03 1.26430615e+03 9.94850708e+02
 4.16102448e+02 1.16141797e+03 9.10232605e+02 1.33391016e+03
 8.46921143e+02 1.43230396e+03 6.19606628e+02 3.61109741e+02
 1.34463660e+03 5.41560242e+02 1.24251575e+03 5.44392334e+02
 1.00629022e+03 1.39063867e+03 6.25530090e+02 9.24698730e+02
 1.27158459e+03 7.36418701e+02 2.87254059e+02 1.39672839e+03
 7.47851257e+02 9.51430664e+02 8.90306641e+02 1.47650098e+03
 3.18229462e+02 1.41297681e+03 1.42165430e+03 1.04170288e+03
 1.35830359e+03 1.45944495e+03 9.17230469e+02 1.40254883e+03
 7.94340332e+02 1.39710254e+03 8.03534302e+02 1.23197803e+03
 1.41364551e+03 1.78769592e+02 1.11124023e+03 1.65509186e+02
 1.49501685e+03 4.96174896e+02 1.41334937e+03 7.80634583e+02
 5.48254089e+02 3.87268066e-01 7.41103027e+02 4.64691437e+02
 1.41017297e+03 1.45264343e+03 1.36586597e+03 1.48870532e+03
 3.89561920e+02 1.38546472e+03 8.75978516e+02 1.39815540e+03
 1.12734473e+03 7.07420105e+02 1.44923157e+03 1.03643433e+03
 1.14971851e+03 5.10289307e+02 5.86064087e+02 1.48554102e+03
 1.40444849e+03 1.05911401e+03 1.33570361e+03 5.66070557e+02
 3.97759308e+02 1.27304590e+03 1.28769617e+03 2.00127960e+02
 7.27027466e+02 1.40578027e+03 5.96466370e+01 7.18960571e+02
 1.46940149e+03 1.32124561e+03 1.19748804e+03 1.31471326e+03
 1.40131555e+03 4.13498688e+02 1.20107178e+03 1.49753711e+03
 9.04868347e+02 1.46035889e+02 2.93916687e+02 1.42077734e+03
 1.30955505e+02 1.43009180e+03 1.00910211e+03 1.13250562e+03
 1.48858044e+03 5.44347412e+02 7.67765015e+02 4.20308868e+02
 1.14476123e+03 1.20891626e+03 1.49246680e+03 9.33023621e+02
 8.07235413e+02 1.17532190e+03 1.40466110e+02 1.17445264e+03
 7.46525146e+02 1.43046069e+03 1.40218848e+03 5.01562012e+02
 1.25784497e+03 2.91409393e+02 1.08396838e+03 5.21401978e+02
 1.48858508e+03 2.00287460e+02 1.47637085e+03 1.22162744e+03
 3.91849670e+02 1.30936011e+03 1.44812622e+03 5.01284393e+02
 1.42684424e+03 1.94577728e+02 1.51421677e+02 9.98216797e+02
 1.49355188e+03 8.89118713e+02 1.39424976e+03 4.43121918e+02
 9.63502014e+02 1.32973499e+03 2.16034073e+02 1.09629651e+03
 1.17570435e+03 1.41710974e+03 9.26299133e+02 1.34396521e+03
 1.18497791e+03 1.27191321e+03 1.47228516e+03 2.08387634e+02]","[1439.7273     177.25229   1379.2557    1344.6519    1097.4828
 1576.4728     315.45734    950.4245     939.45264   1039.0317
  914.4062     134.86272    771.0348    1387.4469    1112.3317
  589.31213   1164.815      367.86902    948.0488    1250.8042
 1318.9288     -43.943115  1105.9282    1031.8375    1378.237
 1470.0344    1005.0227     279.1746     506.40775    928.43896
 1834.893      924.67487   1025.1462       5.3115845 1095.5895
   84.8378    1530.117      795.4832     308.3587    1483.8037
  806.38464    519.46924    314.12247   1172.77       964.5231
 1282.1199     102.86905   1243.6682     510.7719    1287.6115
  140.21977   1797.1938     547.0675    1395.5475     -52.255432
  938.4602     184.99602   1085.1516    1222.5781    1552.522
  456.11758   1090.6782    1290.4121     202.6976     932.4545
  296.69797    261.26572   1441.1006    1406.4178    1010.6597
  485.21457   1476.1642     207.57793    917.0408    1537.2568
  690.88446   1100.7281    1491.2178     924.67633   1170.7256
  955.45074   1143.0092    1445.1003     452.3833    1579.3037
  534.8959    1003.297     1521.6553     222.69095    861.8235
  951.16644    159.34296   1742.2284    1270.5018    1490.3049
  582.7889    1388.3984    1419.273     1329.6748    1117.7432
 1434.9061     319.0684     932.81854    833.96674    623.13837
 1019.6079    1210.8438    1655.8008     696.32495   2081.0283
  791.1329    1355.946     1166.386     1661.1992     172.28926
  902.7383    1621.4932     220.26654    474.7477     783.99835
 1597.4456     344.74786   1066.584     1396.9607    1390.4023
  208.8728    1015.1437    1181.818      977.253      425.26804
  613.8112    1088.0645     209.01587    771.7057    1406.7046
  970.8853     730.2969     293.0838     704.23456    681.7955
  351.93875   1528.8948     438.7326     868.9734     222.5741
 1342.2385     250.85645    956.67834    231.18045   1236.54
 1346.7225     585.7508     545.48987   1441.9736     413.23175
 1154.237     1471.5237     571.28253    874.0009    1035.8557
 1439.6836     161.79297   1559.5924    1108.4698     926.44495
 1486.733     1321.5131     610.3565    1752.8978     421.31216
  990.7796     469.33755    399.02643   1000.1078     654.5494
 1729.7756      49.534424  1929.2312    1415.6233    1064.6559
 1472.392     1374.9348    1399.8318     433.8218     487.22876
 1327.0488    1535.3652     668.1128    1038.8335     870.57556
  242.9148    1496.2705    1286.3239     364.21698    878.09534
 1271.4241    1039.3987     705.7798     608.88055   1099.1493
  329.6097    1554.9626    1336.6548     822.9147    1583.5159
  169.57104    621.60486   2061.9138     219.06445   1245.6962
 1373.193      230.02126   1174.787      235.62085    739.0598
 1157.9845    1493.8018     513.63617   1381.2898     618.4936
  440.01953    834.958      517.3136     663.6318     925.4766
  632.5425     956.2525     557.044      706.5399     906.6114
 1416.4224     186.36612    571.62695   1440.2483    1806.895
   48.781982  1387.7578     818.4151    1380.0002     861.86237
 1173.8727    1112.0088     623.5558    1201.003     1103.6411
 1374.1836     995.5693    1211.0721    1369.8937     568.8149
  272.44412   1244.9893     746.39557    855.15283   1370.2579
 1266.2314     647.5929     996.4181    1379.409      977.4024
  368.2438    1330.9116     813.8217    1411.4282     900.34
 1321.0864    1044.724      315.88763   1329.0194     556.1763
 1501.8055     441.9393    1046.6129    1541.1323     706.1876
  986.83044   1201.0985     842.00024    329.5296    1396.467
  628.2988     908.7165     985.1433    1568.8607     359.8942
 1539.3633    1477.1359    1116.0956    1125.4987    1339.1007
 1059.9468    1434.7043     844.8005    1372.0786     637.7695
 1312.7595    1455.4667     192.56927   1194.0682     152.78033
 1465.479      461.33148   1324.1096     824.293      556.30914
   82.43518    790.97424    433.73126    562.9356    1429.6312
 1121.675     1457.3601     348.11145   1423.7297     718.4168
 1043.4352     679.057      417.24197   1394.2626    1027.2886
 1192.6527     530.4025     593.2316    1463.1348    1537.8376
  963.7149    1502.5232     406.72415    453.58395   1339.6456
 1024.9355     109.05969    613.9863    1257.7742      66.85669
  758.4666    1330.0557    1125.9841     889.2751    1221.63
 1387.2317     287.5606    1313.7834    1564.362      873.7716
  174.38014    235.95331   1303.2103      93.23566   1360.3525
  934.6885    1386.1449    1509.59       562.9292    1131.251
  178.0232    1129.7681    1103.2878    1542.9547     913.24603
  910.0896     908.0514     140.30403    942.6001     740.3922
 1288.8025    1036.1058     403.55334   1888.7627     455.21204
 1006.09906    528.7378    1425.8716     509.60938   1115.5869
  345.74408    382.3641    1378.6793    1356.483      509.09866
 1520.2917     166.31464    470.40662   1142.918     1568.2063
  929.2508    1424.4832     421.05707   1004.5441    1365.8717
  658.9585    1761.5295    1221.0557    1480.8512    1099.8339
 1456.6251    1098.7078    1231.0021    1523.6228     130.97327  ]",128.89783,44842.37,211.76017353069486
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 0.128333853173802, Val Loss: 0.354392241239548', 'Epoch: 1, Train Loss: 0.108539485521899, Val Loss: 0.285752139488856', 'Epoch: 2, Train Loss: 0.074658399661079, Val Loss: 0.144629737536112', 'Epoch: 3, Train Loss: 0.033676499230716, Val Loss: 0.063086701730887', 'Epoch: 4, Train Loss: 0.023274670148851, Val Loss: 0.049896092216174', 'Epoch: 5, Train Loss: 0.018547287424102, Val Loss: 0.046942023436228', 'Epoch: 6, Train Loss: 0.016685189920982, Val Loss: 0.036136115690072', 'Epoch: 7, Train Loss: 0.014777664052507, Val Loss: 0.038144802947839', 'Epoch: 8, Train Loss: 0.014786844902480, Val Loss: 0.027291368246078', 'Epoch: 9, Train Loss: 0.010107070804780, Val Loss: 0.021393270740906', 'Epoch: 10, Train Loss: 0.009144598973616, Val Loss: 0.018335185199976', 'Epoch: 11, Train Loss: 0.009191205689527, Val Loss: 0.017257781550288', 'Epoch: 12, Train Loss: 0.009369351872677, Val Loss: 0.017389886577924', 'Epoch: 13, Train Loss: 0.007588361333060, Val Loss: 0.013386460517844', 'Epoch: 14, Train Loss: 0.007983202754541, Val Loss: 0.018156555940708', 'Epoch: 15, Train Loss: 0.008693224473195, Val Loss: 0.014570551216602', 'Epoch: 16, Train Loss: 0.009192141000437, Val Loss: 0.018506387695670', 'Epoch: 17, Train Loss: 0.007415582596516, Val Loss: 0.014992023209731', 'Epoch: 18, Train Loss: 0.006768808479755, Val Loss: 0.012257188806931', 'Epoch: 19, Train Loss: 0.006673614359425, Val Loss: 0.020938761333625', 'Epoch: 20, Train Loss: 0.008703465239351, Val Loss: 0.018549056102832', 'Epoch: 21, Train Loss: 0.005819850487507, Val Loss: 0.011265749906500', 'Epoch: 22, Train Loss: 0.007213055390779, Val Loss: 0.012510165572166', 'Epoch: 23, Train Loss: 0.006846968681758, Val Loss: 0.016151265924176', 'Epoch: 24, Train Loss: 0.007184124587260, Val Loss: 0.026404292682807', 'Epoch: 25, Train Loss: 0.008194247587719, Val Loss: 0.010387225138644', 'Epoch: 26, Train Loss: 0.006378603459315, Val Loss: 0.023174261997143', 'Epoch: 27, Train Loss: 0.006988966787760, Val Loss: 0.014214981918534', 'Epoch: 28, Train Loss: 0.006056219097653, Val Loss: 0.014958351006111', 'Epoch: 29, Train Loss: 0.006611651797843, Val Loss: 0.027760234127442', 'Epoch: 30, Train Loss: 0.007250590057944, Val Loss: 0.013738701542219', 'Epoch: 31, Train Loss: 0.005886549709493, Val Loss: 0.011855086609721', 'Epoch: 32, Train Loss: 0.005603773981503, Val Loss: 0.009595324844122', 'Epoch: 33, Train Loss: 0.005852910803759, Val Loss: 0.026793529018760', 'Epoch: 34, Train Loss: 0.006529360910067, Val Loss: 0.011269048973918', 'Epoch: 35, Train Loss: 0.005710291747317, Val Loss: 0.019396620988846', 'Epoch: 36, Train Loss: 0.006510906212942, Val Loss: 0.010953104148308', 'Epoch: 37, Train Loss: 0.006593952730355, Val Loss: 0.019930520504713', 'Epoch: 38, Train Loss: 0.006654083415980, Val Loss: 0.016106952776512', 'Epoch: 39, Train Loss: 0.006699087652769, Val Loss: 0.009023627191782', 'Epoch: 40, Train Loss: 0.005676583266099, Val Loss: 0.024748120158911', 'Epoch: 41, Train Loss: 0.006939925047221, Val Loss: 0.008777900710702', 'Epoch: 42, Train Loss: 0.006161504972527, Val Loss: 0.010193517009417', 'Epoch: 43, Train Loss: 0.005299535750603, Val Loss: 0.009144693426788', 'Epoch: 44, Train Loss: 0.007222856217213, Val Loss: 0.009793458369871', 'Epoch: 45, Train Loss: 0.006056124870559, Val Loss: 0.010625652124484', 'Epoch: 46, Train Loss: 0.005367167137620, Val Loss: 0.013716192469001', 'Epoch: 47, Train Loss: 0.005256367747793, Val Loss: 0.012023762601117', 'Epoch: 48, Train Loss: 0.005162484104965, Val Loss: 0.014552162388961', 'Epoch: 49, Train Loss: 0.005158599601163, Val Loss: 0.010872883523504', 'Epoch: 50, Train Loss: 0.005748666662950, Val Loss: 0.008359062510232', 'Epoch: 51, Train Loss: 0.004713665605132, Val Loss: 0.012470698828499', 'Epoch: 52, Train Loss: 0.005310136839065, Val Loss: 0.013598397746682', 'Epoch: 53, Train Loss: 0.005451925660533, Val Loss: 0.010174009253581', 'Epoch: 54, Train Loss: 0.004830155951746, Val Loss: 0.012040973082185', 'Epoch: 55, Train Loss: 0.005650915255244, Val Loss: 0.007602061579625', 'Epoch: 56, Train Loss: 0.004688557695939, Val Loss: 0.009431216120720', 'Epoch: 57, Train Loss: 0.005259214573405, Val Loss: 0.009733531065285', 'Epoch: 58, Train Loss: 0.005686353465528, Val Loss: 0.008040174742540', 'Epoch: 59, Train Loss: 0.006086441873082, Val Loss: 0.020323131283124', 'Epoch: 60, Train Loss: 0.005752741913702, Val Loss: 0.009631291665137', 'Epoch: 61, Train Loss: 0.005853970869238, Val Loss: 0.013242558240891', 'Epoch: 62, Train Loss: 0.004824194609266, Val Loss: 0.011268510172764', 'Epoch: 63, Train Loss: 0.006361525221408, Val Loss: 0.012974989786744', 'Epoch: 64, Train Loss: 0.006415149026358, Val Loss: 0.007672373993943', 'Epoch: 65, Train Loss: 0.005548121297433, Val Loss: 0.010938138986627', 'Epoch: 66, Train Loss: 0.005529335646655, Val Loss: 0.006737646802018', 'Epoch: 67, Train Loss: 0.005105025646853, Val Loss: 0.011303573722641', 'Epoch: 68, Train Loss: 0.005328197153072, Val Loss: 0.009557791811725', 'Epoch: 69, Train Loss: 0.005520659598401, Val Loss: 0.010394624074300', 'Epoch: 70, Train Loss: 0.004903765988913, Val Loss: 0.009683219368259', 'Epoch: 71, Train Loss: 0.004831978709984, Val Loss: 0.012955221384764', 'Epoch: 72, Train Loss: 0.005122228657102, Val Loss: 0.009441852159798', 'Epoch: 73, Train Loss: 0.005091857972007, Val Loss: 0.007996526757876', 'Epoch: 74, Train Loss: 0.004799343190575, Val Loss: 0.010304552664359', 'Epoch: 75, Train Loss: 0.004949454047525, Val Loss: 0.009688402041793', 'Epoch: 76, Train Loss: 0.004598717404288, Val Loss: 0.007479728100200', 'Epoch: 77, Train Loss: 0.004807412674124, Val Loss: 0.009287094535927', 'Epoch: 78, Train Loss: 0.004691923804979, Val Loss: 0.007145157828927', 'Epoch: 79, Train Loss: 0.005088576709297, Val Loss: 0.010144895662864', 'Epoch: 80, Train Loss: 0.005270090601087, Val Loss: 0.012532778754830', 'Epoch: 81, Train Loss: 0.005227748677845, Val Loss: 0.007518571068843', 'Epoch: 82, Train Loss: 0.004296599738015, Val Loss: 0.009400333315134', 'Epoch: 83, Train Loss: 0.004538679847366, Val Loss: 0.007556761826078', 'Epoch: 84, Train Loss: 0.005025307320855, Val Loss: 0.011174473886689', 'Epoch: 85, Train Loss: 0.004469732505106, Val Loss: 0.007252929154783', 'Epoch: 86, Train Loss: 0.004545873674415, Val Loss: 0.008774526572476', 'Epoch: 87, Train Loss: 0.004629060757553, Val Loss: 0.008095504442851', 'Epoch: 88, Train Loss: 0.004366506115029, Val Loss: 0.007517148753007', 'Epoch: 89, Train Loss: 0.004769645745063, Val Loss: 0.007323482769231', 'Epoch: 90, Train Loss: 0.004036079359930, Val Loss: 0.007200144343078', 'Epoch: 91, Train Loss: 0.004508961599946, Val Loss: 0.009432310039798', 'Epoch: 92, Train Loss: 0.004792963876211, Val Loss: 0.007124319871267', 'Epoch: 93, Train Loss: 0.004203034774578, Val Loss: 0.008458545828859', 'Epoch: 94, Train Loss: 0.004559415001564, Val Loss: 0.007962301087876', 'Epoch: 95, Train Loss: 0.004915103636227, Val Loss: 0.006666091767450', 'Epoch: 96, Train Loss: 0.004725710449755, Val Loss: 0.008580653816462', 'Epoch: 97, Train Loss: 0.004687109315156, Val Loss: 0.007854604745905', 'Epoch: 98, Train Loss: 0.004901800820078, Val Loss: 0.007571730427444', 'Epoch: 99, Train Loss: 0.004046504275575, Val Loss: 0.007158726987739', 'Epoch: 100, Train Loss: 0.004405692505885, Val Loss: 0.007232360678415', 'Epoch: 101, Train Loss: 0.004015504318567, Val Loss: 0.007197939210261', 'Epoch: 102, Train Loss: 0.004432297713401, Val Loss: 0.005986795822779', 'Epoch: 103, Train Loss: 0.004412374565847, Val Loss: 0.009198329169303', 'Epoch: 104, Train Loss: 0.004221071858841, Val Loss: 0.008560192820927', 'Epoch: 105, Train Loss: 0.004030373793465, Val Loss: 0.007320469729602', 'Epoch: 106, Train Loss: 0.003990709810084, Val Loss: 0.008100904462238', 'Epoch: 107, Train Loss: 0.004394958172534, Val Loss: 0.008272305342058', 'Epoch: 108, Train Loss: 0.004943907680345, Val Loss: 0.008105595372617', 'Epoch: 109, Train Loss: 0.003849813700405, Val Loss: 0.006727689324568', 'Epoch: 110, Train Loss: 0.005012578220739, Val Loss: 0.008497664282719', 'Epoch: 111, Train Loss: 0.004472189707298, Val Loss: 0.006756634277602', 'Epoch: 112, Train Loss: 0.004119698605180, Val Loss: 0.007899315742155', 'Epoch: 113, Train Loss: 0.004739515294982, Val Loss: 0.007777504461507', 'Epoch: 114, Train Loss: 0.004046781493337, Val Loss: 0.009842263944447', 'Epoch: 115, Train Loss: 0.004385175499781, Val Loss: 0.006668432410806', 'Epoch: 116, Train Loss: 0.004188115513023, Val Loss: 0.007894352612396', 'Epoch: 117, Train Loss: 0.003859960481183, Val Loss: 0.007964613772929', 'Epoch: 118, Train Loss: 0.004509237502481, Val Loss: 0.006498733392606', 'Epoch: 119, Train Loss: 0.004227626244075, Val Loss: 0.006325352794180', 'Epoch: 120, Train Loss: 0.004079374701552, Val Loss: 0.005697988135119', 'Epoch: 121, Train Loss: 0.004578300492255, Val Loss: 0.006239387032886', 'Epoch: 122, Train Loss: 0.004075546809366, Val Loss: 0.005294420408706', 'Epoch: 123, Train Loss: 0.004263938369073, Val Loss: 0.006659957195322', 'Epoch: 124, Train Loss: 0.004320683348782, Val Loss: 0.008212975896895', 'Epoch: 125, Train Loss: 0.004364312299392, Val Loss: 0.008056648584704', 'Epoch: 126, Train Loss: 0.004185940373604, Val Loss: 0.006509488094598', 'Epoch: 127, Train Loss: 0.004428758566758, Val Loss: 0.009612361639738', 'Epoch: 128, Train Loss: 0.003766188525972, Val Loss: 0.008992470055819', 'Epoch: 129, Train Loss: 0.003726980169055, Val Loss: 0.006775326977173', 'Epoch: 130, Train Loss: 0.004274254266656, Val Loss: 0.005724704228342', 'Epoch: 131, Train Loss: 0.004365364437965, Val Loss: 0.005538123665998', 'Epoch: 132, Train Loss: 0.003922789414477, Val Loss: 0.006005949123452', 'Epoch: 133, Train Loss: 0.003624417509827, Val Loss: 0.006669548933084', 'Epoch: 134, Train Loss: 0.003701278395979, Val Loss: 0.007064228281379', 'Epoch: 135, Train Loss: 0.004096536897123, Val Loss: 0.005487872678787', 'Epoch: 136, Train Loss: 0.004074430025631, Val Loss: 0.005724167606483', 'Epoch: 137, Train Loss: 0.003821605958670, Val Loss: 0.005501912720501', 'Epoch: 138, Train Loss: 0.003820897698516, Val Loss: 0.007006392395124', 'Epoch: 139, Train Loss: 0.004118874185640, Val Loss: 0.006467270838718', 'Epoch: 140, Train Loss: 0.003736146636848, Val Loss: 0.006536848222216', 'Epoch: 141, Train Loss: 0.003761080879263, Val Loss: 0.006902349510541', 'Epoch: 142, Train Loss: 0.004014020725260, Val Loss: 0.005739506067087', 'Epoch: 143, Train Loss: 0.004152320357367, Val Loss: 0.007544068271915', 'Epoch: 144, Train Loss: 0.003980799675884, Val Loss: 0.007165116903683', 'Epoch: 145, Train Loss: 0.004133314907352, Val Loss: 0.006495761579523', 'Epoch: 146, Train Loss: 0.003571499750473, Val Loss: 0.005435810051858', 'Epoch: 147, Train Loss: 0.004063586178342, Val Loss: 0.004865319952369', 'Epoch: 148, Train Loss: 0.004509377780278, Val Loss: 0.005849991999567', 'Epoch: 149, Train Loss: 0.003653370977898, Val Loss: 0.006147104874253', 'Epoch: 150, Train Loss: 0.004192639707467, Val Loss: 0.005391557210435', 'Epoch: 151, Train Loss: 0.003998265978489, Val Loss: 0.006071166259547', 'Epoch: 152, Train Loss: 0.003936053228828, Val Loss: 0.007019289291153', 'Epoch: 153, Train Loss: 0.004227049072906, Val Loss: 0.005150464953234', 'Epoch: 154, Train Loss: 0.003326290056024, Val Loss: 0.005619565465798', 'Epoch: 155, Train Loss: 0.003797675276758, Val Loss: 0.005423171805839', 'Epoch: 156, Train Loss: 0.003580429507704, Val Loss: 0.008042421390613', 'Epoch: 157, Train Loss: 0.003931776528026, Val Loss: 0.005993422785153', 'Epoch: 158, Train Loss: 0.003655312625506, Val Loss: 0.006290966731807', 'Epoch: 159, Train Loss: 0.003880297949978, Val Loss: 0.005755813904107', 'Epoch: 160, Train Loss: 0.003783750077638, Val Loss: 0.005414912452300', 'Epoch: 161, Train Loss: 0.003672249956440, Val Loss: 0.005352832830201', 'Epoch: 162, Train Loss: 0.003688017002357, Val Loss: 0.005692477890601', 'Epoch: 163, Train Loss: 0.003752778805010, Val Loss: 0.005058535135662', 'Epoch: 164, Train Loss: 0.004094512187627, Val Loss: 0.006287751483421', 'Epoch: 165, Train Loss: 0.003902179341877, Val Loss: 0.005630781613290', 'Epoch: 166, Train Loss: 0.003339378664426, Val Loss: 0.005351171338310', 'Epoch: 167, Train Loss: 0.003345210510413, Val Loss: 0.005403153921167', 'Epoch: 168, Train Loss: 0.003464418662470, Val Loss: 0.005829221482078', 'Epoch: 169, Train Loss: 0.003419978860481, Val Loss: 0.005311551562821', 'Epoch: 170, Train Loss: 0.003841575814539, Val Loss: 0.005954347103834', 'Epoch: 171, Train Loss: 0.003849271565804, Val Loss: 0.005700476287554', 'Epoch: 172, Train Loss: 0.003751295714689, Val Loss: 0.005824264138937', 'Epoch: 173, Train Loss: 0.004070797828488, Val Loss: 0.006587356030941', 'Epoch: 174, Train Loss: 0.003701559321258, Val Loss: 0.005198371298611', 'Epoch: 175, Train Loss: 0.003831036822543, Val Loss: 0.005789648412416', 'Epoch: 176, Train Loss: 0.003709568105325, Val Loss: 0.005153172708427', 'Epoch: 177, Train Loss: 0.003525851888028, Val Loss: 0.006083811298013', 'Epoch: 178, Train Loss: 0.003522713977900, Val Loss: 0.005734860207886', 'Epoch: 179, Train Loss: 0.003732450299306, Val Loss: 0.006565052121878', 'Epoch: 180, Train Loss: 0.003474049963313, Val Loss: 0.007567859515548', 'Epoch: 181, Train Loss: 0.004031126273668, Val Loss: 0.005593872573227', 'Epoch: 182, Train Loss: 0.003475763362242, Val Loss: 0.004911152639737', 'Epoch: 183, Train Loss: 0.003892689925540, Val Loss: 0.005732594293853', 'Epoch: 184, Train Loss: 0.003857373544335, Val Loss: 0.005631698767344', 'Epoch: 185, Train Loss: 0.003592394242589, Val Loss: 0.004869500757195', 'Epoch: 186, Train Loss: 0.003404518009967, Val Loss: 0.004818826750852', 'Epoch: 187, Train Loss: 0.003626387146877, Val Loss: 0.005096094043305', 'Epoch: 188, Train Loss: 0.003798868279648, Val Loss: 0.005426877842595', 'Epoch: 189, Train Loss: 0.003473376204750, Val Loss: 0.005685137131562', 'Epoch: 190, Train Loss: 0.003417929897497, Val Loss: 0.005078758122399', 'Epoch: 191, Train Loss: 0.003226331044131, Val Loss: 0.005425308705308', 'Epoch: 192, Train Loss: 0.003711797183252, Val Loss: 0.005007890233149', 'Epoch: 193, Train Loss: 0.003443454619753, Val Loss: 0.005299620271350', 'Epoch: 194, Train Loss: 0.003507468006965, Val Loss: 0.005259377003337', 'Epoch: 195, Train Loss: 0.003510545679716, Val Loss: 0.004955625957809', 'Epoch: 196, Train Loss: 0.003122637108793, Val Loss: 0.005161359772707', 'Epoch: 197, Train Loss: 0.003141813175682, Val Loss: 0.004962977936181', 'Epoch: 198, Train Loss: 0.003100882188367, Val Loss: 0.004929520486233', 'Epoch: 199, Train Loss: 0.003443259136211, Val Loss: 0.004974301395317']",[129.56122 208.99292 556.1773  ... 199.79778  95.75073  86.38275],[115.576935 200.30571  561.09326  ... 197.61781  118.49194  106.319824],25.34047,1595.7272,39.946553954647484
trial_1,cartesian_knn_minmax,"['Epoch: 0, Train Loss: 0.329502723257960, Val Loss: 0.240339363416036', 'Epoch: 1, Train Loss: 0.125903749028007, Val Loss: 0.058719635407130', 'Epoch: 2, Train Loss: 0.059397398487075, Val Loss: 0.050849376519521', 'Epoch: 3, Train Loss: 0.049377407466296, Val Loss: 0.038408088584741', 'Epoch: 4, Train Loss: 0.036138337311683, Val Loss: 0.022152522380153', 'Epoch: 5, Train Loss: 0.026490522943124, Val Loss: 0.013216793611646', 'Epoch: 6, Train Loss: 0.021466657714847, Val Loss: 0.010781353476147', 'Epoch: 7, Train Loss: 0.017336689458293, Val Loss: 0.008223396986723', 'Epoch: 8, Train Loss: 0.018273805858183, Val Loss: 0.012927319829663', 'Epoch: 9, Train Loss: 0.018992421711361, Val Loss: 0.009615508845697', 'Epoch: 10, Train Loss: 0.018066391540791, Val Loss: 0.017385645061731', 'Epoch: 11, Train Loss: 0.019044701141511, Val Loss: 0.006995554454625', 'Epoch: 12, Train Loss: 0.016897574052897, Val Loss: 0.007922053349515', 'Epoch: 13, Train Loss: 0.017522277026117, Val Loss: 0.005894809265931', 'Epoch: 14, Train Loss: 0.018499595752939, Val Loss: 0.010548003253837', 'Epoch: 15, Train Loss: 0.018782950642711, Val Loss: 0.008432941809297', 'Epoch: 16, Train Loss: 0.017660430205972, Val Loss: 0.006010695844889', 'Epoch: 17, Train Loss: 0.017287797184362, Val Loss: 0.009763110789160', 'Epoch: 18, Train Loss: 0.016413299928469, Val Loss: 0.006371444327136', 'Epoch: 19, Train Loss: 0.015410171309841, Val Loss: 0.008880595055719', 'Epoch: 20, Train Loss: 0.015791303698571, Val Loss: 0.006535169295967', 'Epoch: 21, Train Loss: 0.016194091832535, Val Loss: 0.006658060538272', 'Epoch: 22, Train Loss: 0.015483899255290, Val Loss: 0.005382189415395', 'Epoch: 23, Train Loss: 0.016356004579775, Val Loss: 0.011271055601537', 'Epoch: 24, Train Loss: 0.016393537288318, Val Loss: 0.006383457494279', 'Epoch: 25, Train Loss: 0.016357196111033, Val Loss: 0.008877018572142', 'Epoch: 26, Train Loss: 0.017404109861645, Val Loss: 0.008507763619224', 'Epoch: 27, Train Loss: 0.017714473392231, Val Loss: 0.006588307476292', 'Epoch: 28, Train Loss: 0.015783301703916, Val Loss: 0.007208192876230', 'Epoch: 29, Train Loss: 0.015312559390796, Val Loss: 0.006776638943702', 'Epoch: 30, Train Loss: 0.016246838552010, Val Loss: 0.006517362408340', 'Epoch: 31, Train Loss: 0.015714353042875, Val Loss: 0.006379519446443', 'Epoch: 32, Train Loss: 0.017586793448378, Val Loss: 0.007880653490623', 'Epoch: 33, Train Loss: 0.014810857206640, Val Loss: 0.006271382626146', 'Epoch: 34, Train Loss: 0.015028179534320, Val Loss: 0.011114026022454', 'Epoch: 35, Train Loss: 0.015517665855302, Val Loss: 0.007487673026820', 'Epoch: 36, Train Loss: 0.015872764234069, Val Loss: 0.006534435333063', 'Epoch: 37, Train Loss: 0.016038351301246, Val Loss: 0.007572936142484', 'Epoch: 38, Train Loss: 0.014861460817793, Val Loss: 0.006912622476617', 'Epoch: 39, Train Loss: 0.016199399823792, Val Loss: 0.007612909525633', 'Epoch: 40, Train Loss: 0.015924367040595, Val Loss: 0.006737272478640', 'Epoch: 41, Train Loss: 0.015157192316304, Val Loss: 0.007358513108144', 'Epoch: 42, Train Loss: 0.015758438824982, Val Loss: 0.006935195662081', 'Epoch: 43, Train Loss: 0.014049844183596, Val Loss: 0.006188072518756', 'Epoch: 44, Train Loss: 0.015314642187094, Val Loss: 0.007021305561066', 'Epoch: 45, Train Loss: 0.014234722762561, Val Loss: 0.007364938631654', 'Epoch: 46, Train Loss: 0.014295264762179, Val Loss: 0.007193442011873', 'Epoch: 47, Train Loss: 0.013809743369325, Val Loss: 0.006821827162057', 'Epoch: 48, Train Loss: 0.013554202904569, Val Loss: 0.006698748357594', 'Epoch: 49, Train Loss: 0.014138653789085, Val Loss: 0.005909190538029', 'Epoch: 50, Train Loss: 0.014484072153862, Val Loss: 0.007134354126950', 'Epoch: 51, Train Loss: 0.014258479514650, Val Loss: 0.005526780734460', 'Epoch: 52, Train Loss: 0.014107135554619, Val Loss: 0.004880078025162', 'Epoch: 53, Train Loss: 0.013533251975016, Val Loss: 0.006528480934600', 'Epoch: 54, Train Loss: 0.013364446640925, Val Loss: 0.006066681568821', 'Epoch: 55, Train Loss: 0.013554707905349, Val Loss: 0.007869831286371', 'Epoch: 56, Train Loss: 0.012973870723046, Val Loss: 0.005494608605901', 'Epoch: 57, Train Loss: 0.013708405186003, Val Loss: 0.008120195927719', 'Epoch: 58, Train Loss: 0.013970390328327, Val Loss: 0.007315772430350', 'Epoch: 59, Train Loss: 0.012934896192080, Val Loss: 0.006114103371898', 'Epoch: 60, Train Loss: 0.013257840282163, Val Loss: 0.005190302034219', 'Epoch: 61, Train Loss: 0.012543057910885, Val Loss: 0.007025653986881', 'Epoch: 62, Train Loss: 0.013550535697518, Val Loss: 0.006192612908781', 'Epoch: 63, Train Loss: 0.013077525576605, Val Loss: 0.007170901161929', 'Epoch: 64, Train Loss: 0.012964912608465, Val Loss: 0.006326051528255', 'Epoch: 65, Train Loss: 0.012924517968755, Val Loss: 0.006435857142011', 'Epoch: 66, Train Loss: 0.012882376590900, Val Loss: 0.007211284774045', 'Epoch: 67, Train Loss: 0.012806491208270, Val Loss: 0.005148337880770', 'Epoch: 68, Train Loss: 0.012372728671793, Val Loss: 0.005933710535367', 'Epoch: 69, Train Loss: 0.012412559927107, Val Loss: 0.005424082782120', 'Epoch: 70, Train Loss: 0.012543205473970, Val Loss: 0.006391459082564', 'Epoch: 71, Train Loss: 0.012205725837897, Val Loss: 0.005454763649032', 'Epoch: 72, Train Loss: 0.013399087902130, Val Loss: 0.005529594607651', 'Epoch: 73, Train Loss: 0.012727542304014, Val Loss: 0.005160007843127', 'Epoch: 74, Train Loss: 0.012750120968593, Val Loss: 0.005697914436460', 'Epoch: 75, Train Loss: 0.012912061946993, Val Loss: 0.004846894815564', 'Epoch: 76, Train Loss: 0.011749492300575, Val Loss: 0.004885678067803', 'Epoch: 77, Train Loss: 0.012073683029908, Val Loss: 0.004665927961469', 'Epoch: 78, Train Loss: 0.012349910728406, Val Loss: 0.005081053220977', 'Epoch: 79, Train Loss: 0.011902558180070, Val Loss: 0.005550472090642', 'Epoch: 80, Train Loss: 0.012969976817151, Val Loss: 0.005181843085835', 'Epoch: 81, Train Loss: 0.011517414787628, Val Loss: 0.006336898387720', 'Epoch: 82, Train Loss: 0.011863187854783, Val Loss: 0.006001738402992', 'Epoch: 83, Train Loss: 0.012095044199946, Val Loss: 0.004884733191381', 'Epoch: 84, Train Loss: 0.012205733745252, Val Loss: 0.005185116287321', 'Epoch: 85, Train Loss: 0.012174459888763, Val Loss: 0.005428780385604', 'Epoch: 86, Train Loss: 0.011933514204957, Val Loss: 0.007365441831450', 'Epoch: 87, Train Loss: 0.012420710816069, Val Loss: 0.004543509744108', 'Epoch: 88, Train Loss: 0.012265659104464, Val Loss: 0.004758900838594', 'Epoch: 89, Train Loss: 0.012220046120404, Val Loss: 0.006256804130971', 'Epoch: 90, Train Loss: 0.012166113864616, Val Loss: 0.005202349722385', 'Epoch: 91, Train Loss: 0.012191986224351, Val Loss: 0.005021694892397', 'Epoch: 92, Train Loss: 0.011479334335220, Val Loss: 0.005715615960459', 'Epoch: 93, Train Loss: 0.012023279702874, Val Loss: 0.005389601029456', 'Epoch: 94, Train Loss: 0.011753735630169, Val Loss: 0.005659004760285', 'Epoch: 95, Train Loss: 0.011576319196908, Val Loss: 0.005453296179573', 'Epoch: 96, Train Loss: 0.011542509242409, Val Loss: 0.004594541747744', 'Epoch: 97, Train Loss: 0.012058038680409, Val Loss: 0.004531908438851', 'Epoch: 98, Train Loss: 0.012226900910489, Val Loss: 0.004638287977626', 'Epoch: 99, Train Loss: 0.011170805243505, Val Loss: 0.005074682198465', 'Epoch: 100, Train Loss: 0.011274645945683, Val Loss: 0.005249045851330', 'Epoch: 101, Train Loss: 0.012419400491418, Val Loss: 0.006758569243054', 'Epoch: 102, Train Loss: 0.011659063644110, Val Loss: 0.004266892342518', 'Epoch: 103, Train Loss: 0.011581237113302, Val Loss: 0.005261769834906', 'Epoch: 104, Train Loss: 0.012079007422395, Val Loss: 0.005793884545565', 'Epoch: 105, Train Loss: 0.011452755597527, Val Loss: 0.004634265409162', 'Epoch: 106, Train Loss: 0.011212239838170, Val Loss: 0.004816023670137', 'Epoch: 107, Train Loss: 0.011581208245857, Val Loss: 0.005362569118539', 'Epoch: 108, Train Loss: 0.011593376933277, Val Loss: 0.004985821992159', 'Epoch: 109, Train Loss: 0.011793369894762, Val Loss: 0.004160220182190', 'Epoch: 110, Train Loss: 0.010803039288788, Val Loss: 0.004539152830839', 'Epoch: 111, Train Loss: 0.011318107459069, Val Loss: 0.007500535336634', 'Epoch: 112, Train Loss: 0.010502964521239, Val Loss: 0.004099788367748', 'Epoch: 113, Train Loss: 0.010774626616986, Val Loss: 0.004596274296443', 'Epoch: 114, Train Loss: 0.010920273369349, Val Loss: 0.005398303779463', 'Epoch: 115, Train Loss: 0.011401812016310, Val Loss: 0.004511369131505', 'Epoch: 116, Train Loss: 0.011062957657473, Val Loss: 0.004963520610084', 'Epoch: 117, Train Loss: 0.011041512837250, Val Loss: 0.004797551073134', 'Epoch: 118, Train Loss: 0.011672885580173, Val Loss: 0.004616153625151', 'Epoch: 119, Train Loss: 0.011285790786119, Val Loss: 0.004518768123041', 'Epoch: 120, Train Loss: 0.011636257875455, Val Loss: 0.004018182614818', 'Epoch: 121, Train Loss: 0.010817619303654, Val Loss: 0.005310490361104', 'Epoch: 122, Train Loss: 0.011215653010992, Val Loss: 0.004634151011705', 'Epoch: 123, Train Loss: 0.010671923612422, Val Loss: 0.004767392364641', 'Epoch: 124, Train Loss: 0.011239262111130, Val Loss: 0.004228809755296', 'Epoch: 125, Train Loss: 0.011280220503144, Val Loss: 0.004651472028345', 'Epoch: 126, Train Loss: 0.010916461485602, Val Loss: 0.004675941498329', 'Epoch: 127, Train Loss: 0.011038755726083, Val Loss: 0.004763646709422', 'Epoch: 128, Train Loss: 0.010985809346334, Val Loss: 0.004159945013622', 'Epoch: 129, Train Loss: 0.010788617721396, Val Loss: 0.003584238290787', 'Epoch: 130, Train Loss: 0.011067930306841, Val Loss: 0.004548214493940', 'Epoch: 131, Train Loss: 0.010686891157009, Val Loss: 0.004314708268891', 'Epoch: 132, Train Loss: 0.010890977485603, Val Loss: 0.004143409493069', 'Epoch: 133, Train Loss: 0.011070167699132, Val Loss: 0.004499671018372', 'Epoch: 134, Train Loss: 0.011247113395042, Val Loss: 0.006996033849816', 'Epoch: 135, Train Loss: 0.010640721354022, Val Loss: 0.004672988181313', 'Epoch: 136, Train Loss: 0.010617856572574, Val Loss: 0.004596935144315', 'Epoch: 137, Train Loss: 0.010241561272459, Val Loss: 0.003972129502023', 'Epoch: 138, Train Loss: 0.010571763306885, Val Loss: 0.004427530582373', 'Epoch: 139, Train Loss: 0.010375121569275, Val Loss: 0.005028302582602', 'Epoch: 140, Train Loss: 0.010550109993041, Val Loss: 0.004965018158158', 'Epoch: 141, Train Loss: 0.010563662023291, Val Loss: 0.004185043691347', 'Epoch: 142, Train Loss: 0.010652045975262, Val Loss: 0.004484582189471', 'Epoch: 143, Train Loss: 0.010027796877832, Val Loss: 0.004321415697535', 'Epoch: 144, Train Loss: 0.010375292182594, Val Loss: 0.004467013068497', 'Epoch: 145, Train Loss: 0.010280363693592, Val Loss: 0.005262558677544', 'Epoch: 146, Train Loss: 0.010273713245277, Val Loss: 0.004140626875063', 'Epoch: 147, Train Loss: 0.010390277932405, Val Loss: 0.004083694334452', 'Epoch: 148, Train Loss: 0.010641581110500, Val Loss: 0.003916343885163', 'Epoch: 149, Train Loss: 0.010060734012456, Val Loss: 0.004710749375323', 'Epoch: 150, Train Loss: 0.010184967348295, Val Loss: 0.004252081351976', 'Epoch: 151, Train Loss: 0.010749275334009, Val Loss: 0.004333755498131', 'Epoch: 152, Train Loss: 0.010216909812635, Val Loss: 0.004151028540606', 'Epoch: 153, Train Loss: 0.010400073428617, Val Loss: 0.004019213967646', 'Epoch: 154, Train Loss: 0.010486595481919, Val Loss: 0.004564489827802', 'Epoch: 155, Train Loss: 0.010060766176854, Val Loss: 0.004438293110579', 'Epoch: 156, Train Loss: 0.009957152600080, Val Loss: 0.005756204860906', 'Epoch: 157, Train Loss: 0.010041391269041, Val Loss: 0.004388559615860', 'Epoch: 158, Train Loss: 0.010387051822120, Val Loss: 0.004153658502425', 'Epoch: 159, Train Loss: 0.010105443154177, Val Loss: 0.004494602493942', 'Epoch: 160, Train Loss: 0.010374885399023, Val Loss: 0.003912600887318', 'Epoch: 161, Train Loss: 0.009914935433185, Val Loss: 0.004329886722068', 'Epoch: 162, Train Loss: 0.010062127802450, Val Loss: 0.004163076567153', 'Epoch: 163, Train Loss: 0.010183133287995, Val Loss: 0.004089190779875', 'Epoch: 164, Train Loss: 0.010416073904138, Val Loss: 0.004144028710822', 'Epoch: 165, Train Loss: 0.010302748840359, Val Loss: 0.004147112928331', 'Epoch: 166, Train Loss: 0.009745119294180, Val Loss: 0.004240607460961', 'Epoch: 167, Train Loss: 0.010069544563951, Val Loss: 0.004178956154113', 'Epoch: 168, Train Loss: 0.009618458554916, Val Loss: 0.004266779143363', 'Epoch: 169, Train Loss: 0.009604820450199, Val Loss: 0.004299183115363', 'Epoch: 170, Train Loss: 0.009933819448689, Val Loss: 0.004314106926322', 'Epoch: 171, Train Loss: 0.009419945543205, Val Loss: 0.004000470116735', 'Epoch: 172, Train Loss: 0.010387169367826, Val Loss: 0.004073355983322', 'Epoch: 173, Train Loss: 0.009675304144123, Val Loss: 0.004059637983640', 'Epoch: 174, Train Loss: 0.009630879461907, Val Loss: 0.003938334826380', 'Epoch: 175, Train Loss: 0.009941048568243, Val Loss: 0.004261376522481', 'Epoch: 176, Train Loss: 0.009603393982157, Val Loss: 0.004405960074315', 'Epoch: 177, Train Loss: 0.009540663913020, Val Loss: 0.003988455127304', 'Epoch: 178, Train Loss: 0.009611745725763, Val Loss: 0.004160465747118', 'Epoch: 179, Train Loss: 0.010272473471865, Val Loss: 0.004146200185642', 'Epoch: 180, Train Loss: 0.009782430132894, Val Loss: 0.003815630053480', 'Epoch: 181, Train Loss: 0.009211754959560, Val Loss: 0.003937127493943', 'Epoch: 182, Train Loss: 0.009674472096269, Val Loss: 0.004099737827977', 'Epoch: 183, Train Loss: 0.010086960292542, Val Loss: 0.003908396971722', 'Epoch: 184, Train Loss: 0.009638086850008, Val Loss: 0.004280955269933', 'Epoch: 185, Train Loss: 0.009589024282679, Val Loss: 0.003964655337234', 'Epoch: 186, Train Loss: 0.009349393301096, Val Loss: 0.003786184415221', 'Epoch: 187, Train Loss: 0.009675033642903, Val Loss: 0.003844407567134', 'Epoch: 188, Train Loss: 0.009158206318029, Val Loss: 0.003866266608238', 'Epoch: 189, Train Loss: 0.009316245968390, Val Loss: 0.004036936480552', 'Epoch: 190, Train Loss: 0.009542339548952, Val Loss: 0.003671340594689', 'Epoch: 191, Train Loss: 0.009634929193710, Val Loss: 0.004065217059106', 'Epoch: 192, Train Loss: 0.009016212230577, Val Loss: 0.003857184747855', 'Epoch: 193, Train Loss: 0.009014782995227, Val Loss: 0.003919401032229', 'Epoch: 194, Train Loss: 0.009222951349767, Val Loss: 0.003869154832015', 'Epoch: 195, Train Loss: 0.009420845677138, Val Loss: 0.003772158306092', 'Epoch: 196, Train Loss: 0.009012383060487, Val Loss: 0.003777078861992', 'Epoch: 197, Train Loss: 0.009297693667237, Val Loss: 0.003756517739967', 'Epoch: 198, Train Loss: 0.008756242937743, Val Loss: 0.003816517433152', 'Epoch: 199, Train Loss: 0.009384748223771, Val Loss: 0.003785986937582']","[1194.5619    505.84637  1329.3651   ...  648.2666     31.544159
  590.078   ]",[1194.2837   514.5317  1270.1194  ...  653.16895   84.71045  551.1926 ],23.236366,1513.9513,38.909527033174186
